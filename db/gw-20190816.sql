-- --------------------------------------------------------
-- Host:                         127.0.0.1
-- Server version:               5.5.60 - MySQL Community Server (GPL)
-- Server OS:                    Win64
-- HeidiSQL version:             7.0.0.4053
-- Date/time:                    2019-08-16 16:28:09
-- --------------------------------------------------------

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET NAMES utf8 */;
/*!40014 SET FOREIGN_KEY_CHECKS=0 */;

-- Dumping database structure for cyberconnector
DROP DATABASE IF EXISTS `cyberconnector`;
CREATE DATABASE IF NOT EXISTS `cyberconnector` /*!40100 DEFAULT CHARACTER SET latin1 */;
USE `cyberconnector`;


-- Dumping structure for table cyberconnector.abstract_model
DROP TABLE IF EXISTS `abstract_model`;
CREATE TABLE IF NOT EXISTS `abstract_model` (
  `id` int(10) NOT NULL AUTO_INCREMENT,
  `identifier` varchar(50) NOT NULL,
  `name` varchar(50) NOT NULL,
  `namespace` varchar(150) NOT NULL,
  `process_connection` text NOT NULL,
  `param_connection` text,
  `keywords` tinytext,
  `description` tinytext,
  `begin_date` date DEFAULT '2013-09-11',
  `end_date` date DEFAULT '2013-09-11',
  `ecsdisciplinekeyword` varchar(50) DEFAULT 'N/A',
  `ecstopickeyword` varchar(50) DEFAULT 'N/A',
  `ecsparameterkeyword` varchar(50) DEFAULT 'N/A',
  `ecsvariablekeyword` varchar(50) DEFAULT 'N/A',
  `ecstermkeyword` varchar(50) DEFAULT 'N/A',
  `suported_format` varchar(50) DEFAULT 'image/png',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=76 DEFAULT CHARSET=latin1 COMMENT='This table stores the processing models of VDPs.';

-- Dumping data for table cyberconnector.abstract_model: ~52 rows (approximately)
DELETE FROM `abstract_model`;
/*!40000 ALTER TABLE `abstract_model` DISABLE KEYS */;
INSERT INTO `abstract_model` (`id`, `identifier`, `name`, `namespace`, `process_connection`, `param_connection`, `keywords`, `description`, `begin_date`, `end_date`, `ecsdisciplinekeyword`, `ecstopickeyword`, `ecsparameterkeyword`, `ecsvariablekeyword`, `ecstermkeyword`, `suported_format`) VALUES
	(11, 'urn:uuid:330ffdf0-07a0-1031-9281-9200c0a80164', 'near', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="near"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="buffer.20b644c0-07a0-1031-91a7-b87ec0a80164" operation="buffer.20b644c0-07a0-1031-91a7-b87ec0a80164" /%3E\n  %3Cactivitymember name="select_feature.21ffdbc0-07a0-1031-80e0-0c21c0a80164" operation="select_feature.21ffdbc0-07a0-1031-80e0-0c21c0a80164" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Csequenceactivity name="Activity_1"  memberfirst="select_feature.21ffdbc0-07a0-1031-80e0-0c21c0a80164"  memberlast="buffer.20b644c0-07a0-1031-91a7-b87ec0a80164"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_1" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>select_feature.21ffdbc0-07a0-1031-80e0-0c21c0a80164</first_process>\n                   <last_process>buffer.20b644c0-07a0-1031-91a7-b87ec0a80164</last_process>\n                   <channel>\n                                  <from>returnURL</from>\n                                  <to>sourceURL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', 'near,buffer,overlap', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(12, 'urn:uuid:cfd373c0-092a-1031-8c80-aeecc0a80164', 'DailyVCICalcWorkflow', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="DailyVCICalcWorkflow"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="tiledDailyNDVI2VCICalc.7a6afb10-092a-1031-9b82-a69fc0a80164" operation="tiledDailyNDVI2VCICalc.7a6afb10-092a-1031-9b82-a69fc0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVICalc.05beaa00-092a-1031-8a99-4ccbc0a80164" operation="tiledDailyNDVICalc.05beaa00-092a-1031-8a99-4ccbc0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVIMaxMinCalc.3984e7f0-092a-1031-acca-9bbfc0a80164" operation="tiledDailyNDVIMaxMinCalc.3984e7f0-092a-1031-acca-9bbfc0a80164" /%3E\n  %3Cactivitymember name="tiledYearsDailyNDVICalc.23e579a0-092a-1031-90f3-a55ac0a80164" operation="tiledYearsDailyNDVICalc.23e579a0-092a-1031-90f3-a55ac0a80164" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Csequenceactivity name="Activity_1"  memberfirst="tiledYearsDailyNDVICalc.23e579a0-092a-1031-90f3-a55ac0a80164"  memberlast="tiledDailyNDVIMaxMinCalc.3984e7f0-092a-1031-acca-9bbfc0a80164"  /%3E\n  %3Cparallelactivity name="Activity_2"  memberfirst="tiledDailyNDVICalc.05beaa00-092a-1031-8a99-4ccbc0a80164"  memberlast="Activity_1"  /%3E\n  %3Csequenceactivity name="Activity_3"  memberfirst="Activity_2"  memberlast="tiledDailyNDVI2VCICalc.7a6afb10-092a-1031-9b82-a69fc0a80164"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_3" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>tiledYearsDailyNDVICalc.23e579a0-092a-1031-90f3-a55ac0a80164</first_process>\n                   <last_process>tiledDailyNDVIMaxMinCalc.3984e7f0-092a-1031-acca-9bbfc0a80164</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVICalc.05beaa00-092a-1031-8a99-4ccbc0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.7a6afb10-092a-1031-9b82-a69fc0a80164</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVIMaxMinCalc.3984e7f0-092a-1031-acca-9bbfc0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.7a6afb10-092a-1031-9b82-a69fc0a80164</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>Max_Min_NDVI_URL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(14, 'urn:uuid:15cb5410-20d2-1031-a58c-03e8c0a80164', 'DailyVCICalc', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="DailyVCICalc"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="tiledDailyNDVI2VCICalc.e95d6d50-20d1-1031-8d2f-99bec0a80164" operation="tiledDailyNDVI2VCICalc.e95d6d50-20d1-1031-8d2f-99bec0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVICalc.c4583170-20d1-1031-a14d-6e4ac0a80164" operation="tiledDailyNDVICalc.c4583170-20d1-1031-a14d-6e4ac0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVIMaxMinCalc.d7842ec0-20d1-1031-88ac-d10ec0a80164" operation="tiledDailyNDVIMaxMinCalc.d7842ec0-20d1-1031-88ac-d10ec0a80164" /%3E\n  %3Cactivitymember name="tiledYearsDailyNDVICalc.cfe076b0-20d1-1031-b53b-78bec0a80164" operation="tiledYearsDailyNDVICalc.cfe076b0-20d1-1031-b53b-78bec0a80164" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Csequenceactivity name="Activity_1"  memberfirst="tiledYearsDailyNDVICalc.cfe076b0-20d1-1031-b53b-78bec0a80164"  memberlast="tiledDailyNDVIMaxMinCalc.d7842ec0-20d1-1031-88ac-d10ec0a80164"  /%3E\n  %3Cparallelactivity name="Activity_2"  memberfirst="tiledDailyNDVICalc.c4583170-20d1-1031-a14d-6e4ac0a80164"  memberlast="Activity_1"  /%3E\n  %3Csequenceactivity name="Activity_3"  memberfirst="Activity_2"  memberlast="tiledDailyNDVI2VCICalc.e95d6d50-20d1-1031-8d2f-99bec0a80164"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_3" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>tiledYearsDailyNDVICalc.cfe076b0-20d1-1031-b53b-78bec0a80164</first_process>\n                   <last_process>tiledDailyNDVIMaxMinCalc.d7842ec0-20d1-1031-88ac-d10ec0a80164</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVICalc.c4583170-20d1-1031-a14d-6e4ac0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.e95d6d50-20d1-1031-8d2f-99bec0a80164</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVIMaxMinCalc.d7842ec0-20d1-1031-88ac-d10ec0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.e95d6d50-20d1-1031-8d2f-99bec0a80164</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>Max_Min_NDVI_URL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(17, 'urn:uuid:a70ea150-24d5-1031-ab7b-9d6cc0a80164', 'NewDailyVCICalc', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="NewDailyVCICalc"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="tiledDailyNDVI2VCICalc.2986b470-24d5-1031-af9b-8193c0a80164" operation="tiledDailyNDVI2VCICalc.2986b470-24d5-1031-af9b-8193c0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVICalc.24a96f60-24d5-1031-9f9e-6b6ec0a80164" operation="tiledDailyNDVICalc.24a96f60-24d5-1031-9f9e-6b6ec0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVIMaxMinCalc.5be747e0-24d5-1031-8b1a-b505c0a80164" operation="tiledDailyNDVIMaxMinCalc.5be747e0-24d5-1031-8b1a-b505c0a80164" /%3E\n  %3Cactivitymember name="tiledYearsDailyNDVICalc.54009360-24d5-1031-947d-aed6c0a80164" operation="tiledYearsDailyNDVICalc.54009360-24d5-1031-947d-aed6c0a80164" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Csequenceactivity name="Activity_1"  memberfirst="tiledYearsDailyNDVICalc.54009360-24d5-1031-947d-aed6c0a80164"  memberlast="tiledDailyNDVIMaxMinCalc.5be747e0-24d5-1031-8b1a-b505c0a80164"  /%3E\n  %3Cparallelactivity name="Activity_2"  memberfirst="tiledDailyNDVICalc.24a96f60-24d5-1031-9f9e-6b6ec0a80164"  memberlast="Activity_1"  /%3E\n  %3Csequenceactivity name="Activity_3"  memberfirst="Activity_2"  memberlast="tiledDailyNDVI2VCICalc.2986b470-24d5-1031-af9b-8193c0a80164"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_3" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>tiledDailyNDVICalc.24a96f60-24d5-1031-9f9e-6b6ec0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.2986b470-24d5-1031-af9b-8193c0a80164</last_process>\n                   <channel>\n                                  <from>daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVIMaxMinCalc.5be747e0-24d5-1031-8b1a-b505c0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.2986b470-24d5-1031-af9b-8193c0a80164</last_process>\n                   <channel>\n                                  <from>daily_ndvi_max_min</from>\n                                  <to>Max_Min_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledYearsDailyNDVICalc.54009360-24d5-1031-947d-aed6c0a80164</first_process>\n                   <last_process>tiledDailyNDVIMaxMinCalc.5be747e0-24d5-1031-8b1a-b505c0a80164</last_process>\n                   <channel>\n                                  <from>years_daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(20, 'urn:uuid:9df48ee0-2b15-1031-b504-3dbec0a80164', 'daily_vci_complete', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="daily_vci_complete"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="tiledDailyNDVI2VCICalc.38d0d5a0-2b15-1031-b6b6-7949c0a80164" operation="tiledDailyNDVI2VCICalc.38d0d5a0-2b15-1031-b6b6-7949c0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVICalc.e8e6c400-2b14-1031-a826-2161c0a80164" operation="tiledDailyNDVICalc.e8e6c400-2b14-1031-a826-2161c0a80164" /%3E\n  %3Cactivitymember name="getb1b2Tiles.a7a01a50-2b14-1031-82c1-48efc0a80164" operation="getb1b2Tiles.a7a01a50-2b14-1031-82c1-48efc0a80164" /%3E\n  %3Cactivitymember name="getQATiles.afbf43f0-2b14-1031-a6cc-0f86c0a80164" operation="getQATiles.afbf43f0-2b14-1031-a6cc-0f86c0a80164" /%3E\n  %3Cactivitymember name="tiledDailyNDVIMaxMinCalc.1b413cf0-2b15-1031-b1b8-7ff6c0a80164" operation="tiledDailyNDVIMaxMinCalc.1b413cf0-2b15-1031-b1b8-7ff6c0a80164" /%3E\n  %3Cactivitymember name="tiledYearsDailyNDVICalc.01b5ee70-2b15-1031-bf8b-89a7c0a80164" operation="tiledYearsDailyNDVICalc.01b5ee70-2b15-1031-bf8b-89a7c0a80164" /%3E\n  %3Cactivitymember name="getb1b2TilesYears.aaa1c190-2b14-1031-b48e-aafec0a80164" operation="getb1b2TilesYears.aaa1c190-2b14-1031-b48e-aafec0a80164" /%3E\n  %3Cactivitymember name="getQATilesYears.c4fb5c90-2b14-1031-80bd-ec25c0a80164" operation="getQATilesYears.c4fb5c90-2b14-1031-80bd-ec25c0a80164" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Cparallelactivity name="Activity_1"  memberfirst="getb1b2TilesYears.aaa1c190-2b14-1031-b48e-aafec0a80164"  memberlast="getQATilesYears.c4fb5c90-2b14-1031-80bd-ec25c0a80164"  /%3E\n  %3Csequenceactivity name="Activity_2"  memberfirst="Activity_1"  memberlast="tiledYearsDailyNDVICalc.01b5ee70-2b15-1031-bf8b-89a7c0a80164"  /%3E\n  %3Cparallelactivity name="Activity_3"  memberfirst="getb1b2Tiles.a7a01a50-2b14-1031-82c1-48efc0a80164"  memberlast="getQATiles.afbf43f0-2b14-1031-a6cc-0f86c0a80164"  /%3E\n  %3Csequenceactivity name="Activity_4"  memberfirst="Activity_2"  memberlast="tiledDailyNDVIMaxMinCalc.1b413cf0-2b15-1031-b1b8-7ff6c0a80164"  /%3E\n  %3Csequenceactivity name="Activity_5"  memberfirst="Activity_3"  memberlast="tiledDailyNDVICalc.e8e6c400-2b14-1031-a826-2161c0a80164"  /%3E\n  %3Cparallelactivity name="Activity_6"  memberfirst="Activity_4"  memberlast="Activity_5"  /%3E\n  %3Csequenceactivity name="Activity_7"  memberfirst="Activity_6"  memberlast="tiledDailyNDVI2VCICalc.38d0d5a0-2b15-1031-b6b6-7949c0a80164"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_7" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>getb1b2Tiles.a7a01a50-2b14-1031-82c1-48efc0a80164</first_process>\n                   <last_process>tiledDailyNDVICalc.e8e6c400-2b14-1031-a826-2161c0a80164</last_process>\n                   <channel>\n                                  <from>b1_b2_tiles</from>\n                                  <to>MOD09GQK_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getQATiles.afbf43f0-2b14-1031-a6cc-0f86c0a80164</first_process>\n                   <last_process>tiledDailyNDVICalc.e8e6c400-2b14-1031-a826-2161c0a80164</last_process>\n                   <channel>\n                                  <from>qa_tiles</from>\n                                  <to>MOD09GST_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getb1b2TilesYears.aaa1c190-2b14-1031-b48e-aafec0a80164</first_process>\n                   <last_process>tiledYearsDailyNDVICalc.01b5ee70-2b15-1031-bf8b-89a7c0a80164</last_process>\n                   <channel>\n                                  <from>years_b1b2_tiles</from>\n                                  <to>MOD09GQK_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getQATilesYears.c4fb5c90-2b14-1031-80bd-ec25c0a80164</first_process>\n                   <last_process>tiledYearsDailyNDVICalc.01b5ee70-2b15-1031-bf8b-89a7c0a80164</last_process>\n                   <channel>\n                                  <from>years_qa_tiles</from>\n                                  <to>MOD09GST_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledYearsDailyNDVICalc.01b5ee70-2b15-1031-bf8b-89a7c0a80164</first_process>\n                   <last_process>tiledDailyNDVIMaxMinCalc.1b413cf0-2b15-1031-b1b8-7ff6c0a80164</last_process>\n                   <channel>\n                                  <from>years_daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVICalc.e8e6c400-2b14-1031-a826-2161c0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.38d0d5a0-2b15-1031-b6b6-7949c0a80164</last_process>\n                   <channel>\n                                  <from>daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVIMaxMinCalc.1b413cf0-2b15-1031-b1b8-7ff6c0a80164</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.38d0d5a0-2b15-1031-b6b6-7949c0a80164</last_process>\n                   <channel>\n                                  <from>max_min_daily_ndvi</from>\n                                  <to>Max_Min_NDVI_URL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(21, 'urn:uuid:a91c1120-2d73-1031-ad9b-b6fec0a83801', 'weeklyvci', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="weeklyvci"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="tiledWeeklyNDVI2VCICalc.7e576d90-2d73-1031-a56b-5e93c0a83801" operation="tiledWeeklyNDVI2VCICalc.7e576d90-2d73-1031-a56b-5e93c0a83801" /%3E\n  %3Cactivitymember name="tiled7DayNDVICalc.87d691d0-2d72-1031-b4f1-501cc0a83801" operation="tiled7DayNDVICalc.87d691d0-2d72-1031-b4f1-501cc0a83801" /%3E\n  %3Cactivitymember name="getb1b2TilesWeekly.597d07b0-2d72-1031-9c44-f797c0a83801" operation="getb1b2TilesWeekly.597d07b0-2d72-1031-9c44-f797c0a83801" /%3E\n  %3Cactivitymember name="getQATilesWeekly.5e88d6d0-2d72-1031-989a-cd1bc0a83801" operation="getQATilesWeekly.5e88d6d0-2d72-1031-989a-cd1bc0a83801" /%3E\n  %3Cactivitymember name="tiledWeeklyNDVIMaxMinCalc.9569e950-2d72-1031-86e8-d821c0a83801" operation="tiledWeeklyNDVIMaxMinCalc.9569e950-2d72-1031-86e8-d821c0a83801" /%3E\n  %3Cactivitymember name="tiledYears7DaysNDVICalc.829a15c0-2d72-1031-aabc-3000c0a83801" operation="tiledYears7DaysNDVICalc.829a15c0-2d72-1031-aabc-3000c0a83801" /%3E\n  %3Cactivitymember name="getb1b2TilesYearsWeekly.620e05f0-2d72-1031-a15b-bda5c0a83801" operation="getb1b2TilesYearsWeekly.620e05f0-2d72-1031-a15b-bda5c0a83801" /%3E\n  %3Cactivitymember name="getQATilesYearsWeekly.6787b210-2d72-1031-873a-7003c0a83801" operation="getQATilesYearsWeekly.6787b210-2d72-1031-873a-7003c0a83801" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Cparallelactivity name="Activity_1"  memberfirst="getb1b2TilesYearsWeekly.620e05f0-2d72-1031-a15b-bda5c0a83801"  memberlast="getQATilesYearsWeekly.6787b210-2d72-1031-873a-7003c0a83801"  /%3E\n  %3Csequenceactivity name="Activity_2"  memberfirst="Activity_1"  memberlast="tiledYears7DaysNDVICalc.829a15c0-2d72-1031-aabc-3000c0a83801"  /%3E\n  %3Cparallelactivity name="Activity_3"  memberfirst="getb1b2TilesWeekly.597d07b0-2d72-1031-9c44-f797c0a83801"  memberlast="getQATilesWeekly.5e88d6d0-2d72-1031-989a-cd1bc0a83801"  /%3E\n  %3Csequenceactivity name="Activity_4"  memberfirst="Activity_2"  memberlast="tiledWeeklyNDVIMaxMinCalc.9569e950-2d72-1031-86e8-d821c0a83801"  /%3E\n  %3Csequenceactivity name="Activity_5"  memberfirst="Activity_3"  memberlast="tiled7DayNDVICalc.87d691d0-2d72-1031-b4f1-501cc0a83801"  /%3E\n  %3Cparallelactivity name="Activity_6"  memberfirst="Activity_4"  memberlast="Activity_5"  /%3E\n  %3Csequenceactivity name="Activity_7"  memberfirst="Activity_6"  memberlast="tiledWeeklyNDVI2VCICalc.7e576d90-2d73-1031-a56b-5e93c0a83801"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_7" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>getb1b2TilesYearsWeekly.620e05f0-2d72-1031-a15b-bda5c0a83801</first_process>\n                   <last_process>tiledYears7DaysNDVICalc.829a15c0-2d72-1031-aabc-3000c0a83801</last_process>\n                   <channel>\n                                  <from>years_weekly_b1b2_tiles</from>\n                                  <to>MOD09GQK_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getQATilesYearsWeekly.6787b210-2d72-1031-873a-7003c0a83801</first_process>\n                   <last_process>tiledYears7DaysNDVICalc.829a15c0-2d72-1031-aabc-3000c0a83801</last_process>\n                   <channel>\n                                  <from>years_weekly_qa_tiles</from>\n                                  <to>MOD09GST_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getb1b2TilesWeekly.597d07b0-2d72-1031-9c44-f797c0a83801</first_process>\n                   <last_process>tiled7DayNDVICalc.87d691d0-2d72-1031-b4f1-501cc0a83801</last_process>\n                   <channel>\n                                  <from>weekly_b1b2_tiles</from>\n                                  <to>MOD09GQK_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getQATilesWeekly.5e88d6d0-2d72-1031-989a-cd1bc0a83801</first_process>\n                   <last_process>tiled7DayNDVICalc.87d691d0-2d72-1031-b4f1-501cc0a83801</last_process>\n                   <channel>\n                                  <from>weekly_qa_tiles</from>\n                                  <to>MOD09GST_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledYears7DaysNDVICalc.829a15c0-2d72-1031-aabc-3000c0a83801</first_process>\n                   <last_process>tiledWeeklyNDVIMaxMinCalc.9569e950-2d72-1031-86e8-d821c0a83801</last_process>\n                   <channel>\n                                  <from>years_weekly_daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiled7DayNDVICalc.87d691d0-2d72-1031-b4f1-501cc0a83801</first_process>\n                   <last_process>tiledWeeklyNDVI2VCICalc.7e576d90-2d73-1031-a56b-5e93c0a83801</last_process>\n                   <channel>\n                                  <from>weekly_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledWeeklyNDVIMaxMinCalc.9569e950-2d72-1031-86e8-d821c0a83801</first_process>\n                   <last_process>tiledWeeklyNDVI2VCICalc.7e576d90-2d73-1031-a56b-5e93c0a83801</last_process>\n                   <channel>\n                                  <from>max_min_ndvi</from>\n                                  <to>Weekly_Max_Min_URL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(22, 'urn:uuid:25f95b80-7022-1031-bb02-d0ad81aea6d6', 'Annotate', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="Annotate"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="filterbyarea.032382c0-7022-1031-b52a-f0c381aea6d6" operation="filterbyarea.032382c0-7022-1031-b52a-f0c381aea6d6" /%3E\n  %3Cactivitymember name="SimilarToShape.f0d22e00-7021-1031-a586-59f181aea6d6" operation="SimilarToShape.f0d22e00-7021-1031-a586-59f181aea6d6" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Csequenceactivity name="Activity_1"  memberfirst="SimilarToShape.f0d22e00-7021-1031-a586-59f181aea6d6"  memberlast="filterbyarea.032382c0-7022-1031-b52a-f0c381aea6d6"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_1" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>SimilarToShape.f0d22e00-7021-1031-a586-59f181aea6d6</first_process>\n                   <last_process>filterbyarea.032382c0-7022-1031-b52a-f0c381aea6d6</last_process>\n                   <channel>\n                                  <from>return</from>\n                                  <to>inputURL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(23, 'urn:uuid:6d8c7fc0-7024-1031-bdfb-67e581aea6d6', 'PostProcess', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="PostProcess"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="r2v.5f639f00-7024-1031-8588-3eea81aea6d6" operation="r2v.5f639f00-7024-1031-8588-3eea81aea6d6" /%3E\n  %3Cactivitymember name="eliminate_smallpolygons.5d923a60-7024-1031-bb3f-d95381aea6d6" operation="eliminate_smallpolygons.5d923a60-7024-1031-bb3f-d95381aea6d6" /%3E\n  %3Cactivitymember name="rgb2singlevalue.5b300770-7024-1031-ab2b-911381aea6d6" operation="rgb2singlevalue.5b300770-7024-1031-ab2b-911381aea6d6" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Csequenceactivity name="Activity_1"  memberfirst="rgb2singlevalue.5b300770-7024-1031-ab2b-911381aea6d6"  memberlast="eliminate_smallpolygons.5d923a60-7024-1031-bb3f-d95381aea6d6"  /%3E\n  %3Csequenceactivity name="Activity_2"  memberfirst="Activity_1"  memberlast="r2v.5f639f00-7024-1031-8588-3eea81aea6d6"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_2" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>rgb2singlevalue.5b300770-7024-1031-ab2b-911381aea6d6</first_process>\n                   <last_process>eliminate_smallpolygons.5d923a60-7024-1031-bb3f-d95381aea6d6</last_process>\n                   <channel>\n                                  <from>returnURL</from>\n                                  <to>imgURL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>eliminate_smallpolygons.5d923a60-7024-1031-bb3f-d95381aea6d6</first_process>\n                   <last_process>r2v.5f639f00-7024-1031-8588-3eea81aea6d6</last_process>\n                   <channel>\n                                  <from>returnURL</from>\n                                  <to>imgURL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(24, 'urn:uuid:71da4a70-75d4-1031-b64f-598681aea6d6', 'dailyvci', 'http://bpel.laits.gmu.edu/bpel/lpm', '%3C?xml version="1.0" encoding="UTF-8"?%3E\n%3Clogicprocess  name="dailyvci"  targetnamespace="http://bpel.laits.gmu.edu/bpel/lpm" %3E\n %3Cactivitymembers%3E\n  %3Cactivitymember name="tiledDailyNDVI2VCICalc.552903d0-75d4-1031-8f49-7d1d81aea6d6" operation="tiledDailyNDVI2VCICalc.552903d0-75d4-1031-8f49-7d1d81aea6d6" /%3E\n  %3Cactivitymember name="tiledDailyNDVICalc.1a1a4d30-75d4-1031-8b4d-8ef781aea6d6" operation="tiledDailyNDVICalc.1a1a4d30-75d4-1031-8b4d-8ef781aea6d6" /%3E\n  %3Cactivitymember name="getb1b2Tiles.ef6d9e70-75d3-1031-b5fb-665281aea6d6" operation="getb1b2Tiles.ef6d9e70-75d3-1031-b5fb-665281aea6d6" /%3E\n  %3Cactivitymember name="getQATiles.005fff70-75d4-1031-b64e-baae81aea6d6" operation="getQATiles.005fff70-75d4-1031-b64e-baae81aea6d6" /%3E\n  %3Cactivitymember name="tiledDailyNDVIMaxMinCalc.472ed430-75d4-1031-b7b7-de6881aea6d6" operation="tiledDailyNDVIMaxMinCalc.472ed430-75d4-1031-b7b7-de6881aea6d6" /%3E\n  %3Cactivitymember name="tiledYearsDailyNDVICalc.2a164040-75d4-1031-b200-3bd181aea6d6" operation="tiledYearsDailyNDVICalc.2a164040-75d4-1031-b200-3bd181aea6d6" /%3E\n  %3Cactivitymember name="getb1b2TilesYears.fa611dc0-75d3-1031-98f4-76eb81aea6d6" operation="getb1b2TilesYears.fa611dc0-75d3-1031-98f4-76eb81aea6d6" /%3E\n  %3Cactivitymember name="getQATilesYears.0da62150-75d4-1031-9e79-7e9281aea6d6" operation="getQATilesYears.0da62150-75d4-1031-9e79-7e9281aea6d6" /%3E\n %3C/activitymembers%3E\n %3Ccompositeactivity%3E\n  %3Cparallelactivity name="Activity_1"  memberfirst="getb1b2TilesYears.fa611dc0-75d3-1031-98f4-76eb81aea6d6"  memberlast="getQATilesYears.0da62150-75d4-1031-9e79-7e9281aea6d6"  /%3E\n  %3Csequenceactivity name="Activity_2"  memberfirst="Activity_1"  memberlast="tiledYearsDailyNDVICalc.2a164040-75d4-1031-b200-3bd181aea6d6"  /%3E\n  %3Cparallelactivity name="Activity_3"  memberfirst="getb1b2Tiles.ef6d9e70-75d3-1031-b5fb-665281aea6d6"  memberlast="getQATiles.005fff70-75d4-1031-b64e-baae81aea6d6"  /%3E\n  %3Csequenceactivity name="Activity_4"  memberfirst="Activity_2"  memberlast="tiledDailyNDVIMaxMinCalc.472ed430-75d4-1031-b7b7-de6881aea6d6"  /%3E\n  %3Csequenceactivity name="Activity_5"  memberfirst="Activity_3"  memberlast="tiledDailyNDVICalc.1a1a4d30-75d4-1031-8b4d-8ef781aea6d6"  /%3E\n  %3Cparallelactivity name="Activity_6"  memberfirst="Activity_4"  memberlast="Activity_5"  /%3E\n  %3Csequenceactivity name="Activity_7"  memberfirst="Activity_6"  memberlast="tiledDailyNDVI2VCICalc.552903d0-75d4-1031-8f49-7d1d81aea6d6"  /%3E\n  %3Cflowactivity name="model"  expression="Activity_7" /%3E\n %3C/compositeactivity%3E\n%3C/logicprocess%3E\n', '<ConnectionSet>\n<connection>\n                   <first_process>getb1b2Tiles.ef6d9e70-75d3-1031-b5fb-665281aea6d6</first_process>\n                   <last_process>tiledDailyNDVICalc.1a1a4d30-75d4-1031-8b4d-8ef781aea6d6</last_process>\n                   <channel>\n                                  <from>b1_b2_tiles</from>\n                                  <to>MOD09GQK_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getQATiles.005fff70-75d4-1031-b64e-baae81aea6d6</first_process>\n                   <last_process>tiledDailyNDVICalc.1a1a4d30-75d4-1031-8b4d-8ef781aea6d6</last_process>\n                   <channel>\n                                  <from>qa_tiles</from>\n                                  <to>MOD09GST_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getb1b2TilesYears.fa611dc0-75d3-1031-98f4-76eb81aea6d6</first_process>\n                   <last_process>tiledYearsDailyNDVICalc.2a164040-75d4-1031-b200-3bd181aea6d6</last_process>\n                   <channel>\n                                  <from>years_b1b2_tiles</from>\n                                  <to>MOD09GQK_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>getQATilesYears.0da62150-75d4-1031-9e79-7e9281aea6d6</first_process>\n                   <last_process>tiledYearsDailyNDVICalc.2a164040-75d4-1031-b200-3bd181aea6d6</last_process>\n                   <channel>\n                                  <from>years_qa_tiles</from>\n                                  <to>MOD09GST_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledYearsDailyNDVICalc.2a164040-75d4-1031-b200-3bd181aea6d6</first_process>\n                   <last_process>tiledDailyNDVIMaxMinCalc.472ed430-75d4-1031-b7b7-de6881aea6d6</last_process>\n                   <channel>\n                                  <from>years_daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVICalc.1a1a4d30-75d4-1031-8b4d-8ef781aea6d6</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.552903d0-75d4-1031-8f49-7d1d81aea6d6</last_process>\n                   <channel>\n                                  <from>daily_ndvi</from>\n                                  <to>Daily_NDVI_URL</to>\n                   </channel>\n</connection>\n<connection>\n                   <first_process>tiledDailyNDVIMaxMinCalc.472ed430-75d4-1031-b7b7-de6881aea6d6</first_process>\n                   <last_process>tiledDailyNDVI2VCICalc.552903d0-75d4-1031-8f49-7d1d81aea6d6</last_process>\n                   <channel>\n                                  <from>max_min_daily_ndvi</from>\n                                  <to>Max_Min_NDVI_URL</to>\n                   </channel>\n</connection>\n</ConnectionSet>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(29, 'urn:uuid:ff313e20-2ee1-1033-8121-0a62c0a80004', 'seq', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="seq" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:ff313e20-2ee1-1033-8121-0a62c0a80004" name="seq" author="Ziheng Sun" date="2015-08-26-04:00" desc="Description"/><modeloutput parameter="d91c18e0-2ee1-1033-af81-3e61c0a80004" keywords=""/><activitymembers><activitymember id="cd235e90-2ee1-1033-ad8d-e240c0a80004" name="merge" operation="merge" servicetype="merge"/><activitymember id="cece7680-2ee1-1033-879f-9f5fc0a80004" name="remove" operation="remove" servicetype="remove"/><activitymember id="d91b5590-2ee1-1033-8001-90c1c0a80004" name="remove" operation="remove" servicetype="remove"/></activitymembers><parametermembers><parametermember id="cd340060-2ee1-1033-b826-158ec0a80004" name="sourceURL" type="input" datatype="sourceURL" activity="cd235e90-2ee1-1033-ad8d-e240c0a80004"/><parametermember id="cd397ea0-2ee1-1033-b7f9-9f76c0a80004" name="classlist" type="input" datatype="classlist" activity="cd235e90-2ee1-1033-ad8d-e240c0a80004"/><parametermember id="cd39a5b0-2ee1-1033-812b-fea5c0a80004" name="returnURL" type="output" datatype="returnURL" activity="cd235e90-2ee1-1033-ad8d-e240c0a80004"/><parametermember id="cd39ccc0-2ee1-1033-bb94-6a9bc0a80004" name="returnFormat" type="output" datatype="returnFormat" activity="cd235e90-2ee1-1033-ad8d-e240c0a80004"/><parametermember id="cecec4a0-2ee1-1033-8058-7864c0a80004" name="sourceURL" type="input" datatype="sourceURL" activity="cece7680-2ee1-1033-879f-9f5fc0a80004"/><parametermember id="ceceebb0-2ee1-1033-8d9f-04d3c0a80004" name="min_area" type="input" datatype="min_area" activity="cece7680-2ee1-1033-879f-9f5fc0a80004"/><parametermember id="cecf12c0-2ee1-1033-8390-9ba4c0a80004" name="returnURL" type="output" datatype="returnURL" activity="cece7680-2ee1-1033-879f-9f5fc0a80004"/><parametermember id="cecf39d0-2ee1-1033-8348-e720c0a80004" name="returnFormat" type="output" datatype="returnFormat" activity="cece7680-2ee1-1033-879f-9f5fc0a80004"/><parametermember id="d91bcac0-2ee1-1033-84d6-dc4fc0a80004" name="sourceURL" type="input" datatype="sourceURL" activity="d91b5590-2ee1-1033-8001-90c1c0a80004"/><parametermember id="d91bf1d0-2ee1-1033-88eb-b801c0a80004" name="min_area" type="input" datatype="min_area" activity="d91b5590-2ee1-1033-8001-90c1c0a80004"/><parametermember id="d91c18e0-2ee1-1033-af81-3e61c0a80004" name="returnURL" type="output" datatype="returnURL" activity="d91b5590-2ee1-1033-8001-90c1c0a80004"/><parametermember id="d91c6700-2ee1-1033-a415-a2f0c0a80004" name="returnFormat" type="output" datatype="returnFormat" activity="d91b5590-2ee1-1033-8001-90c1c0a80004"/></parametermembers><connectionmembers><connectionmember id="dfb98480-2ee1-1033-9c81-2b1fc0a80004" name="Connection0" activityto="cd340060-2ee1-1033-b826-158ec0a80004" parameterfrom="cd340060-2ee1-1033-b826-158ec0a80004"/><connectionmember id="dfb9f9b0-2ee1-1033-98d8-2ba5c0a80004" name="Connection1" activityto="cd397ea0-2ee1-1033-b7f9-9f76c0a80004" parameterfrom="cd397ea0-2ee1-1033-b7f9-9f76c0a80004"/><connectionmember id="dfba20c0-2ee1-1033-b49d-fd60c0a80004" name="Connection2" activityfrom="cd235e90-2ee1-1033-ad8d-e240c0a80004" parameterto="cd39a5b0-2ee1-1033-812b-fea5c0a80004"/><connectionmember id="dfba20c0-2ee1-1033-8dea-953cc0a80004" name="Connection3" activityfrom="cd235e90-2ee1-1033-ad8d-e240c0a80004" parameterto="cd39ccc0-2ee1-1033-bb94-6a9bc0a80004"/><connectionmember id="dfba47d0-2ee1-1033-8b9f-4bf5c0a80004" name="Connection4" activityto="cecec4a0-2ee1-1033-8058-7864c0a80004" parameterfrom="cecec4a0-2ee1-1033-8058-7864c0a80004"/><connectionmember id="dfba6ee0-2ee1-1033-b934-d9d8c0a80004" name="Connection5" activityto="ceceebb0-2ee1-1033-8d9f-04d3c0a80004" parameterfrom="ceceebb0-2ee1-1033-8d9f-04d3c0a80004"/><connectionmember id="dfba6ee0-2ee1-1033-bd31-7c70c0a80004" name="Connection6" activityfrom="cece7680-2ee1-1033-879f-9f5fc0a80004" parameterto="cecf12c0-2ee1-1033-8390-9ba4c0a80004"/><connectionmember id="dfba95f0-2ee1-1033-b8ad-4eb2c0a80004" name="Connection7" activityfrom="cece7680-2ee1-1033-879f-9f5fc0a80004" parameterto="cecf39d0-2ee1-1033-8348-e720c0a80004"/><connectionmember id="dfbabd00-2ee1-1033-9adc-8f4dc0a80004" name="Connection8" parameterfrom="cd39a5b0-2ee1-1033-812b-fea5c0a80004" parameterto="cecec4a0-2ee1-1033-8058-7864c0a80004"/><connectionmember id="dfbabd00-2ee1-1033-b7ef-ad24c0a80004" name="Connection9" activityto="d91bcac0-2ee1-1033-84d6-dc4fc0a80004" parameterfrom="d91bcac0-2ee1-1033-84d6-dc4fc0a80004"/><connectionmember id="dfbae410-2ee1-1033-a334-4200c0a80004" name="Connection10" activityto="d91bf1d0-2ee1-1033-88eb-b801c0a80004" parameterfrom="d91bf1d0-2ee1-1033-88eb-b801c0a80004"/><connectionmember id="dfbae410-2ee1-1033-82a6-7aeac0a80004" name="Connection11" activityfrom="d91b5590-2ee1-1033-8001-90c1c0a80004" parameterto="d91c18e0-2ee1-1033-af81-3e61c0a80004"/><connectionmember id="dfbb0b20-2ee1-1033-b5ea-d830c0a80004" name="Connection12" activityfrom="d91b5590-2ee1-1033-8001-90c1c0a80004" parameterto="d91c6700-2ee1-1033-a415-a2f0c0a80004"/><connectionmember id="dfbb3230-2ee1-1033-91f8-5716c0a80004" name="Connection13" parameterfrom="cecf12c0-2ee1-1033-8390-9ba4c0a80004" parameterto="d91bcac0-2ee1-1033-84d6-dc4fc0a80004"/></connectionmembers></logicprocess>', '', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(36, 'urn:uuid:1aecf430-2f71-1033-b535-9c6f81aea662', 'YearsDaysVCI', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/YearsDaysVCI" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:1aecf430-2f71-1033-b535-9c6f81aea662" name="YearsDaysVCI" author="Ziheng Sun" date="2015-08-26-04:00" desc="Customized  days VCI over years."/><modeloutput parameter="5f0d83c0-2f6f-1033-b453-405c81aea662" keywords="VCI"/><activitymembers><activitymember id="d03c3c40-2f6e-1033-bd84-ac8281aea662" name="clipROIHDFDays" operation="clipROIHDFDays" servicetype="clipROIHDFDays"/><activitymember id="d331d590-2f6e-1033-b6e0-1cab81aea662" name="clipROIHDFYearsDays" operation="clipROIHDFYearsDays" servicetype="clipROIHDFYearsDays"/><activitymember id="ebb0bd20-2f6e-1033-94dc-cf2c81aea662" name="ROIYearsDaysNDVICalc" operation="ROIYearsDaysNDVICalc" servicetype="ROIYearsDaysNDVICalc"/><activitymember id="fba3fda0-2f6e-1033-bcce-97ae81aea662" name="ROIDaysDailyNDVICalc" operation="ROIDaysDailyNDVICalc" servicetype="ROIDaysDailyNDVICalc"/><activitymember id="06c01390-2f6f-1033-8600-5d5181aea662" name="ROIDaysNDVICompositeCalc" operation="ROIDaysNDVICompositeCalc" servicetype="ROIDaysNDVICompositeCalc"/><activitymember id="163bb310-2f6f-1033-b02a-66c281aea662" name="ROIYearsDaysNDVICompositeCalc" operation="ROIYearsDaysNDVICompositeCalc" servicetype="ROIYearsDaysNDVICompositeCalc"/><activitymember id="37991ca0-2f6f-1033-a5e8-eb4881aea662" name="ROIYearsDailyNDVIMaxMinCalc" operation="ROIYearsDailyNDVIMaxMinCalc" servicetype="ROIYearsDailyNDVIMaxMinCalc"/><activitymember id="5f0cc070-2f6f-1033-bead-3e7281aea662" name="ROIDailyNDVI2VCICalc" operation="ROIDailyNDVI2VCICalc" servicetype="ROIDailyNDVI2VCICalc"/></activitymembers><parametermembers><parametermember id="d03cd880-2f6e-1033-891f-650381aea662" name="bbox" type="input" datatype="bbox" activity="d03c3c40-2f6e-1033-bd84-ac8281aea662"/><parametermember id="d03cff90-2f6e-1033-a798-251781aea662" name="in_year" type="input" datatype="in_year" activity="d03c3c40-2f6e-1033-bd84-ac8281aea662"/><parametermember id="d03cff90-2f6e-1033-a22a-c75081aea662" name="in_day" type="input" datatype="in_day" activity="d03c3c40-2f6e-1033-bd84-ac8281aea662"/><parametermember id="d03d26a0-2f6e-1033-9fe1-61c281aea662" name="daynum" type="input" datatype="daynum" activity="d03c3c40-2f6e-1033-bd84-ac8281aea662"/><parametermember id="d03d4db0-2f6e-1033-9eb4-fe3d81aea662" name="return" type="output" datatype="return" activity="d03c3c40-2f6e-1033-bd84-ac8281aea662"/><parametermember id="d331fca0-2f6e-1033-aa11-75fe81aea662" name="bbox" type="input" datatype="bbox" activity="d331d590-2f6e-1033-b6e0-1cab81aea662"/><parametermember id="d33223b0-2f6e-1033-ad42-f45381aea662" name="years" type="input" datatype="years" activity="d331d590-2f6e-1033-b6e0-1cab81aea662"/><parametermember id="d3324ac0-2f6e-1033-80c2-c46281aea662" name="in_day" type="input" datatype="in_day" activity="d331d590-2f6e-1033-b6e0-1cab81aea662"/><parametermember id="d33271d0-2f6e-1033-8d03-e15681aea662" name="daynum" type="input" datatype="daynum" activity="d331d590-2f6e-1033-b6e0-1cab81aea662"/><parametermember id="d33298e0-2f6e-1033-8ac8-33a081aea662" name="return" type="output" datatype="return" activity="d331d590-2f6e-1033-b6e0-1cab81aea662"/><parametermember id="ebb13250-2f6e-1033-be88-adb181aea662" name="years_b1b2QA_URL" type="input" datatype="years_b1b2QA_URL" activity="ebb0bd20-2f6e-1033-94dc-cf2c81aea662"/><parametermember id="ebb15960-2f6e-1033-a754-44e581aea662" name="years" type="input" datatype="years" activity="ebb0bd20-2f6e-1033-94dc-cf2c81aea662"/><parametermember id="ebb18070-2f6e-1033-bbc5-028581aea662" name="in_day" type="input" datatype="in_day" activity="ebb0bd20-2f6e-1033-94dc-cf2c81aea662"/><parametermember id="ebb18070-2f6e-1033-b0b8-b34781aea662" name="daynum" type="input" datatype="daynum" activity="ebb0bd20-2f6e-1033-94dc-cf2c81aea662"/><parametermember id="ebb1a780-2f6e-1033-8a95-4fdb81aea662" name="return" type="output" datatype="return" activity="ebb0bd20-2f6e-1033-94dc-cf2c81aea662"/><parametermember id="fba472d0-2f6e-1033-b577-8cfb81aea662" name="days_b1b2QA_URL" type="input" datatype="days_b1b2QA_URL" activity="fba3fda0-2f6e-1033-bcce-97ae81aea662"/><parametermember id="fba499e0-2f6e-1033-9c0b-ff0a81aea662" name="in_year" type="input" datatype="in_year" activity="fba3fda0-2f6e-1033-bcce-97ae81aea662"/><parametermember id="fba4c0f0-2f6e-1033-bc75-c74f81aea662" name="in_day" type="input" datatype="in_day" activity="fba3fda0-2f6e-1033-bcce-97ae81aea662"/><parametermember id="fba4e800-2f6e-1033-8477-acb281aea662" name="daynum" type="input" datatype="daynum" activity="fba3fda0-2f6e-1033-bcce-97ae81aea662"/><parametermember id="fba50f10-2f6e-1033-91d4-4bd681aea662" name="return" type="output" datatype="return" activity="fba3fda0-2f6e-1033-bcce-97ae81aea662"/><parametermember id="06c088c0-2f6f-1033-a316-43b681aea662" name="Daily_NDVI_URL" type="input" datatype="Daily_NDVI_URL" activity="06c01390-2f6f-1033-8600-5d5181aea662"/><parametermember id="06c0afd0-2f6f-1033-8ea2-f68e81aea662" name="in_year" type="input" datatype="in_year" activity="06c01390-2f6f-1033-8600-5d5181aea662"/><parametermember id="06c0d6e0-2f6f-1033-9129-700181aea662" name="in_day" type="input" datatype="in_day" activity="06c01390-2f6f-1033-8600-5d5181aea662"/><parametermember id="06c0fdf0-2f6f-1033-ad83-0e0081aea662" name="daynum" type="input" datatype="daynum" activity="06c01390-2f6f-1033-8600-5d5181aea662"/><parametermember id="06c12500-2f6f-1033-8111-0c8481aea662" name="return" type="output" datatype="return" activity="06c01390-2f6f-1033-8600-5d5181aea662"/><parametermember id="163c2840-2f6f-1033-ba80-af2d81aea662" name="Daily_NDVI_URL" type="input" datatype="Daily_NDVI_URL" activity="163bb310-2f6f-1033-b02a-66c281aea662"/><parametermember id="163c4f50-2f6f-1033-a1ec-be6181aea662" name="years" type="input" datatype="years" activity="163bb310-2f6f-1033-b02a-66c281aea662"/><parametermember id="163c4f50-2f6f-1033-8957-e32c81aea662" name="in_day" type="input" datatype="in_day" activity="163bb310-2f6f-1033-b02a-66c281aea662"/><parametermember id="163c7660-2f6f-1033-88fd-43a681aea662" name="daynum" type="input" datatype="daynum" activity="163bb310-2f6f-1033-b02a-66c281aea662"/><parametermember id="163c9d70-2f6f-1033-bc05-56e481aea662" name="return" type="output" datatype="return" activity="163bb310-2f6f-1033-b02a-66c281aea662"/><parametermember id="379991d0-2f6f-1033-9bd0-57ff81aea662" name="Daily_NDVI_URL" type="input" datatype="Daily_NDVI_URL" activity="37991ca0-2f6f-1033-a5e8-eb4881aea662"/><parametermember id="3799b8e0-2f6f-1033-8914-2f5981aea662" name="years" type="input" datatype="years" activity="37991ca0-2f6f-1033-a5e8-eb4881aea662"/><parametermember id="3799b8e0-2f6f-1033-a39d-ba7881aea662" name="in_day" type="input" datatype="in_day" activity="37991ca0-2f6f-1033-a5e8-eb4881aea662"/><parametermember id="3799dff0-2f6f-1033-b1cc-937481aea662" name="return" type="output" datatype="return" activity="37991ca0-2f6f-1033-a5e8-eb4881aea662"/><parametermember id="5f0d0e90-2f6f-1033-b996-5e3a81aea662" name="Daily_NDVI_URL" type="input" datatype="Daily_NDVI_URL" activity="5f0cc070-2f6f-1033-bead-3e7281aea662"/><parametermember id="5f0d35a0-2f6f-1033-a511-3a9581aea662" name="Max_Min_NDVI_URL" type="input" datatype="Max_Min_NDVI_URL" activity="5f0cc070-2f6f-1033-bead-3e7281aea662"/><parametermember id="5f0d5cb0-2f6f-1033-adb0-17e381aea662" name="in_year" type="input" datatype="in_year" activity="5f0cc070-2f6f-1033-bead-3e7281aea662"/><parametermember id="5f0d83c0-2f6f-1033-bbe4-620781aea662" name="in_day" type="input" datatype="in_day" activity="5f0cc070-2f6f-1033-bead-3e7281aea662"/><parametermember id="5f0d83c0-2f6f-1033-b453-405c81aea662" name="return" type="output" datatype="return" activity="5f0cc070-2f6f-1033-bead-3e7281aea662"/></parametermembers><connectionmembers><connectionmember id="b0cd18b0-2f6f-1033-b0b3-092081aea662" name="Connection0" activityto="d03c3c40-2f6e-1033-bd84-ac8281aea662" parameterfrom="d03cd880-2f6e-1033-891f-650381aea662"/><connectionmember id="b0cd8de0-2f6f-1033-9bb7-13e481aea662" name="Connection1" activityto="d03c3c40-2f6e-1033-bd84-ac8281aea662" parameterfrom="d03cff90-2f6e-1033-a798-251781aea662"/><connectionmember id="b0cdb4f0-2f6f-1033-8a01-373981aea662" name="Connection2" activityto="d03c3c40-2f6e-1033-bd84-ac8281aea662" parameterfrom="d03cff90-2f6e-1033-a22a-c75081aea662"/><connectionmember id="b0cdb4f0-2f6f-1033-b300-105b81aea662" name="Connection3" activityto="d03c3c40-2f6e-1033-bd84-ac8281aea662" parameterfrom="d03d26a0-2f6e-1033-9fe1-61c281aea662"/><connectionmember id="b0cddc00-2f6f-1033-b062-805281aea662" name="Connection4" activityfrom="d03c3c40-2f6e-1033-bd84-ac8281aea662" parameterto="d03d4db0-2f6e-1033-9eb4-fe3d81aea662"/><connectionmember id="b0cddc00-2f6f-1033-a908-d01a81aea662" name="Connection5" activityto="d331d590-2f6e-1033-b6e0-1cab81aea662" parameterfrom="d331fca0-2f6e-1033-aa11-75fe81aea662"/><connectionmember id="b0ce0310-2f6f-1033-b847-a70081aea662" name="Connection6" activityto="d331d590-2f6e-1033-b6e0-1cab81aea662" parameterfrom="d33223b0-2f6e-1033-ad42-f45381aea662"/><connectionmember id="b0ce0310-2f6f-1033-bb31-0eea81aea662" name="Connection7" activityto="d331d590-2f6e-1033-b6e0-1cab81aea662" parameterfrom="d3324ac0-2f6e-1033-80c2-c46281aea662"/><connectionmember id="b0ce2a20-2f6f-1033-88dc-5d0181aea662" name="Connection8" activityto="d331d590-2f6e-1033-b6e0-1cab81aea662" parameterfrom="d33271d0-2f6e-1033-8d03-e15681aea662"/><connectionmember id="b0ce5130-2f6f-1033-81b5-b36081aea662" name="Connection9" activityfrom="d331d590-2f6e-1033-b6e0-1cab81aea662" parameterto="d33298e0-2f6e-1033-8ac8-33a081aea662"/><connectionmember id="b0ce5130-2f6f-1033-b58a-51f881aea662" name="Connection10" activityto="ebb0bd20-2f6e-1033-94dc-cf2c81aea662" parameterfrom="ebb13250-2f6e-1033-be88-adb181aea662"/><connectionmember id="b0ce7840-2f6f-1033-9704-02b381aea662" name="Connection11" activityto="ebb0bd20-2f6e-1033-94dc-cf2c81aea662" parameterfrom="ebb15960-2f6e-1033-a754-44e581aea662"/><connectionmember id="b0ce9f50-2f6f-1033-982a-8a9f81aea662" name="Connection12" activityto="ebb0bd20-2f6e-1033-94dc-cf2c81aea662" parameterfrom="ebb18070-2f6e-1033-bbc5-028581aea662"/><connectionmember id="b0ce9f50-2f6f-1033-be32-47cd81aea662" name="Connection13" activityto="ebb0bd20-2f6e-1033-94dc-cf2c81aea662" parameterfrom="ebb18070-2f6e-1033-b0b8-b34781aea662"/><connectionmember id="b0ce9f50-2f6f-1033-8043-b2bc81aea662" name="Connection14" activityfrom="ebb0bd20-2f6e-1033-94dc-cf2c81aea662" parameterto="ebb1a780-2f6e-1033-8a95-4fdb81aea662"/><connectionmember id="b0cec660-2f6f-1033-8859-d4b781aea662" name="Connection15" parameterfrom="d33298e0-2f6e-1033-8ac8-33a081aea662" parameterto="ebb13250-2f6e-1033-be88-adb181aea662"/><connectionmember id="b0cec660-2f6f-1033-a0ff-fa5e81aea662" name="Connection16" activityto="fba3fda0-2f6e-1033-bcce-97ae81aea662" parameterfrom="fba472d0-2f6e-1033-b577-8cfb81aea662"/><connectionmember id="b0cec660-2f6f-1033-8968-8f5081aea662" name="Connection17" activityto="fba3fda0-2f6e-1033-bcce-97ae81aea662" parameterfrom="fba499e0-2f6e-1033-9c0b-ff0a81aea662"/><connectionmember id="b0cec660-2f6f-1033-b579-91e881aea662" name="Connection18" activityto="fba3fda0-2f6e-1033-bcce-97ae81aea662" parameterfrom="fba4c0f0-2f6e-1033-bc75-c74f81aea662"/><connectionmember id="b0ceed70-2f6f-1033-bd78-156a81aea662" name="Connection19" activityto="fba3fda0-2f6e-1033-bcce-97ae81aea662" parameterfrom="fba4e800-2f6e-1033-8477-acb281aea662"/><connectionmember id="b0ceed70-2f6f-1033-8f81-388181aea662" name="Connection20" activityfrom="fba3fda0-2f6e-1033-bcce-97ae81aea662" parameterto="fba50f10-2f6e-1033-91d4-4bd681aea662"/><connectionmember id="b0ceed70-2f6f-1033-84a9-123a81aea662" name="Connection21" parameterfrom="d03d4db0-2f6e-1033-9eb4-fe3d81aea662" parameterto="fba472d0-2f6e-1033-b577-8cfb81aea662"/><connectionmember id="b0ceed70-2f6f-1033-a6fd-1a2b81aea662" name="Connection22" activityto="06c01390-2f6f-1033-8600-5d5181aea662" parameterfrom="06c088c0-2f6f-1033-a316-43b681aea662"/><connectionmember id="b0cf1480-2f6f-1033-a3c2-841281aea662" name="Connection23" activityto="06c01390-2f6f-1033-8600-5d5181aea662" parameterfrom="06c0afd0-2f6f-1033-8ea2-f68e81aea662"/><connectionmember id="b0cf1480-2f6f-1033-92a2-a6c281aea662" name="Connection24" activityto="06c01390-2f6f-1033-8600-5d5181aea662" parameterfrom="06c0d6e0-2f6f-1033-9129-700181aea662"/><connectionmember id="b0cf1480-2f6f-1033-9b82-6a1181aea662" name="Connection25" activityto="06c01390-2f6f-1033-8600-5d5181aea662" parameterfrom="06c0fdf0-2f6f-1033-ad83-0e0081aea662"/><connectionmember id="b0cf1480-2f6f-1033-ada0-5c7b81aea662" name="Connection26" activityfrom="06c01390-2f6f-1033-8600-5d5181aea662" parameterto="06c12500-2f6f-1033-8111-0c8481aea662"/><connectionmember id="b0cf3b90-2f6f-1033-be08-a93f81aea662" name="Connection27" parameterfrom="fba50f10-2f6e-1033-91d4-4bd681aea662" parameterto="06c088c0-2f6f-1033-a316-43b681aea662"/><connectionmember id="b0cf3b90-2f6f-1033-89b1-dbde81aea662" name="Connection28" activityto="163bb310-2f6f-1033-b02a-66c281aea662" parameterfrom="163c2840-2f6f-1033-ba80-af2d81aea662"/><connectionmember id="b0cf3b90-2f6f-1033-a895-88e581aea662" name="Connection29" activityto="163bb310-2f6f-1033-b02a-66c281aea662" parameterfrom="163c4f50-2f6f-1033-a1ec-be6181aea662"/><connectionmember id="b0cf62a0-2f6f-1033-8089-b39a81aea662" name="Connection30" activityto="163bb310-2f6f-1033-b02a-66c281aea662" parameterfrom="163c4f50-2f6f-1033-8957-e32c81aea662"/><connectionmember id="b0cf62a0-2f6f-1033-9aff-6c5181aea662" name="Connection31" activityto="163bb310-2f6f-1033-b02a-66c281aea662" parameterfrom="163c7660-2f6f-1033-88fd-43a681aea662"/><connectionmember id="b0cf62a0-2f6f-1033-a87e-da7e81aea662" name="Connection32" activityfrom="163bb310-2f6f-1033-b02a-66c281aea662" parameterto="163c9d70-2f6f-1033-bc05-56e481aea662"/><connectionmember id="b0cf62a0-2f6f-1033-b0b9-73a081aea662" name="Connection33" parameterfrom="ebb1a780-2f6e-1033-8a95-4fdb81aea662" parameterto="163c2840-2f6f-1033-ba80-af2d81aea662"/><connectionmember id="b0cf89b0-2f6f-1033-9ff2-63a481aea662" name="Connection34" activityto="37991ca0-2f6f-1033-a5e8-eb4881aea662" parameterfrom="379991d0-2f6f-1033-9bd0-57ff81aea662"/><connectionmember id="b0cf89b0-2f6f-1033-8a7b-772d81aea662" name="Connection35" activityto="37991ca0-2f6f-1033-a5e8-eb4881aea662" parameterfrom="3799b8e0-2f6f-1033-8914-2f5981aea662"/><connectionmember id="b0cf89b0-2f6f-1033-b103-b8ae81aea662" name="Connection36" activityto="37991ca0-2f6f-1033-a5e8-eb4881aea662" parameterfrom="3799b8e0-2f6f-1033-a39d-ba7881aea662"/><connectionmember id="b0cf89b0-2f6f-1033-864d-85dd81aea662" name="Connection37" activityfrom="37991ca0-2f6f-1033-a5e8-eb4881aea662" parameterto="3799dff0-2f6f-1033-b1cc-937481aea662"/><connectionmember id="b0cfb0c0-2f6f-1033-b0aa-ce4881aea662" name="Connection38" activityto="5f0cc070-2f6f-1033-bead-3e7281aea662" parameterfrom="5f0d0e90-2f6f-1033-b996-5e3a81aea662"/><connectionmember id="b0cfb0c0-2f6f-1033-8b01-0f0881aea662" name="Connection39" activityto="5f0cc070-2f6f-1033-bead-3e7281aea662" parameterfrom="5f0d35a0-2f6f-1033-a511-3a9581aea662"/><connectionmember id="b0cfb0c0-2f6f-1033-98a6-8dc981aea662" name="Connection40" activityto="5f0cc070-2f6f-1033-bead-3e7281aea662" parameterfrom="5f0d5cb0-2f6f-1033-adb0-17e381aea662"/><connectionmember id="b0cfb0c0-2f6f-1033-a1af-186581aea662" name="Connection41" activityto="5f0cc070-2f6f-1033-bead-3e7281aea662" parameterfrom="5f0d83c0-2f6f-1033-bbe4-620781aea662"/><connectionmember id="b0cfd7d0-2f6f-1033-813f-d19681aea662" name="Connection42" activityfrom="5f0cc070-2f6f-1033-bead-3e7281aea662" parameterto="5f0d83c0-2f6f-1033-b453-405c81aea662"/><connectionmember id="b0cfd7d0-2f6f-1033-8549-755381aea662" name="Connection43" parameterfrom="3799dff0-2f6f-1033-b1cc-937481aea662" parameterto="5f0d35a0-2f6f-1033-a511-3a9581aea662"/><connectionmember id="b0cfd7d0-2f6f-1033-ac60-3af481aea662" name="Connection44" parameterfrom="06c12500-2f6f-1033-8111-0c8481aea662" parameterto="5f0d0e90-2f6f-1033-b996-5e3a81aea662"/><connectionmember id="b0cffee0-2f6f-1033-a433-5cea81aea662" name="Connection45" parameterfrom="163c9d70-2f6f-1033-bc05-56e481aea662" parameterto="379991d0-2f6f-1033-9bd0-57ff81aea662"/><connectionmember id="b0cffee0-2f6f-1033-ba56-514a81aea662" name="Connection46" parameterfrom="d33223b0-2f6e-1033-ad42-f45381aea662" parameterto="ebb15960-2f6e-1033-a754-44e581aea662"/><connectionmember id="b0cffee0-2f6f-1033-b16d-50d981aea662" name="Connection47" parameterfrom="d3324ac0-2f6e-1033-80c2-c46281aea662" parameterto="ebb18070-2f6e-1033-bbc5-028581aea662"/><connectionmember id="b0cffee0-2f6f-1033-8ac6-e1a681aea662" name="Connection48" parameterfrom="d33271d0-2f6e-1033-8d03-e15681aea662" parameterto="ebb18070-2f6e-1033-b0b8-b34781aea662"/><connectionmember id="b0d025f0-2f6f-1033-8d8c-5d4d81aea662" name="Connection49" parameterfrom="ebb18070-2f6e-1033-bbc5-028581aea662" parameterto="163c4f50-2f6f-1033-8957-e32c81aea662"/><connectionmember id="b0d025f0-2f6f-1033-8276-167481aea662" name="Connection50" parameterfrom="ebb18070-2f6e-1033-b0b8-b34781aea662" parameterto="163c7660-2f6f-1033-88fd-43a681aea662"/><connectionmember id="b0d025f0-2f6f-1033-ab62-e55981aea662" name="Connection51" parameterfrom="ebb15960-2f6e-1033-a754-44e581aea662" parameterto="163c4f50-2f6f-1033-a1ec-be6181aea662"/><connectionmember id="b0d025f0-2f6f-1033-a648-47e881aea662" name="Connection52" parameterfrom="163c4f50-2f6f-1033-8957-e32c81aea662" parameterto="3799b8e0-2f6f-1033-a39d-ba7881aea662"/><connectionmember id="b0d04d00-2f6f-1033-9fb4-6e6881aea662" name="Connection53" parameterfrom="163c4f50-2f6f-1033-a1ec-be6181aea662" parameterto="3799b8e0-2f6f-1033-8914-2f5981aea662"/><connectionmember id="b0d04d00-2f6f-1033-aa96-f92681aea662" name="Connection54" parameterfrom="3799b8e0-2f6f-1033-a39d-ba7881aea662" parameterto="5f0d83c0-2f6f-1033-bbe4-620781aea662"/><connectionmember id="b0d04d00-2f6f-1033-a1c5-663681aea662" name="Connection55" parameterfrom="fba4c0f0-2f6e-1033-bc75-c74f81aea662" parameterto="06c0d6e0-2f6f-1033-9129-700181aea662"/><connectionmember id="b0d04d00-2f6f-1033-b570-dacd81aea662" name="Connection56" parameterfrom="fba4e800-2f6e-1033-8477-acb281aea662" parameterto="06c0fdf0-2f6f-1033-ad83-0e0081aea662"/><connectionmember id="b0d07410-2f6f-1033-8f75-98da81aea662" name="Connection57" parameterfrom="fba499e0-2f6e-1033-9c0b-ff0a81aea662" parameterto="06c0afd0-2f6f-1033-8ea2-f68e81aea662"/><connectionmember id="b0d07410-2f6f-1033-b822-e27c81aea662" name="Connection58" parameterfrom="d03d26a0-2f6e-1033-9fe1-61c281aea662" parameterto="fba4e800-2f6e-1033-8477-acb281aea662"/><connectionmember id="b0d07410-2f6f-1033-8d70-b9d681aea662" name="Connection59" parameterfrom="d03cff90-2f6e-1033-a22a-c75081aea662" parameterto="fba4c0f0-2f6e-1033-bc75-c74f81aea662"/><connectionmember id="b0d07410-2f6f-1033-834c-519b81aea662" name="Connection60" parameterfrom="d03cff90-2f6e-1033-a798-251781aea662" parameterto="fba499e0-2f6e-1033-9c0b-ff0a81aea662"/><connectionmember id="b0d09b20-2f6f-1033-adef-00ac81aea662" name="Connection61" parameterfrom="d03cd880-2f6e-1033-891f-650381aea662" parameterto="d331fca0-2f6e-1033-aa11-75fe81aea662"/><connectionmember id="b0d09b20-2f6f-1033-95d7-6eca81aea662" name="Connection62" parameterfrom="06c0afd0-2f6f-1033-8ea2-f68e81aea662" parameterto="5f0d5cb0-2f6f-1033-adb0-17e381aea662"/></connectionmembers></logicprocess>', '', 'VCI', 'Customized  days VCI over years.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(37, 'urn:uuid:d5fe14e0-3032-1033-a66e-bc5081aea662', 'AutoClassification', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/AutoClassification" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:d5fe14e0-3032-1033-a66e-bc5081aea662" name="AutoClassification" author="Ziheng Sun" date="2015-08-27-04:00" desc="Automatic classification"/><modeloutput parameter="f4faa080-3031-1033-a65a-5b6081aea662" keywords="pacs"/><activitymembers><activitymember id="df4c3e10-3031-1033-9470-934881aea662" name="segment" operation="segment" servicetype="segment"/><activitymember id="e5e982a0-3031-1033-8116-c28181aea662" name="rgb2singlevalue" operation="rgb2singlevalue" servicetype="rgb2singlevalue"/><activitymember id="e9dae110-3031-1033-9011-5a9181aea662" name="eliminate_smallpolygons" operation="eliminate_smallpolygons" servicetype="eliminate_smallpolygons"/><activitymember id="ec658390-3031-1033-9673-fa2b81aea662" name="r2v" operation="r2v" servicetype="r2v"/><activitymember id="f4f96800-3031-1033-94a9-38cf81aea662" name="classify" operation="classify" servicetype="classify"/></activitymembers><parametermembers><parametermember id="df55db00-3031-1033-befa-145e81aea662" name="imgURL" type="input" datatype="imgURL" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df562920-3031-1033-9879-50d281aea662" name="sigmaS" type="input" datatype="sigmaS" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df565030-3031-1033-b0b1-35c881aea662" name="sigmaR" type="input" datatype="sigmaR" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df565030-3031-1033-b487-d84881aea662" name="minRegion" type="input" datatype="minRegion" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df567740-3031-1033-b725-df5d81aea662" name="speedUpLevel" type="input" datatype="speedUpLevel" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df569e50-3031-1033-8fa0-e0d081aea662" name="speedUpThreshold" type="input" datatype="speedUpThreshold" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df56c560-3031-1033-8772-888c81aea662" name="checkWeightMap" type="input" datatype="checkWeightMap" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df56ec70-3031-1033-bcfa-229c81aea662" name="gradientWindow" type="input" datatype="gradientWindow" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df571380-3031-1033-bf7a-cfe481aea662" name="blendVar" type="input" datatype="blendVar" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df571380-3031-1033-8f2c-fc9c81aea662" name="threshold" type="input" datatype="threshold" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df571380-3031-1033-90f4-84dd81aea662" name="returnFormat" type="input" datatype="returnFormat" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df573a90-3031-1033-89cb-495081aea662" name="sigmaS2" type="input" datatype="sigmaS2" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df573a90-3031-1033-bbdb-7d4981aea662" name="filter_imgURL" type="output" datatype="filter_imgURL" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df5761a0-3031-1033-a2da-632781aea662" name="fusion_imgURL" type="output" datatype="fusion_imgURL" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df5788b0-3031-1033-9365-c0cc81aea662" name="seg_imgURL" type="output" datatype="seg_imgURL" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="df5788b0-3031-1033-bd87-819781aea662" name="boundary_imgURL" type="output" datatype="boundary_imgURL" activity="df4c3e10-3031-1033-9470-934881aea662"/><parametermember id="e5e9f7d0-3031-1033-a803-074081aea662" name="imgURL" type="input" datatype="imgURL" activity="e5e982a0-3031-1033-8116-c28181aea662"/><parametermember id="e5ea1ee0-3031-1033-b3e5-db9e81aea662" name="returnformat" type="input" datatype="returnformat" activity="e5e982a0-3031-1033-8116-c28181aea662"/><parametermember id="e5ea45f0-3031-1033-bede-a6a081aea662" name="returnURL" type="output" datatype="returnURL" activity="e5e982a0-3031-1033-8116-c28181aea662"/><parametermember id="e9db5640-3031-1033-a6b9-891781aea662" name="imgURL" type="input" datatype="imgURL" activity="e9dae110-3031-1033-9011-5a9181aea662"/><parametermember id="e9db7d50-3031-1033-a414-316a81aea662" name="returnformat" type="input" datatype="returnformat" activity="e9dae110-3031-1033-9011-5a9181aea662"/><parametermember id="e9dba460-3031-1033-9876-0db481aea662" name="returnURL" type="output" datatype="returnURL" activity="e9dae110-3031-1033-9011-5a9181aea662"/><parametermember id="ec65d1b0-3031-1033-b1a4-2fe481aea662" name="imgURL" type="input" datatype="imgURL" activity="ec658390-3031-1033-9673-fa2b81aea662"/><parametermember id="ec65f8c0-3031-1033-b4d7-255e81aea662" name="returnformat" type="input" datatype="returnformat" activity="ec658390-3031-1033-9673-fa2b81aea662"/><parametermember id="ec65f8c0-3031-1033-ae4c-7b3781aea662" name="returnURL" type="output" datatype="returnURL" activity="ec658390-3031-1033-9673-fa2b81aea662"/><parametermember id="f4f9b620-3031-1033-ad4a-890281aea662" name="vectorURL" type="input" datatype="vectorURL" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4f9dd30-3031-1033-bd04-e64581aea662" name="rasterURL" type="input" datatype="rasterURL" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4fa0440-3031-1033-9a82-1a5381aea662" name="segURL" type="input" datatype="segURL" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4fa0440-3031-1033-8c36-773f81aea662" name="classhierarchy" type="input" datatype="classhierarchy" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4fa2b50-3031-1033-88f6-422681aea662" name="featurespace" type="input" datatype="featurespace" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4fa5260-3031-1033-9dba-6b6d81aea662" name="k" type="input" datatype="k" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4fa5260-3031-1033-a29f-280581aea662" name="unclassfied" type="input" datatype="unclassfied" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4fa7970-3031-1033-945d-90f881aea662" name="threshold" type="input" datatype="threshold" activity="f4f96800-3031-1033-94a9-38cf81aea662"/><parametermember id="f4faa080-3031-1033-a65a-5b6081aea662" name="returnVURL" type="output" datatype="returnVURL" activity="f4f96800-3031-1033-94a9-38cf81aea662"/></parametermembers><connectionmembers><connectionmember id="abc5abc0-3032-1033-be07-91f581aea662" name="Connection0" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df55db00-3031-1033-befa-145e81aea662"/><connectionmember id="abc64800-3032-1033-8114-678c81aea662" name="Connection1" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df562920-3031-1033-9879-50d281aea662"/><connectionmember id="abc66f10-3032-1033-96a2-304f81aea662" name="Connection2" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df565030-3031-1033-b0b1-35c881aea662"/><connectionmember id="abc69620-3032-1033-9fc1-59a381aea662" name="Connection3" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df565030-3031-1033-b487-d84881aea662"/><connectionmember id="abc69620-3032-1033-85e0-074081aea662" name="Connection4" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df567740-3031-1033-b725-df5d81aea662"/><connectionmember id="abc6bd30-3032-1033-a13c-756b81aea662" name="Connection5" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df569e50-3031-1033-8fa0-e0d081aea662"/><connectionmember id="abc6bd30-3032-1033-9ff4-c7ed81aea662" name="Connection6" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df56c560-3031-1033-8772-888c81aea662"/><connectionmember id="abc6e440-3032-1033-a920-5ba881aea662" name="Connection7" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df56ec70-3031-1033-bcfa-229c81aea662"/><connectionmember id="abc6e440-3032-1033-ad02-f24881aea662" name="Connection8" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df571380-3031-1033-bf7a-cfe481aea662"/><connectionmember id="abc70b50-3032-1033-b86d-744b81aea662" name="Connection9" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df571380-3031-1033-8f2c-fc9c81aea662"/><connectionmember id="abc70b50-3032-1033-9bd8-f3dd81aea662" name="Connection10" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df571380-3031-1033-90f4-84dd81aea662"/><connectionmember id="abc73260-3032-1033-8809-c9b781aea662" name="Connection11" activityto="df4c3e10-3031-1033-9470-934881aea662" parameterfrom="df573a90-3031-1033-89cb-495081aea662"/><connectionmember id="abc73260-3032-1033-ab93-8e9a81aea662" name="Connection12" activityfrom="df4c3e10-3031-1033-9470-934881aea662" parameterto="df573a90-3031-1033-bbdb-7d4981aea662"/><connectionmember id="abc75970-3032-1033-8cce-4b5281aea662" name="Connection13" activityfrom="df4c3e10-3031-1033-9470-934881aea662" parameterto="df5761a0-3031-1033-a2da-632781aea662"/><connectionmember id="abc75970-3032-1033-a70e-5bd581aea662" name="Connection14" activityfrom="df4c3e10-3031-1033-9470-934881aea662" parameterto="df5788b0-3031-1033-9365-c0cc81aea662"/><connectionmember id="abc78080-3032-1033-9801-0be281aea662" name="Connection15" activityfrom="df4c3e10-3031-1033-9470-934881aea662" parameterto="df5788b0-3031-1033-bd87-819781aea662"/><connectionmember id="abc78080-3032-1033-b96b-080981aea662" name="Connection16" activityto="e5e982a0-3031-1033-8116-c28181aea662" parameterfrom="e5e9f7d0-3031-1033-a803-074081aea662"/><connectionmember id="abc7a790-3032-1033-8b50-d2b081aea662" name="Connection17" activityto="e5e982a0-3031-1033-8116-c28181aea662" parameterfrom="e5ea1ee0-3031-1033-b3e5-db9e81aea662"/><connectionmember id="abc7a790-3032-1033-8adc-5f2b81aea662" name="Connection18" activityfrom="e5e982a0-3031-1033-8116-c28181aea662" parameterto="e5ea45f0-3031-1033-bede-a6a081aea662"/><connectionmember id="abc7cea0-3032-1033-a900-d80381aea662" name="Connection19" activityto="e9dae110-3031-1033-9011-5a9181aea662" parameterfrom="e9db5640-3031-1033-a6b9-891781aea662"/><connectionmember id="abc7cea0-3032-1033-9a52-394e81aea662" name="Connection20" activityto="e9dae110-3031-1033-9011-5a9181aea662" parameterfrom="e9db7d50-3031-1033-a414-316a81aea662"/><connectionmember id="abc7f5b0-3032-1033-8022-d77f81aea662" name="Connection21" activityfrom="e9dae110-3031-1033-9011-5a9181aea662" parameterto="e9dba460-3031-1033-9876-0db481aea662"/><connectionmember id="abc7f5b0-3032-1033-94ec-726481aea662" name="Connection22" activityto="ec658390-3031-1033-9673-fa2b81aea662" parameterfrom="ec65d1b0-3031-1033-b1a4-2fe481aea662"/><connectionmember id="abc81cc0-3032-1033-9c5e-3ae781aea662" name="Connection23" activityto="ec658390-3031-1033-9673-fa2b81aea662" parameterfrom="ec65f8c0-3031-1033-b4d7-255e81aea662"/><connectionmember id="abc81cc0-3032-1033-85e0-42b681aea662" name="Connection24" activityfrom="ec658390-3031-1033-9673-fa2b81aea662" parameterto="ec65f8c0-3031-1033-ae4c-7b3781aea662"/><connectionmember id="abc843d0-3032-1033-849e-4ef281aea662" name="Connection25" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4f9b620-3031-1033-ad4a-890281aea662"/><connectionmember id="abc843d0-3032-1033-a198-645781aea662" name="Connection26" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4f9dd30-3031-1033-bd04-e64581aea662"/><connectionmember id="abc86ae0-3032-1033-a8d4-cd3281aea662" name="Connection27" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4fa0440-3031-1033-9a82-1a5381aea662"/><connectionmember id="abc86ae0-3032-1033-bb21-b4d581aea662" name="Connection28" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4fa0440-3031-1033-8c36-773f81aea662"/><connectionmember id="abc891f0-3032-1033-82d9-523681aea662" name="Connection29" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4fa2b50-3031-1033-88f6-422681aea662"/><connectionmember id="abc891f0-3032-1033-b528-ed9f81aea662" name="Connection30" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4fa5260-3031-1033-9dba-6b6d81aea662"/><connectionmember id="abc891f0-3032-1033-8fd2-7f6381aea662" name="Connection31" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4fa5260-3031-1033-a29f-280581aea662"/><connectionmember id="abc8b900-3032-1033-af35-383d81aea662" name="Connection32" activityto="f4f96800-3031-1033-94a9-38cf81aea662" parameterfrom="f4fa7970-3031-1033-945d-90f881aea662"/><connectionmember id="abc8b900-3032-1033-afd7-84b681aea662" name="Connection33" activityfrom="f4f96800-3031-1033-94a9-38cf81aea662" parameterto="f4faa080-3031-1033-a65a-5b6081aea662"/><connectionmember id="abc8e010-3032-1033-8d0d-3beb81aea662" name="Connection34" parameterfrom="ec65f8c0-3031-1033-ae4c-7b3781aea662" parameterto="f4f9b620-3031-1033-ad4a-890281aea662"/><connectionmember id="abc8e010-3032-1033-ae93-507481aea662" name="Connection35" parameterfrom="df55db00-3031-1033-befa-145e81aea662" parameterto="f4f9dd30-3031-1033-bd04-e64581aea662"/><connectionmember id="abc90720-3032-1033-b61f-f16f81aea662" name="Connection36" parameterfrom="e9dba460-3031-1033-9876-0db481aea662" parameterto="ec65d1b0-3031-1033-b1a4-2fe481aea662"/><connectionmember id="abc90720-3032-1033-ae4f-61d781aea662" name="Connection37" parameterfrom="e5ea45f0-3031-1033-bede-a6a081aea662" parameterto="e9db5640-3031-1033-a6b9-891781aea662"/><connectionmember id="abc90720-3032-1033-8336-cfa281aea662" name="Connection38" parameterfrom="df5761a0-3031-1033-a2da-632781aea662" parameterto="e5e9f7d0-3031-1033-a803-074081aea662"/><connectionmember id="abc92e30-3032-1033-9f5a-4d0c81aea662" name="Connection39" parameterfrom="e5ea1ee0-3031-1033-b3e5-db9e81aea662" parameterto="e9db7d50-3031-1033-a414-316a81aea662"/><connectionmember id="abc92e30-3032-1033-a9d2-de1981aea662" name="Connection40" parameterfrom="df571380-3031-1033-90f4-84dd81aea662" parameterto="e5ea1ee0-3031-1033-b3e5-db9e81aea662"/><connectionmember id="abc95540-3032-1033-a86d-15f681aea662" name="Connection41" parameterfrom="df5761a0-3031-1033-a2da-632781aea662" parameterto="f4fa0440-3031-1033-9a82-1a5381aea662"/></connectionmembers></logicprocess>', '', 'pacs', 'Automatic classification', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(38, 'urn:uuid:bb2f5a10-3bdc-1033-be02-03ab81aea662', 'PACS', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/PACS" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:bb2f5a10-3bdc-1033-be02-03ab81aea662" name="PACS" author="Ziheng Sun" date="2015-09-11-04:00" desc="Description"/><modeloutput parameter="5dd46d10-3bdc-1033-92dd-cdd281aea662" keywords=""/><activitymembers><activitymember id="4420af00-3bdc-1033-bd9e-d72b81aea662" name="segment" operation="segment" servicetype="segment"/><activitymember id="4ba434e0-3bdc-1033-9009-ca4a81aea662" name="rgb2singlevalue" operation="rgb2singlevalue" servicetype="rgb2singlevalue"/><activitymember id="4d43b410-3bdc-1033-a267-8a9681aea662" name="eliminate_smallpolygons" operation="eliminate_smallpolygons" servicetype="eliminate_smallpolygons"/><activitymember id="51179f70-3bdc-1033-82c8-370781aea662" name="r2v" operation="r2v" servicetype="r2v"/><activitymember id="5dd30d80-3bdc-1033-b343-002881aea662" name="classify" operation="classify" servicetype="classify"/></activitymembers><parametermembers><parametermember id="4431c600-3bdc-1033-a89d-4ab281aea662" name="imgURL" type="input" datatype="imgURL" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44323b30-3bdc-1033-98e8-cd1781aea662" name="sigmaS" type="input" datatype="sigmaS" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44326240-3bdc-1033-9872-06c681aea662" name="sigmaR" type="input" datatype="sigmaR" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44328950-3bdc-1033-aaf1-69c581aea662" name="minRegion" type="input" datatype="minRegion" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4432b060-3bdc-1033-b67e-83a881aea662" name="speedUpLevel" type="input" datatype="speedUpLevel" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4432d770-3bdc-1033-b3a7-6c4781aea662" name="speedUpThreshold" type="input" datatype="speedUpThreshold" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4432fe80-3bdc-1033-a1b1-e36f81aea662" name="checkWeightMap" type="input" datatype="checkWeightMap" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44332590-3bdc-1033-bbc0-de0c81aea662" name="gradientWindow" type="input" datatype="gradientWindow" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44334ca0-3bdc-1033-b99a-81ba81aea662" name="blendVar" type="input" datatype="blendVar" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="443373b0-3bdc-1033-970c-a69481aea662" name="threshold" type="input" datatype="threshold" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="443373b0-3bdc-1033-b587-5f6d81aea662" name="returnFormat" type="input" datatype="returnFormat" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44339ac0-3bdc-1033-b1fb-9fad81aea662" name="sigmaS2" type="input" datatype="sigmaS2" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4433c1d0-3bdc-1033-8491-5aef81aea662" name="filter_imgURL" type="output" datatype="filter_imgURL" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4433e8e0-3bdc-1033-8032-fb2b81aea662" name="fusion_imgURL" type="output" datatype="fusion_imgURL" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4433e8e0-3bdc-1033-bffa-b09f81aea662" name="seg_imgURL" type="output" datatype="seg_imgURL" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="44340ff0-3bdc-1033-8896-9c2681aea662" name="boundary_imgURL" type="output" datatype="boundary_imgURL" activity="4420af00-3bdc-1033-bd9e-d72b81aea662"/><parametermember id="4ba45bf0-3bdc-1033-af92-ed5681aea662" name="imgURL" type="input" datatype="imgURL" activity="4ba434e0-3bdc-1033-9009-ca4a81aea662"/><parametermember id="4ba45bf0-3bdc-1033-bc8b-dbff81aea662" name="returnformat" type="input" datatype="returnformat" activity="4ba434e0-3bdc-1033-9009-ca4a81aea662"/><parametermember id="4ba48300-3bdc-1033-bee3-683781aea662" name="returnURL" type="output" datatype="returnURL" activity="4ba434e0-3bdc-1033-9009-ca4a81aea662"/><parametermember id="4d43db20-3bdc-1033-beb3-167f81aea662" name="imgURL" type="input" datatype="imgURL" activity="4d43b410-3bdc-1033-a267-8a9681aea662"/><parametermember id="4d440230-3bdc-1033-8bc1-140681aea662" name="returnformat" type="input" datatype="returnformat" activity="4d43b410-3bdc-1033-a267-8a9681aea662"/><parametermember id="4d442940-3bdc-1033-9730-27f581aea662" name="returnURL" type="output" datatype="returnURL" activity="4d43b410-3bdc-1033-a267-8a9681aea662"/><parametermember id="5117ed90-3bdc-1033-b877-53a081aea662" name="imgURL" type="input" datatype="imgURL" activity="51179f70-3bdc-1033-82c8-370781aea662"/><parametermember id="5117ed90-3bdc-1033-87ac-066481aea662" name="returnformat" type="input" datatype="returnformat" activity="51179f70-3bdc-1033-82c8-370781aea662"/><parametermember id="511814a0-3bdc-1033-b724-3a8c81aea662" name="returnURL" type="output" datatype="returnURL" activity="51179f70-3bdc-1033-82c8-370781aea662"/><parametermember id="5dd35ba0-3bdc-1033-868c-301781aea662" name="vectorURL" type="input" datatype="vectorURL" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd382b0-3bdc-1033-bb84-4ac381aea662" name="rasterURL" type="input" datatype="rasterURL" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd382b0-3bdc-1033-bc4d-d29e81aea662" name="segURL" type="input" datatype="segURL" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd3a9c0-3bdc-1033-937d-a25281aea662" name="classhierarchy" type="input" datatype="classhierarchy" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd3f7e0-3bdc-1033-af9d-9f5781aea662" name="featurespace" type="input" datatype="featurespace" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd3f7e0-3bdc-1033-abe5-243c81aea662" name="k" type="input" datatype="k" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd41ef0-3bdc-1033-947b-95e481aea662" name="unclassfied" type="input" datatype="unclassfied" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd44600-3bdc-1033-b0ac-9eff81aea662" name="threshold" type="input" datatype="threshold" activity="5dd30d80-3bdc-1033-b343-002881aea662"/><parametermember id="5dd46d10-3bdc-1033-92dd-cdd281aea662" name="returnVURL" type="output" datatype="returnVURL" activity="5dd30d80-3bdc-1033-b343-002881aea662"/></parametermembers><connectionmembers><connectionmember id="a02051c0-3bdc-1033-8abc-035681aea662" name="Connection0" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="4431c600-3bdc-1033-a89d-4ab281aea662"/><connectionmember id="a02078d0-3bdc-1033-ae7d-9fb381aea662" name="Connection1" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="44323b30-3bdc-1033-98e8-cd1781aea662"/><connectionmember id="a0209fe0-3bdc-1033-9bbb-ca1281aea662" name="Connection2" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="44326240-3bdc-1033-9872-06c681aea662"/><connectionmember id="a0209fe0-3bdc-1033-8b50-5c0481aea662" name="Connection3" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="44328950-3bdc-1033-aaf1-69c581aea662"/><connectionmember id="a020c6f0-3bdc-1033-b621-a71c81aea662" name="Connection4" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="4432b060-3bdc-1033-b67e-83a881aea662"/><connectionmember id="a020c6f0-3bdc-1033-8714-b20b81aea662" name="Connection5" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="4432d770-3bdc-1033-b3a7-6c4781aea662"/><connectionmember id="a020c6f0-3bdc-1033-ab9b-037881aea662" name="Connection6" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="4432fe80-3bdc-1033-a1b1-e36f81aea662"/><connectionmember id="a020c6f0-3bdc-1033-bc66-644481aea662" name="Connection7" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="44332590-3bdc-1033-bbc0-de0c81aea662"/><connectionmember id="a020ee00-3bdc-1033-957c-d20f81aea662" name="Connection8" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="44334ca0-3bdc-1033-b99a-81ba81aea662"/><connectionmember id="a020ee00-3bdc-1033-957f-25a081aea662" name="Connection9" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="443373b0-3bdc-1033-970c-a69481aea662"/><connectionmember id="a020ee00-3bdc-1033-89a3-b73181aea662" name="Connection10" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="443373b0-3bdc-1033-b587-5f6d81aea662"/><connectionmember id="a0211510-3bdc-1033-9e31-cec781aea662" name="Connection11" activityto="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterfrom="44339ac0-3bdc-1033-b1fb-9fad81aea662"/><connectionmember id="a0211510-3bdc-1033-8e05-2ba881aea662" name="Connection12" activityfrom="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterto="4433c1d0-3bdc-1033-8491-5aef81aea662"/><connectionmember id="a0211510-3bdc-1033-b726-9f2b81aea662" name="Connection13" activityfrom="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterto="4433e8e0-3bdc-1033-8032-fb2b81aea662"/><connectionmember id="a0211510-3bdc-1033-a3e0-b0b281aea662" name="Connection14" activityfrom="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterto="4433e8e0-3bdc-1033-bffa-b09f81aea662"/><connectionmember id="a0213c20-3bdc-1033-b27a-0a2581aea662" name="Connection15" activityfrom="4420af00-3bdc-1033-bd9e-d72b81aea662" parameterto="44340ff0-3bdc-1033-8896-9c2681aea662"/><connectionmember id="a0213c20-3bdc-1033-af24-928681aea662" name="Connection16" activityto="4ba434e0-3bdc-1033-9009-ca4a81aea662" parameterfrom="4ba45bf0-3bdc-1033-af92-ed5681aea662"/><connectionmember id="a0213c20-3bdc-1033-a459-4a1b81aea662" name="Connection17" activityto="4ba434e0-3bdc-1033-9009-ca4a81aea662" parameterfrom="4ba45bf0-3bdc-1033-bc8b-dbff81aea662"/><connectionmember id="a0213c20-3bdc-1033-bd4a-fef681aea662" name="Connection18" activityfrom="4ba434e0-3bdc-1033-9009-ca4a81aea662" parameterto="4ba48300-3bdc-1033-bee3-683781aea662"/><connectionmember id="a0216330-3bdc-1033-93e1-7f5081aea662" name="Connection19" activityto="4d43b410-3bdc-1033-a267-8a9681aea662" parameterfrom="4d43db20-3bdc-1033-beb3-167f81aea662"/><connectionmember id="a0216330-3bdc-1033-bdb1-856881aea662" name="Connection20" activityto="4d43b410-3bdc-1033-a267-8a9681aea662" parameterfrom="4d440230-3bdc-1033-8bc1-140681aea662"/><connectionmember id="a0216330-3bdc-1033-9891-bb2a81aea662" name="Connection21" activityfrom="4d43b410-3bdc-1033-a267-8a9681aea662" parameterto="4d442940-3bdc-1033-9730-27f581aea662"/><connectionmember id="a0216330-3bdc-1033-b536-80ac81aea662" name="Connection22" activityto="51179f70-3bdc-1033-82c8-370781aea662" parameterfrom="5117ed90-3bdc-1033-b877-53a081aea662"/><connectionmember id="a0218a40-3bdc-1033-9dba-67b081aea662" name="Connection23" activityto="51179f70-3bdc-1033-82c8-370781aea662" parameterfrom="5117ed90-3bdc-1033-87ac-066481aea662"/><connectionmember id="a0218a40-3bdc-1033-8830-c65281aea662" name="Connection24" activityfrom="51179f70-3bdc-1033-82c8-370781aea662" parameterto="511814a0-3bdc-1033-b724-3a8c81aea662"/><connectionmember id="a0218a40-3bdc-1033-a9c6-dec581aea662" name="Connection25" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd35ba0-3bdc-1033-868c-301781aea662"/><connectionmember id="a0218a40-3bdc-1033-8013-8d9781aea662" name="Connection26" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd382b0-3bdc-1033-bb84-4ac381aea662"/><connectionmember id="a021b150-3bdc-1033-8150-8ce781aea662" name="Connection27" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd382b0-3bdc-1033-bc4d-d29e81aea662"/><connectionmember id="a021b150-3bdc-1033-9ffe-80ae81aea662" name="Connection28" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd3a9c0-3bdc-1033-937d-a25281aea662"/><connectionmember id="a021b150-3bdc-1033-8828-bdf681aea662" name="Connection29" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd3f7e0-3bdc-1033-af9d-9f5781aea662"/><connectionmember id="a021b150-3bdc-1033-8321-d63681aea662" name="Connection30" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd3f7e0-3bdc-1033-abe5-243c81aea662"/><connectionmember id="a021d860-3bdc-1033-896f-230681aea662" name="Connection31" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd41ef0-3bdc-1033-947b-95e481aea662"/><connectionmember id="a021d860-3bdc-1033-8755-099281aea662" name="Connection32" activityto="5dd30d80-3bdc-1033-b343-002881aea662" parameterfrom="5dd44600-3bdc-1033-b0ac-9eff81aea662"/><connectionmember id="a021d860-3bdc-1033-bd1f-091b81aea662" name="Connection33" activityfrom="5dd30d80-3bdc-1033-b343-002881aea662" parameterto="5dd46d10-3bdc-1033-92dd-cdd281aea662"/><connectionmember id="a021d860-3bdc-1033-88c4-c60681aea662" name="Connection34" parameterfrom="511814a0-3bdc-1033-b724-3a8c81aea662" parameterto="5dd35ba0-3bdc-1033-868c-301781aea662"/><connectionmember id="a021ff70-3bdc-1033-9e44-cddb81aea662" name="Connection35" parameterfrom="4d442940-3bdc-1033-9730-27f581aea662" parameterto="5117ed90-3bdc-1033-b877-53a081aea662"/><connectionmember id="a021ff70-3bdc-1033-ba93-c69981aea662" name="Connection36" parameterfrom="4ba48300-3bdc-1033-bee3-683781aea662" parameterto="4d43db20-3bdc-1033-beb3-167f81aea662"/><connectionmember id="a021ff70-3bdc-1033-9826-368e81aea662" name="Connection37" parameterfrom="4433e8e0-3bdc-1033-8032-fb2b81aea662" parameterto="4ba45bf0-3bdc-1033-af92-ed5681aea662"/><connectionmember id="a021ff70-3bdc-1033-951f-b82881aea662" name="Connection38" parameterfrom="4431c600-3bdc-1033-a89d-4ab281aea662" parameterto="5dd382b0-3bdc-1033-bb84-4ac381aea662"/><connectionmember id="a0222680-3bdc-1033-b0fd-f76381aea662" name="Connection39" parameterfrom="4d442940-3bdc-1033-9730-27f581aea662" parameterto="5dd382b0-3bdc-1033-bc4d-d29e81aea662"/><connectionmember id="a0222680-3bdc-1033-a7ea-ec9181aea662" name="Connection40" parameterfrom="443373b0-3bdc-1033-b587-5f6d81aea662" parameterto="4ba45bf0-3bdc-1033-bc8b-dbff81aea662"/><connectionmember id="a0222680-3bdc-1033-a4d5-82c081aea662" name="Connection41" parameterfrom="4ba45bf0-3bdc-1033-bc8b-dbff81aea662" parameterto="4d440230-3bdc-1033-8bc1-140681aea662"/></connectionmembers></logicprocess>', '', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(42, 'urn:uuid:287c10c0-55e3-1033-be58-498081aea662', 'workflow1', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/workflow1" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:287c10c0-55e3-1033-be58-498081aea662" name="workflow1" author="Ziheng Sun" date="2015-10-14-04:00" desc="Description"/><modeloutput parameter="1e638820-55e3-1033-bc33-b5b981aea662" keywords=""/><activitymembers><activitymember id="1d249f80-55e3-1033-82c5-078f81aea662" name="r2v" operation="r2v" servicetype="r2v"/><activitymember id="1e62c4d0-55e3-1033-9298-b89781aea662" name="remove" operation="remove" servicetype="remove"/></activitymembers><parametermembers><parametermember id="1d2a1dc0-55e3-1033-9061-3bdd81aea662" name="imgURL" type="input" datatype="imgURL" activity="1d249f80-55e3-1033-82c5-078f81aea662"/><parametermember id="1d2a6be0-55e3-1033-b131-a3af81aea662" name="returnformat" type="input" datatype="returnformat" activity="1d249f80-55e3-1033-82c5-078f81aea662"/><parametermember id="1d2aba00-55e3-1033-95a7-5b2b81aea662" name="returnURL" type="output" datatype="returnURL" activity="1d249f80-55e3-1033-82c5-078f81aea662"/><parametermember id="1e62ebe0-55e3-1033-b267-36c481aea662" name="sourceURL" type="input" datatype="sourceURL" activity="1e62c4d0-55e3-1033-9298-b89781aea662"/><parametermember id="1e633a00-55e3-1033-92dd-375381aea662" name="min_area" type="input" datatype="min_area" activity="1e62c4d0-55e3-1033-9298-b89781aea662"/><parametermember id="1e638820-55e3-1033-bc33-b5b981aea662" name="returnURL" type="output" datatype="returnURL" activity="1e62c4d0-55e3-1033-9298-b89781aea662"/><parametermember id="1e63af30-55e3-1033-a846-2b3281aea662" name="returnFormat" type="output" datatype="returnFormat" activity="1e62c4d0-55e3-1033-9298-b89781aea662"/></parametermembers><connectionmembers><connectionmember id="208b7130-55e3-1033-8fc2-e54b81aea662" name="Connection0" activityto="1d249f80-55e3-1033-82c5-078f81aea662" parameterfrom="1d2a1dc0-55e3-1033-9061-3bdd81aea662"/><connectionmember id="208b9840-55e3-1033-954b-0d4d81aea662" name="Connection1" activityto="1d249f80-55e3-1033-82c5-078f81aea662" parameterfrom="1d2a6be0-55e3-1033-b131-a3af81aea662"/><connectionmember id="208bbf50-55e3-1033-bbe8-2da881aea662" name="Connection2" activityfrom="1d249f80-55e3-1033-82c5-078f81aea662" parameterto="1d2aba00-55e3-1033-95a7-5b2b81aea662"/><connectionmember id="208bbf50-55e3-1033-8b34-8a1081aea662" name="Connection3" activityto="1e62c4d0-55e3-1033-9298-b89781aea662" parameterfrom="1e62ebe0-55e3-1033-b267-36c481aea662"/><connectionmember id="208bbf50-55e3-1033-a717-d60381aea662" name="Connection4" activityto="1e62c4d0-55e3-1033-9298-b89781aea662" parameterfrom="1e633a00-55e3-1033-92dd-375381aea662"/><connectionmember id="208be660-55e3-1033-bbed-c7cb81aea662" name="Connection5" activityfrom="1e62c4d0-55e3-1033-9298-b89781aea662" parameterto="1e638820-55e3-1033-bc33-b5b981aea662"/><connectionmember id="208be660-55e3-1033-9956-cb0781aea662" name="Connection6" activityfrom="1e62c4d0-55e3-1033-9298-b89781aea662" parameterto="1e63af30-55e3-1033-a846-2b3281aea662"/><connectionmember id="208c0d70-55e3-1033-a6f9-70c681aea662" name="Connection7" parameterfrom="1d2aba00-55e3-1033-95a7-5b2b81aea662" parameterto="1e62ebe0-55e3-1033-b267-36c481aea662"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd"><objectlocation><id>1d249f80-55e3-1033-82c5-078f81aea662</id><type>0</type><name>r2v</name><description>null</description><x>326.0</x><y>407.0</y></objectlocation><objectlocation><id>1d2a1dc0-55e3-1033-9061-3bdd81aea662</id><type>1</type><name>imgURL</name><description>DataType:imgURL</description><x>282.0</x><y>484.0</y></objectlocation><objectlocation><id>1d2a6be0-55e3-1033-b131-a3af81aea662</id><type>1</type><name>returnformat</name><description>DataType:returnformat</description><x>371.0</x><y>484.0</y></objectlocation><objectlocation><id>1d2aba00-55e3-1033-95a7-5b2b81aea662</id><type>1</type><name>returnURL</name><description>DataType: returnURL</description><x>326.0</x><y>318.0</y></objectlocation><objectlocation><id>1e62c4d0-55e3-1033-9298-b89781aea662</id><type>0</type><name>remove</name><description>null</description><x>266.0</x><y>115.0</y></objectlocation><objectlocation><id>1e62ebe0-55e3-1033-b267-36c481aea662</id><type>1</type><name>sourceURL</name><description>DataType:sourceURL</description><x>222.0</x><y>192.0</y></objectlocation><objectlocation><id>1e633a00-55e3-1033-92dd-375381aea662</id><type>1</type><name>min_area</name><description>DataType:min_area</description><x>311.0</x><y>192.0</y></objectlocation><objectlocation><id>1e638820-55e3-1033-bc33-b5b981aea662</id><type>1</type><name>returnURL</name><description>DataType: returnURL</description><x>222.0</x><y>38.0</y></objectlocation><objectlocation><id>1e63af30-55e3-1033-a846-2b3281aea662</id><type>1</type><name>returnFormat</name><description>DataType: returnFormat</description><x>311.0</x><y>38.0</y></objectlocation></parameterconnection>', '', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(44, 'urn:uuid:55918540-56ab-1033-a3e4-942e81aea662', 'FVCOM_River_input', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\n<logicprocess version="2.0"\n	targetnamespace="http://csiss.gmu.edu/lpm2/object/FVCOM_River_input"\n	xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd">\n	<modelmetadata id="urn:uuid:55918540-56ab-1033-a3e4-942e81aea662"\n		name="FVCOM_River_input" author="Ziheng Sun" date="2015-10-15-04:00"\n		desc="Description" />\n	<modeloutput parameter="86f60cd0-56a8-1033-bd58-466e81aea662"\n		keywords="river, usgs, fvcom" />\n	<activitymembers>\n		<activitymember id="18c631e0-56a8-1033-890b-ecc281aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="19e647e0-56a8-1033-b790-bc3381aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="24d00330-56a8-1033-b74c-cc0681aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="2755eac0-56a8-1033-a7d1-3b4281aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			name="GMT_Check" operation="GMT_Check" servicetype="GMT_Check" />\n		<activitymember id="355c2850-56a8-1033-b330-0d3681aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="361d0750-56a8-1033-89bb-9ceb81aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="3c2cb1e0-56a8-1033-bde6-38b781aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="3ce74f50-56a8-1033-a85d-fe0381aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="48d7f350-56a8-1033-80f0-1ea181aea662"\n			name="GMT_Check" operation="GMT_Check" servicetype="GMT_Check" />\n		<activitymember id="53d6e450-56a8-1033-ad65-69ed81aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="54f832d0-56a8-1033-b08f-4dc881aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="5ada8bd0-56a8-1033-aed4-161a81aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="5bb3d4d0-56a8-1033-a029-4c1481aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			name="GMT_Check" operation="GMT_Check" servicetype="GMT_Check" />\n		<activitymember id="6da55650-56a8-1033-b499-2f0c81aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="6f027550-56a8-1033-8166-87a181aea662"\n			name="Generate_River_USGS_links" operation="Generate_River_USGS_links"\n			servicetype="Generate_River_USGS_links" />\n		<activitymember id="74d3b750-56a8-1033-9cc8-de3081aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="78bcb150-56a8-1033-af81-fb3f81aea662"\n			name="CDT_and_CST_to_GMT" operation="CDT_and_CST_to_GMT" servicetype="CDT_and_CST_to_GMT" />\n		<activitymember id="7de5a560-56a8-1033-895a-bbc881aea662"\n			name="GMT_Check" operation="GMT_Check" servicetype="GMT_Check" />\n		<activitymember id="86f4ad40-56a8-1033-8f03-b1e881aea662"\n			name="Write_River_FVCOM_Input" operation="Write_River_FVCOM_Input"\n			servicetype="Write_River_FVCOM_Input" />\n	</activitymembers>\n	<parametermembers>\n		<parametermember id="18cf80b0-56a8-1033-a018-cda981aea662"\n			name="year" type="input" datatype="year"\n			activity="18c631e0-56a8-1033-890b-ecc281aea662" />\n		<parametermember id="18cfced0-56a8-1033-90ea-801881aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="18c631e0-56a8-1033-890b-ecc281aea662" fixedvalue="07374525"\n			dataformat="string" exteriorname="missi_station" />\n		<parametermember id="18cff5e0-56a8-1033-a86f-1b5481aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="18c631e0-56a8-1033-890b-ecc281aea662" fixedvalue="00065;00055;00060"\n			dataformat="string" exteriorname="miss_list" />\n		<parametermember id="18d01cf0-56a8-1033-a6aa-0e3281aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="18c631e0-56a8-1033-890b-ecc281aea662" />\n		<parametermember id="19e66ef0-56a8-1033-8ccd-b36181aea662"\n			name="year" type="input" datatype="year"\n			activity="19e647e0-56a8-1033-b790-bc3381aea662" />\n		<parametermember id="19e69600-56a8-1033-bfba-c95381aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="19e647e0-56a8-1033-b790-bc3381aea662" />\n		<parametermember id="19e6e420-56a8-1033-9068-412e81aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="19e647e0-56a8-1033-b790-bc3381aea662" />\n		<parametermember id="19e70b30-56a8-1033-a51e-90e781aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="19e647e0-56a8-1033-b790-bc3381aea662" />\n		<parametermember id="24d05150-56a8-1033-97e9-88a681aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="24d00330-56a8-1033-b74c-cc0681aea662" />\n		<parametermember id="24d05150-56a8-1033-832b-c87181aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="24d00330-56a8-1033-b74c-cc0681aea662" fixedvalue="missi"\n			dataformat="string" exteriorname="missi_name" />\n		<parametermember id="24d05150-56a8-1033-bd90-cf1781aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="24d00330-56a8-1033-b74c-cc0681aea662" />\n		<parametermember id="275611d0-56a8-1033-b5bb-6e9f81aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="2755eac0-56a8-1033-a7d1-3b4281aea662" />\n		<parametermember id="275638e0-56a8-1033-a385-3a9881aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="2755eac0-56a8-1033-a7d1-3b4281aea662" />\n		<parametermember id="27565ff0-56a8-1033-b6b0-236681aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="2755eac0-56a8-1033-a7d1-3b4281aea662" />\n		<parametermember id="2c97e510-56a8-1033-a9bc-11d381aea662"\n			name="GMT_file_URL" type="input" datatype="GMT_file_URL"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c980c20-56a8-1033-93a5-34b681aea662"\n			name="last_year_GMT_file_URL" type="input" datatype="last_year_GMT_file_URL"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c983330-56a8-1033-9ad4-30a181aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c985a40-56a8-1033-b42e-ecce81aea662"\n			name="year" type="input" datatype="year"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c988150-56a8-1033-a481-204981aea662"\n			name="GMT_DAT_URL" type="output" datatype="GMT_DAT_URL"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c98a860-56a8-1033-af1e-e4af81aea662"\n			name="Report_DAT_URL" type="output" datatype="Report_DAT_URL"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c98cf70-56a8-1033-aacf-152c81aea662"\n			name="Check_DAT_URL" type="output" datatype="Check_DAT_URL"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="2c98f680-56a8-1033-b639-696381aea662"\n			name="No_NAN_DAT_URL" type="output" datatype="No_NAN_DAT_URL"\n			activity="2c976fe0-56a8-1033-a1f0-7fea81aea662" />\n		<parametermember id="355c9d80-56a8-1033-beb9-50d081aea662"\n			name="year" type="input" datatype="year"\n			activity="355c2850-56a8-1033-b330-0d3681aea662" />\n		<parametermember id="355cc490-56a8-1033-abc2-8b0b81aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="355c2850-56a8-1033-b330-0d3681aea662" fixedvalue="07381590"\n			dataformat="string" exteriorname="wax_station" />\n		<parametermember id="355ceba0-56a8-1033-bca9-bea281aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="355c2850-56a8-1033-b330-0d3681aea662" fixedvalue="00065;00060"\n			dataformat="string" exteriorname="wax_list" />\n		<parametermember id="355d12b0-56a8-1033-9753-6bc981aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="355c2850-56a8-1033-b330-0d3681aea662" />\n		<parametermember id="361d5570-56a8-1033-92d4-b0e481aea662"\n			name="year" type="input" datatype="year"\n			activity="361d0750-56a8-1033-89bb-9ceb81aea662" />\n		<parametermember id="361d7c80-56a8-1033-bf9b-d95581aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="361d0750-56a8-1033-89bb-9ceb81aea662" />\n		<parametermember id="361da390-56a8-1033-8fc3-ad5c81aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="361d0750-56a8-1033-89bb-9ceb81aea662" />\n		<parametermember id="361dcaa0-56a8-1033-9d96-075b81aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="361d0750-56a8-1033-89bb-9ceb81aea662" />\n		<parametermember id="3c2d0000-56a8-1033-b63e-868b81aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="3c2cb1e0-56a8-1033-bde6-38b781aea662" />\n		<parametermember id="3c2d2710-56a8-1033-8172-b30581aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="3c2cb1e0-56a8-1033-bde6-38b781aea662" fixedvalue="wax"\n			dataformat="string" exteriorname="wax_name" />\n		<parametermember id="3c2d4e20-56a8-1033-9459-f5d081aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="3c2cb1e0-56a8-1033-bde6-38b781aea662" />\n		<parametermember id="3ce77660-56a8-1033-8822-034d81aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="3ce74f50-56a8-1033-a85d-fe0381aea662" />\n		<parametermember id="3ce7c480-56a8-1033-b10b-f66581aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="3ce74f50-56a8-1033-a85d-fe0381aea662" />\n		<parametermember id="3ce7eb90-56a8-1033-ad09-80dc81aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="3ce74f50-56a8-1033-a85d-fe0381aea662" />\n		<parametermember id="48d84170-56a8-1033-9fbd-818981aea662"\n			name="GMT_file_URL" type="input" datatype="GMT_file_URL"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d86880-56a8-1033-adbb-ec0a81aea662"\n			name="last_year_GMT_file_URL" type="input" datatype="last_year_GMT_file_URL"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d88f90-56a8-1033-b266-414f81aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d8b6a0-56a8-1033-af84-458081aea662"\n			name="year" type="input" datatype="year"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d8b6a0-56a8-1033-af59-bf5d81aea662"\n			name="GMT_DAT_URL" type="output" datatype="GMT_DAT_URL"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d8ddb0-56a8-1033-9be1-ee2c81aea662"\n			name="Report_DAT_URL" type="output" datatype="Report_DAT_URL"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d904c0-56a8-1033-8786-34db81aea662"\n			name="Check_DAT_URL" type="output" datatype="Check_DAT_URL"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="48d92bd0-56a8-1033-8215-e9f581aea662"\n			name="No_NAN_DAT_URL" type="output" datatype="No_NAN_DAT_URL"\n			activity="48d7f350-56a8-1033-80f0-1ea181aea662" />\n		<parametermember id="53d75980-56a8-1033-97e3-098481aea662"\n			name="year" type="input" datatype="year"\n			activity="53d6e450-56a8-1033-ad65-69ed81aea662" />\n		<parametermember id="53d78090-56a8-1033-8d1a-805381aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="53d6e450-56a8-1033-ad65-69ed81aea662" />\n		<parametermember id="53d7a7a0-56a8-1033-8573-8d7c81aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="53d6e450-56a8-1033-ad65-69ed81aea662" />\n		<parametermember id="53d7ceb0-56a8-1033-860b-960581aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="53d6e450-56a8-1033-ad65-69ed81aea662" />\n		<parametermember id="54f859e0-56a8-1033-8318-5f6f81aea662"\n			name="year" type="input" datatype="year"\n			activity="54f832d0-56a8-1033-b08f-4dc881aea662" />\n		<parametermember id="54f880f0-56a8-1033-87cf-501881aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="54f832d0-56a8-1033-b08f-4dc881aea662" fixedvalue="07381600"\n			dataformat="string" exteriorname="atcha_station" />\n		<parametermember id="54f880f0-56a8-1033-9486-500681aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="54f832d0-56a8-1033-b08f-4dc881aea662" fixedvalue="00065;00060"\n			dataformat="string" exteriorname="atcha_list" />\n		<parametermember id="54f8a800-56a8-1033-9a7d-8f1e81aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="54f832d0-56a8-1033-b08f-4dc881aea662" />\n		<parametermember id="5adb0100-56a8-1033-9d2d-b12e81aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="5ada8bd0-56a8-1033-aed4-161a81aea662" />\n		<parametermember id="5adb2810-56a8-1033-b8a9-80eb81aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="5ada8bd0-56a8-1033-aed4-161a81aea662" />\n		<parametermember id="5adb2810-56a8-1033-a476-78dd81aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="5ada8bd0-56a8-1033-aed4-161a81aea662" />\n		<parametermember id="5bb3fbe0-56a8-1033-a32f-a75f81aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="5bb3d4d0-56a8-1033-a029-4c1481aea662" />\n		<parametermember id="5bb422f0-56a8-1033-914d-e93781aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="5bb3d4d0-56a8-1033-a029-4c1481aea662" fixedvalue="atcha"\n			dataformat="string" exteriorname="atcha_name" />\n		<parametermember id="5bb44a00-56a8-1033-89cc-7f5781aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="5bb3d4d0-56a8-1033-a029-4c1481aea662" />\n		<parametermember id="63e30400-56a8-1033-8a46-433a81aea662"\n			name="GMT_file_URL" type="input" datatype="GMT_file_URL"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e32b10-56a8-1033-8472-299781aea662"\n			name="last_year_GMT_file_URL" type="input" datatype="last_year_GMT_file_URL"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e35220-56a8-1033-9946-74e581aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e37930-56a8-1033-8ec3-05b081aea662"\n			name="year" type="input" datatype="year"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e3a040-56a8-1033-a8ac-4b9381aea662"\n			name="GMT_DAT_URL" type="output" datatype="GMT_DAT_URL"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e3c750-56a8-1033-8f3f-643e81aea662"\n			name="Report_DAT_URL" type="output" datatype="Report_DAT_URL"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e3c750-56a8-1033-93f4-c67b81aea662"\n			name="Check_DAT_URL" type="output" datatype="Check_DAT_URL"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="63e3ee60-56a8-1033-a1a5-b54181aea662"\n			name="No_NAN_DAT_URL" type="output" datatype="No_NAN_DAT_URL"\n			activity="63e28ed0-56a8-1033-8b5a-477a81aea662" />\n		<parametermember id="6da5cb80-56a8-1033-961e-400981aea662"\n			name="year" type="input" datatype="year"\n			activity="6da55650-56a8-1033-b499-2f0c81aea662" fixedvalue=""\n			dataformat="year" exteriorname="last_year" />\n		<parametermember id="6da5f290-56a8-1033-92cc-466781aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="6da55650-56a8-1033-b499-2f0c81aea662" />\n		<parametermember id="6da5f290-56a8-1033-9aef-5cb281aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="6da55650-56a8-1033-b499-2f0c81aea662" />\n		<parametermember id="6da619a0-56a8-1033-b0fe-c23181aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="6da55650-56a8-1033-b499-2f0c81aea662" />\n		<parametermember id="6f029c60-56a8-1033-a8a3-0b5f81aea662"\n			name="year" type="input" datatype="year"\n			activity="6f027550-56a8-1033-8166-87a181aea662" fixedvalue=""\n			dataformat="year" exteriorname="current_year" />\n		<parametermember id="6f02c370-56a8-1033-9e3c-83b681aea662"\n			name="stationid" type="input" datatype="stationid"\n			activity="6f027550-56a8-1033-8166-87a181aea662" fixedvalue="295124089542100"\n			dataformat="string" exteriorname="caern_station" />\n		<parametermember id="6f02ea80-56a8-1033-94ee-512d81aea662"\n			name="parameterlist" type="input" datatype="parameterlist"\n			activity="6f027550-56a8-1033-8166-87a181aea662" fixedvalue="00065; 00010;00060;00095;00480"\n			dataformat="string" exteriorname="caern_list" />\n		<parametermember id="6f031190-56a8-1033-ba3e-4dd981aea662"\n			name="river_originial_file_url" type="output" datatype="river_originial_file_url"\n			activity="6f027550-56a8-1033-8166-87a181aea662" />\n		<parametermember id="74d42c80-56a8-1033-beec-8f3a81aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="74d3b750-56a8-1033-9cc8-de3081aea662" />\n		<parametermember id="74d45390-56a8-1033-86b0-1e2881aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="74d3b750-56a8-1033-9cc8-de3081aea662" />\n		<parametermember id="74d47aa0-56a8-1033-b8b8-0ed081aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="74d3b750-56a8-1033-9cc8-de3081aea662" />\n		<parametermember id="78bd2680-56a8-1033-80cf-913681aea662"\n			name="original_file_URL" type="input" datatype="original_file_URL"\n			activity="78bcb150-56a8-1033-af81-fb3f81aea662" />\n		<parametermember id="78bd4d90-56a8-1033-939e-9cb481aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="78bcb150-56a8-1033-af81-fb3f81aea662" fixedvalue="caern"\n			dataformat="string" exteriorname="caern_name" />\n		<parametermember id="78bd74a0-56a8-1033-9ae3-9faa81aea662"\n			name="returnURL" type="output" datatype="returnURL"\n			activity="78bcb150-56a8-1033-af81-fb3f81aea662" />\n		<parametermember id="7de61a90-56a8-1033-b37c-606481aea662"\n			name="GMT_file_URL" type="input" datatype="GMT_file_URL"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de641a0-56a8-1033-bd62-278081aea662"\n			name="last_year_GMT_file_URL" type="input" datatype="last_year_GMT_file_URL"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de641a0-56a8-1033-9fe1-ad6681aea662"\n			name="rivername" type="input" datatype="rivername"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de668b0-56a8-1033-9376-cd5181aea662"\n			name="year" type="input" datatype="year"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de68fc0-56a8-1033-9dd7-4ebe81aea662"\n			name="GMT_DAT_URL" type="output" datatype="GMT_DAT_URL"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de68fc0-56a8-1033-9746-c65281aea662"\n			name="Report_DAT_URL" type="output" datatype="Report_DAT_URL"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de6b6d0-56a8-1033-9af3-37cb81aea662"\n			name="Check_DAT_URL" type="output" datatype="Check_DAT_URL"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="7de6b6d0-56a8-1033-a871-255e81aea662"\n			name="No_NAN_DAT_URL" type="output" datatype="No_NAN_DAT_URL"\n			activity="7de5a560-56a8-1033-895a-bbc881aea662" />\n		<parametermember id="86f57090-56a8-1033-a908-25b981aea662"\n			name="Caern_file_URL" type="input" datatype="Caern_file_URL"\n			activity="86f4ad40-56a8-1033-8f03-b1e881aea662" />\n		<parametermember id="86f597a0-56a8-1033-8360-7b3281aea662"\n			name="Atcha_file_URL" type="input" datatype="Atcha_file_URL"\n			activity="86f4ad40-56a8-1033-8f03-b1e881aea662" />\n		<parametermember id="86f5beb0-56a8-1033-98c4-4e1481aea662"\n			name="Missi_file_URL" type="input" datatype="Missi_file_URL"\n			activity="86f4ad40-56a8-1033-8f03-b1e881aea662" />\n		<parametermember id="86f5e5c0-56a8-1033-8aa4-935281aea662"\n			name="Wax_file_URL" type="input" datatype="Wax_file_URL"\n			activity="86f4ad40-56a8-1033-8f03-b1e881aea662" />\n		<parametermember id="86f60cd0-56a8-1033-bd58-466e81aea662"\n			name="River_FVCOM_Input_URL" type="output" datatype="River_FVCOM_Input_URL"\n			activity="86f4ad40-56a8-1033-8f03-b1e881aea662" />\n	</parametermembers>\n	<connectionmembers>\n		<connectionmember id="e7d1c6b0-56a9-1033-a8d7-7d3d81aea662"\n			name="Connection0" activityto="18c631e0-56a8-1033-890b-ecc281aea662"\n			parameterfrom="18cf80b0-56a8-1033-a018-cda981aea662" />\n		<connectionmember id="e7d23be0-56a9-1033-aea8-3c6381aea662"\n			name="Connection1" activityto="18c631e0-56a8-1033-890b-ecc281aea662"\n			parameterfrom="18cfced0-56a8-1033-90ea-801881aea662" />\n		<connectionmember id="e7d23be0-56a9-1033-b540-851b81aea662"\n			name="Connection2" activityto="18c631e0-56a8-1033-890b-ecc281aea662"\n			parameterfrom="18cff5e0-56a8-1033-a86f-1b5481aea662" />\n		<connectionmember id="e7d262f0-56a9-1033-be1d-556781aea662"\n			name="Connection3" activityfrom="18c631e0-56a8-1033-890b-ecc281aea662"\n			parameterto="18d01cf0-56a8-1033-a6aa-0e3281aea662" />\n		<connectionmember id="e7d28a00-56a9-1033-9221-47c281aea662"\n			name="Connection4" activityto="19e647e0-56a8-1033-b790-bc3381aea662"\n			parameterfrom="19e66ef0-56a8-1033-8ccd-b36181aea662" />\n		<connectionmember id="e7d28a00-56a9-1033-aa37-fbea81aea662"\n			name="Connection5" activityto="19e647e0-56a8-1033-b790-bc3381aea662"\n			parameterfrom="19e69600-56a8-1033-bfba-c95381aea662" />\n		<connectionmember id="e7d2b110-56a9-1033-b26f-788c81aea662"\n			name="Connection6" activityto="19e647e0-56a8-1033-b790-bc3381aea662"\n			parameterfrom="19e6e420-56a8-1033-9068-412e81aea662" />\n		<connectionmember id="e7d2b110-56a9-1033-a67a-969981aea662"\n			name="Connection7" activityfrom="19e647e0-56a8-1033-b790-bc3381aea662"\n			parameterto="19e70b30-56a8-1033-a51e-90e781aea662" />\n		<connectionmember id="e7d2d820-56a9-1033-97f4-502781aea662"\n			name="Connection8" activityto="24d00330-56a8-1033-b74c-cc0681aea662"\n			parameterfrom="24d05150-56a8-1033-97e9-88a681aea662" />\n		<connectionmember id="e7d2d820-56a9-1033-8c8d-9f2c81aea662"\n			name="Connection9" activityto="24d00330-56a8-1033-b74c-cc0681aea662"\n			parameterfrom="24d05150-56a8-1033-832b-c87181aea662" />\n		<connectionmember id="e7d2ff30-56a9-1033-8a8e-191881aea662"\n			name="Connection10" activityfrom="24d00330-56a8-1033-b74c-cc0681aea662"\n			parameterto="24d05150-56a8-1033-bd90-cf1781aea662" />\n		<connectionmember id="e7d2ff30-56a9-1033-8d8d-9d0481aea662"\n			name="Connection11" activityto="2755eac0-56a8-1033-a7d1-3b4281aea662"\n			parameterfrom="275611d0-56a8-1033-b5bb-6e9f81aea662" />\n		<connectionmember id="e7d32640-56a9-1033-b52b-f6c781aea662"\n			name="Connection12" activityto="2755eac0-56a8-1033-a7d1-3b4281aea662"\n			parameterfrom="275638e0-56a8-1033-a385-3a9881aea662" />\n		<connectionmember id="e7d32640-56a9-1033-af9a-523d81aea662"\n			name="Connection13" activityfrom="2755eac0-56a8-1033-a7d1-3b4281aea662"\n			parameterto="27565ff0-56a8-1033-b6b0-236681aea662" />\n		<connectionmember id="e7d34d50-56a9-1033-9c66-a00581aea662"\n			name="Connection14" parameterfrom="19e70b30-56a8-1033-a51e-90e781aea662"\n			parameterto="275611d0-56a8-1033-b5bb-6e9f81aea662" />\n		<connectionmember id="e7d34d50-56a9-1033-a4c3-82cd81aea662"\n			name="Connection15" parameterfrom="18d01cf0-56a8-1033-a6aa-0e3281aea662"\n			parameterto="24d05150-56a8-1033-97e9-88a681aea662" />\n		<connectionmember id="e7d37460-56a9-1033-a6a1-9b4681aea662"\n			name="Connection16" activityto="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterfrom="2c97e510-56a8-1033-a9bc-11d381aea662" />\n		<connectionmember id="e7d37460-56a9-1033-b6e2-9fb981aea662"\n			name="Connection17" activityto="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterfrom="2c980c20-56a8-1033-93a5-34b681aea662" />\n		<connectionmember id="e7d39b70-56a9-1033-9780-194081aea662"\n			name="Connection18" activityto="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterfrom="2c983330-56a8-1033-9ad4-30a181aea662" />\n		<connectionmember id="e7d3c280-56a9-1033-b7f0-065e81aea662"\n			name="Connection19" activityto="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterfrom="2c985a40-56a8-1033-b42e-ecce81aea662" />\n		<connectionmember id="e7d3e990-56a9-1033-b92f-2d2481aea662"\n			name="Connection20" activityfrom="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterto="2c988150-56a8-1033-a481-204981aea662" />\n		<connectionmember id="e7d3e990-56a9-1033-ac98-c27681aea662"\n			name="Connection21" activityfrom="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterto="2c98a860-56a8-1033-af1e-e4af81aea662" />\n		<connectionmember id="e7d410a0-56a9-1033-9116-d3a481aea662"\n			name="Connection22" activityfrom="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterto="2c98cf70-56a8-1033-aacf-152c81aea662" />\n		<connectionmember id="e7d410a0-56a9-1033-91a5-dca181aea662"\n			name="Connection23" activityfrom="2c976fe0-56a8-1033-a1f0-7fea81aea662"\n			parameterto="2c98f680-56a8-1033-b639-696381aea662" />\n		<connectionmember id="e7d437b0-56a9-1033-8174-20af81aea662"\n			name="Connection24" parameterfrom="24d05150-56a8-1033-bd90-cf1781aea662"\n			parameterto="2c97e510-56a8-1033-a9bc-11d381aea662" />\n		<connectionmember id="e7d437b0-56a9-1033-bdf8-ceb581aea662"\n			name="Connection25" parameterfrom="27565ff0-56a8-1033-b6b0-236681aea662"\n			parameterto="2c980c20-56a8-1033-93a5-34b681aea662" />\n		<connectionmember id="e7d45ec0-56a9-1033-b26f-6c0481aea662"\n			name="Connection26" activityto="355c2850-56a8-1033-b330-0d3681aea662"\n			parameterfrom="355c9d80-56a8-1033-beb9-50d081aea662" />\n		<connectionmember id="e7d485d0-56a9-1033-93ef-6ccb81aea662"\n			name="Connection27" activityto="355c2850-56a8-1033-b330-0d3681aea662"\n			parameterfrom="355cc490-56a8-1033-abc2-8b0b81aea662" />\n		<connectionmember id="e7d4ace0-56a9-1033-a4ce-599d81aea662"\n			name="Connection28" activityto="355c2850-56a8-1033-b330-0d3681aea662"\n			parameterfrom="355ceba0-56a8-1033-bca9-bea281aea662" />\n		<connectionmember id="e7d4ace0-56a9-1033-9be7-160081aea662"\n			name="Connection29" activityfrom="355c2850-56a8-1033-b330-0d3681aea662"\n			parameterto="355d12b0-56a8-1033-9753-6bc981aea662" />\n		<connectionmember id="e7d4d3f0-56a9-1033-b451-c81081aea662"\n			name="Connection30" activityto="361d0750-56a8-1033-89bb-9ceb81aea662"\n			parameterfrom="361d5570-56a8-1033-92d4-b0e481aea662" />\n		<connectionmember id="e7d4d3f0-56a9-1033-946f-926481aea662"\n			name="Connection31" activityto="361d0750-56a8-1033-89bb-9ceb81aea662"\n			parameterfrom="361d7c80-56a8-1033-bf9b-d95581aea662" />\n		<connectionmember id="e7d4fb00-56a9-1033-9272-304e81aea662"\n			name="Connection32" activityto="361d0750-56a8-1033-89bb-9ceb81aea662"\n			parameterfrom="361da390-56a8-1033-8fc3-ad5c81aea662" />\n		<connectionmember id="e7d4fb00-56a9-1033-988b-ed9f81aea662"\n			name="Connection33" activityfrom="361d0750-56a8-1033-89bb-9ceb81aea662"\n			parameterto="361dcaa0-56a8-1033-9d96-075b81aea662" />\n		<connectionmember id="e7d52210-56a9-1033-a437-078d81aea662"\n			name="Connection34" activityto="3c2cb1e0-56a8-1033-bde6-38b781aea662"\n			parameterfrom="3c2d0000-56a8-1033-b63e-868b81aea662" />\n		<connectionmember id="e7d52210-56a9-1033-8940-a42281aea662"\n			name="Connection35" activityto="3c2cb1e0-56a8-1033-bde6-38b781aea662"\n			parameterfrom="3c2d2710-56a8-1033-8172-b30581aea662" />\n		<connectionmember id="e7d54920-56a9-1033-879c-33f581aea662"\n			name="Connection36" activityfrom="3c2cb1e0-56a8-1033-bde6-38b781aea662"\n			parameterto="3c2d4e20-56a8-1033-9459-f5d081aea662" />\n		<connectionmember id="e7d54920-56a9-1033-af5f-15d481aea662"\n			name="Connection37" activityto="3ce74f50-56a8-1033-a85d-fe0381aea662"\n			parameterfrom="3ce77660-56a8-1033-8822-034d81aea662" />\n		<connectionmember id="e7d57030-56a9-1033-8106-586d81aea662"\n			name="Connection38" activityto="3ce74f50-56a8-1033-a85d-fe0381aea662"\n			parameterfrom="3ce7c480-56a8-1033-b10b-f66581aea662" />\n		<connectionmember id="e7d59740-56a9-1033-a4db-663181aea662"\n			name="Connection39" activityfrom="3ce74f50-56a8-1033-a85d-fe0381aea662"\n			parameterto="3ce7eb90-56a8-1033-ad09-80dc81aea662" />\n		<connectionmember id="e7d59740-56a9-1033-830e-861381aea662"\n			name="Connection40" parameterfrom="361dcaa0-56a8-1033-9d96-075b81aea662"\n			parameterto="3ce77660-56a8-1033-8822-034d81aea662" />\n		<connectionmember id="e7d5be50-56a9-1033-8967-659881aea662"\n			name="Connection41" parameterfrom="355d12b0-56a8-1033-9753-6bc981aea662"\n			parameterto="3c2d0000-56a8-1033-b63e-868b81aea662" />\n		<connectionmember id="e7d5be50-56a9-1033-90bf-f6e381aea662"\n			name="Connection42" activityto="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterfrom="48d84170-56a8-1033-9fbd-818981aea662" />\n		<connectionmember id="e7d5e560-56a9-1033-acb7-4bb881aea662"\n			name="Connection43" activityto="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterfrom="48d86880-56a8-1033-adbb-ec0a81aea662" />\n		<connectionmember id="e7d5e560-56a9-1033-9244-574781aea662"\n			name="Connection44" activityto="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterfrom="48d88f90-56a8-1033-b266-414f81aea662" />\n		<connectionmember id="e7d60c70-56a9-1033-972a-58a281aea662"\n			name="Connection45" activityto="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterfrom="48d8b6a0-56a8-1033-af84-458081aea662" />\n		<connectionmember id="e7d60c70-56a9-1033-a7c5-572881aea662"\n			name="Connection46" activityfrom="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterto="48d8b6a0-56a8-1033-af59-bf5d81aea662" />\n		<connectionmember id="e7d60c70-56a9-1033-8703-bf7081aea662"\n			name="Connection47" activityfrom="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterto="48d8ddb0-56a8-1033-9be1-ee2c81aea662" />\n		<connectionmember id="e7d60c70-56a9-1033-9a7f-849481aea662"\n			name="Connection48" activityfrom="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterto="48d904c0-56a8-1033-8786-34db81aea662" />\n		<connectionmember id="e7d63380-56a9-1033-b054-aa4c81aea662"\n			name="Connection49" activityfrom="48d7f350-56a8-1033-80f0-1ea181aea662"\n			parameterto="48d92bd0-56a8-1033-8215-e9f581aea662" />\n		<connectionmember id="e7d63380-56a9-1033-9705-f4d481aea662"\n			name="Connection50" parameterfrom="3c2d4e20-56a8-1033-9459-f5d081aea662"\n			parameterto="48d84170-56a8-1033-9fbd-818981aea662" />\n		<connectionmember id="e7d63380-56a9-1033-99cf-639e81aea662"\n			name="Connection51" parameterfrom="3ce7eb90-56a8-1033-ad09-80dc81aea662"\n			parameterto="48d86880-56a8-1033-adbb-ec0a81aea662" />\n		<connectionmember id="e7d63380-56a9-1033-a14f-5a1b81aea662"\n			name="Connection52" activityto="53d6e450-56a8-1033-ad65-69ed81aea662"\n			parameterfrom="53d75980-56a8-1033-97e3-098481aea662" />\n		<connectionmember id="e7d65a90-56a9-1033-95d9-7cfc81aea662"\n			name="Connection53" activityto="53d6e450-56a8-1033-ad65-69ed81aea662"\n			parameterfrom="53d78090-56a8-1033-8d1a-805381aea662" />\n		<connectionmember id="e7d65a90-56a9-1033-a976-ee8381aea662"\n			name="Connection54" activityto="53d6e450-56a8-1033-ad65-69ed81aea662"\n			parameterfrom="53d7a7a0-56a8-1033-8573-8d7c81aea662" />\n		<connectionmember id="e7d65a90-56a9-1033-b520-6d6881aea662"\n			name="Connection55" activityfrom="53d6e450-56a8-1033-ad65-69ed81aea662"\n			parameterto="53d7ceb0-56a8-1033-860b-960581aea662" />\n		<connectionmember id="e7d65a90-56a9-1033-b2ae-ebc281aea662"\n			name="Connection56" activityto="54f832d0-56a8-1033-b08f-4dc881aea662"\n			parameterfrom="54f859e0-56a8-1033-8318-5f6f81aea662" />\n		<connectionmember id="e7d681a0-56a9-1033-a2e5-697481aea662"\n			name="Connection57" activityto="54f832d0-56a8-1033-b08f-4dc881aea662"\n			parameterfrom="54f880f0-56a8-1033-87cf-501881aea662" />\n		<connectionmember id="e7d681a0-56a9-1033-a970-7d9281aea662"\n			name="Connection58" activityto="54f832d0-56a8-1033-b08f-4dc881aea662"\n			parameterfrom="54f880f0-56a8-1033-9486-500681aea662" />\n		<connectionmember id="e7d681a0-56a9-1033-932b-39b281aea662"\n			name="Connection59" activityfrom="54f832d0-56a8-1033-b08f-4dc881aea662"\n			parameterto="54f8a800-56a8-1033-9a7d-8f1e81aea662" />\n		<connectionmember id="e7d6a8b0-56a9-1033-83f2-767e81aea662"\n			name="Connection60" activityto="5ada8bd0-56a8-1033-aed4-161a81aea662"\n			parameterfrom="5adb0100-56a8-1033-9d2d-b12e81aea662" />\n		<connectionmember id="e7d6a8b0-56a9-1033-94ec-ceb081aea662"\n			name="Connection61" activityto="5ada8bd0-56a8-1033-aed4-161a81aea662"\n			parameterfrom="5adb2810-56a8-1033-b8a9-80eb81aea662" />\n		<connectionmember id="e7d6a8b0-56a9-1033-9cc7-88ea81aea662"\n			name="Connection62" activityfrom="5ada8bd0-56a8-1033-aed4-161a81aea662"\n			parameterto="5adb2810-56a8-1033-a476-78dd81aea662" />\n		<connectionmember id="e7d6a8b0-56a9-1033-848c-e56c81aea662"\n			name="Connection63" activityto="5bb3d4d0-56a8-1033-a029-4c1481aea662"\n			parameterfrom="5bb3fbe0-56a8-1033-a32f-a75f81aea662" />\n		<connectionmember id="e7d6cfc0-56a9-1033-bf39-70dd81aea662"\n			name="Connection64" activityto="5bb3d4d0-56a8-1033-a029-4c1481aea662"\n			parameterfrom="5bb422f0-56a8-1033-914d-e93781aea662" />\n		<connectionmember id="e7d6cfc0-56a9-1033-9012-cabc81aea662"\n			name="Connection65" activityfrom="5bb3d4d0-56a8-1033-a029-4c1481aea662"\n			parameterto="5bb44a00-56a8-1033-89cc-7f5781aea662" />\n		<connectionmember id="e7d6cfc0-56a9-1033-be28-592981aea662"\n			name="Connection66" parameterfrom="53d7ceb0-56a8-1033-860b-960581aea662"\n			parameterto="5adb0100-56a8-1033-9d2d-b12e81aea662" />\n		<connectionmember id="e7d6cfc0-56a9-1033-88f4-a6cd81aea662"\n			name="Connection67" parameterfrom="54f8a800-56a8-1033-9a7d-8f1e81aea662"\n			parameterto="5bb3fbe0-56a8-1033-a32f-a75f81aea662" />\n		<connectionmember id="e7d6f6d0-56a9-1033-9953-eaff81aea662"\n			name="Connection68" activityto="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterfrom="63e30400-56a8-1033-8a46-433a81aea662" />\n		<connectionmember id="e7d6f6d0-56a9-1033-bc25-c0fa81aea662"\n			name="Connection69" activityto="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterfrom="63e32b10-56a8-1033-8472-299781aea662" />\n		<connectionmember id="e7d6f6d0-56a9-1033-89c6-0fe081aea662"\n			name="Connection70" activityto="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterfrom="63e35220-56a8-1033-9946-74e581aea662" />\n		<connectionmember id="e7d6f6d0-56a9-1033-9de9-7c5681aea662"\n			name="Connection71" activityto="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterfrom="63e37930-56a8-1033-8ec3-05b081aea662" />\n		<connectionmember id="e7d71de0-56a9-1033-87fb-801d81aea662"\n			name="Connection72" activityfrom="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterto="63e3a040-56a8-1033-a8ac-4b9381aea662" />\n		<connectionmember id="e7d71de0-56a9-1033-b2ff-0acf81aea662"\n			name="Connection73" activityfrom="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterto="63e3c750-56a8-1033-8f3f-643e81aea662" />\n		<connectionmember id="e7d71de0-56a9-1033-a42b-24e081aea662"\n			name="Connection74" activityfrom="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterto="63e3c750-56a8-1033-93f4-c67b81aea662" />\n		<connectionmember id="e7d744f0-56a9-1033-a088-8d9581aea662"\n			name="Connection75" activityfrom="63e28ed0-56a8-1033-8b5a-477a81aea662"\n			parameterto="63e3ee60-56a8-1033-a1a5-b54181aea662" />\n		<connectionmember id="e7d744f0-56a9-1033-ac5e-27e481aea662"\n			name="Connection76" parameterfrom="5adb2810-56a8-1033-a476-78dd81aea662"\n			parameterto="63e32b10-56a8-1033-8472-299781aea662" />\n		<connectionmember id="e7d744f0-56a9-1033-b0ba-a20281aea662"\n			name="Connection77" parameterfrom="5bb44a00-56a8-1033-89cc-7f5781aea662"\n			parameterto="63e30400-56a8-1033-8a46-433a81aea662" />\n		<connectionmember id="e7d744f0-56a9-1033-853c-573981aea662"\n			name="Connection78" activityto="6da55650-56a8-1033-b499-2f0c81aea662"\n			parameterfrom="6da5cb80-56a8-1033-961e-400981aea662" />\n		<connectionmember id="e7d76c00-56a9-1033-b99e-b6a181aea662"\n			name="Connection79" activityto="6da55650-56a8-1033-b499-2f0c81aea662"\n			parameterfrom="6da5f290-56a8-1033-92cc-466781aea662" />\n		<connectionmember id="e7d76c00-56a9-1033-8834-fc5d81aea662"\n			name="Connection80" activityto="6da55650-56a8-1033-b499-2f0c81aea662"\n			parameterfrom="6da5f290-56a8-1033-9aef-5cb281aea662" />\n		<connectionmember id="e7d76c00-56a9-1033-9405-c1f981aea662"\n			name="Connection81" activityfrom="6da55650-56a8-1033-b499-2f0c81aea662"\n			parameterto="6da619a0-56a8-1033-b0fe-c23181aea662" />\n		<connectionmember id="e7d76c00-56a9-1033-8611-da1181aea662"\n			name="Connection82" activityto="6f027550-56a8-1033-8166-87a181aea662"\n			parameterfrom="6f029c60-56a8-1033-a8a3-0b5f81aea662" />\n		<connectionmember id="e7d79310-56a9-1033-a02c-9a9d81aea662"\n			name="Connection83" activityto="6f027550-56a8-1033-8166-87a181aea662"\n			parameterfrom="6f02c370-56a8-1033-9e3c-83b681aea662" />\n		<connectionmember id="e7d79310-56a9-1033-aae8-f09d81aea662"\n			name="Connection84" activityto="6f027550-56a8-1033-8166-87a181aea662"\n			parameterfrom="6f02ea80-56a8-1033-94ee-512d81aea662" />\n		<connectionmember id="e7d79310-56a9-1033-ae12-5a5b81aea662"\n			name="Connection85" activityfrom="6f027550-56a8-1033-8166-87a181aea662"\n			parameterto="6f031190-56a8-1033-ba3e-4dd981aea662" />\n		<connectionmember id="e7d79310-56a9-1033-bd9c-60e281aea662"\n			name="Connection86" activityto="74d3b750-56a8-1033-9cc8-de3081aea662"\n			parameterfrom="74d42c80-56a8-1033-beec-8f3a81aea662" />\n		<connectionmember id="e7d7ba20-56a9-1033-b531-fec781aea662"\n			name="Connection87" activityto="74d3b750-56a8-1033-9cc8-de3081aea662"\n			parameterfrom="74d45390-56a8-1033-86b0-1e2881aea662" />\n		<connectionmember id="e7d7ba20-56a9-1033-85b3-865981aea662"\n			name="Connection88" activityfrom="74d3b750-56a8-1033-9cc8-de3081aea662"\n			parameterto="74d47aa0-56a8-1033-b8b8-0ed081aea662" />\n		<connectionmember id="e7d7ba20-56a9-1033-be49-f34f81aea662"\n			name="Connection89" parameterfrom="6da619a0-56a8-1033-b0fe-c23181aea662"\n			parameterto="74d42c80-56a8-1033-beec-8f3a81aea662" />\n		<connectionmember id="e7d7ba20-56a9-1033-91c8-49a881aea662"\n			name="Connection90" activityto="78bcb150-56a8-1033-af81-fb3f81aea662"\n			parameterfrom="78bd2680-56a8-1033-80cf-913681aea662" />\n		<connectionmember id="e7d7e130-56a9-1033-b521-21a681aea662"\n			name="Connection91" activityto="78bcb150-56a8-1033-af81-fb3f81aea662"\n			parameterfrom="78bd4d90-56a8-1033-939e-9cb481aea662" />\n		<connectionmember id="e7d7e130-56a9-1033-9bdd-fd4381aea662"\n			name="Connection92" activityfrom="78bcb150-56a8-1033-af81-fb3f81aea662"\n			parameterto="78bd74a0-56a8-1033-9ae3-9faa81aea662" />\n		<connectionmember id="e7d7e130-56a9-1033-a42e-753a81aea662"\n			name="Connection93" parameterfrom="6f031190-56a8-1033-ba3e-4dd981aea662"\n			parameterto="78bd2680-56a8-1033-80cf-913681aea662" />\n		<connectionmember id="e7d7e130-56a9-1033-b579-845181aea662"\n			name="Connection94" activityto="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterfrom="7de61a90-56a8-1033-b37c-606481aea662" />\n		<connectionmember id="e7d80840-56a9-1033-8199-cde681aea662"\n			name="Connection95" activityto="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterfrom="7de641a0-56a8-1033-bd62-278081aea662" />\n		<connectionmember id="e7d80840-56a9-1033-94b4-995681aea662"\n			name="Connection96" activityto="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterfrom="7de641a0-56a8-1033-9fe1-ad6681aea662" />\n		<connectionmember id="e7d80840-56a9-1033-a340-ca2181aea662"\n			name="Connection97" activityto="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterfrom="7de668b0-56a8-1033-9376-cd5181aea662" />\n		<connectionmember id="e7d82f50-56a9-1033-9e06-42f581aea662"\n			name="Connection98" activityfrom="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterto="7de68fc0-56a8-1033-9dd7-4ebe81aea662" />\n		<connectionmember id="e7d82f50-56a9-1033-808e-8b8281aea662"\n			name="Connection99" activityfrom="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterto="7de68fc0-56a8-1033-9746-c65281aea662" />\n		<connectionmember id="e7d82f50-56a9-1033-9da3-c63181aea662"\n			name="Connection100" activityfrom="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterto="7de6b6d0-56a8-1033-9af3-37cb81aea662" />\n		<connectionmember id="e7d85660-56a9-1033-8503-715c81aea662"\n			name="Connection101" activityfrom="7de5a560-56a8-1033-895a-bbc881aea662"\n			parameterto="7de6b6d0-56a8-1033-a871-255e81aea662" />\n		<connectionmember id="e7d85660-56a9-1033-9cb0-99da81aea662"\n			name="Connection102" parameterfrom="78bd74a0-56a8-1033-9ae3-9faa81aea662"\n			parameterto="7de61a90-56a8-1033-b37c-606481aea662" />\n		<connectionmember id="e7d85660-56a9-1033-85ae-9d1381aea662"\n			name="Connection103" parameterfrom="74d47aa0-56a8-1033-b8b8-0ed081aea662"\n			parameterto="7de641a0-56a8-1033-bd62-278081aea662" />\n		<connectionmember id="e7d85660-56a9-1033-8e6f-bf0f81aea662"\n			name="Connection104" activityto="86f4ad40-56a8-1033-8f03-b1e881aea662"\n			parameterfrom="86f57090-56a8-1033-a908-25b981aea662" />\n		<connectionmember id="e7d87d70-56a9-1033-80a4-e52881aea662"\n			name="Connection105" activityto="86f4ad40-56a8-1033-8f03-b1e881aea662"\n			parameterfrom="86f597a0-56a8-1033-8360-7b3281aea662" />\n		<connectionmember id="e7d87d70-56a9-1033-af50-5e5e81aea662"\n			name="Connection106" activityto="86f4ad40-56a8-1033-8f03-b1e881aea662"\n			parameterfrom="86f5beb0-56a8-1033-98c4-4e1481aea662" />\n		<connectionmember id="e7d87d70-56a9-1033-9d19-027281aea662"\n			name="Connection107" activityto="86f4ad40-56a8-1033-8f03-b1e881aea662"\n			parameterfrom="86f5e5c0-56a8-1033-8aa4-935281aea662" />\n		<connectionmember id="e7d87d70-56a9-1033-87be-8fb381aea662"\n			name="Connection108" activityfrom="86f4ad40-56a8-1033-8f03-b1e881aea662"\n			parameterto="86f60cd0-56a8-1033-bd58-466e81aea662" />\n		<connectionmember id="e7d8a480-56a9-1033-a0f5-166281aea662"\n			name="Connection109" parameterfrom="48d92bd0-56a8-1033-8215-e9f581aea662"\n			parameterto="86f5e5c0-56a8-1033-8aa4-935281aea662" />\n		<connectionmember id="e7d8a480-56a9-1033-be68-ca8481aea662"\n			name="Connection110" parameterfrom="2c98f680-56a8-1033-b639-696381aea662"\n			parameterto="86f5beb0-56a8-1033-98c4-4e1481aea662" />\n		<connectionmember id="e7d8a480-56a9-1033-82be-717c81aea662"\n			name="Connection111" parameterfrom="63e3ee60-56a8-1033-a1a5-b54181aea662"\n			parameterto="86f597a0-56a8-1033-8360-7b3281aea662" />\n		<connectionmember id="e7d8cb90-56a9-1033-8cdc-6d5181aea662"\n			name="Connection112" parameterfrom="7de6b6d0-56a8-1033-a871-255e81aea662"\n			parameterto="86f57090-56a8-1033-a908-25b981aea662" />\n		<connectionmember id="e7d8cb90-56a9-1033-a9b1-2b1581aea662"\n			name="Connection113" parameterfrom="78bd4d90-56a8-1033-939e-9cb481aea662"\n			parameterto="7de641a0-56a8-1033-9fe1-ad6681aea662" />\n		<connectionmember id="e7d8cb90-56a9-1033-b4f8-44be81aea662"\n			name="Connection114" parameterfrom="78bd4d90-56a8-1033-939e-9cb481aea662"\n			parameterto="74d45390-56a8-1033-86b0-1e2881aea662" />\n		<connectionmember id="e7d8cb90-56a9-1033-a063-62dd81aea662"\n			name="Connection115" parameterfrom="6f02ea80-56a8-1033-94ee-512d81aea662"\n			parameterto="6da5f290-56a8-1033-9aef-5cb281aea662" />\n		<connectionmember id="e7d8f2a0-56a9-1033-bce8-84a181aea662"\n			name="Connection116" parameterfrom="6f02c370-56a8-1033-9e3c-83b681aea662"\n			parameterto="6da5f290-56a8-1033-92cc-466781aea662" />\n		<connectionmember id="e7d8f2a0-56a9-1033-8243-218181aea662"\n			name="Connection117" parameterfrom="6f029c60-56a8-1033-a8a3-0b5f81aea662"\n			parameterto="7de668b0-56a8-1033-9376-cd5181aea662" />\n		<connectionmember id="e7d8f2a0-56a9-1033-961e-b77081aea662"\n			name="Connection118" parameterfrom="5bb422f0-56a8-1033-914d-e93781aea662"\n			parameterto="63e35220-56a8-1033-9946-74e581aea662" />\n		<connectionmember id="e7d8f2a0-56a9-1033-9993-344181aea662"\n			name="Connection119" parameterfrom="54f859e0-56a8-1033-8318-5f6f81aea662"\n			parameterto="63e37930-56a8-1033-8ec3-05b081aea662" />\n		<connectionmember id="e7d8f2a0-56a9-1033-9d20-7ae881aea662"\n			name="Connection120" parameterfrom="54f880f0-56a8-1033-87cf-501881aea662"\n			parameterto="53d78090-56a8-1033-8d1a-805381aea662" />\n		<connectionmember id="e7d919b0-56a9-1033-b2d9-dd6381aea662"\n			name="Connection121" parameterfrom="54f880f0-56a8-1033-9486-500681aea662"\n			parameterto="53d7a7a0-56a8-1033-8573-8d7c81aea662" />\n		<connectionmember id="e7d919b0-56a9-1033-9c21-845481aea662"\n			name="Connection122" parameterfrom="5bb422f0-56a8-1033-914d-e93781aea662"\n			parameterto="5adb2810-56a8-1033-b8a9-80eb81aea662" />\n		<connectionmember id="e7d919b0-56a9-1033-8dbe-d0e981aea662"\n			name="Connection123" parameterfrom="18cf80b0-56a8-1033-a018-cda981aea662"\n			parameterto="2c985a40-56a8-1033-b42e-ecce81aea662" />\n		<connectionmember id="e7d919b0-56a9-1033-ad00-91f581aea662"\n			name="Connection124" parameterfrom="24d05150-56a8-1033-832b-c87181aea662"\n			parameterto="2c983330-56a8-1033-9ad4-30a181aea662" />\n		<connectionmember id="e7d940c0-56a9-1033-835f-9e4181aea662"\n			name="Connection125" parameterfrom="24d05150-56a8-1033-832b-c87181aea662"\n			parameterto="275638e0-56a8-1033-a385-3a9881aea662" />\n		<connectionmember id="e7d940c0-56a9-1033-b06d-732181aea662"\n			name="Connection126" parameterfrom="18cff5e0-56a8-1033-a86f-1b5481aea662"\n			parameterto="19e6e420-56a8-1033-9068-412e81aea662" />\n		<connectionmember id="e7d940c0-56a9-1033-aa42-d1aa81aea662"\n			name="Connection127" parameterfrom="18cfced0-56a8-1033-90ea-801881aea662"\n			parameterto="19e69600-56a8-1033-bfba-c95381aea662" />\n		<connectionmember id="e7d940c0-56a9-1033-b693-c0d181aea662"\n			name="Connection128" parameterfrom="3c2d2710-56a8-1033-8172-b30581aea662"\n			parameterto="48d88f90-56a8-1033-b266-414f81aea662" />\n		<connectionmember id="e7d967d0-56a9-1033-9227-a1c781aea662"\n			name="Connection129" parameterfrom="3c2d2710-56a8-1033-8172-b30581aea662"\n			parameterto="3ce7c480-56a8-1033-b10b-f66581aea662" />\n		<connectionmember id="e7d967d0-56a9-1033-b81b-94a681aea662"\n			name="Connection130" parameterfrom="355c9d80-56a8-1033-beb9-50d081aea662"\n			parameterto="48d8b6a0-56a8-1033-af84-458081aea662" />\n		<connectionmember id="e7d967d0-56a9-1033-a335-588581aea662"\n			name="Connection131" parameterfrom="355cc490-56a8-1033-abc2-8b0b81aea662"\n			parameterto="361d7c80-56a8-1033-bf9b-d95581aea662" />\n		<connectionmember id="e7d967d0-56a9-1033-8529-d17f81aea662"\n			name="Connection132" parameterfrom="355ceba0-56a8-1033-bca9-bea281aea662"\n			parameterto="361da390-56a8-1033-8fc3-ad5c81aea662" />\n		<connectionmember id="e7d98ee0-56a9-1033-9d53-95a081aea662"\n			name="Connection133" parameterfrom="19e66ef0-56a8-1033-8ccd-b36181aea662"\n			parameterto="361d5570-56a8-1033-92d4-b0e481aea662" />\n		<connectionmember id="e7d98ee0-56a9-1033-87f0-e94281aea662"\n			name="Connection134" parameterfrom="18cf80b0-56a8-1033-a018-cda981aea662"\n			parameterto="355c9d80-56a8-1033-beb9-50d081aea662" />\n		<connectionmember id="e7d98ee0-56a9-1033-834b-1ca881aea662"\n			name="Connection135" parameterfrom="53d75980-56a8-1033-97e3-098481aea662"\n			parameterto="19e66ef0-56a8-1033-8ccd-b36181aea662" />\n		<connectionmember id="e7d9b5f0-56a9-1033-9722-d75581aea662"\n			name="Connection136" parameterfrom="54f859e0-56a8-1033-8318-5f6f81aea662"\n			parameterto="18cf80b0-56a8-1033-a018-cda981aea662" />\n		<connectionmember id="e7d9b5f0-56a9-1033-8c50-27f581aea662"\n			name="Connection137" parameterfrom="6da5cb80-56a8-1033-961e-400981aea662"\n			parameterto="53d75980-56a8-1033-97e3-098481aea662" />\n		<connectionmember id="e7d9b5f0-56a9-1033-b38c-b1df81aea662"\n			name="Connection138" parameterfrom="6f029c60-56a8-1033-a8a3-0b5f81aea662"\n			parameterto="54f859e0-56a8-1033-8318-5f6f81aea662" />\n	</connectionmembers>\n</logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\r\n<parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd">\r\n	<objectlocation>\r\n		<id>18c631e0-56a8-1033-890b-ecc281aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>1155.0</x>\r\n		<y>841.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>18cf80b0-56a8-1033-a018-cda981aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>1080.0</x>\r\n		<y>885.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>18cfced0-56a8-1033-90ea-801881aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>1133.0</x>\r\n		<y>931.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>18cff5e0-56a8-1033-a86f-1b5481aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>1211.0</x>\r\n		<y>910.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>18d01cf0-56a8-1033-a6aa-0e3281aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:river_originial_file_url</description>\r\n		<x>1156.0</x>\r\n		<y>777.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>19e647e0-56a8-1033-b790-bc3381aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>1352.0</x>\r\n		<y>842.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>19e66ef0-56a8-1033-8ccd-b36181aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>1275.0</x>\r\n		<y>885.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>19e69600-56a8-1033-bfba-c95381aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>1354.0</x>\r\n		<y>928.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>19e6e420-56a8-1033-9068-412e81aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>1427.0</x>\r\n		<y>901.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>19e70b30-56a8-1033-a51e-90e781aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:river_originial_file_url</description>\r\n		<x>1349.0</x>\r\n		<y>776.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>24d00330-56a8-1033-b74c-cc0681aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>1143.0</x>\r\n		<y>661.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>24d05150-56a8-1033-97e9-88a681aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>1104.0</x>\r\n		<y>722.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>24d05150-56a8-1033-832b-c87181aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>1219.0</x>\r\n		<y>721.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>24d05150-56a8-1033-bd90-cf1781aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:returnURL</description>\r\n		<x>1146.0</x>\r\n		<y>595.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2755eac0-56a8-1033-a7d1-3b4281aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>1364.0</x>\r\n		<y>665.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>275611d0-56a8-1033-b5bb-6e9f81aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>1334.0</x>\r\n		<y>721.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>275638e0-56a8-1033-a385-3a9881aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>1445.0</x>\r\n		<y>717.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>27565ff0-56a8-1033-b6b0-236681aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>1365.0</x>\r\n		<y>604.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c976fe0-56a8-1033-a1f0-7fea81aea662</id>\r\n		<type>0</type>\r\n		<name>GMT_Check</name>\r\n		<description>null</description>\r\n		<x>1241.0</x>\r\n		<y>465.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c97e510-56a8-1033-a9bc-11d381aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:GMT_file_URL</description>\r\n		<x>1156.0</x>\r\n		<y>521.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c980c20-56a8-1033-93a5-34b681aea662</id>\r\n		<type>1</type>\r\n		<name>last_year_GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:last_year_GMT_file_URL</description>\r\n		<x>1381.0</x>\r\n		<y>505.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c983330-56a8-1033-9ad4-30a181aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:GMT_Check:rivername</description>\r\n		<x>1240.0</x>\r\n		<y>550.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c985a40-56a8-1033-b42e-ecce81aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:GMT_Check:year</description>\r\n		<x>1314.0</x>\r\n		<y>536.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c988150-56a8-1033-a481-204981aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:GMT_DAT_URL</description>\r\n		<x>1172.0</x>\r\n		<y>416.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c98a860-56a8-1033-af1e-e4af81aea662</id>\r\n		<type>1</type>\r\n		<name>Report_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:Report_DAT_URL</description>\r\n		<x>1217.0</x>\r\n		<y>383.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c98cf70-56a8-1033-aacf-152c81aea662</id>\r\n		<type>1</type>\r\n		<name>Check_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: Check_DAT_URL</description>\r\n		<x>1271.0</x>\r\n		<y>383.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>2c98f680-56a8-1033-b639-696381aea662</id>\r\n		<type>1</type>\r\n		<name>No_NAN_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: No_NAN_DAT_URL</description>\r\n		<x>1316.0</x>\r\n		<y>416.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>355c2850-56a8-1033-b330-0d3681aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>1620.0</x>\r\n		<y>833.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>355c9d80-56a8-1033-beb9-50d081aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>1557.0</x>\r\n		<y>896.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>355cc490-56a8-1033-abc2-8b0b81aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>1620.0</x>\r\n		<y>922.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>355ceba0-56a8-1033-bca9-bea281aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>1683.0</x>\r\n		<y>896.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>355d12b0-56a8-1033-9753-6bc981aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:river_originial_file_url</description>\r\n		<x>1619.0</x>\r\n		<y>785.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>361d0750-56a8-1033-89bb-9ceb81aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>1830.0</x>\r\n		<y>835.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>361d5570-56a8-1033-92d4-b0e481aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>1775.0</x>\r\n		<y>884.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>361d7c80-56a8-1033-bf9b-d95581aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>1834.0</x>\r\n		<y>931.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>361da390-56a8-1033-8fc3-ad5c81aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>1901.0</x>\r\n		<y>901.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>361dcaa0-56a8-1033-9d96-075b81aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:river_originial_file_url</description>\r\n		<x>1829.0</x>\r\n		<y>775.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3c2cb1e0-56a8-1033-bde6-38b781aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>1599.0</x>\r\n		<y>674.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3c2d0000-56a8-1033-b63e-868b81aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>1557.0</x>\r\n		<y>741.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3c2d2710-56a8-1033-8172-b30581aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>1668.0</x>\r\n		<y>723.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3c2d4e20-56a8-1033-9459-f5d081aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>1600.0</x>\r\n		<y>604.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3ce74f50-56a8-1033-a85d-fe0381aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>1812.0</x>\r\n		<y>676.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3ce77660-56a8-1033-8822-034d81aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>1773.0</x>\r\n		<y>734.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3ce7c480-56a8-1033-b10b-f66581aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>1899.0</x>\r\n		<y>730.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>3ce7eb90-56a8-1033-ad09-80dc81aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>1796.0</x>\r\n		<y>605.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d7f350-56a8-1033-80f0-1ea181aea662</id>\r\n		<type>0</type>\r\n		<name>GMT_Check</name>\r\n		<description>null</description>\r\n		<x>1683.0</x>\r\n		<y>466.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d84170-56a8-1033-9fbd-818981aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:GMT_file_URL</description>\r\n		<x>1597.0</x>\r\n		<y>528.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d86880-56a8-1033-adbb-ec0a81aea662</id>\r\n		<type>1</type>\r\n		<name>last_year_GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:last_year_GMT_file_URL</description>\r\n		<x>1820.0</x>\r\n		<y>500.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d88f90-56a8-1033-b266-414f81aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:GMT_Check:rivername</description>\r\n		<x>1673.0</x>\r\n		<y>553.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d8b6a0-56a8-1033-af84-458081aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:GMT_Check:year</description>\r\n		<x>1739.0</x>\r\n		<y>529.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d8b6a0-56a8-1033-af59-bf5d81aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: GMT_DAT_URL</description>\r\n		<x>1611.0</x>\r\n		<y>408.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d8ddb0-56a8-1033-9be1-ee2c81aea662</id>\r\n		<type>1</type>\r\n		<name>Report_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: Report_DAT_URL</description>\r\n		<x>1656.0</x>\r\n		<y>375.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d904c0-56a8-1033-8786-34db81aea662</id>\r\n		<type>1</type>\r\n		<name>Check_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: Check_DAT_URL</description>\r\n		<x>1710.0</x>\r\n		<y>375.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48d92bd0-56a8-1033-8215-e9f581aea662</id>\r\n		<type>1</type>\r\n		<name>No_NAN_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: No_NAN_DAT_URL</description>\r\n		<x>1755.0</x>\r\n		<y>408.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>53d6e450-56a8-1033-ad65-69ed81aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>842.0</x>\r\n		<y>841.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>53d75980-56a8-1033-97e3-098481aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>779.0</x>\r\n		<y>904.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>53d78090-56a8-1033-8d1a-805381aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>842.0</x>\r\n		<y>930.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>53d7a7a0-56a8-1033-8573-8d7c81aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>905.0</x>\r\n		<y>904.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>53d7ceb0-56a8-1033-860b-960581aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links: river_originial_file_url</description>\r\n		<x>842.0</x>\r\n		<y>792.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>54f832d0-56a8-1033-b08f-4dc881aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>598.0</x>\r\n		<y>844.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>54f859e0-56a8-1033-8318-5f6f81aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>536.0</x>\r\n		<y>892.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>54f880f0-56a8-1033-87cf-501881aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>599.0</x>\r\n		<y>918.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>54f880f0-56a8-1033-9486-500681aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>669.0</x>\r\n		<y>901.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>54f8a800-56a8-1033-9a7d-8f1e81aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links: river_originial_file_url</description>\r\n		<x>602.0</x>\r\n		<y>791.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5ada8bd0-56a8-1033-aed4-161a81aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>830.0</x>\r\n		<y>666.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5adb0100-56a8-1033-9d2d-b12e81aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>786.0</x>\r\n		<y>743.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5adb2810-56a8-1033-b8a9-80eb81aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>896.0</x>\r\n		<y>720.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5adb2810-56a8-1033-a476-78dd81aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>831.0</x>\r\n		<y>601.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5bb3d4d0-56a8-1033-a029-4c1481aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>621.0</x>\r\n		<y>660.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5bb3fbe0-56a8-1033-a32f-a75f81aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>564.0</x>\r\n		<y>738.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5bb422f0-56a8-1033-914d-e93781aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>670.0</x>\r\n		<y>724.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>5bb44a00-56a8-1033-89cc-7f5781aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>621.0</x>\r\n		<y>595.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e28ed0-56a8-1033-8b5a-477a81aea662</id>\r\n		<type>0</type>\r\n		<name>GMT_Check</name>\r\n		<description>null</description>\r\n		<x>766.0</x>\r\n		<y>460.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e30400-56a8-1033-8a46-433a81aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:GMT_file_URL</description>\r\n		<x>650.0</x>\r\n		<y>513.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e32b10-56a8-1033-8472-299781aea662</id>\r\n		<type>1</type>\r\n		<name>last_year_GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:last_year_GMT_file_URL</description>\r\n		<x>918.0</x>\r\n		<y>511.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e35220-56a8-1033-9946-74e581aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:GMT_Check:rivername</description>\r\n		<x>703.0</x>\r\n		<y>547.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e37930-56a8-1033-8ec3-05b081aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:GMT_Check:year</description>\r\n		<x>792.0</x>\r\n		<y>527.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e3a040-56a8-1033-a8ac-4b9381aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: GMT_DAT_URL</description>\r\n		<x>700.0</x>\r\n		<y>399.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e3c750-56a8-1033-8f3f-643e81aea662</id>\r\n		<type>1</type>\r\n		<name>Report_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: Report_DAT_URL</description>\r\n		<x>745.0</x>\r\n		<y>366.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e3c750-56a8-1033-93f4-c67b81aea662</id>\r\n		<type>1</type>\r\n		<name>Check_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:Check_DAT_URL</description>\r\n		<x>799.0</x>\r\n		<y>366.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>63e3ee60-56a8-1033-a1a5-b54181aea662</id>\r\n		<type>1</type>\r\n		<name>No_NAN_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: No_NAN_DAT_URL</description>\r\n		<x>845.0</x>\r\n		<y>399.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6da55650-56a8-1033-b499-2f0c81aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>336.0</x>\r\n		<y>847.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6da5cb80-56a8-1033-961e-400981aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>273.0</x>\r\n		<y>910.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6da5f290-56a8-1033-92cc-466781aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>336.0</x>\r\n		<y>936.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6da5f290-56a8-1033-9aef-5cb281aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>399.0</x>\r\n		<y>910.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6da619a0-56a8-1033-b0fe-c23181aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links: river_originial_file_url</description>\r\n		<x>336.0</x>\r\n		<y>780.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6f027550-56a8-1033-8166-87a181aea662</id>\r\n		<type>0</type>\r\n		<name>Generate_River_USGS_links</name>\r\n		<description>null</description>\r\n		<x>126.0</x>\r\n		<y>847.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6f029c60-56a8-1033-a8a3-0b5f81aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:year</description>\r\n		<x>53.0</x>\r\n		<y>900.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6f02c370-56a8-1033-9e3c-83b681aea662</id>\r\n		<type>1</type>\r\n		<name>stationid</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:stationid</description>\r\n		<x>123.0</x>\r\n		<y>919.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6f02ea80-56a8-1033-94ee-512d81aea662</id>\r\n		<type>1</type>\r\n		<name>parameterlist</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links:parameterlist</description>\r\n		<x>188.0</x>\r\n		<y>892.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>6f031190-56a8-1033-ba3e-4dd981aea662</id>\r\n		<type>1</type>\r\n		<name>river_originial_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_River_USGS_links: river_originial_file_url</description>\r\n		<x>131.0</x>\r\n		<y>774.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>74d3b750-56a8-1033-9cc8-de3081aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>349.0</x>\r\n		<y>658.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>74d42c80-56a8-1033-beec-8f3a81aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>300.0</x>\r\n		<y>717.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>74d45390-56a8-1033-86b0-1e2881aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>425.0</x>\r\n		<y>715.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>74d47aa0-56a8-1033-b8b8-0ed081aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>348.0</x>\r\n		<y>594.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>78bcb150-56a8-1033-af81-fb3f81aea662</id>\r\n		<type>0</type>\r\n		<name>CDT_and_CST_to_GMT</name>\r\n		<description>null</description>\r\n		<x>131.0</x>\r\n		<y>663.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>78bd2680-56a8-1033-80cf-913681aea662</id>\r\n		<type>1</type>\r\n		<name>original_file_URL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:original_file_URL</description>\r\n		<x>82.0</x>\r\n		<y>723.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>78bd4d90-56a8-1033-939e-9cb481aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT:rivername</description>\r\n		<x>197.0</x>\r\n		<y>718.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>78bd74a0-56a8-1033-9ae3-9faa81aea662</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:CDT_and_CST_to_GMT: returnURL</description>\r\n		<x>135.0</x>\r\n		<y>588.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de5a560-56a8-1033-895a-bbc881aea662</id>\r\n		<type>0</type>\r\n		<name>GMT_Check</name>\r\n		<description>null</description>\r\n		<x>271.0</x>\r\n		<y>451.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de61a90-56a8-1033-b37c-606481aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:GMT_file_URL</description>\r\n		<x>127.0</x>\r\n		<y>505.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de641a0-56a8-1033-bd62-278081aea662</id>\r\n		<type>1</type>\r\n		<name>last_year_GMT_file_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check:last_year_GMT_file_URL</description>\r\n		<x>461.0</x>\r\n		<y>497.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de641a0-56a8-1033-9fe1-ad6681aea662</id>\r\n		<type>1</type>\r\n		<name>rivername</name>\r\n		<description>DataType:FVCOMService:GMT_Check:rivername</description>\r\n		<x>298.0</x>\r\n		<y>536.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de668b0-56a8-1033-9376-cd5181aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:GMT_Check:year</description>\r\n		<x>343.0</x>\r\n		<y>503.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de68fc0-56a8-1033-9dd7-4ebe81aea662</id>\r\n		<type>1</type>\r\n		<name>GMT_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: GMT_DAT_URL</description>\r\n		<x>199.0</x>\r\n		<y>399.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de68fc0-56a8-1033-9746-c65281aea662</id>\r\n		<type>1</type>\r\n		<name>Report_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: Report_DAT_URL</description>\r\n		<x>244.0</x>\r\n		<y>366.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de6b6d0-56a8-1033-9af3-37cb81aea662</id>\r\n		<type>1</type>\r\n		<name>Check_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: Check_DAT_URL</description>\r\n		<x>298.0</x>\r\n		<y>366.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>7de6b6d0-56a8-1033-a871-255e81aea662</id>\r\n		<type>1</type>\r\n		<name>No_NAN_DAT_URL</name>\r\n		<description>DataType:FVCOMService:GMT_Check: No_NAN_DAT_URL</description>\r\n		<x>343.0</x>\r\n		<y>399.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>86f4ad40-56a8-1033-8f03-b1e881aea662</id>\r\n		<type>0</type>\r\n		<name>Write_River_FVCOM_Input</name>\r\n		<description>null</description>\r\n		<x>1018.0</x>\r\n		<y>249.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>86f57090-56a8-1033-a908-25b981aea662</id>\r\n		<type>1</type>\r\n		<name>Caern_file_URL</name>\r\n		<description>DataType:FVCOMService:Write_River_FVCOM_Input:Caern_file_URL</description>\r\n		<x>600.0</x>\r\n		<y>312.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>86f597a0-56a8-1033-8360-7b3281aea662</id>\r\n		<type>1</type>\r\n		<name>Atcha_file_URL</name>\r\n		<description>DataType:FVCOMService:Write_River_FVCOM_Input:Atcha_file_URL</description>\r\n		<x>886.0</x>\r\n		<y>319.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>86f5beb0-56a8-1033-98c4-4e1481aea662</id>\r\n		<type>1</type>\r\n		<name>Missi_file_URL</name>\r\n		<description>DataType:FVCOMService:Write_River_FVCOM_Input:Missi_file_URL</description>\r\n		<x>1141.0</x>\r\n		<y>314.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>86f5e5c0-56a8-1033-8aa4-935281aea662</id>\r\n		<type>1</type>\r\n		<name>Wax_file_URL</name>\r\n		<description>DataType:FVCOMService:Write_River_FVCOM_Input:Wax_file_URL</description>\r\n		<x>1564.0</x>\r\n		<y>296.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>86f60cd0-56a8-1033-bd58-466e81aea662</id>\r\n		<type>1</type>\r\n		<name>River_FVCOM_Input_URL</name>\r\n		<description>DataType:FVCOMService:Write_River_FVCOM_Input:River_FVCOM_Input_URL</description>\r\n		<x>1015.0</x>\r\n		<y>164.0</y>\r\n	</objectlocation>\r\n</parameterconnection>', 'river, usgs, fvcom', 'Description', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(45, 'urn:uuid:7e364d60-581c-1033-877f-55fbc0a80002', 'T_S_condition_fvcom_input', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/T_S_condition_fvcom_input" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:7e364d60-581c-1033-877f-55fbc0a80002" name="T_S_condition_fvcom_input" author="Ziheng Sun" date="2015-10-17-04:00" desc="Initial fields of water temperature and salinity at individual triangular nodes"/><modeloutput parameter="cfb3ecc0-581b-1033-9a0b-622ec0a80002" keywords="temperature,salinity,uvelocity,vvelocity"/><activitymembers><activitymember id="af2b3850-581b-1033-80f8-4d06c0a80002" name="Generate_HYCOM_links" operation="Generate_HYCOM_links" servicetype="Generate_HYCOM_links"/><activitymember id="b9e6b7b0-581b-1033-b7b2-1b18c0a80002" name="interpolate_HYCOM_combine_to_FVCOM_grid" operation="interpolate_HYCOM_combine_to_FVCOM_grid" servicetype="interpolate_HYCOM_combine_to_FVCOM_grid"/><activitymember id="cfb28d30-581b-1033-ac8f-f91fc0a80002" name="rewrite_to_FVCOM_input_format" operation="rewrite_to_FVCOM_input_format" servicetype="rewrite_to_FVCOM_input_format"/></activitymembers><parametermembers><parametermember id="afb8d250-581b-1033-919a-718cc0a80002" name="year" type="input" datatype="year" activity="af2b3850-581b-1033-80f8-4d06c0a80002" fixedvalue="" dataformat="year" exteriorname="year"/><parametermember id="afc0c190-581b-1033-a0a3-f34ac0a80002" name="day" type="input" datatype="day" activity="af2b3850-581b-1033-80f8-4d06c0a80002" fixedvalue="" dataformat="day_in_year" exteriorname="day"/><parametermember id="afc0e8a0-581b-1033-b1bf-f4ccc0a80002" name="hour" type="input" datatype="hour" activity="af2b3850-581b-1033-80f8-4d06c0a80002" fixedvalue="" dataformat="hour" exteriorname="hour"/><parametermember id="afc15dd0-581b-1033-83b4-ae73c0a80002" name="hycom_combination_file_url" type="output" datatype="hycom_combination_file_url" activity="af2b3850-581b-1033-80f8-4d06c0a80002"/><parametermember id="b9e72ce0-581b-1033-8a76-f134c0a80002" name="hycom_combine_InputURL" type="input" datatype="hycom_combine_InputURL" activity="b9e6b7b0-581b-1033-b7b2-1b18c0a80002"/><parametermember id="b9e7a210-581b-1033-af3c-c31fc0a80002" name="inter_temperature_InputURL" type="output" datatype="inter_temperature_InputURL" activity="b9e6b7b0-581b-1033-b7b2-1b18c0a80002"/><parametermember id="b9e7c920-581b-1033-a6b6-4badc0a80002" name="inter_salinity_InputURL" type="output" datatype="inter_salinity_InputURL" activity="b9e6b7b0-581b-1033-b7b2-1b18c0a80002"/><parametermember id="b9e83e50-581b-1033-85fb-f5c4c0a80002" name="inter_U_velocity_InputURL" type="output" datatype="inter_U_velocity_InputURL" activity="b9e6b7b0-581b-1033-b7b2-1b18c0a80002"/><parametermember id="b9e88c70-581b-1033-b538-a888c0a80002" name="inter_V_velocity_InputURL" type="output" datatype="inter_V_velocity_InputURL" activity="b9e6b7b0-581b-1033-b7b2-1b18c0a80002"/><parametermember id="cfb30260-581b-1033-8570-b10ac0a80002" name="inter_temperature_InputURL" type="input" datatype="inter_temperature_InputURL" activity="cfb28d30-581b-1033-ac8f-f91fc0a80002"/><parametermember id="cfb35080-581b-1033-95a4-7313c0a80002" name="inter_salinity_InputURL" type="input" datatype="inter_salinity_InputURL" activity="cfb28d30-581b-1033-ac8f-f91fc0a80002"/><parametermember id="cfb39ea0-581b-1033-adbc-8acdc0a80002" name="inter_U_velocity_InputURL" type="input" datatype="inter_U_velocity_InputURL" activity="cfb28d30-581b-1033-ac8f-f91fc0a80002"/><parametermember id="cfb3c5b0-581b-1033-a58b-6c5dc0a80002" name="inter_V_velocity_InputURL" type="input" datatype="inter_V_velocity_InputURL" activity="cfb28d30-581b-1033-ac8f-f91fc0a80002"/><parametermember id="cfb3ecc0-581b-1033-9a0b-622ec0a80002" name="returnURL" type="output" datatype="returnURL" activity="cfb28d30-581b-1033-ac8f-f91fc0a80002"/></parametermembers><connectionmembers><connectionmember id="e2f546d0-581b-1033-ad8c-688ac0a80002" name="Connection0" activityto="af2b3850-581b-1033-80f8-4d06c0a80002" parameterfrom="afb8d250-581b-1033-919a-718cc0a80002"/><connectionmember id="e2f594f0-581b-1033-bcc7-d6b6c0a80002" name="Connection1" activityto="af2b3850-581b-1033-80f8-4d06c0a80002" parameterfrom="afc0c190-581b-1033-a0a3-f34ac0a80002"/><connectionmember id="e2f594f0-581b-1033-89aa-a21bc0a80002" name="Connection2" activityto="af2b3850-581b-1033-80f8-4d06c0a80002" parameterfrom="afc0e8a0-581b-1033-b1bf-f4ccc0a80002"/><connectionmember id="e2f5bc00-581b-1033-82e1-aed5c0a80002" name="Connection3" activityfrom="af2b3850-581b-1033-80f8-4d06c0a80002" parameterto="afc15dd0-581b-1033-83b4-ae73c0a80002"/><connectionmember id="e2f5bc00-581b-1033-a95f-0bfcc0a80002" name="Connection4" activityto="b9e6b7b0-581b-1033-b7b2-1b18c0a80002" parameterfrom="b9e72ce0-581b-1033-8a76-f134c0a80002"/><connectionmember id="e2f5bc00-581b-1033-bb00-e6f5c0a80002" name="Connection5" activityfrom="b9e6b7b0-581b-1033-b7b2-1b18c0a80002" parameterto="b9e7a210-581b-1033-af3c-c31fc0a80002"/><connectionmember id="e2f5e310-581b-1033-8ab2-d6b7c0a80002" name="Connection6" activityfrom="b9e6b7b0-581b-1033-b7b2-1b18c0a80002" parameterto="b9e7c920-581b-1033-a6b6-4badc0a80002"/><connectionmember id="e2f5e310-581b-1033-840f-33fcc0a80002" name="Connection7" activityfrom="b9e6b7b0-581b-1033-b7b2-1b18c0a80002" parameterto="b9e83e50-581b-1033-85fb-f5c4c0a80002"/><connectionmember id="e2f5e310-581b-1033-bc10-ef79c0a80002" name="Connection8" activityfrom="b9e6b7b0-581b-1033-b7b2-1b18c0a80002" parameterto="b9e88c70-581b-1033-b538-a888c0a80002"/><connectionmember id="e2f60a20-581b-1033-bbcb-d140c0a80002" name="Connection9" parameterfrom="afc15dd0-581b-1033-83b4-ae73c0a80002" parameterto="b9e72ce0-581b-1033-8a76-f134c0a80002"/><connectionmember id="e2f63130-581b-1033-8790-1c55c0a80002" name="Connection10" activityto="cfb28d30-581b-1033-ac8f-f91fc0a80002" parameterfrom="cfb30260-581b-1033-8570-b10ac0a80002"/><connectionmember id="e2f63130-581b-1033-8434-8dccc0a80002" name="Connection11" activityto="cfb28d30-581b-1033-ac8f-f91fc0a80002" parameterfrom="cfb35080-581b-1033-95a4-7313c0a80002"/><connectionmember id="e2f63130-581b-1033-a88a-c4c3c0a80002" name="Connection12" activityto="cfb28d30-581b-1033-ac8f-f91fc0a80002" parameterfrom="cfb39ea0-581b-1033-adbc-8acdc0a80002"/><connectionmember id="e2f65840-581b-1033-ac74-467fc0a80002" name="Connection13" activityto="cfb28d30-581b-1033-ac8f-f91fc0a80002" parameterfrom="cfb3c5b0-581b-1033-a58b-6c5dc0a80002"/><connectionmember id="e2f65840-581b-1033-afc0-cf4ac0a80002" name="Connection14" activityfrom="cfb28d30-581b-1033-ac8f-f91fc0a80002" parameterto="cfb3ecc0-581b-1033-9a0b-622ec0a80002"/><connectionmember id="e2f65840-581b-1033-99af-cf2fc0a80002" name="Connection15" parameterfrom="b9e88c70-581b-1033-b538-a888c0a80002" parameterto="cfb3c5b0-581b-1033-a58b-6c5dc0a80002"/><connectionmember id="e2f67f50-581b-1033-9e13-36a5c0a80002" name="Connection16" parameterfrom="b9e83e50-581b-1033-85fb-f5c4c0a80002" parameterto="cfb39ea0-581b-1033-adbc-8acdc0a80002"/><connectionmember id="e2f67f50-581b-1033-8792-ae18c0a80002" name="Connection17" parameterfrom="b9e7c920-581b-1033-a6b6-4badc0a80002" parameterto="cfb35080-581b-1033-95a4-7313c0a80002"/><connectionmember id="e2f67f50-581b-1033-a53f-48f0c0a80002" name="Connection18" parameterfrom="b9e7a210-581b-1033-af3c-c31fc0a80002" parameterto="cfb30260-581b-1033-8570-b10ac0a80002"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\r\n<parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd">\r\n	<objectlocation>\r\n		<id>af2b3850-581b-1033-80f8-4d06c0a80002</id>\r\n		<type>0</type>\r\n		<name>Generate_HYCOM_links</name>\r\n		<description>null</description>\r\n		<x>359.0</x>\r\n		<y>532.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>afb8d250-581b-1033-919a-718cc0a80002</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:FVCOMService:Generate_HYCOM_links:year</description>\r\n		<x>296.0</x>\r\n		<y>595.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>afc0c190-581b-1033-a0a3-f34ac0a80002</id>\r\n		<type>1</type>\r\n		<name>day</name>\r\n		<description>DataType:FVCOMService:Generate_HYCOM_links:day</description>\r\n		<x>359.0</x>\r\n		<y>621.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>afc0e8a0-581b-1033-b1bf-f4ccc0a80002</id>\r\n		<type>1</type>\r\n		<name>hour</name>\r\n		<description>DataType:FVCOMService:Generate_HYCOM_links:hour</description>\r\n		<x>422.0</x>\r\n		<y>595.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>afc15dd0-581b-1033-83b4-ae73c0a80002</id>\r\n		<type>1</type>\r\n		<name>hycom_combination_file_url</name>\r\n		<description>DataType:FVCOMService:Generate_HYCOM_links:hycom_combination_file_url</description>\r\n		<x>356.0</x>\r\n		<y>457.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>b9e6b7b0-581b-1033-b7b2-1b18c0a80002</id>\r\n		<type>0</type>\r\n		<name>interpolate_HYCOM_combine_to_FVCOM_grid</name>\r\n		<description>null</description>\r\n		<x>354.0</x>\r\n		<y>338.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>b9e72ce0-581b-1033-8a76-f134c0a80002</id>\r\n		<type>1</type>\r\n		<name>hycom_combine_InputURL</name>\r\n		<description>DataType:FVCOMService:interpolate_HYCOM_combine_to_FVCOM_grid:hycom_combine_InputURL</description>\r\n		<x>358.0</x>\r\n		<y>392.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>b9e7a210-581b-1033-af3c-c31fc0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_temperature_InputURL</name>\r\n		<description>DataType:FVCOMService:interpolate_HYCOM_combine_to_FVCOM_grid:inter_temperature_InputURL</description>\r\n		<x>232.0</x>\r\n		<y>278.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>b9e7c920-581b-1033-a6b6-4badc0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_salinity_InputURL</name>\r\n		<description>DataType:FVCOMService:interpolate_HYCOM_combine_to_FVCOM_grid:inter_salinity_InputURL</description>\r\n		<x>264.0</x>\r\n		<y>228.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>b9e83e50-581b-1033-85fb-f5c4c0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_U_velocity_InputURL</name>\r\n		<description>DataType:FVCOMService:interpolate_HYCOM_combine_to_FVCOM_grid:inter_U_velocity_InputURL</description>\r\n		<x>462.0</x>\r\n		<y>228.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>b9e88c70-581b-1033-b538-a888c0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_V_velocity_InputURL</name>\r\n		<description>DataType:FVCOMService:interpolate_HYCOM_combine_to_FVCOM_grid:inter_V_velocity_InputURL</description>\r\n		<x>494.0</x>\r\n		<y>276.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>cfb28d30-581b-1033-ac8f-f91fc0a80002</id>\r\n		<type>0</type>\r\n		<name>rewrite_to_FVCOM_input_format</name>\r\n		<description>null</description>\r\n		<x>362.0</x>\r\n		<y>91.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>cfb30260-581b-1033-8570-b10ac0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_temperature_InputURL</name>\r\n		<description>DataType:FVCOMService:rewrite_to_FVCOM_input_format:inter_temperature_InputURL</description>\r\n		<x>157.0</x>\r\n		<y>143.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>cfb35080-581b-1033-95a4-7313c0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_salinity_InputURL</name>\r\n		<description>DataType:FVCOMService:rewrite_to_FVCOM_input_format:inter_salinity_InputURL</description>\r\n		<x>270.0</x>\r\n		<y>176.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>cfb39ea0-581b-1033-adbc-8acdc0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_U_velocity_InputURL</name>\r\n		<description>DataType:FVCOMService:rewrite_to_FVCOM_input_format:inter_U_velocity_InputURL</description>\r\n		<x>453.0</x>\r\n		<y>179.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>cfb3c5b0-581b-1033-a58b-6c5dc0a80002</id>\r\n		<type>1</type>\r\n		<name>inter_V_velocity_InputURL</name>\r\n		<description>DataType:FVCOMService:rewrite_to_FVCOM_input_format:inter_V_velocity_InputURL</description>\r\n		<x>545.0</x>\r\n		<y>138.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>cfb3ecc0-581b-1033-9a0b-622ec0a80002</id>\r\n		<type>1</type>\r\n		<name>returnURL</name>\r\n		<description>DataType:FVCOMService:rewrite_to_FVCOM_input_format:returnURL</description>\r\n		<x>360.0</x>\r\n		<y>30.0</y>\r\n	</objectlocation>\r\n</parameterconnection>', 'temperature,salinity,uvelocity,vvelocity', 'Initial fields of water temperature and salinity at individual triangular nodes', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(46, 'urn:uuid:23e43e80-5867-1033-acac-bba0c0a80002', 'wind_forcing_fvcom_input', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/wind_forcing_fvcom_input" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:23e43e80-5867-1033-acac-bba0c0a80002" name="wind_forcing_fvcom_input" author="Ziheng Sun" date="2015-10-17-04:00" desc="The real-time fields of wind velocity or wind stress used for FVCOM."/><modeloutput parameter="1d6171b0-5865-1033-8a35-24c4c0a80002" keywords="wind force, wind velocity, wind stress"/><activitymembers><activitymember id="03e23120-5865-1033-a7b1-002bc0a80002" name="Downlad_NARR_TO_ASCII" operation="Downlad_NARR_TO_ASCII" servicetype="Downlad_NARR_TO_ASCII"/><activitymember id="08130990-5865-1033-85f1-a310c0a80002" name="Pick_NARR_Wind_Vector" operation="Pick_NARR_Wind_Vector" servicetype="Pick_NARR_Wind_Vector"/><activitymember id="0aa8cfa0-5865-1033-8e09-20acc0a80002" name="Interpolate_NARR_Wind_Vector" operation="Interpolate_NARR_Wind_Vector" servicetype="Interpolate_NARR_Wind_Vector"/><activitymember id="1d603930-5865-1033-8b8b-328dc0a80002" name="Generate_Wind_FVCOM_Input" operation="Generate_Wind_FVCOM_Input" servicetype="Generate_Wind_FVCOM_Input"/></activitymembers><parametermembers><parametermember id="03e2a650-5865-1033-97aa-d255c0a80002" name="year_start" type="input" datatype="year_start" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="year" exteriorname="start_year"/><parametermember id="03e2cd60-5865-1033-8cbe-dd0fc0a80002" name="year_end" type="input" datatype="year_end" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="year" exteriorname="end_year"/><parametermember id="03e2cd60-5865-1033-ba3f-bfaec0a80002" name="month_start" type="input" datatype="month_start" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="year" exteriorname="start_month"/><parametermember id="03e2f470-5865-1033-84ce-bc8cc0a80002" name="month_end" type="input" datatype="month_end" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="year" exteriorname="end_month"/><parametermember id="03e31b80-5865-1033-9442-5b0ac0a80002" name="full_month" type="input" datatype="full_month" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="datelist" exteriorname="iffullmonth"/><parametermember id="03e31b80-5865-1033-9dfd-ff88c0a80002" name="day_start" type="input" datatype="day_start" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="day_in_month" exteriorname="start_day"/><parametermember id="03e34290-5865-1033-a397-3e95c0a80002" name="day_end" type="input" datatype="day_end" activity="03e23120-5865-1033-a7b1-002bc0a80002" fixedvalue="" dataformat="day_in_month" exteriorname="end_day"/><parametermember id="03e34290-5865-1033-b5ad-0788c0a80002" name="narr_grb_url_list" type="output" datatype="narr_grb_url_list" activity="03e23120-5865-1033-a7b1-002bc0a80002"/><parametermember id="03e369a0-5865-1033-b3e9-0cb3c0a80002" name="narr_txt_url_list" type="output" datatype="narr_txt_url_list" activity="03e23120-5865-1033-a7b1-002bc0a80002"/><parametermember id="081330a0-5865-1033-93f1-70e8c0a80002" name="narr_txt_list" type="input" datatype="narr_txt_list" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081330a0-5865-1033-932e-bd74c0a80002" name="year_start" type="input" datatype="year_start" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081330a0-5865-1033-b49c-aa11c0a80002" name="year_end" type="input" datatype="year_end" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081330a0-5865-1033-bac7-d851c0a80002" name="month_start" type="input" datatype="month_start" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081357b0-5865-1033-921e-5b16c0a80002" name="month_end" type="input" datatype="month_end" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081357b0-5865-1033-af51-a12bc0a80002" name="day_start" type="input" datatype="day_start" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081357b0-5865-1033-898c-a147c0a80002" name="day_end" type="input" datatype="day_end" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="081357b0-5865-1033-ae11-af63c0a80002" name="lat1" type="input" datatype="lat1" activity="08130990-5865-1033-85f1-a310c0a80002" fixedvalue="18.0" dataformat="latitude" exteriorname="low_latitude"/><parametermember id="08137ec0-5865-1033-970a-48c3c0a80002" name="lon1" type="input" datatype="lon1" activity="08130990-5865-1033-85f1-a310c0a80002" fixedvalue="-98.0" dataformat="longitude" exteriorname="low_longitude"/><parametermember id="08137ec0-5865-1033-a85d-78abc0a80002" name="lat2" type="input" datatype="lat2" activity="08130990-5865-1033-85f1-a310c0a80002" fixedvalue="31.0" dataformat="latitude" exteriorname="high_latitude"/><parametermember id="08137ec0-5865-1033-9ada-70ebc0a80002" name="lon2" type="input" datatype="lon2" activity="08130990-5865-1033-85f1-a310c0a80002" fixedvalue="-80.0" dataformat="longitude" exteriorname="high_longitude"/><parametermember id="0813cce0-5865-1033-aeb0-9a29c0a80002" name="nomads_data_subset_list" type="output" datatype="nomads_data_subset_list" activity="08130990-5865-1033-85f1-a310c0a80002"/><parametermember id="0aa8f6b0-5865-1033-ba4e-b925c0a80002" name="nomads_txt_list" type="input" datatype="nomads_txt_list" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="0aa91dc0-5865-1033-9e11-669cc0a80002" name="year_start" type="input" datatype="year_start" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="0aa944d0-5865-1033-986b-44e5c0a80002" name="year_end" type="input" datatype="year_end" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="0aa96be0-5865-1033-8c68-3a3fc0a80002" name="month_start" type="input" datatype="month_start" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="0aa96be0-5865-1033-81d6-8e4bc0a80002" name="month_end" type="input" datatype="month_end" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002" fixedvalue="" dataformat="day_in_month" exteriorname="end_month"/><parametermember id="0aa992f0-5865-1033-aeba-5067c0a80002" name="day_start" type="input" datatype="day_start" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="0aa9ba00-5865-1033-9e22-d18cc0a80002" name="day_end" type="input" datatype="day_end" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="0aa9e110-5865-1033-ae2a-db2ec0a80002" name="interpl_uv_file_list" type="output" datatype="interpl_uv_file_list" activity="0aa8cfa0-5865-1033-8e09-20acc0a80002"/><parametermember id="1d608750-5865-1033-a1ed-00e4c0a80002" name="interp_wind_vector_list" type="input" datatype="interp_wind_vector_list" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d60ae60-5865-1033-867c-bad5c0a80002" name="year_start" type="input" datatype="year_start" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d60d570-5865-1033-b338-93ecc0a80002" name="year_end" type="input" datatype="year_end" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d60fc80-5865-1033-9871-5247c0a80002" name="month_start" type="input" datatype="month_start" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d612390-5865-1033-b23a-6a45c0a80002" name="month_end" type="input" datatype="month_end" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d614aa0-5865-1033-90f4-15e1c0a80002" name="day_start" type="input" datatype="day_start" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d6171b0-5865-1033-b51a-8da9c0a80002" name="day_end" type="input" datatype="day_end" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d6171b0-5865-1033-8a35-24c4c0a80002" name="wind_wnd_fvcom_input_url" type="output" datatype="wind_wnd_fvcom_input_url" activity="1d603930-5865-1033-8b8b-328dc0a80002"/><parametermember id="1d6198c0-5865-1033-8c72-36c1c0a80002" name="wind_hfx_fvcom_input_url" type="output" datatype="wind_hfx_fvcom_input_url" activity="1d603930-5865-1033-8b8b-328dc0a80002"/></parametermembers><connectionmembers><connectionmember id="9f471360-5865-1033-954a-eff9c0a80002" name="Connection0" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e2a650-5865-1033-97aa-d255c0a80002"/><connectionmember id="9f476180-5865-1033-b12b-3171c0a80002" name="Connection1" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e2cd60-5865-1033-8cbe-dd0fc0a80002"/><connectionmember id="9f478890-5865-1033-8d33-1abfc0a80002" name="Connection2" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e2cd60-5865-1033-ba3f-bfaec0a80002"/><connectionmember id="9f478890-5865-1033-9594-dd8fc0a80002" name="Connection3" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e2f470-5865-1033-84ce-bc8cc0a80002"/><connectionmember id="9f47afa0-5865-1033-b469-8f23c0a80002" name="Connection4" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e31b80-5865-1033-9442-5b0ac0a80002"/><connectionmember id="9f47afa0-5865-1033-9e5f-408bc0a80002" name="Connection5" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e31b80-5865-1033-9dfd-ff88c0a80002"/><connectionmember id="9f47afa0-5865-1033-b1c5-af6ac0a80002" name="Connection6" activityto="03e23120-5865-1033-a7b1-002bc0a80002" parameterfrom="03e34290-5865-1033-a397-3e95c0a80002"/><connectionmember id="9f47afa0-5865-1033-b5c2-4a27c0a80002" name="Connection7" activityfrom="03e23120-5865-1033-a7b1-002bc0a80002" parameterto="03e34290-5865-1033-b5ad-0788c0a80002"/><connectionmember id="9f47d6b0-5865-1033-83eb-3661c0a80002" name="Connection8" activityfrom="03e23120-5865-1033-a7b1-002bc0a80002" parameterto="03e369a0-5865-1033-b3e9-0cb3c0a80002"/><connectionmember id="9f47d6b0-5865-1033-a8fb-e2abc0a80002" name="Connection9" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081330a0-5865-1033-93f1-70e8c0a80002"/><connectionmember id="9f47d6b0-5865-1033-974c-8f17c0a80002" name="Connection10" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081330a0-5865-1033-932e-bd74c0a80002"/><connectionmember id="9f47d6b0-5865-1033-9c3a-2ebdc0a80002" name="Connection11" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081330a0-5865-1033-b49c-aa11c0a80002"/><connectionmember id="9f47d6b0-5865-1033-92d2-ea63c0a80002" name="Connection12" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081330a0-5865-1033-bac7-d851c0a80002"/><connectionmember id="9f47fdc0-5865-1033-abe5-0405c0a80002" name="Connection13" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081357b0-5865-1033-921e-5b16c0a80002"/><connectionmember id="9f47fdc0-5865-1033-b440-6b22c0a80002" name="Connection14" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081357b0-5865-1033-af51-a12bc0a80002"/><connectionmember id="9f47fdc0-5865-1033-b4da-ff08c0a80002" name="Connection15" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081357b0-5865-1033-898c-a147c0a80002"/><connectionmember id="9f47fdc0-5865-1033-82b6-37b6c0a80002" name="Connection16" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="081357b0-5865-1033-ae11-af63c0a80002"/><connectionmember id="9f4824d0-5865-1033-8236-ea27c0a80002" name="Connection17" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="08137ec0-5865-1033-970a-48c3c0a80002"/><connectionmember id="9f4824d0-5865-1033-9396-eba6c0a80002" name="Connection18" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="08137ec0-5865-1033-a85d-78abc0a80002"/><connectionmember id="9f4824d0-5865-1033-8427-2395c0a80002" name="Connection19" activityto="08130990-5865-1033-85f1-a310c0a80002" parameterfrom="08137ec0-5865-1033-9ada-70ebc0a80002"/><connectionmember id="9f4824d0-5865-1033-901c-44fac0a80002" name="Connection20" activityfrom="08130990-5865-1033-85f1-a310c0a80002" parameterto="0813cce0-5865-1033-aeb0-9a29c0a80002"/><connectionmember id="9f4824d0-5865-1033-abf4-6f2ac0a80002" name="Connection21" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa8f6b0-5865-1033-ba4e-b925c0a80002"/><connectionmember id="9f484be0-5865-1033-83a8-d54dc0a80002" name="Connection22" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa91dc0-5865-1033-9e11-669cc0a80002"/><connectionmember id="9f484be0-5865-1033-b962-f982c0a80002" name="Connection23" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa944d0-5865-1033-986b-44e5c0a80002"/><connectionmember id="9f484be0-5865-1033-a54b-f0afc0a80002" name="Connection24" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa96be0-5865-1033-8c68-3a3fc0a80002"/><connectionmember id="9f484be0-5865-1033-bf33-f6b9c0a80002" name="Connection25" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa96be0-5865-1033-81d6-8e4bc0a80002"/><connectionmember id="9f4872f0-5865-1033-ada7-6f04c0a80002" name="Connection26" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa992f0-5865-1033-aeba-5067c0a80002"/><connectionmember id="9f4872f0-5865-1033-bac4-27bcc0a80002" name="Connection27" activityto="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterfrom="0aa9ba00-5865-1033-9e22-d18cc0a80002"/><connectionmember id="9f4872f0-5865-1033-86aa-5a53c0a80002" name="Connection28" activityfrom="0aa8cfa0-5865-1033-8e09-20acc0a80002" parameterto="0aa9e110-5865-1033-ae2a-db2ec0a80002"/><connectionmember id="9f4872f0-5865-1033-bc55-1e0ec0a80002" name="Connection29" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d608750-5865-1033-a1ed-00e4c0a80002"/><connectionmember id="9f489a00-5865-1033-a92d-9024c0a80002" name="Connection30" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d60ae60-5865-1033-867c-bad5c0a80002"/><connectionmember id="9f489a00-5865-1033-a356-d88bc0a80002" name="Connection31" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d60d570-5865-1033-b338-93ecc0a80002"/><connectionmember id="9f489a00-5865-1033-adeb-d075c0a80002" name="Connection32" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d60fc80-5865-1033-9871-5247c0a80002"/><connectionmember id="9f489a00-5865-1033-a167-ebd0c0a80002" name="Connection33" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d612390-5865-1033-b23a-6a45c0a80002"/><connectionmember id="9f489a00-5865-1033-a2d7-4742c0a80002" name="Connection34" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d614aa0-5865-1033-90f4-15e1c0a80002"/><connectionmember id="9f48c110-5865-1033-8d72-909ec0a80002" name="Connection35" activityto="1d603930-5865-1033-8b8b-328dc0a80002" parameterfrom="1d6171b0-5865-1033-b51a-8da9c0a80002"/><connectionmember id="9f48c110-5865-1033-bcf8-de42c0a80002" name="Connection36" activityfrom="1d603930-5865-1033-8b8b-328dc0a80002" parameterto="1d6171b0-5865-1033-8a35-24c4c0a80002"/><connectionmember id="9f48c110-5865-1033-a8b6-4de3c0a80002" name="Connection37" activityfrom="1d603930-5865-1033-8b8b-328dc0a80002" parameterto="1d6198c0-5865-1033-8c72-36c1c0a80002"/><connectionmember id="9f48c110-5865-1033-be83-e2aec0a80002" name="Connection38" parameterfrom="03e369a0-5865-1033-b3e9-0cb3c0a80002" parameterto="081330a0-5865-1033-93f1-70e8c0a80002"/><connectionmember id="9f48c110-5865-1033-a6bc-98e7c0a80002" name="Connection39" parameterfrom="0813cce0-5865-1033-aeb0-9a29c0a80002" parameterto="0aa8f6b0-5865-1033-ba4e-b925c0a80002"/><connectionmember id="9f48e820-5865-1033-84e8-0664c0a80002" name="Connection40" parameterfrom="0aa9e110-5865-1033-ae2a-db2ec0a80002" parameterto="1d608750-5865-1033-a1ed-00e4c0a80002"/><connectionmember id="9f48e820-5865-1033-9fbd-5655c0a80002" name="Connection41" parameterfrom="03e2a650-5865-1033-97aa-d255c0a80002" parameterto="081330a0-5865-1033-932e-bd74c0a80002"/><connectionmember id="9f48e820-5865-1033-af6d-345bc0a80002" name="Connection42" parameterfrom="03e2cd60-5865-1033-8cbe-dd0fc0a80002" parameterto="081330a0-5865-1033-b49c-aa11c0a80002"/><connectionmember id="9f48e820-5865-1033-a4e0-1b99c0a80002" name="Connection43" parameterfrom="03e2cd60-5865-1033-ba3f-bfaec0a80002" parameterto="081330a0-5865-1033-bac7-d851c0a80002"/><connectionmember id="9f490f30-5865-1033-b7d4-761ac0a80002" name="Connection44" parameterfrom="03e2f470-5865-1033-84ce-bc8cc0a80002" parameterto="081357b0-5865-1033-921e-5b16c0a80002"/><connectionmember id="9f490f30-5865-1033-b95b-7a78c0a80002" name="Connection45" parameterfrom="03e31b80-5865-1033-9dfd-ff88c0a80002" parameterto="081357b0-5865-1033-af51-a12bc0a80002"/><connectionmember id="9f490f30-5865-1033-905a-0f74c0a80002" name="Connection46" parameterfrom="03e34290-5865-1033-a397-3e95c0a80002" parameterto="081357b0-5865-1033-898c-a147c0a80002"/><connectionmember id="9f490f30-5865-1033-9522-978cc0a80002" name="Connection47" parameterfrom="081330a0-5865-1033-932e-bd74c0a80002" parameterto="0aa91dc0-5865-1033-9e11-669cc0a80002"/><connectionmember id="9f493640-5865-1033-86ca-1c11c0a80002" name="Connection48" parameterfrom="081357b0-5865-1033-af51-a12bc0a80002" parameterto="0aa992f0-5865-1033-aeba-5067c0a80002"/><connectionmember id="9f493640-5865-1033-9741-dd8ac0a80002" name="Connection49" parameterfrom="081330a0-5865-1033-bac7-d851c0a80002" parameterto="0aa96be0-5865-1033-8c68-3a3fc0a80002"/><connectionmember id="9f493640-5865-1033-981a-9c88c0a80002" name="Connection50" parameterfrom="081330a0-5865-1033-b49c-aa11c0a80002" parameterto="0aa944d0-5865-1033-986b-44e5c0a80002"/><connectionmember id="9f493640-5865-1033-84ad-3662c0a80002" name="Connection51" parameterfrom="081357b0-5865-1033-898c-a147c0a80002" parameterto="0aa9ba00-5865-1033-9e22-d18cc0a80002"/><connectionmember id="9f495d50-5865-1033-9e42-b5b9c0a80002" name="Connection52" parameterfrom="0aa96be0-5865-1033-8c68-3a3fc0a80002" parameterto="1d60fc80-5865-1033-9871-5247c0a80002"/><connectionmember id="9f495d50-5865-1033-ba1c-f225c0a80002" name="Connection53" parameterfrom="0aa91dc0-5865-1033-9e11-669cc0a80002" parameterto="1d60ae60-5865-1033-867c-bad5c0a80002"/><connectionmember id="9f495d50-5865-1033-9966-1612c0a80002" name="Connection54" parameterfrom="0aa992f0-5865-1033-aeba-5067c0a80002" parameterto="1d614aa0-5865-1033-90f4-15e1c0a80002"/><connectionmember id="9f495d50-5865-1033-ab02-a100c0a80002" name="Connection55" parameterfrom="0aa944d0-5865-1033-986b-44e5c0a80002" parameterto="1d60d570-5865-1033-b338-93ecc0a80002"/><connectionmember id="9f498460-5865-1033-bde9-d776c0a80002" name="Connection56" parameterfrom="0aa96be0-5865-1033-81d6-8e4bc0a80002" parameterto="1d612390-5865-1033-b23a-6a45c0a80002"/><connectionmember id="9f498460-5865-1033-b7b0-40b1c0a80002" name="Connection57" parameterfrom="0aa9ba00-5865-1033-9e22-d18cc0a80002" parameterto="1d6171b0-5865-1033-b51a-8da9c0a80002"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\r\n<parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd">\r\n	<objectlocation>\r\n		<id>03e23120-5865-1033-a7b1-002bc0a80002</id>\r\n		<type>0</type>\r\n		<name>Downlad_NARR_TO_ASCII</name>\r\n		<description>null</description>\r\n		<x>372.0</x>\r\n		<y>848.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e2a650-5865-1033-97aa-d255c0a80002</id>\r\n		<type>1</type>\r\n		<name>year_start</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:year_start</description>\r\n		<x>132.0</x>\r\n		<y>876.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e2cd60-5865-1033-8cbe-dd0fc0a80002</id>\r\n		<type>1</type>\r\n		<name>year_end</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:year_end</description>\r\n		<x>200.0</x>\r\n		<y>909.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e2cd60-5865-1033-ba3f-bfaec0a80002</id>\r\n		<type>1</type>\r\n		<name>month_start</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:month_start</description>\r\n		<x>293.0</x>\r\n		<y>904.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e2f470-5865-1033-84ce-bc8cc0a80002</id>\r\n		<type>1</type>\r\n		<name>month_end</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:month_end</description>\r\n		<x>327.0</x>\r\n		<y>941.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e31b80-5865-1033-9442-5b0ac0a80002</id>\r\n		<type>1</type>\r\n		<name>full_month</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:full_month</description>\r\n		<x>438.0</x>\r\n		<y>940.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e31b80-5865-1033-9dfd-ff88c0a80002</id>\r\n		<type>1</type>\r\n		<name>day_start</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:day_start</description>\r\n		<x>506.0</x>\r\n		<y>911.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e34290-5865-1033-a397-3e95c0a80002</id>\r\n		<type>1</type>\r\n		<name>day_end</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII:day_end</description>\r\n		<x>585.0</x>\r\n		<y>889.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e34290-5865-1033-b5ad-0788c0a80002</id>\r\n		<type>1</type>\r\n		<name>narr_grb_url_list</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII: narr_grb_url_list</description>\r\n		<x>286.0</x>\r\n		<y>790.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>03e369a0-5865-1033-b3e9-0cb3c0a80002</id>\r\n		<type>1</type>\r\n		<name>narr_txt_url_list</name>\r\n		<description>DataType:FVCOMService:Downlad_NARR_TO_ASCII: narr_txt_url_list</description>\r\n		<x>439.0</x>\r\n		<y>792.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>08130990-5865-1033-85f1-a310c0a80002</id>\r\n		<type>0</type>\r\n		<name>Pick_NARR_Wind_Vector</name>\r\n		<description>null</description>\r\n		<x>357.0</x>\r\n		<y>648.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081330a0-5865-1033-93f1-70e8c0a80002</id>\r\n		<type>1</type>\r\n		<name>narr_txt_list</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:narr_txt_list</description>\r\n		<x>331.0</x>\r\n		<y>745.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081330a0-5865-1033-932e-bd74c0a80002</id>\r\n		<type>1</type>\r\n		<name>year_start</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:year_start</description>\r\n		<x>96.0</x>\r\n		<y>739.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081330a0-5865-1033-b49c-aa11c0a80002</id>\r\n		<type>1</type>\r\n		<name>year_end</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:year_end</description>\r\n		<x>385.0</x>\r\n		<y>711.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081330a0-5865-1033-bac7-d851c0a80002</id>\r\n		<type>1</type>\r\n		<name>month_start</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:month_start</description>\r\n		<x>279.0</x>\r\n		<y>707.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081357b0-5865-1033-921e-5b16c0a80002</id>\r\n		<type>1</type>\r\n		<name>month_end</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:month_end</description>\r\n		<x>128.0</x>\r\n		<y>677.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081357b0-5865-1033-af51-a12bc0a80002</id>\r\n		<type>1</type>\r\n		<name>day_start</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:day_start</description>\r\n		<x>210.0</x>\r\n		<y>739.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081357b0-5865-1033-898c-a147c0a80002</id>\r\n		<type>1</type>\r\n		<name>day_end</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:day_end</description>\r\n		<x>461.0</x>\r\n		<y>734.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>081357b0-5865-1033-ae11-af63c0a80002</id>\r\n		<type>1</type>\r\n		<name>lat1</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:lat1</description>\r\n		<x>535.0</x>\r\n		<y>726.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>08137ec0-5865-1033-970a-48c3c0a80002</id>\r\n		<type>1</type>\r\n		<name>lon1</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:lon1</description>\r\n		<x>584.0</x>\r\n		<y>693.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>08137ec0-5865-1033-a85d-78abc0a80002</id>\r\n		<type>1</type>\r\n		<name>lat2</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:lat2</description>\r\n		<x>648.0</x>\r\n		<y>732.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>08137ec0-5865-1033-9ada-70ebc0a80002</id>\r\n		<type>1</type>\r\n		<name>lon2</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector:lon2</description>\r\n		<x>686.0</x>\r\n		<y>680.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0813cce0-5865-1033-aeb0-9a29c0a80002</id>\r\n		<type>1</type>\r\n		<name>nomads_data_subset_list</name>\r\n		<description>DataType:FVCOMService:Pick_NARR_Wind_Vector: nomads_data_subset_list</description>\r\n		<x>355.0</x>\r\n		<y>587.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa8cfa0-5865-1033-8e09-20acc0a80002</id>\r\n		<type>0</type>\r\n		<name>Interpolate_NARR_Wind_Vector</name>\r\n		<description>null</description>\r\n		<x>361.0</x>\r\n		<y>442.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa8f6b0-5865-1033-ba4e-b925c0a80002</id>\r\n		<type>1</type>\r\n		<name>nomads_txt_list</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:nomads_txt_list</description>\r\n		<x>347.0</x>\r\n		<y>516.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa91dc0-5865-1033-9e11-669cc0a80002</id>\r\n		<type>1</type>\r\n		<name>year_start</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:year_start</description>\r\n		<x>243.0</x>\r\n		<y>530.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa944d0-5865-1033-986b-44e5c0a80002</id>\r\n		<type>1</type>\r\n		<name>year_end</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:year_end</description>\r\n		<x>527.0</x>\r\n		<y>532.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa96be0-5865-1033-8c68-3a3fc0a80002</id>\r\n		<type>1</type>\r\n		<name>month_start</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:month_start</description>\r\n		<x>163.0</x>\r\n		<y>506.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa96be0-5865-1033-81d6-8e4bc0a80002</id>\r\n		<type>1</type>\r\n		<name>month_end</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:month_end</description>\r\n		<x>574.0</x>\r\n		<y>499.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa992f0-5865-1033-aeba-5067c0a80002</id>\r\n		<type>1</type>\r\n		<name>day_start</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:day_start</description>\r\n		<x>441.0</x>\r\n		<y>542.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa9ba00-5865-1033-9e22-d18cc0a80002</id>\r\n		<type>1</type>\r\n		<name>day_end</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector:day_end</description>\r\n		<x>464.0</x>\r\n		<y>491.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>0aa9e110-5865-1033-ae2a-db2ec0a80002</id>\r\n		<type>1</type>\r\n		<name>interpl_uv_file_list</name>\r\n		<description>DataType:FVCOMService:Interpolate_NARR_Wind_Vector: interpl_uv_file_list</description>\r\n		<x>360.0</x>\r\n		<y>387.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d603930-5865-1033-8b8b-328dc0a80002</id>\r\n		<type>0</type>\r\n		<name>Generate_Wind_FVCOM_Input</name>\r\n		<description>null</description>\r\n		<x>357.0</x>\r\n		<y>272.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d608750-5865-1033-a1ed-00e4c0a80002</id>\r\n		<type>1</type>\r\n		<name>interp_wind_vector_list</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:interp_wind_vector_list</description>\r\n		<x>356.0</x>\r\n		<y>339.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d60ae60-5865-1033-867c-bad5c0a80002</id>\r\n		<type>1</type>\r\n		<name>year_start</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:year_start</description>\r\n		<x>142.0</x>\r\n		<y>339.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d60d570-5865-1033-b338-93ecc0a80002</id>\r\n		<type>1</type>\r\n		<name>year_end</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:year_end</description>\r\n		<x>227.0</x>\r\n		<y>358.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d60fc80-5865-1033-9871-5247c0a80002</id>\r\n		<type>1</type>\r\n		<name>month_start</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:month_start</description>\r\n		<x>558.0</x>\r\n		<y>291.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d612390-5865-1033-b23a-6a45c0a80002</id>\r\n		<type>1</type>\r\n		<name>month_end</name>\r\n		<description>DataType:FVCOMServic:Generate_Wind_FVCOM_Inpute:month_end</description>\r\n		<x>516.0</x>\r\n		<y>347.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d614aa0-5865-1033-90f4-15e1c0a80002</id>\r\n		<type>1</type>\r\n		<name>day_start</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:day_start</description>\r\n		<x>158.0</x>\r\n		<y>299.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d6171b0-5865-1033-b51a-8da9c0a80002</id>\r\n		<type>1</type>\r\n		<name>day_end</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:day_end</description>\r\n		<x>631.0</x>\r\n		<y>326.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d6171b0-5865-1033-8a35-24c4c0a80002</id>\r\n		<type>1</type>\r\n		<name>wind_wnd_fvcom_input_url</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:wind_wnd_fvcom_input_url</description>\r\n		<x>264.0</x>\r\n		<y>201.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>1d6198c0-5865-1033-8c72-36c1c0a80002</id>\r\n		<type>1</type>\r\n		<name>wind_hfx_fvcom_input_url</name>\r\n		<description>DataType:FVCOMService:Generate_Wind_FVCOM_Input:wind_hfx_fvcom_input_url</description>\r\n		<x>463.0</x>\r\n		<y>199.0</y>\r\n	</objectlocation>\r\n</parameterconnection>', 'wind force, wind velocity, wind stress', 'The real-time fields of wind velocity or wind stress used for FVCOM.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(47, 'urn:uuid:beb9d320-7531-1033-ac74-df4e81aea662', 'CRM_array_averaged_analysis_model', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/CRM_array_averaged_analysis_model" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:beb9d320-7531-1033-ac74-df4e81aea662" name="CRM_array_averaged_analysis_model" author="Ziheng Sun" date="2015-11-23-05:00" desc="This model generates CSU array-averaged analysis products."/><modeloutput productname="cloud_resolving_model_input_package" parameter="4f21d220-7530-1033-83e1-ebb681aea662" keywords="cloud, fluxes, sounding, forcing, q1, q2"/><activitymembers><activitymember id="47106420-7530-1033-95db-c4cf81aea662" name="dynamo_reform1" operation="dynamo_reform1" servicetype="dynamo_reform1"/><activitymember id="48bcdba0-7530-1033-b91b-300d81aea662" name="dynamo_reform2" operation="dynamo_reform2" servicetype="dynamo_reform2"/><activitymember id="4a96a4b0-7530-1033-8d2c-713581aea662" name="get_sst_sflux_6hourly" operation="get_sst_sflux_6hourly" servicetype="get_sst_sflux_6hourly"/><activitymember id="4d2c43b0-7530-1033-adcf-4e0181aea662" name="get_crm_input_dynamo" operation="get_crm_input_dynamo" servicetype="get_crm_input_dynamo"/><activitymember id="4f20c0b0-7530-1033-b6b1-8e2681aea662" name="zip_crm_input" operation="zip_crm_input" servicetype="zip_crm_input"/></activitymembers><parametermembers><parametermember id="4729b880-7530-1033-a9d5-d8e681aea662" name="fieldDataURL" type="input" datatype="fieldDataURL" activity="47106420-7530-1033-95db-c4cf81aea662" fixedvalue="" dataformat="fileurl" exteriorname="basic_fields"/><parametermember id="472a06a0-7530-1033-94b5-6e9e81aea662" name="Q1Q2DataURL" type="input" datatype="Q1Q2DataURL" activity="47106420-7530-1033-95db-c4cf81aea662" fixedvalue="" dataformat="fileurl" exteriorname="q1_and_q2"/><parametermember id="472a2db0-7530-1033-96a6-fe3f81aea662" name="dynamoForcingDataURL" type="output" datatype="dynamoForcingDataURL" activity="47106420-7530-1033-95db-c4cf81aea662"/><parametermember id="472a54c0-7530-1033-a3f8-dbd881aea662" name="dynamoQ1Q2DataURL" type="output" datatype="dynamoQ1Q2DataURL" activity="47106420-7530-1033-95db-c4cf81aea662"/><parametermember id="48bd02b0-7530-1033-a4f1-12c781aea662" name="fieldDataURL" type="input" datatype="fieldDataURL" activity="48bcdba0-7530-1033-b91b-300d81aea662"/><parametermember id="48bd50d0-7530-1033-9350-377d81aea662" name="surfaceDataURL" type="output" datatype="surfaceDataURL" activity="48bcdba0-7530-1033-b91b-300d81aea662"/><parametermember id="48bdc600-7530-1033-adf9-495e81aea662" name="soundingDataURL" type="output" datatype="soundingDataURL" activity="48bcdba0-7530-1033-b91b-300d81aea662"/><parametermember id="4a9740f0-7530-1033-92b8-cda781aea662" name="fluxDataURL" type="input" datatype="fluxDataURL" activity="4a96a4b0-7530-1033-8d2c-713581aea662" fixedvalue="" dataformat="fileurl" exteriorname="surface_fluxes"/><parametermember id="4a978f10-7530-1033-9769-57f781aea662" name="surfaceFlux6HrsURI" type="output" datatype="surfaceFlux6HrsURI" activity="4a96a4b0-7530-1033-8d2c-713581aea662"/><parametermember id="4d2c91d0-7530-1033-ad56-6c9681aea662" name="soundingDataURL" type="input" datatype="soundingDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2cdff0-7530-1033-9df8-6d0881aea662" name="forcingDataURL" type="input" datatype="forcingDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2d0700-7530-1033-8f94-9d8481aea662" name="SSTLSHDataURL" type="input" datatype="SSTLSHDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2d7c30-7530-1033-ae1a-9a6581aea662" name="surfaceDataURL" type="input" datatype="surfaceDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2da340-7530-1033-b261-987381aea662" name="forcingProfilesDataURL" type="output" datatype="forcingProfilesDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2dca50-7530-1033-ab81-121381aea662" name="initalSoundingDataURL" type="output" datatype="initalSoundingDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2df160-7530-1033-b7a8-fda081aea662" name="thetaAndQVProfilesURL" type="output" datatype="thetaAndQVProfilesURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2e6690-7530-1033-b4bf-3fd381aea662" name="timeseriesOfThetaAndQVDataURL" type="output" datatype="timeseriesOfThetaAndQVDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4d2e8da0-7530-1033-ac7b-564981aea662" name="velocityProfileDataURL" type="output" datatype="velocityProfileDataURL" activity="4d2c43b0-7530-1033-adcf-4e0181aea662"/><parametermember id="4f2135e0-7530-1033-846d-980d81aea662" name="forcingProfilesDataURL" type="input" datatype="forcingProfilesDataURL" activity="4f20c0b0-7530-1033-b6b1-8e2681aea662"/><parametermember id="4f215cf0-7530-1033-8970-a96c81aea662" name="initalSoundingDataURL" type="input" datatype="initalSoundingDataURL" activity="4f20c0b0-7530-1033-b6b1-8e2681aea662"/><parametermember id="4f218400-7530-1033-83ec-9ea881aea662" name="thetaAndQVProfilesURL" type="input" datatype="thetaAndQVProfilesURL" activity="4f20c0b0-7530-1033-b6b1-8e2681aea662"/><parametermember id="4f21ab10-7530-1033-9cba-6ccb81aea662" name="timeseriesOfThetaAndQVDataURL" type="input" datatype="timeseriesOfThetaAndQVDataURL" activity="4f20c0b0-7530-1033-b6b1-8e2681aea662"/><parametermember id="4f21d220-7530-1033-a409-d1f081aea662" name="velocityProfileDataURL" type="input" datatype="velocityProfileDataURL" activity="4f20c0b0-7530-1033-b6b1-8e2681aea662"/><parametermember id="4f21d220-7530-1033-83e1-ebb681aea662" name="crmInputPackage" type="output" datatype="crmInputPackage" activity="4f20c0b0-7530-1033-b6b1-8e2681aea662"/></parametermembers><connectionmembers><connectionmember id="9946afb0-7530-1033-9005-ea8a81aea662" name="Connection0" activityto="47106420-7530-1033-95db-c4cf81aea662" parameterfrom="4729b880-7530-1033-a9d5-d8e681aea662"/><connectionmember id="9946fdd0-7530-1033-a405-807f81aea662" name="Connection1" activityto="47106420-7530-1033-95db-c4cf81aea662" parameterfrom="472a06a0-7530-1033-94b5-6e9e81aea662"/><connectionmember id="9946fdd0-7530-1033-bc60-6a6d81aea662" name="Connection2" activityfrom="47106420-7530-1033-95db-c4cf81aea662" parameterto="472a2db0-7530-1033-96a6-fe3f81aea662"/><connectionmember id="9946fdd0-7530-1033-85a8-c33781aea662" name="Connection3" activityfrom="47106420-7530-1033-95db-c4cf81aea662" parameterto="472a54c0-7530-1033-a3f8-dbd881aea662"/><connectionmember id="994724e0-7530-1033-84d4-bddb81aea662" name="Connection4" activityto="48bcdba0-7530-1033-b91b-300d81aea662" parameterfrom="48bd02b0-7530-1033-a4f1-12c781aea662"/><connectionmember id="994724e0-7530-1033-a611-0f0781aea662" name="Connection5" activityfrom="48bcdba0-7530-1033-b91b-300d81aea662" parameterto="48bd50d0-7530-1033-9350-377d81aea662"/><connectionmember id="994724e0-7530-1033-9d30-b08d81aea662" name="Connection6" activityfrom="48bcdba0-7530-1033-b91b-300d81aea662" parameterto="48bdc600-7530-1033-adf9-495e81aea662"/><connectionmember id="994724e0-7530-1033-a5e9-28e581aea662" name="Connection7" activityto="4a96a4b0-7530-1033-8d2c-713581aea662" parameterfrom="4a9740f0-7530-1033-92b8-cda781aea662"/><connectionmember id="99474bf0-7530-1033-9600-426d81aea662" name="Connection8" activityfrom="4a96a4b0-7530-1033-8d2c-713581aea662" parameterto="4a978f10-7530-1033-9769-57f781aea662"/><connectionmember id="99474bf0-7530-1033-b23c-99f881aea662" name="Connection9" activityto="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterfrom="4d2c91d0-7530-1033-ad56-6c9681aea662"/><connectionmember id="99474bf0-7530-1033-bc00-b1d181aea662" name="Connection10" activityto="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterfrom="4d2cdff0-7530-1033-9df8-6d0881aea662"/><connectionmember id="99477300-7530-1033-b261-780981aea662" name="Connection11" activityto="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterfrom="4d2d0700-7530-1033-8f94-9d8481aea662"/><connectionmember id="99477300-7530-1033-bd97-9e4981aea662" name="Connection12" activityto="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterfrom="4d2d7c30-7530-1033-ae1a-9a6581aea662"/><connectionmember id="99477300-7530-1033-8015-53f981aea662" name="Connection13" activityfrom="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterto="4d2da340-7530-1033-b261-987381aea662"/><connectionmember id="99477300-7530-1033-afe8-e87281aea662" name="Connection14" activityfrom="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterto="4d2dca50-7530-1033-ab81-121381aea662"/><connectionmember id="99479a10-7530-1033-b393-228381aea662" name="Connection15" activityfrom="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterto="4d2df160-7530-1033-b7a8-fda081aea662"/><connectionmember id="9947c120-7530-1033-bc86-f73081aea662" name="Connection16" activityfrom="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterto="4d2e6690-7530-1033-b4bf-3fd381aea662"/><connectionmember id="9947c120-7530-1033-8b9e-88fc81aea662" name="Connection17" activityfrom="4d2c43b0-7530-1033-adcf-4e0181aea662" parameterto="4d2e8da0-7530-1033-ac7b-564981aea662"/><connectionmember id="9947c120-7530-1033-a364-f46681aea662" name="Connection18" activityto="4f20c0b0-7530-1033-b6b1-8e2681aea662" parameterfrom="4f2135e0-7530-1033-846d-980d81aea662"/><connectionmember id="9947c120-7530-1033-87ef-7e7881aea662" name="Connection19" activityto="4f20c0b0-7530-1033-b6b1-8e2681aea662" parameterfrom="4f215cf0-7530-1033-8970-a96c81aea662"/><connectionmember id="9947e830-7530-1033-86ed-f5b981aea662" name="Connection20" activityto="4f20c0b0-7530-1033-b6b1-8e2681aea662" parameterfrom="4f218400-7530-1033-83ec-9ea881aea662"/><connectionmember id="9947e830-7530-1033-8722-bf7881aea662" name="Connection21" activityto="4f20c0b0-7530-1033-b6b1-8e2681aea662" parameterfrom="4f21ab10-7530-1033-9cba-6ccb81aea662"/><connectionmember id="9947e830-7530-1033-88bc-75cb81aea662" name="Connection22" activityto="4f20c0b0-7530-1033-b6b1-8e2681aea662" parameterfrom="4f21d220-7530-1033-a409-d1f081aea662"/><connectionmember id="99480f40-7530-1033-b115-456281aea662" name="Connection23" activityfrom="4f20c0b0-7530-1033-b6b1-8e2681aea662" parameterto="4f21d220-7530-1033-83e1-ebb681aea662"/><connectionmember id="99480f40-7530-1033-b2c5-d26e81aea662" name="Connection24" parameterfrom="4d2e8da0-7530-1033-ac7b-564981aea662" parameterto="4f21d220-7530-1033-a409-d1f081aea662"/><connectionmember id="99480f40-7530-1033-9d71-426681aea662" name="Connection25" parameterfrom="4d2e6690-7530-1033-b4bf-3fd381aea662" parameterto="4f21ab10-7530-1033-9cba-6ccb81aea662"/><connectionmember id="99480f40-7530-1033-827b-d23f81aea662" name="Connection26" parameterfrom="4d2da340-7530-1033-b261-987381aea662" parameterto="4f2135e0-7530-1033-846d-980d81aea662"/><connectionmember id="99480f40-7530-1033-a029-a99a81aea662" name="Connection27" parameterfrom="4d2df160-7530-1033-b7a8-fda081aea662" parameterto="4f218400-7530-1033-83ec-9ea881aea662"/><connectionmember id="99480f40-7530-1033-b659-693481aea662" name="Connection28" parameterfrom="4d2dca50-7530-1033-ab81-121381aea662" parameterto="4f215cf0-7530-1033-8970-a96c81aea662"/><connectionmember id="99483650-7530-1033-9863-de9e81aea662" name="Connection29" parameterfrom="472a2db0-7530-1033-96a6-fe3f81aea662" parameterto="4d2cdff0-7530-1033-9df8-6d0881aea662"/><connectionmember id="99483650-7530-1033-8f88-00c881aea662" name="Connection30" parameterfrom="48bdc600-7530-1033-adf9-495e81aea662" parameterto="4d2c91d0-7530-1033-ad56-6c9681aea662"/><connectionmember id="99483650-7530-1033-957d-84ea81aea662" name="Connection31" parameterfrom="4a978f10-7530-1033-9769-57f781aea662" parameterto="4d2d0700-7530-1033-8f94-9d8481aea662"/><connectionmember id="99483650-7530-1033-b559-856a81aea662" name="Connection32" parameterfrom="48bd50d0-7530-1033-9350-377d81aea662" parameterto="4d2d7c30-7530-1033-ae1a-9a6581aea662"/><connectionmember id="99483650-7530-1033-8751-753081aea662" name="Connection33" parameterfrom="4729b880-7530-1033-a9d5-d8e681aea662" parameterto="48bd02b0-7530-1033-a4f1-12c781aea662"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\r\n<parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd">\r\n	<objectlocation>\r\n		<id>47106420-7530-1033-95db-c4cf81aea662</id>\r\n		<type>0</type>\r\n		<name>dynamo_reform1</name>\r\n		<description>null</description>\r\n		<x>233.0</x>\r\n		<y>687.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4729b880-7530-1033-a9d5-d8e681aea662</id>\r\n		<type>1</type>\r\n		<name>fieldDataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform1:fieldDataURL</description>\r\n		<x>293.0</x>\r\n		<y>774.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>472a06a0-7530-1033-94b5-6e9e81aea662</id>\r\n		<type>1</type>\r\n		<name>Q1Q2DataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform1:Q1Q2DataURL</description>\r\n		<x>171.0</x>\r\n		<y>756.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>472a2db0-7530-1033-96a6-fe3f81aea662</id>\r\n		<type>1</type>\r\n		<name>dynamoForcingDataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform1: dynamoForcingDataURL</description>\r\n		<x>146.0</x>\r\n		<y>568.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>472a54c0-7530-1033-a3f8-dbd881aea662</id>\r\n		<type>1</type>\r\n		<name>dynamoQ1Q2DataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform1: dynamoQ1Q2DataURL</description>\r\n		<x>265.0</x>\r\n		<y>615.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48bcdba0-7530-1033-b91b-300d81aea662</id>\r\n		<type>0</type>\r\n		<name>dynamo_reform2</name>\r\n		<description>null</description>\r\n		<x>431.0</x>\r\n		<y>689.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48bd02b0-7530-1033-a4f1-12c781aea662</id>\r\n		<type>1</type>\r\n		<name>fieldDataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform2:fieldDataURL</description>\r\n		<x>434.0</x>\r\n		<y>770.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48bd50d0-7530-1033-9350-377d81aea662</id>\r\n		<type>1</type>\r\n		<name>surfaceDataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform2: surfaceDataURL</description>\r\n		<x>497.0</x>\r\n		<y>583.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>48bdc600-7530-1033-adf9-495e81aea662</id>\r\n		<type>1</type>\r\n		<name>soundingDataURL</name>\r\n		<description>DataType:CRMService:dynamo_reform2: soundingDataURL</description>\r\n		<x>347.0</x>\r\n		<y>582.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4a96a4b0-7530-1033-8d2c-713581aea662</id>\r\n		<type>0</type>\r\n		<name>get_sst_sflux_6hourly</name>\r\n		<description>null</description>\r\n		<x>657.0</x>\r\n		<y>682.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4a9740f0-7530-1033-92b8-cda781aea662</id>\r\n		<type>1</type>\r\n		<name>fluxDataURL</name>\r\n		<description>DataType:CRMService:get_sst_sflux_6hourly:fluxDataURL</description>\r\n		<x>657.0</x>\r\n		<y>771.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4a978f10-7530-1033-9769-57f781aea662</id>\r\n		<type>1</type>\r\n		<name>surfaceFlux6HrsURI</name>\r\n		<description>DataType:CRMService:get_sst_sflux_6hourly: surfaceFlux6HrsURI</description>\r\n		<x>657.0</x>\r\n		<y>592.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2c43b0-7530-1033-adcf-4e0181aea662</id>\r\n		<type>0</type>\r\n		<name>get_crm_input_dynamo</name>\r\n		<description>null</description>\r\n		<x>413.0</x>\r\n		<y>431.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2c91d0-7530-1033-ad56-6c9681aea662</id>\r\n		<type>1</type>\r\n		<name>soundingDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: soundingDataURL</description>\r\n		<x>326.0</x>\r\n		<y>521.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2cdff0-7530-1033-9df8-6d0881aea662</id>\r\n		<type>1</type>\r\n		<name>forcingDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo:forcingDataURL</description>\r\n		<x>182.0</x>\r\n		<y>493.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2d0700-7530-1033-8f94-9d8481aea662</id>\r\n		<type>1</type>\r\n		<name>SSTLSHDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo:SSTLSHDataURL</description>\r\n		<x>648.0</x>\r\n		<y>505.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2d7c30-7530-1033-ae1a-9a6581aea662</id>\r\n		<type>1</type>\r\n		<name>surfaceDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: surfaceDataURL</description>\r\n		<x>495.0</x>\r\n		<y>520.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2da340-7530-1033-b261-987381aea662</id>\r\n		<type>1</type>\r\n		<name>forcingProfilesDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: forcingProfilesDataURL</description>\r\n		<x>183.0</x>\r\n		<y>415.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2dca50-7530-1033-ab81-121381aea662</id>\r\n		<type>1</type>\r\n		<name>initalSoundingDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: initalSoundingDataURL</description>\r\n		<x>415.0</x>\r\n		<y>353.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2df160-7530-1033-b7a8-fda081aea662</id>\r\n		<type>1</type>\r\n		<name>thetaAndQVProfilesURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: thetaAndQVProfilesURL</description>\r\n		<x>253.0</x>\r\n		<y>374.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2e6690-7530-1033-b4bf-3fd381aea662</id>\r\n		<type>1</type>\r\n		<name>timeseriesOfThetaAndQVDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: timeseriesOfThetaAndQVDataURL</description>\r\n		<x>628.0</x>\r\n		<y>377.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4d2e8da0-7530-1033-ac7b-564981aea662</id>\r\n		<type>1</type>\r\n		<name>velocityProfileDataURL</name>\r\n		<description>DataType:CRMService:get_crm_input_dynamo: velocityProfileDataURL</description>\r\n		<x>680.0</x>\r\n		<y>417.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f20c0b0-7530-1033-b6b1-8e2681aea662</id>\r\n		<type>0</type>\r\n		<name>zip_crm_input</name>\r\n		<description>null</description>\r\n		<x>409.0</x>\r\n		<y>222.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f2135e0-7530-1033-846d-980d81aea662</id>\r\n		<type>1</type>\r\n		<name>forcingProfilesDataURL</name>\r\n		<description>DataType:CRMService:zip_crm_input: forcingProfilesDataURL</description>\r\n		<x>181.0</x>\r\n		<y>274.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f215cf0-7530-1033-8970-a96c81aea662</id>\r\n		<type>1</type>\r\n		<name>initalSoundingDataURL</name>\r\n		<description>DataType:CRMService:zip_crm_input: initalSoundingDataURL</description>\r\n		<x>410.0</x>\r\n		<y>292.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f218400-7530-1033-83ec-9ea881aea662</id>\r\n		<type>1</type>\r\n		<name>thetaAndQVProfilesURL</name>\r\n		<description>DataType:CRMService:zip_crm_input: thetaAndQVProfilesURL</description>\r\n		<x>252.0</x>\r\n		<y>318.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f21ab10-7530-1033-9cba-6ccb81aea662</id>\r\n		<type>1</type>\r\n		<name>timeseriesOfThetaAndQVDataURL</name>\r\n		<description>DataType:CRMService:zip_crm_input: timeseriesOfThetaAndQVDataURL</description>\r\n		<x>624.0</x>\r\n		<y>316.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f21d220-7530-1033-a409-d1f081aea662</id>\r\n		<type>1</type>\r\n		<name>velocityProfileDataURL</name>\r\n		<description>DataType:CRMService:zip_crm_input: velocityProfileDataURL</description>\r\n		<x>677.0</x>\r\n		<y>266.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>4f21d220-7530-1033-83e1-ebb681aea662</id>\r\n		<type>1</type>\r\n		<name>crmInputPackage</name>\r\n		<description>DataType:CRMService:zip_crm_input: crmInputPackage</description>\r\n		<x>408.0</x>\r\n		<y>163.0</y>\r\n	</objectlocation>\r\n</parameterconnection>', 'cloud, fluxes, sounding, forcing, q1, q2', 'This model generates CSU array-averaged analysis products.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(50, 'urn:uuid:3aae5df0-af4a-1033-bd29-552e81aea662', 'YearsDailyNDVIModel', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/YearsDailyNDVIModel" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:3aae5df0-af4a-1033-bd29-552e81aea662" name="YearsDailyNDVIModel" author="Ziheng Sun" date="2016-02-05-05:00" desc="Generate daily NDVI for one day in different year. The output is a list of daily NDVI corresponding to the year list."/><modeloutput productname="YearsDailyNDVIs" parameter="a7bfc600-af49-1033-ae66-33a981aea662" begintime="1970-01-01T00:00:00Z" endtime="2016-02-05T10:05:01Z" keywords="NDVI, MODIS, Remote sensing"/><activitymembers><activitymember id="87a05ab0-af49-1033-9974-546381aea662" name="clipROIHDFYears" operation="clipROIHDFYears" servicetype="clipROIHDFYears"/><activitymember id="a7bda320-af49-1033-ac77-c21981aea662" name="ROIYearsDailyNDVICalc" operation="ROIYearsDailyNDVICalc" servicetype="ROIYearsDailyNDVICalc"/></activitymembers><parametermembers><parametermember id="87a0f6f0-af49-1033-8ca8-960f81aea662" name="bbox" type="input" datatype="bbox" activity="87a05ab0-af49-1033-9974-546381aea662" fixedvalue="" dataformat="boundingbox" exteriorname="bounding box"/><parametermember id="87a11e00-af49-1033-a76a-843881aea662" name="years" type="input" datatype="years" activity="87a05ab0-af49-1033-9974-546381aea662" fixedvalue="" dataformat="yearlist" exteriorname="year list"/><parametermember id="87a14510-af49-1033-8390-fb7581aea662" name="day" type="input" datatype="day" activity="87a05ab0-af49-1033-9974-546381aea662" fixedvalue="" dataformat="day_in_year" exteriorname="target day"/><parametermember id="87a16c20-af49-1033-874b-6b8281aea662" name="return" type="output" datatype="return" activity="87a05ab0-af49-1033-9974-546381aea662"/><parametermember id="a7beb490-af49-1033-be0d-e3c181aea662" name="years_b1b2QA_URL" type="input" datatype="years_b1b2QA_URL" activity="a7bda320-af49-1033-ac77-c21981aea662"/><parametermember id="a7bf77e0-af49-1033-b494-604d81aea662" name="years" type="input" datatype="years" activity="a7bda320-af49-1033-ac77-c21981aea662"/><parametermember id="a7bf9ef0-af49-1033-b8e1-0cc881aea662" name="in_day" type="input" datatype="in_day" activity="a7bda320-af49-1033-ac77-c21981aea662"/><parametermember id="a7bfc600-af49-1033-ae66-33a981aea662" name="return" type="output" datatype="return" activity="a7bda320-af49-1033-ac77-c21981aea662"/></parametermembers><connectionmembers><connectionmember id="ca7e9450-af49-1033-800d-d4ff81aea662" name="Connection0" activityto="87a05ab0-af49-1033-9974-546381aea662" parameterfrom="87a0f6f0-af49-1033-8ca8-960f81aea662"/><connectionmember id="ca7f3090-af49-1033-aa79-706a81aea662" name="Connection1" activityto="87a05ab0-af49-1033-9974-546381aea662" parameterfrom="87a11e00-af49-1033-a76a-843881aea662"/><connectionmember id="ca7f57a0-af49-1033-84e9-5e8181aea662" name="Connection2" activityto="87a05ab0-af49-1033-9974-546381aea662" parameterfrom="87a14510-af49-1033-8390-fb7581aea662"/><connectionmember id="ca7f7eb0-af49-1033-9b7d-ff9081aea662" name="Connection3" activityfrom="87a05ab0-af49-1033-9974-546381aea662" parameterto="87a16c20-af49-1033-874b-6b8281aea662"/><connectionmember id="ca7f7eb0-af49-1033-8fee-d81181aea662" name="Connection4" activityto="a7bda320-af49-1033-ac77-c21981aea662" parameterfrom="a7beb490-af49-1033-be0d-e3c181aea662"/><connectionmember id="ca7fa5c0-af49-1033-94ed-5bf681aea662" name="Connection5" activityto="a7bda320-af49-1033-ac77-c21981aea662" parameterfrom="a7bf77e0-af49-1033-b494-604d81aea662"/><connectionmember id="ca7fccd0-af49-1033-8b47-c44981aea662" name="Connection6" activityto="a7bda320-af49-1033-ac77-c21981aea662" parameterfrom="a7bf9ef0-af49-1033-b8e1-0cc881aea662"/><connectionmember id="ca7fccd0-af49-1033-b84b-394481aea662" name="Connection7" activityfrom="a7bda320-af49-1033-ac77-c21981aea662" parameterto="a7bfc600-af49-1033-ae66-33a981aea662"/><connectionmember id="ca7ff3e0-af49-1033-af79-8cb281aea662" name="Connection8" parameterfrom="87a16c20-af49-1033-874b-6b8281aea662" parameterto="a7beb490-af49-1033-be0d-e3c181aea662"/><connectionmember id="ca801af0-af49-1033-8333-9ea381aea662" name="Connection9" parameterfrom="87a14510-af49-1033-8390-fb7581aea662" parameterto="a7bf9ef0-af49-1033-b8e1-0cc881aea662"/><connectionmember id="ca801af0-af49-1033-b7dd-eb7081aea662" name="Connection10" parameterfrom="87a11e00-af49-1033-a76a-843881aea662" parameterto="a7bf77e0-af49-1033-b494-604d81aea662"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\r\n<parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd">\r\n	<objectlocation>\r\n		<id>87a05ab0-af49-1033-9974-546381aea662</id>\r\n		<type>0</type>\r\n		<name>clipROIHDFYears</name>\r\n		<description>null</description>\r\n		<x>234.0</x>\r\n		<y>324.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>87a0f6f0-af49-1033-8ca8-960f81aea662</id>\r\n		<type>1</type>\r\n		<name>bbox</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDFYears:bbox</description>\r\n		<x>189.0</x>\r\n		<y>393.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>87a11e00-af49-1033-a76a-843881aea662</id>\r\n		<type>1</type>\r\n		<name>years</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDFYears:years</description>\r\n		<x>328.0</x>\r\n		<y>401.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>87a14510-af49-1033-8390-fb7581aea662</id>\r\n		<type>1</type>\r\n		<name>day</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDFYears:day</description>\r\n		<x>446.0</x>\r\n		<y>391.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>87a16c20-af49-1033-874b-6b8281aea662</id>\r\n		<type>1</type>\r\n		<name>return</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDFYears: return</description>\r\n		<x>235.0</x>\r\n		<y>269.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>a7bda320-af49-1033-ac77-c21981aea662</id>\r\n		<type>0</type>\r\n		<name>ROIYearsDailyNDVICalc</name>\r\n		<description>null</description>\r\n		<x>354.0</x>\r\n		<y>115.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>a7beb490-af49-1033-be0d-e3c181aea662</id>\r\n		<type>1</type>\r\n		<name>years_b1b2QA_URL</name>\r\n		<description>DataType:NDVICalWorkflow:ROIYearsDailyNDVICalc:years_b1b2QA_URL</description>\r\n		<x>234.0</x>\r\n		<y>197.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>a7bf77e0-af49-1033-b494-604d81aea662</id>\r\n		<type>1</type>\r\n		<name>years</name>\r\n		<description>DataType:NDVICalWorkflow:ROIYearsDailyNDVICalc:years</description>\r\n		<x>351.0</x>\r\n		<y>235.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>a7bf9ef0-af49-1033-b8e1-0cc881aea662</id>\r\n		<type>1</type>\r\n		<name>in_day</name>\r\n		<description>DataType:NDVICalWorkflow:ROIYearsDailyNDVICalc:in_day</description>\r\n		<x>441.0</x>\r\n		<y>191.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>a7bfc600-af49-1033-ae66-33a981aea662</id>\r\n		<type>1</type>\r\n		<name>return</name>\r\n		<description>DataType:NDVICalWorkflow:ROIYearsDailyNDVICalc: return</description>\r\n		<x>354.0</x>\r\n		<y>54.0</y>\r\n	</objectlocation>\r\n</parameterconnection>', 'NDVI, MODIS, Remote sensing', 'Generate daily NDVI for one day in different year. The output is a list of daily NDVI corresponding to the year list.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(51, 'urn:uuid:00d25020-bc1d-1033-90a3-940e81aea662', 'MODIS_NDVI_Generation_Model', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/MODIS_NDVI_Generation_Model" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:00d25020-bc1d-1033-90a3-940e81aea662" name="MODIS_NDVI_Generation_Model" author="Ziheng Sun" date="2016-02-21-05:00" desc="Generating MODIS NDVI."/><modeloutput productname="MODIS_NDVI" parameter="9e5a40d0-bc1a-1033-ba6d-793081aea662" boundingbox="-180;-90;180;90" projection="EPSG:4326" begintime="1970-01-01T00:00:00" endtime="2016-02-21T05:40:05" keywords="NDVI, VCI" format="image/png"/><activitymembers><activitymember id="92609c20-bc1a-1033-99ae-cbdc81aea662" name="clipROIHDF" operation="clipROIHDF" servicetype="clipROIHDF"/><activitymember id="9e589320-bc1a-1033-a3de-c31681aea662" name="ROIDaysNDVICompositeCalc" operation="ROIDaysNDVICompositeCalc" servicetype="ROIDaysNDVICompositeCalc"/></activitymembers><parametermembers><parametermember id="928d2a60-bc1a-1033-b11b-271581aea662" name="bbox" type="input" datatype="bbox" activity="92609c20-bc1a-1033-99ae-cbdc81aea662" fixedvalue="" dataformat="boundingbox" exteriorname="Bounding Box"/><parametermember id="92925a80-bc1a-1033-824d-ac1d81aea662" name="year" type="input" datatype="year" activity="92609c20-bc1a-1033-99ae-cbdc81aea662" fixedvalue="" dataformat="year" exteriorname="Year"/><parametermember id="9292cfb0-bc1a-1033-a72b-3d5881aea662" name="day" type="input" datatype="day" activity="92609c20-bc1a-1033-99ae-cbdc81aea662" fixedvalue="" dataformat="day_in_year" exteriorname="Day"/><parametermember id="9292f6c0-bc1a-1033-b2b3-ae5c81aea662" name="return" type="output" datatype="return" activity="92609c20-bc1a-1033-99ae-cbdc81aea662"/><parametermember id="9e595670-bc1a-1033-a8e4-566581aea662" name="Daily_NDVI_URL" type="input" datatype="Daily_NDVI_URL" activity="9e589320-bc1a-1033-a3de-c31681aea662"/><parametermember id="9e59a490-bc1a-1033-b528-032c81aea662" name="in_year" type="input" datatype="in_year" activity="9e589320-bc1a-1033-a3de-c31681aea662"/><parametermember id="9e59cba0-bc1a-1033-8baf-ac2081aea662" name="in_day" type="input" datatype="in_day" activity="9e589320-bc1a-1033-a3de-c31681aea662"/><parametermember id="9e5a19c0-bc1a-1033-8017-a48081aea662" name="daynum" type="input" datatype="daynum" activity="9e589320-bc1a-1033-a3de-c31681aea662" fixedvalue="" dataformat="integer" exteriorname="Period Days"/><parametermember id="9e5a40d0-bc1a-1033-ba6d-793081aea662" name="return" type="output" datatype="return" activity="9e589320-bc1a-1033-a3de-c31681aea662"/></parametermembers><connectionmembers><connectionmember id="082a0080-bc1c-1033-ae6c-bd3481aea662" name="Connection0" activityto="92609c20-bc1a-1033-99ae-cbdc81aea662" parameterfrom="928d2a60-bc1a-1033-b11b-271581aea662"/><connectionmember id="082a4ea0-bc1c-1033-899a-daed81aea662" name="Connection1" activityto="92609c20-bc1a-1033-99ae-cbdc81aea662" parameterfrom="92925a80-bc1a-1033-824d-ac1d81aea662"/><connectionmember id="082a4ea0-bc1c-1033-97ba-c45081aea662" name="Connection2" activityto="92609c20-bc1a-1033-99ae-cbdc81aea662" parameterfrom="9292cfb0-bc1a-1033-a72b-3d5881aea662"/><connectionmember id="082a75b0-bc1c-1033-95eb-e9ec81aea662" name="Connection3" activityfrom="92609c20-bc1a-1033-99ae-cbdc81aea662" parameterto="9292f6c0-bc1a-1033-b2b3-ae5c81aea662"/><connectionmember id="082a75b0-bc1c-1033-98f7-618281aea662" name="Connection4" activityto="9e589320-bc1a-1033-a3de-c31681aea662" parameterfrom="9e595670-bc1a-1033-a8e4-566581aea662"/><connectionmember id="082a9cc0-bc1c-1033-b931-005f81aea662" name="Connection5" activityto="9e589320-bc1a-1033-a3de-c31681aea662" parameterfrom="9e59a490-bc1a-1033-b528-032c81aea662"/><connectionmember id="082a9cc0-bc1c-1033-b6ac-713781aea662" name="Connection6" activityto="9e589320-bc1a-1033-a3de-c31681aea662" parameterfrom="9e59cba0-bc1a-1033-8baf-ac2081aea662"/><connectionmember id="082ac3d0-bc1c-1033-9bf3-560781aea662" name="Connection7" activityto="9e589320-bc1a-1033-a3de-c31681aea662" parameterfrom="9e5a19c0-bc1a-1033-8017-a48081aea662"/><connectionmember id="082ac3d0-bc1c-1033-b942-661481aea662" name="Connection8" activityfrom="9e589320-bc1a-1033-a3de-c31681aea662" parameterto="9e5a40d0-bc1a-1033-ba6d-793081aea662"/><connectionmember id="082aeae0-bc1c-1033-b004-641481aea662" name="Connection9" parameterfrom="9292f6c0-bc1a-1033-b2b3-ae5c81aea662" parameterto="9e595670-bc1a-1033-a8e4-566581aea662"/><connectionmember id="082aeae0-bc1c-1033-8b0b-844481aea662" name="Connection10" parameterfrom="92925a80-bc1a-1033-824d-ac1d81aea662" parameterto="9e59a490-bc1a-1033-b528-032c81aea662"/><connectionmember id="082b11f0-bc1c-1033-b107-9f9c81aea662" name="Connection11" parameterfrom="9292cfb0-bc1a-1033-a72b-3d5881aea662" parameterto="9e59cba0-bc1a-1033-8baf-ac2081aea662"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?>\r\n<parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd">\r\n	<objectlocation>\r\n		<id>92609c20-bc1a-1033-99ae-cbdc81aea662</id>\r\n		<type>0</type>\r\n		<name>clipROIHDF</name>\r\n		<description>null</description>\r\n		<x>301.0</x>\r\n		<y>360.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>928d2a60-bc1a-1033-b11b-271581aea662</id>\r\n		<type>1</type>\r\n		<name>bbox</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDF:bbox</description>\r\n		<x>303.0</x>\r\n		<y>442.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>92925a80-bc1a-1033-824d-ac1d81aea662</id>\r\n		<type>1</type>\r\n		<name>year</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDF:year</description>\r\n		<x>239.0</x>\r\n		<y>422.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9292cfb0-bc1a-1033-a72b-3d5881aea662</id>\r\n		<type>1</type>\r\n		<name>day</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDF:day</description>\r\n		<x>364.0</x>\r\n		<y>420.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9292f6c0-bc1a-1033-b2b3-ae5c81aea662</id>\r\n		<type>1</type>\r\n		<name>return</name>\r\n		<description>DataType:NDVICalWorkflow:clipROIHDF:return</description>\r\n		<x>301.0</x>\r\n		<y>270.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9e589320-bc1a-1033-a3de-c31681aea662</id>\r\n		<type>0</type>\r\n		<name>ROIDaysNDVICompositeCalc</name>\r\n		<description>null</description>\r\n		<x>298.0</x>\r\n		<y>120.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9e595670-bc1a-1033-a8e4-566581aea662</id>\r\n		<type>1</type>\r\n		<name>Daily_NDVI_URL</name>\r\n		<description>DataType:NDVICalWorkflow:ROIDaysNDVICompositeCalc:Daily_NDVI_URL</description>\r\n		<x>299.0</x>\r\n		<y>201.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9e59a490-bc1a-1033-b528-032c81aea662</id>\r\n		<type>1</type>\r\n		<name>in_year</name>\r\n		<description>DataType:NDVICalWorkflow:ROIDaysNDVICompositeCalc:in_year</description>\r\n		<x>194.0</x>\r\n		<y>202.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9e59cba0-bc1a-1033-8baf-ac2081aea662</id>\r\n		<type>1</type>\r\n		<name>in_day</name>\r\n		<description>DataType:NDVICalWorkflow:ROIDaysNDVICompositeCalc:in_day</description>\r\n		<x>402.0</x>\r\n		<y>201.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9e5a19c0-bc1a-1033-8017-a48081aea662</id>\r\n		<type>1</type>\r\n		<name>daynum</name>\r\n		<description>DataType:NDVICalWorkflow:ROIDaysNDVICompositeCalc:daynum</description>\r\n		<x>428.0</x>\r\n		<y>164.0</y>\r\n	</objectlocation>\r\n	<objectlocation>\r\n		<id>9e5a40d0-bc1a-1033-ba6d-793081aea662</id>\r\n		<type>1</type>\r\n		<name>return</name>\r\n		<description>DataType:NDVICalWorkflow:ROIDaysNDVICompositeCalc:return</description>\r\n		<x>296.0</x>\r\n		<y>45.0</y>\r\n	</objectlocation>\r\n</parameterconnection>', 'NDVI, VCI', 'Generating MODIS NDVI.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(53, 'urn:uuid:10f33810-255f-1034-8580-adfdc0a80006', 'PreprocessingImageObjects', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/PreprocessingImageObjects" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:10f33810-255f-1034-8580-adfdc0a80006" name="PreprocessingImageObjects" author="Ziheng Sun" date="2016-07-04-04:00" desc="Preprocess image and generate objects."/><modeloutput productname="Preprocessed Image Objects" parameter="c2d86830-255e-1034-9383-9f2fc0a80006" boundingbox="-180;-90;180;90" projection="EPSG:4326" begintime="1970-01-01T00:00:00" endtime="2016-07-04T05:32:30" keywords="image object" format="image/geotiff"/><activitymembers><activitymember id="bea37110-255e-1034-95c2-4f49c0a80006" name="rgb2singlevalue" operation="rgb2singlevalue" servicetype="rgb2singlevalue"/><activitymember id="c0992690-255e-1034-80d6-f7fcc0a80006" name="eliminate_smallpolygons" operation="eliminate_smallpolygons" servicetype="eliminate_smallpolygons"/><activitymember id="c2d84120-255e-1034-a609-8d1ac0a80006" name="r2v" operation="r2v" servicetype="r2v"/></activitymembers><parametermembers><parametermember id="bea3bf30-255e-1034-8505-7e5ec0a80006" name="imgURL" type="input" datatype="imgURL" activity="bea37110-255e-1034-95c2-4f49c0a80006" fixedvalue="" dataformat="fileurl" exteriorname="original image"/><parametermember id="bea3bf30-255e-1034-820c-64f8c0a80006" name="returnformat" type="input" datatype="returnformat" activity="bea37110-255e-1034-95c2-4f49c0a80006" fixedvalue="" dataformat="string" exteriorname="raster format"/><parametermember id="bea3e640-255e-1034-9afa-2c66c0a80006" name="returnURL" type="output" datatype="returnURL" activity="bea37110-255e-1034-95c2-4f49c0a80006"/><parametermember id="c0992690-255e-1034-8c45-e760c0a80006" name="imgURL" type="input" datatype="imgURL" activity="c0992690-255e-1034-80d6-f7fcc0a80006"/><parametermember id="c0994da0-255e-1034-8602-736ec0a80006" name="returnformat" type="input" datatype="returnformat" activity="c0992690-255e-1034-80d6-f7fcc0a80006"/><parametermember id="c0994da0-255e-1034-9372-df18c0a80006" name="returnURL" type="output" datatype="returnURL" activity="c0992690-255e-1034-80d6-f7fcc0a80006"/><parametermember id="c2d86830-255e-1034-9211-a97cc0a80006" name="imgURL" type="input" datatype="imgURL" activity="c2d84120-255e-1034-a609-8d1ac0a80006"/><parametermember id="c2d86830-255e-1034-b8f3-a198c0a80006" name="returnformat" type="input" datatype="returnformat" activity="c2d84120-255e-1034-a609-8d1ac0a80006" fixedvalue="" dataformat="string" exteriorname="vector format"/><parametermember id="c2d86830-255e-1034-9383-9f2fc0a80006" name="returnURL" type="output" datatype="returnURL" activity="c2d84120-255e-1034-a609-8d1ac0a80006"/></parametermembers><connectionmembers><connectionmember id="cbcf7b40-255e-1034-b692-2e2dc0a80006" name="Connection0" activityto="bea37110-255e-1034-95c2-4f49c0a80006" parameterfrom="bea3bf30-255e-1034-8505-7e5ec0a80006"/><connectionmember id="cbcfa250-255e-1034-a68c-25f8c0a80006" name="Connection1" activityto="bea37110-255e-1034-95c2-4f49c0a80006" parameterfrom="bea3bf30-255e-1034-820c-64f8c0a80006"/><connectionmember id="cbcfc960-255e-1034-b5e2-9a62c0a80006" name="Connection2" activityfrom="bea37110-255e-1034-95c2-4f49c0a80006" parameterto="bea3e640-255e-1034-9afa-2c66c0a80006"/><connectionmember id="cbcfc960-255e-1034-be55-0c85c0a80006" name="Connection3" activityto="c0992690-255e-1034-80d6-f7fcc0a80006" parameterfrom="c0992690-255e-1034-8c45-e760c0a80006"/><connectionmember id="cbcfc960-255e-1034-a0a3-256ec0a80006" name="Connection4" activityto="c0992690-255e-1034-80d6-f7fcc0a80006" parameterfrom="c0994da0-255e-1034-8602-736ec0a80006"/><connectionmember id="cbcfc960-255e-1034-8240-62e5c0a80006" name="Connection5" activityfrom="c0992690-255e-1034-80d6-f7fcc0a80006" parameterto="c0994da0-255e-1034-9372-df18c0a80006"/><connectionmember id="cbcfc960-255e-1034-a3d3-a912c0a80006" name="Connection6" activityto="c2d84120-255e-1034-a609-8d1ac0a80006" parameterfrom="c2d86830-255e-1034-9211-a97cc0a80006"/><connectionmember id="cbcfc960-255e-1034-b782-67bbc0a80006" name="Connection7" activityto="c2d84120-255e-1034-a609-8d1ac0a80006" parameterfrom="c2d86830-255e-1034-b8f3-a198c0a80006"/><connectionmember id="cbcff070-255e-1034-a2d8-4b78c0a80006" name="Connection8" activityfrom="c2d84120-255e-1034-a609-8d1ac0a80006" parameterto="c2d86830-255e-1034-9383-9f2fc0a80006"/><connectionmember id="cbcff070-255e-1034-96e0-f834c0a80006" name="Connection9" parameterfrom="bea3e640-255e-1034-9afa-2c66c0a80006" parameterto="c0992690-255e-1034-8c45-e760c0a80006"/><connectionmember id="cbcff070-255e-1034-81dd-3d69c0a80006" name="Connection10" parameterfrom="c0994da0-255e-1034-9372-df18c0a80006" parameterto="c2d86830-255e-1034-9211-a97cc0a80006"/><connectionmember id="cbcff070-255e-1034-bf62-87c3c0a80006" name="Connection11" parameterfrom="bea3bf30-255e-1034-820c-64f8c0a80006" parameterto="c0994da0-255e-1034-8602-736ec0a80006"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd"><objectlocation><id>bea37110-255e-1034-95c2-4f49c0a80006</id><type>0</type><name>rgb2singlevalue</name><description>null</description><x>333.0</x><y>531.0</y></objectlocation><objectlocation><id>bea3bf30-255e-1034-8505-7e5ec0a80006</id><type>1</type><name>imgURL</name><description>DataType:imgURL</description><x>289.0</x><y>608.0</y></objectlocation><objectlocation><id>bea3bf30-255e-1034-820c-64f8c0a80006</id><type>1</type><name>returnformat</name><description>DataType:returnformat</description><x>421.0</x><y>604.0</y></objectlocation><objectlocation><id>bea3e640-255e-1034-9afa-2c66c0a80006</id><type>1</type><name>returnURL</name><description>DataType: returnURL</description><x>333.0</x><y>441.0</y></objectlocation><objectlocation><id>c0992690-255e-1034-80d6-f7fcc0a80006</id><type>0</type><name>eliminate_smallpolygons</name><description>null</description><x>326.0</x><y>323.0</y></objectlocation><objectlocation><id>c0992690-255e-1034-8c45-e760c0a80006</id><type>1</type><name>imgURL</name><description>DataType:imgURL</description><x>282.0</x><y>400.0</y></objectlocation><objectlocation><id>c0994da0-255e-1034-8602-736ec0a80006</id><type>1</type><name>returnformat</name><description>DataType:returnformat</description><x>409.0</x><y>404.0</y></objectlocation><objectlocation><id>c0994da0-255e-1034-9372-df18c0a80006</id><type>1</type><name>returnURL</name><description>DataType: returnURL</description><x>325.0</x><y>233.0</y></objectlocation><objectlocation><id>c2d84120-255e-1034-a609-8d1ac0a80006</id><type>0</type><name>r2v</name><description>null</description><x>328.0</x><y>104.0</y></objectlocation><objectlocation><id>c2d86830-255e-1034-9211-a97cc0a80006</id><type>1</type><name>imgURL</name><description>DataType:imgURL</description><x>284.0</x><y>181.0</y></objectlocation><objectlocation><id>c2d86830-255e-1034-b8f3-a198c0a80006</id><type>1</type><name>returnformat</name><description>DataType:returnformat</description><x>373.0</x><y>181.0</y></objectlocation><objectlocation><id>c2d86830-255e-1034-9383-9f2fc0a80006</id><type>1</type><name>returnURL</name><description>DataType: returnURL</description><x>327.0</x><y>41.0</y></objectlocation></parameterconnection>', 'image object', 'Preprocess image and generate objects.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(54, 'urn:uuid:4da9efd0-dc6e-1034-a8e0-544681aea649', 'DownloadECMWFDatasets', 'http://csiss.gmu.edu/lpm2/object/', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><logicprocess version="2.0" targetnamespace="http://csiss.gmu.edu/lpm2/object/DownloadECMWFDatasets" xmlns="http://csiss.gmu.edu/lpm2/object/lpm2.xsd"><modelmetadata id="urn:uuid:4da9efd0-dc6e-1034-a8e0-544681aea649" name="DownloadECMWFDatasets" author="Ziheng Sun" date="2017-02-22-05:00" desc="This model helps downloading the ECMWF public datasets. The scripts take advantage of the ECMWF Web python API. The dataset will first downloaded and a URL link will be returned."/><modeloutput productname="ECMWF Public Datasets" parameter="358097c0-dc6d-1034-8df0-a38981aea649" boundingbox="-180;-90;180;90" projection="EPSG:4326" begintime="1979-01-01T00:00:00" endtime="2017-02-22T03:26:47" keywords="ECMWF, Temperature, Precipitation, Modeling" format="image/netcdf"/><activitymembers><activitymember id="357414a0-dc6d-1034-b252-502c81aea649" name="download" operation="download" servicetype="download"/></activitymembers><parametermembers><parametermember id="35802290-dc6d-1034-9d60-50e281aea649" name="dataset" type="input" datatype="dataset" activity="357414a0-dc6d-1034-b252-502c81aea649" fixedvalue="" dataformat="string" exteriorname="DataSetName (e.g., interim)"/><parametermember id="358049a0-dc6d-1034-93cc-47e681aea649" name="start_date" type="input" datatype="start_date" activity="357414a0-dc6d-1034-b252-502c81aea649" fixedvalue="" dataformat="string" exteriorname="BeginDate (e.g. 2016-12-01)"/><parametermember id="358070b0-dc6d-1034-97dc-604481aea649" name="end_date" type="input" datatype="end_date" activity="357414a0-dc6d-1034-b252-502c81aea649" fixedvalue="" dataformat="string" exteriorname="EndDate (e.g. 2016-12-31)"/><parametermember id="358070b0-dc6d-1034-bbc9-775881aea649" name="parameters" type="input" datatype="parameters" activity="357414a0-dc6d-1034-b252-502c81aea649" fixedvalue="" dataformat="string" exteriorname="Variables (e.g. 201.128/202.128)"/><parametermember id="358097c0-dc6d-1034-8811-541681aea649" name="step" type="input" datatype="step" activity="357414a0-dc6d-1034-b252-502c81aea649" fixedvalue="" dataformat="string" exteriorname="Time Step (e.g., 3/6/9/12)"/><parametermember id="358097c0-dc6d-1034-8bed-08a281aea649" name="time" type="input" datatype="time" activity="357414a0-dc6d-1034-b252-502c81aea649" fixedvalue="" dataformat="string" exteriorname="Time Start Point (e.g. 00:00:00/12:00:00)"/><parametermember id="358097c0-dc6d-1034-8df0-a38981aea649" name="netcdf_urls" type="output" datatype="netcdf_urls" activity="357414a0-dc6d-1034-b252-502c81aea649"/></parametermembers><connectionmembers><connectionmember id="3a574d20-dc6d-1034-bd37-c1fe81aea649" name="Connection0" activityto="357414a0-dc6d-1034-b252-502c81aea649" parameterfrom="35802290-dc6d-1034-9d60-50e281aea649"/><connectionmember id="3a577430-dc6d-1034-a540-ac8681aea649" name="Connection1" activityto="357414a0-dc6d-1034-b252-502c81aea649" parameterfrom="358049a0-dc6d-1034-93cc-47e681aea649"/><connectionmember id="3a579b40-dc6d-1034-84f1-983a81aea649" name="Connection2" activityto="357414a0-dc6d-1034-b252-502c81aea649" parameterfrom="358070b0-dc6d-1034-97dc-604481aea649"/><connectionmember id="3a579b40-dc6d-1034-8b99-fe6781aea649" name="Connection3" activityto="357414a0-dc6d-1034-b252-502c81aea649" parameterfrom="358070b0-dc6d-1034-bbc9-775881aea649"/><connectionmember id="3a579b40-dc6d-1034-921a-8b3b81aea649" name="Connection4" activityto="357414a0-dc6d-1034-b252-502c81aea649" parameterfrom="358097c0-dc6d-1034-8811-541681aea649"/><connectionmember id="3a57c250-dc6d-1034-928c-e11581aea649" name="Connection5" activityto="357414a0-dc6d-1034-b252-502c81aea649" parameterfrom="358097c0-dc6d-1034-8bed-08a281aea649"/><connectionmember id="3a57c250-dc6d-1034-b53a-51f181aea649" name="Connection6" activityfrom="357414a0-dc6d-1034-b252-502c81aea649" parameterto="358097c0-dc6d-1034-8df0-a38981aea649"/></connectionmembers></logicprocess>', '<?xml version="1.0" encoding="UTF-8" standalone="yes"?><parameterconnection xmlns="http://csiss.gmu.edu/lpm2/object/paramcon.xsd"><objectlocation><id>357414a0-dc6d-1034-b252-502c81aea649</id><type>0</type><name>download</name><description>null</description><x>304.0</x><y>260.0</y></objectlocation><objectlocation><id>35802290-dc6d-1034-9d60-50e281aea649</id><type>1</type><name>dataset</name><description>DataType:dataset</description><x>132.0</x><y>294.0</y></objectlocation><objectlocation><id>358049a0-dc6d-1034-93cc-47e681aea649</id><type>1</type><name>start_date</name><description>DataType:start_date</description><x>175.0</x><y>331.0</y></objectlocation><objectlocation><id>358070b0-dc6d-1034-97dc-604481aea649</id><type>1</type><name>end_date</name><description>DataType:end_date</description><x>209.0</x><y>376.0</y></objectlocation><objectlocation><id>358070b0-dc6d-1034-bbc9-775881aea649</id><type>1</type><name>parameters</name><description>DataType:parameters</description><x>317.0</x><y>385.0</y></objectlocation><objectlocation><id>358097c0-dc6d-1034-8811-541681aea649</id><type>1</type><name>step</name><description>DataType:step</description><x>404.0</x><y>355.0</y></objectlocation><objectlocation><id>358097c0-dc6d-1034-8bed-08a281aea649</id><type>1</type><name>time</name><description>DataType:time</description><x>452.0</x><y>288.0</y></objectlocation><objectlocation><id>358097c0-dc6d-1034-8df0-a38981aea649</id><type>1</type><name>netcdf_urls</name><description>DataType: netcdf_urls</description><x>304.0</x><y>170.0</y></objectlocation></parameterconnection>', 'ECMWF, Temperature, Precipitation, Modeling', 'This model helps downloading the ECMWF public datasets. The scripts take advantage of the ECMWF Web python API. The dataset will first downloaded and a URL link will be returned.', '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(66, '5k56d9vcx4ip3tr5pj26', 'test-bash-2', 'http://geoweaver.csiss.gmu.edu/workflow/test-bash-2', '[{"title":"sleep5s","id":"ac4724-jL0Ep","x":216.67081451416016,"y":87.87157201766968,"color":"red"},{"title":"testbash","id":"199vsg-Xr6FZ","x":505.2892303466797,"y":116.6651611328125,"color":"red"},{"title":"testbash","id":"199vsg-oAq2d","x":-11.481706857681274,"y":280.7070007324219,"color":"red"}]', '[{"source":{"title":"sleep5s","id":"ac4724-jL0Ep","x":216.67081451416016,"y":87.87157201766968,"color":"red"},"target":{"title":"testbash","id":"199vsg-Xr6FZ","x":505.2892303466797,"y":116.6651611328125,"color":"red"}},{"source":{"title":"testbash","id":"199vsg-oAq2d","x":-11.481706857681274,"y":280.7070007324219,"color":"red"},"target":{"title":"sleep5s","id":"ac4724-jL0Ep","x":216.67081451416016,"y":87.87157201766968,"color":"red"}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(67, 't0ie2loym6u46u8mlgr3', 'preprocessing_landsat', 'http://geoweaver.csiss.gmu.edu/workflow/preprocessing_landsat', '[{"title":"download-landsat","id":"nhi96d-7VZhh","x":119,"y":279},{"title":"filter_cloud","id":"rh1u8q-4sCmg","x":286,"y":148},{"title":"filter_shadow","id":"rpnhlg-JZfyQ","x":455,"y":282},{"title":"match_cdl_landsat","id":"omop8l-1p5x1","x":624,"y":152}]', '[{"source":{"title":"download-landsat","id":"nhi96d-7VZhh","x":119,"y":279},"target":{"title":"filter_cloud","id":"rh1u8q-4sCmg","x":286,"y":148}},{"source":{"title":"filter_cloud","id":"rh1u8q-4sCmg","x":286,"y":148},"target":{"title":"filter_shadow","id":"rpnhlg-JZfyQ","x":455,"y":282}},{"source":{"title":"filter_shadow","id":"rpnhlg-JZfyQ","x":455,"y":282},"target":{"title":"match_cdl_landsat","id":"omop8l-1p5x1","x":624,"y":152}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(68, 'qrb8eyx0kx9vk84iaf39', 'test2', 'http://geoweaver.csiss.gmu.edu/workflow/test2', '[{"title":"testsshscript","id":"degrzr-LKHuh","x":493,"y":236},{"title":"sleep15s","id":"ac4724-AJVWV","x":686,"y":427}]', '[{"source":{"title":"testsshscript","id":"degrzr-LKHuh","x":493,"y":236},"target":{"title":"sleep15s","id":"ac4724-AJVWV","x":686,"y":427}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(69, 'q3ttwjbql5d49bffsl94', 'test3', 'http://geoweaver.csiss.gmu.edu/workflow/test3', '[{"title":"filter_cloud","id":"rh1u8q-0MNeQ","x":50,"y":190},{"title":"test1","id":"oax563-i2WdG","x":253,"y":355}]', '[{"source":{"title":"filter_cloud","id":"rh1u8q-0MNeQ","x":50,"y":190},"target":{"title":"test1","id":"oax563-i2WdG","x":253,"y":355}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(70, '7w0ga6df6x6xhex588pk', 'TestWorkflow1', 'http://geoweaver.csiss.gmu.edu/workflow/TestWorkflow1', '[{"title":"testbash","id":"199vsg-rQe87","x":125,"y":205},{"title":"TestProcess1","id":"o634zj-XHZMP","x":298.85044860839844,"y":331.29827880859375},{"title":"sleep15s","id":"ac4724-K7xEA","x":466.0041046142578,"y":214.95480346679688}]', '[{"source":{"title":"testbash","id":"199vsg-rQe87","x":125,"y":205},"target":{"title":"TestProcess1","id":"o634zj-XHZMP","x":298.85044860839844,"y":331.29827880859375}},{"source":{"title":"TestProcess1","id":"o634zj-XHZMP","x":298.85044860839844,"y":331.29827880859375},"target":{"title":"sleep15s","id":"ac4724-K7xEA","x":466.0041046142578,"y":214.95480346679688}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(71, 'vke2yf47hyot7ae7np7h', 'test_cdl', 'http://geoweaver.csiss.gmu.edu/workflow/test_cdl', '[{"title":"ShowCropMap","id":"7sb7xj-jyToc","x":532.7653198242188,"y":685.3731689453125},{"title":"cdl_class_mapping","id":"ew8pku-GsoF6","x":798.9148559570312,"y":354.9559631347656},{"title":"download-landsat","id":"nhi96d-QjAOf","x":455,"y":195.00001525878906},{"title":"match_cdl_landsat","id":"omop8l-CNs0W","x":529.3905029296875,"y":367.332275390625},{"title":"reprojection","id":"qp820f-NCTrl","x":798.5715637207031,"y":187.1134796142578},{"title":"filter_cloud","id":"rh1u8q-4GbwM","x":261.30078125,"y":370.7999572753906},{"title":"filter_shadow","id":"rpnhlg-J05ve","x":265,"y":517},{"title":"rescale_cdl","id":"spz3b5-czpKT","x":795.6377258300781,"y":515.3212432861328},{"title":"filter_bad","id":"umv6tx-4GR5R","x":263,"y":195.00001525878906},{"title":"test_segnet","id":"m6bbrf-KIAHv","x":531.0000076293945,"y":539.9999847412109},{"title":"download_cdl","id":"wsxeps-6vYXt","x":622,"y":191.00001525878906}]', '[{"source":{"title":"download_cdl","id":"wsxeps-6vYXt","x":622,"y":191.00001525878906},"target":{"title":"reprojection","id":"qp820f-NCTrl","x":798.5715637207031,"y":187.1134796142578}},{"source":{"title":"download-landsat","id":"nhi96d-QjAOf","x":455,"y":195.00001525878906},"target":{"title":"filter_bad","id":"umv6tx-4GR5R","x":263,"y":195.00001525878906}},{"source":{"title":"filter_bad","id":"umv6tx-4GR5R","x":263,"y":195.00001525878906},"target":{"title":"filter_cloud","id":"rh1u8q-4GbwM","x":261.30078125,"y":370.7999572753906}},{"source":{"title":"reprojection","id":"qp820f-NCTrl","x":798.5715637207031,"y":187.1134796142578},"target":{"title":"cdl_class_mapping","id":"ew8pku-GsoF6","x":798.9148559570312,"y":354.9559631347656}},{"source":{"title":"cdl_class_mapping","id":"ew8pku-GsoF6","x":798.9148559570312,"y":354.9559631347656},"target":{"title":"rescale_cdl","id":"spz3b5-czpKT","x":795.6377258300781,"y":515.3212432861328}},{"source":{"title":"filter_cloud","id":"rh1u8q-4GbwM","x":261.30078125,"y":370.7999572753906},"target":{"title":"filter_shadow","id":"rpnhlg-J05ve","x":265,"y":517}},{"source":{"title":"filter_shadow","id":"rpnhlg-J05ve","x":265,"y":517},"target":{"title":"match_cdl_landsat","id":"omop8l-CNs0W","x":529.3905029296875,"y":367.332275390625}},{"source":{"title":"rescale_cdl","id":"spz3b5-czpKT","x":795.6377258300781,"y":515.3212432861328},"target":{"title":"match_cdl_landsat","id":"omop8l-CNs0W","x":529.3905029296875,"y":367.332275390625}},{"source":{"title":"match_cdl_landsat","id":"omop8l-CNs0W","x":529.3905029296875,"y":367.332275390625},"target":{"title":"test_segnet","id":"m6bbrf-KIAHv","x":531.0000076293945,"y":539.9999847412109}},{"source":{"title":"test_segnet","id":"m6bbrf-KIAHv","x":531.0000076293945,"y":539.9999847412109},"target":{"title":"ShowCropMap","id":"7sb7xj-jyToc","x":532.7653198242188,"y":685.3731689453125}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(72, 'zdwtvinusmo536sla94v', 'test-new', 'http://geoweaver.csiss.gmu.edu/workflow/test-new', '[{"title":"coords_transform","id":"zdh3ll-yneyR","x":504.74237060546875,"y":83.43736267089844},{"title":"sleep15s","id":"ac4724-7KQLl","x":767.3981323242188,"y":330.38043212890625}]', '[{"source":{"title":"coords_transform","id":"zdh3ll-yneyR","x":504.74237060546875,"y":83.43736267089844},"target":{"title":"sleep15s","id":"ac4724-7KQLl","x":767.3981323242188,"y":330.38043212890625}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(73, 'e6kct2xn7hmmtxu7ww5m', 'jupyter-chain', 'http://geoweaver.csiss.gmu.edu/workflow/jupyter-chain', '[{"title":"deep-learning-tutorial","id":"j9pxl1-NS3eu","x":190.11181640625,"y":359.35125732421875},{"title":"asj","id":"b6deul-dpAHi","x":504,"y":291},{"title":"call_nwis","id":"4hf60x-4VBv2","x":379,"y":433},{"title":"daily_aggregation","id":"t0cqqj-azF9B","x":298,"y":609}]', '[{"source":{"title":"deep-learning-tutorial","id":"j9pxl1-NS3eu","x":190.11181640625,"y":359.35125732421875},"target":{"title":"call_nwis","id":"4hf60x-4VBv2","x":379,"y":433}},{"source":{"title":"asj","id":"b6deul-dpAHi","x":504,"y":291},"target":{"title":"call_nwis","id":"4hf60x-4VBv2","x":379,"y":433}},{"source":{"title":"call_nwis","id":"4hf60x-4VBv2","x":379,"y":433},"target":{"title":"daily_aggregation","id":"t0cqqj-azF9B","x":298,"y":609}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(74, 'kuxiy1ax12m858vuoeps', 'ag-net-preprocessing', 'http://geoweaver.csiss.gmu.edu/workflow/ag-net-preprocessing', '[{"title":"download-landsat","id":"nhi96d-hht7r","x":257.95923614501953,"y":-183.25271606445312},{"title":"match_cdl_landsat","id":"omop8l-EAFYQ","x":439.404296875,"y":-30.069656372070312},{"title":"reprojection","id":"qp820f-ICD7t","x":438.628173828125,"y":-183.31942749023438},{"title":"filter_cloud","id":"rh1u8q-Xh2j8","x":612.7286376953125,"y":-181.46063232421875},{"title":"filter_shadow","id":"rpnhlg-bVSvc","x":609.0150146484375,"y":-28.28240966796875},{"title":"rescale_cdl","id":"spz3b5-xn1QB","x":254.00003051757812,"y":-30},{"title":"download_cdl","id":"wsxeps-N8Rwj","x":77,"y":-32}]', '[{"source":{"title":"download_cdl","id":"wsxeps-N8Rwj","x":77,"y":-32},"target":{"title":"rescale_cdl","id":"spz3b5-xn1QB","x":254.00003051757812,"y":-30}},{"source":{"title":"download-landsat","id":"nhi96d-hht7r","x":257.95923614501953,"y":-183.25271606445312},"target":{"title":"reprojection","id":"qp820f-ICD7t","x":438.628173828125,"y":-183.31942749023438}},{"source":{"title":"reprojection","id":"qp820f-ICD7t","x":438.628173828125,"y":-183.31942749023438},"target":{"title":"filter_cloud","id":"rh1u8q-Xh2j8","x":612.7286376953125,"y":-181.46063232421875}},{"source":{"title":"filter_cloud","id":"rh1u8q-Xh2j8","x":612.7286376953125,"y":-181.46063232421875},"target":{"title":"filter_shadow","id":"rpnhlg-bVSvc","x":609.0150146484375,"y":-28.28240966796875}},{"source":{"title":"filter_shadow","id":"rpnhlg-bVSvc","x":609.0150146484375,"y":-28.28240966796875},"target":{"title":"match_cdl_landsat","id":"omop8l-EAFYQ","x":439.404296875,"y":-30.069656372070312}},{"source":{"title":"rescale_cdl","id":"spz3b5-xn1QB","x":254.00003051757812,"y":-30},"target":{"title":"match_cdl_landsat","id":"omop8l-EAFYQ","x":439.404296875,"y":-30.069656372070312}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png'),
	(75, '9wqw7enxkj8ngnc7pj6f', 'test-workflow', 'http://geoweaver.csiss.gmu.edu/workflow/test-workflow', '[{"title":"test-esip-2","id":"wcyu4q-0i3wI","x":636,"y":417},{"title":"test6","id":"c0cs3l-xDzXh","x":361,"y":246},{"title":"test3.py","id":"f0qvfi-cen9Y","x":638,"y":235}]', '[{"source":{"title":"test6","id":"c0cs3l-xDzXh","x":361,"y":246},"target":{"title":"test3.py","id":"f0qvfi-cen9Y","x":638,"y":235}},{"source":{"title":"test3.py","id":"f0qvfi-cen9Y","x":638,"y":235},"target":{"title":"test-esip-2","id":"wcyu4q-0i3wI","x":636,"y":417}}]', NULL, NULL, '2013-09-11', '2013-09-11', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'image/png');
/*!40000 ALTER TABLE `abstract_model` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.association
DROP TABLE IF EXISTS `association`;
CREATE TABLE IF NOT EXISTS `association` (
  `id` int(10) NOT NULL AUTO_INCREMENT,
  `process_type_id` int(10) NOT NULL,
  `service_id` int(10) NOT NULL,
  `operation_name` varchar(50) NOT NULL,
  `inputs_pathes` text,
  `output_path` text,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=777 DEFAULT CHARSET=latin1 COMMENT='This table stores the links between process and services.';

-- Dumping data for table cyberconnector.association: ~95 rows (approximately)
DELETE FROM `association`;
/*!40000 ALTER TABLE `association` DISABLE KEYS */;
INSERT INTO `association` (`id`, `process_type_id`, `service_id`, `operation_name`, `inputs_pathes`, `output_path`) VALUES
	(108, 108, 30, 'merge', 'mergeElement/sourceURL;mergeElement/classlist', 'mergeResponse/returnURL;mergeResponse/returnFormat'),
	(218, 219, 36, 'r2v', 'r2vElement/imgURL;r2vElement/returnformat', 'r2vResponse/returnURL'),
	(219, 220, 37, 'eliminate_smallpolygons', 'eliminate_smallpolygonsElement/imgURL;eliminate_smallpolygonsElement/returnformat', 'eliminate_smallpolygonsResponse/returnURL'),
	(222, 223, 40, 'rgb2singlevalue', 'rgb2singlevalueElement/imgURL;rgb2singlevalueElement/returnformat', 'rgb2singlevalueResponse/returnURL'),
	(223, 224, 41, 'segment', 'segmentElement/imgURL;segmentElement/sigmaS;segmentElement/sigmaR;segmentElement/minRegion;segmentElement/speedUpLevel;segmentElement/speedUpThreshold;segmentElement/checkWeightMap;segmentElement/gradientWindow;segmentElement/blendVar;segmentElement/threshold;segmentElement/returnFormat;segmentElement/sigmaS2', 'segmentResponse/filter_imgURL;segmentResponse/fusion_imgURL;segmentResponse/seg_imgURL;segmentResponse/boundary_imgURL'),
	(224, 222, 42, 'classify', 'classifyElement/vectorURL;classifyElement/rasterURL;classifyElement/segURL;classifyElement/classhierarchy;classifyElement/featurespace;classifyElement/k;classifyElement/unclassfied;classifyElement/threshold', 'classifyResponse/returnVURL'),
	(228, 229, 44, 'Generate_River_USGS_links', 'Generate_River_USGS_linksElement/year;Generate_River_USGS_linksElement/stationid;Generate_River_USGS_linksElement/parameterlist', 'Generate_River_USGS_linksResponse/river_originial_file_url'),
	(229, 230, 44, 'interpolate_HYCOM_combine_to_FVCOM_grid', 'interpolate_HYCOM_combine_to_FVCOM_gridElement/hycom_combine_InputURL', 'interpolate_HYCOM_combine_to_FVCOM_gridResponse/inter_temperature_InputURL;interpolate_HYCOM_combine_to_FVCOM_gridResponse/inter_salinity_InputURL;interpolate_HYCOM_combine_to_FVCOM_gridResponse/inter_U_velocity_InputURL;interpolate_HYCOM_combine_to_FVCOM_gridResponse/inter_V_velocity_InputURL'),
	(230, 231, 44, 'Generate_HYCOM_links', 'Generate_HYCOM_linksElement/year;Generate_HYCOM_linksElement/day;Generate_HYCOM_linksElement/hour', 'Generate_HYCOM_linksResponse/hycom_combination_file_url'),
	(231, 232, 44, 'Generate_Wind_FVCOM_Input', 'Generate_Wind_FVCOM_InputElement/interp_wind_vector_list;Generate_Wind_FVCOM_InputElement/year_start;Generate_Wind_FVCOM_InputElement/year_end;Generate_Wind_FVCOM_InputElement/month_start;Generate_Wind_FVCOM_InputElement/month_end;Generate_Wind_FVCOM_InputElement/day_start;Generate_Wind_FVCOM_InputElement/day_end', 'Generate_Wind_FVCOM_InputResponse/wind_wnd_fvcom_input_url;Generate_Wind_FVCOM_InputResponse/wind_hfx_fvcom_input_url'),
	(232, 233, 44, 'Interpolate_NARR_Wind_Vector', 'Interpolate_NARR_Wind_VectorElement/nomads_txt_list;Interpolate_NARR_Wind_VectorElement/year_start;Interpolate_NARR_Wind_VectorElement/year_end;Interpolate_NARR_Wind_VectorElement/month_start;Interpolate_NARR_Wind_VectorElement/month_end;Interpolate_NARR_Wind_VectorElement/day_start;Interpolate_NARR_Wind_VectorElement/day_end', 'Interpolate_NARR_Wind_VectorResponse/interpl_uv_file_list'),
	(233, 234, 44, 'Pick_NARR_Wind_Vector', 'Pick_NARR_Wind_VectorElement/narr_txt_list;Pick_NARR_Wind_VectorElement/year_start;Pick_NARR_Wind_VectorElement/year_end;Pick_NARR_Wind_VectorElement/month_start;Pick_NARR_Wind_VectorElement/month_end;Pick_NARR_Wind_VectorElement/day_start;Pick_NARR_Wind_VectorElement/day_end;Pick_NARR_Wind_VectorElement/lat1;Pick_NARR_Wind_VectorElement/lon1;Pick_NARR_Wind_VectorElement/lat2;Pick_NARR_Wind_VectorElement/lon2', 'Pick_NARR_Wind_VectorResponse/nomads_data_subset_list'),
	(234, 235, 44, 'Downlad_NARR_TO_ASCII', 'Downlad_NARR_TO_ASCIIElement/year_start;Downlad_NARR_TO_ASCIIElement/year_end;Downlad_NARR_TO_ASCIIElement/month_start;Downlad_NARR_TO_ASCIIElement/month_end;Downlad_NARR_TO_ASCIIElement/full_month;Downlad_NARR_TO_ASCIIElement/day_start;Downlad_NARR_TO_ASCIIElement/day_end', 'Downlad_NARR_TO_ASCIIResponse/narr_grb_url_list;Downlad_NARR_TO_ASCIIResponse/narr_txt_url_list'),
	(235, 236, 44, 'Write_River_FVCOM_Input', 'Write_River_FVCOM_InputElement/Caern_file_URL;Write_River_FVCOM_InputElement/Atcha_file_URL;Write_River_FVCOM_InputElement/Missi_file_URL;Write_River_FVCOM_InputElement/Wax_file_URL', 'Write_River_FVCOM_InputResponse/River_FVCOM_Input_URL'),
	(236, 237, 44, 'GMT_Check', 'GMT_CheckElement/GMT_file_URL;GMT_CheckElement/last_year_GMT_file_URL;GMT_CheckElement/rivername;GMT_CheckElement/year', 'GMT_CheckResponse/GMT_DAT_URL;GMT_CheckResponse/Report_DAT_URL;GMT_CheckResponse/Check_DAT_URL;GMT_CheckResponse/No_NAN_DAT_URL'),
	(237, 238, 44, 'CDT_and_CST_to_GMT', 'CDT_and_CST_to_GMTElement/original_file_URL;CDT_and_CST_to_GMTElement/rivername', 'CDT_and_CST_to_GMTResponse/returnURL'),
	(238, 239, 44, 'interpolate_HYCOM_to_FVCOM_grid', 'interpolate_HYCOM_to_FVCOM_gridElement/temperature_InputURL;interpolate_HYCOM_to_FVCOM_gridElement/salinity_InputURL;interpolate_HYCOM_to_FVCOM_gridElement/U_velocity_InputURL;interpolate_HYCOM_to_FVCOM_gridElement/V_velocity_InputURL', 'interpolate_HYCOM_to_FVCOM_gridResponse/inter_temperature_InputURL;interpolate_HYCOM_to_FVCOM_gridResponse/inter_salinity_InputURL;interpolate_HYCOM_to_FVCOM_gridResponse/inter_U_velocity_InputURL;interpolate_HYCOM_to_FVCOM_gridResponse/inter_V_velocity_InputURL'),
	(239, 240, 44, 'rewrite_to_FVCOM_input_format', 'rewrite_to_FVCOM_input_formatElement/inter_temperature_InputURL;rewrite_to_FVCOM_input_formatElement/inter_salinity_InputURL;rewrite_to_FVCOM_input_formatElement/inter_U_velocity_InputURL;rewrite_to_FVCOM_input_formatElement/inter_V_velocity_InputURL', 'rewrite_to_FVCOM_input_formatResponse/returnURL'),
	(244, 245, 46, 'dynamo_reform1', 'dynamo_reform1Element/fieldDataURL;dynamo_reform1Element/Q1Q2DataURL', 'dynamo_reform1Response/dynamoForcingDataURL;dynamo_reform1Response/dynamoQ1Q2DataURL'),
	(245, 246, 46, 'dynamo_reform2', 'dynamo_reform2Element/fieldDataURL', 'dynamo_reform2Response/surfaceDataURL;dynamo_reform2Response/soundingDataURL'),
	(246, 247, 46, 'get_sst_sflux_6hourly', 'get_sst_sflux_6hourlyElement/fluxDataURL', 'get_sst_sflux_6hourlyResponse/surfaceFlux6HrsURI'),
	(247, 248, 46, 'get_crm_input_dynamo', 'get_crm_input_dynamoElement/soundingDataURL;get_crm_input_dynamoElement/forcingDataURL;get_crm_input_dynamoElement/SSTLSHDataURL;get_crm_input_dynamoElement/surfaceDataURL', 'get_crm_input_dynamoResponse/forcingProfilesDataURL;get_crm_input_dynamoResponse/initalSoundingDataURL;get_crm_input_dynamoResponse/thetaAndQVProfilesURL;get_crm_input_dynamoResponse/timeseriesOfThetaAndQVDataURL;get_crm_input_dynamoResponse/velocityProfileDataURL'),
	(248, 249, 46, 'zip_crm_input', 'zip_crm_inputElement/forcingProfilesDataURL;zip_crm_inputElement/initalSoundingDataURL;zip_crm_inputElement/thetaAndQVProfilesURL;zip_crm_inputElement/timeseriesOfThetaAndQVDataURL;zip_crm_inputElement/velocityProfileDataURL', 'zip_crm_inputResponse/crmInputPackage'),
	(250, 251, 66, 'DrawDroughtTimeSeries', 'DrawDroughtTimeSeries/Op;DrawDroughtTimeSeries/fips_str;DrawDroughtTimeSeries/in_year;DrawDroughtTimeSeries/cropType', 'DrawDroughtTimeSeriesResponse/return'),
	(251, 252, 66, 'DrawBarChart', 'DrawBarChart/Op;DrawBarChart/fips_str;DrawBarChart/in_year;DrawBarChart/in_day;DrawBarChart/cropType', 'DrawBarChartResponse/return'),
	(252, 253, 66, 'DrawTimeSeries', 'DrawTimeSeries/Op;DrawTimeSeries/fips_str;DrawTimeSeries/in_year;DrawTimeSeries/cropType', 'DrawTimeSeriesResponse/return'),
	(665, 666, 101, 'tiledWeeklyNDVI2VCICalc', 'tiledWeeklyNDVI2VCICalc/Daily_NDVI_URL;tiledWeeklyNDVI2VCICalc/Weekly_Max_Min_URL;tiledWeeklyNDVI2VCICalc/start_year;tiledWeeklyNDVI2VCICalc/start_day;tiledWeeklyNDVI2VCICalc/end_year;tiledWeeklyNDVI2VCICalc/end_day', 'tiledWeeklyNDVI2VCICalcResponse/return'),
	(666, 667, 101, 'clipROIHDF', 'clipROIHDF/bbox;clipROIHDF/year;clipROIHDF/day', 'clipROIHDFResponse/return'),
	(667, 668, 101, 'ROIYearsDailyNDVICalc', 'ROIYearsDailyNDVICalc/years_b1b2QA_URL;ROIYearsDailyNDVICalc/years;ROIYearsDailyNDVICalc/in_day', 'ROIYearsDailyNDVICalcResponse/return'),
	(668, 669, 101, 'tiledWeeklyNDVIMaxMinCalc', 'tiledWeeklyNDVIMaxMinCalc/Daily_NDVI_URL;tiledWeeklyNDVIMaxMinCalc/start_year;tiledWeeklyNDVIMaxMinCalc/start_day;tiledWeeklyNDVIMaxMinCalc/end_year;tiledWeeklyNDVIMaxMinCalc/end_day', 'tiledWeeklyNDVIMaxMinCalcResponse/return'),
	(669, 670, 101, 'tiledDailyNDVICalcSimple', 'tiledDailyNDVICalcSimple/in_year;tiledDailyNDVICalcSimple/in_day', 'tiledDailyNDVICalcSimpleResponse/return'),
	(670, 671, 101, 'clipROIHDFYears', 'clipROIHDFYears/bbox;clipROIHDFYears/years;clipROIHDFYears/day', 'clipROIHDFYearsResponse/return'),
	(671, 672, 101, 'getQATilesWeekly', 'getQATilesWeekly/tile_no;getQATilesWeekly/in_year;getQATilesWeekly/in_day', 'getQATilesWeeklyResponse/return'),
	(672, 673, 101, 'ROIDailyNDVICalc', 'ROIDailyNDVICalc/b1b2QA_URL;ROIDailyNDVICalc/in_year;ROIDailyNDVICalc/in_day', 'ROIDailyNDVICalcResponse/return'),
	(673, 674, 101, 'clipROIHDFYearsDays', 'clipROIHDFYearsDays/bbox;clipROIHDFYearsDays/years;clipROIHDFYearsDays/in_day;clipROIHDFYearsDays/daynum', 'clipROIHDFYearsDaysResponse/return'),
	(674, 675, 101, 'readHDFSubset', 'readHDFSubset/in_hdf;readHDFSubset/subset_no', 'readHDFSubsetResponse/return'),
	(675, 676, 101, 'clipROIHDFDays', 'clipROIHDFDays/bbox;clipROIHDFDays/in_year;clipROIHDFDays/in_day;clipROIHDFDays/daynum', 'clipROIHDFDaysResponse/return'),
	(676, 677, 101, 'tiled7DayNDVICalc', 'tiled7DayNDVICalc/MOD09GQK_URL;tiled7DayNDVICalc/MOD09GST_URL;tiled7DayNDVICalc/in_year;tiled7DayNDVICalc/in_day', 'tiled7DayNDVICalcResponse/return'),
	(677, 678, 101, 'getb1b2TilesYearsWeekly', 'getb1b2TilesYearsWeekly/tile_no;getb1b2TilesYearsWeekly/year_list;getb1b2TilesYearsWeekly/in_day', 'getb1b2TilesYearsWeeklyResponse/return'),
	(678, 679, 101, 'getQATiles', 'getQATiles/tile_list;getQATiles/year;getQATiles/day', 'getQATilesResponse/return'),
	(679, 680, 101, 'VCI16bitsTO8bitsCalc', 'VCI16bitsTO8bitsCalc/Tiff_URL', 'VCI16bitsTO8bitsCalcResponse/return'),
	(680, 681, 101, 'ROIDaysNDVICompositeCalc', 'ROIDaysNDVICompositeCalc/Daily_NDVI_URL;ROIDaysNDVICompositeCalc/in_year;ROIDaysNDVICompositeCalc/in_day;ROIDaysNDVICompositeCalc/daynum', 'ROIDaysNDVICompositeCalcResponse/return'),
	(681, 682, 101, 'ROIYearsDaysNDVICalc', 'ROIYearsDaysNDVICalc/years_b1b2QA_URL;ROIYearsDaysNDVICalc/years;ROIYearsDaysNDVICalc/in_day;ROIYearsDaysNDVICalc/daynum', 'ROIYearsDaysNDVICalcResponse/return'),
	(682, 683, 101, 'getb1b2TilesWeekly', 'getb1b2TilesWeekly/tile_no;getb1b2TilesWeekly/in_year;getb1b2TilesWeekly/in_day', 'getb1b2TilesWeeklyResponse/return'),
	(683, 684, 101, 'getQATilesYears', 'getQATilesYears/tile_no;getQATilesYears/year_list;getQATilesYears/day', 'getQATilesYearsResponse/return'),
	(684, 685, 101, 'ROIDaysDailyNDVICalc', 'ROIDaysDailyNDVICalc/days_b1b2QA_URL;ROIDaysDailyNDVICalc/in_year;ROIDaysDailyNDVICalc/in_day;ROIDaysDailyNDVICalc/daynum', 'ROIDaysDailyNDVICalcResponse/return'),
	(685, 686, 101, 'ROIYearsDailyNDVIMaxMinCalc', 'ROIYearsDailyNDVIMaxMinCalc/Daily_NDVI_URL;ROIYearsDailyNDVIMaxMinCalc/years;ROIYearsDailyNDVIMaxMinCalc/in_day', 'ROIYearsDailyNDVIMaxMinCalcResponse/return'),
	(686, 687, 101, 'ROIDailyNDVI2VCICalc', 'ROIDailyNDVI2VCICalc/Daily_NDVI_URL;ROIDailyNDVI2VCICalc/Max_Min_NDVI_URL;ROIDailyNDVI2VCICalc/in_year;ROIDailyNDVI2VCICalc/in_day', 'ROIDailyNDVI2VCICalcResponse/return'),
	(687, 688, 101, 'ROIMaskVCIByCropLayer', 'ROIMaskVCIByCropLayer/vciurl;ROIMaskVCIByCropLayer/in_year;ROIMaskVCIByCropLayer/in_day', 'ROIMaskVCIByCropLayerResponse/return'),
	(688, 689, 101, 'tiledDailyNDVIMaxMinCalc', 'tiledDailyNDVIMaxMinCalc/Daily_NDVI_URL;tiledDailyNDVIMaxMinCalc/in_year;tiledDailyNDVIMaxMinCalc/in_day', 'tiledDailyNDVIMaxMinCalcResponse/return'),
	(689, 690, 101, 'getQATilesYearsWeekly', 'getQATilesYearsWeekly/tile_no;getQATilesYearsWeekly/year_list;getQATilesYearsWeekly/in_day', 'getQATilesYearsWeeklyResponse/return'),
	(690, 691, 101, 'tiledYearsDailyNDVICalc', 'tiledYearsDailyNDVICalc/MOD09GQK_URL;tiledYearsDailyNDVICalc/MOD09GST_URL;tiledYearsDailyNDVICalc/in_year;tiledYearsDailyNDVICalc/in_day', 'tiledYearsDailyNDVICalcResponse/return'),
	(691, 692, 101, 'ROIYearsDaysNDVICompositeCalc', 'ROIYearsDaysNDVICompositeCalc/Daily_NDVI_URL;ROIYearsDaysNDVICompositeCalc/years;ROIYearsDaysNDVICompositeCalc/in_day;ROIYearsDaysNDVICompositeCalc/daynum', 'ROIYearsDaysNDVICompositeCalcResponse/return'),
	(692, 693, 101, 'getHDFTiles', 'getHDFTiles/LongitudeLo;getHDFTiles/LatitudeHi;getHDFTiles/LongitudeHi;getHDFTiles/LatitudeLo', 'getHDFTilesResponse/return'),
	(693, 694, 101, 'tiledYears7DaysNDVICalc', 'tiledYears7DaysNDVICalc/MOD09GQK_URL;tiledYears7DaysNDVICalc/MOD09GST_URL;tiledYears7DaysNDVICalc/in_year;tiledYears7DaysNDVICalc/in_day', 'tiledYears7DaysNDVICalcResponse/return'),
	(694, 695, 101, 'tiled1YearWeeklyNDVIComposite', 'tiled1YearWeeklyNDVIComposite/Daily_NDVI_URL;tiled1YearWeeklyNDVIComposite/start_year;tiled1YearWeeklyNDVIComposite/start_day;tiled1YearWeeklyNDVIComposite/end_year;tiled1YearWeeklyNDVIComposite/end_day', 'tiled1YearWeeklyNDVICompositeResponse/return'),
	(695, 696, 101, 'tiledDailyNDVICalc', 'tiledDailyNDVICalc/MOD09GQK_URL;tiledDailyNDVICalc/MOD09GST_URL;tiledDailyNDVICalc/in_year;tiledDailyNDVICalc/in_day', 'tiledDailyNDVICalcResponse/return'),
	(696, 697, 101, 'getVCIstats', 'getVCIstats/Tiff_URL', 'getVCIstatsResponse/return'),
	(697, 698, 101, 'getb1b2TilesYears', 'getb1b2TilesYears/tile_no;getb1b2TilesYears/year_list;getb1b2TilesYears/day', 'getb1b2TilesYearsResponse/return'),
	(698, 699, 101, 'tiledDailyNDVI2VCICalc', 'tiledDailyNDVI2VCICalc/Daily_NDVI_URL;tiledDailyNDVI2VCICalc/Max_Min_NDVI_URL;tiledDailyNDVI2VCICalc/in_year;tiledDailyNDVI2VCICalc/in_day', 'tiledDailyNDVI2VCICalcResponse/return'),
	(699, 700, 101, 'getb1b2Tiles', 'getb1b2Tiles/tile_list;getb1b2Tiles/year;getb1b2Tiles/day', 'getb1b2TilesResponse/return'),
	(704, 705, 106, 'remove', 'removeElement/sourceURL;removeElement/min_area', 'removeResponse/returnURL;removeResponse/returnFormat'),
	(705, 706, 107, 'get_projection', 'get_projectionElement/inputURL', 'get_projectionResponse/returnURL;get_projectionResponse/returnFormat'),
	(707, 708, 110, 'download', 'downloadElement/dataset;downloadElement/start_date;downloadElement/end_date;downloadElement/parameters;downloadElement/step;downloadElement/time', 'downloadResponse/netcdf_urls'),
	(709, 710, 112, 'param_scale', 'Param_scaleElement/sourceURL;Param_scaleElement/s_tol;Param_scaleElement/c_tol;Param_scaleElement/size;Param_scaleElement/param;Param_scaleElement/exp;Param_scaleElement/zscale;Param_scaleElement/central_window;Param_scaleElement/outputGeoTiffType', 'Param_scaleResponse/returnURL;Param_scaleResponse/returnFormat'),
	(710, 711, 113, 'gml2shp', 'GML2SHPElement/sourceURL', 'GML2SHPResponse/returnURL;GML2SHPResponse/returnFormat'),
	(711, 712, 114, 'patch', 'PatchElement/sourceURLArray', 'PatchResponse/returnURL;PatchResponse/returnFormat'),
	(712, 713, 115, 'rgb_composite', 'RGB_compositeElement/redImageURL;RGB_compositeElement/greenImageURL;RGB_compositeElement/blueImageURL;RGB_compositeElement/dither;RGB_compositeElement/closestcolor;RGB_compositeElement/levels;RGB_compositeElement/lev_red;RGB_compositeElement/lev_green;RGB_compositeElement/lev_blue;RGB_compositeElement/rgbDisplayMode;RGB_compositeElement/outputFormatType', 'RGB_compositeResponse/returnURL;RGB_compositeResponse/returnFormat'),
	(713, 714, 116, 'patch_singleband', 'Patch_singlebandElement/sourceURLArray;Patch_singlebandElement/outputFormatType;Patch_singlebandElement/outputGeoTiffType', 'Patch_singlebandResponse/returnURL;Patch_singlebandResponse/returnFormat'),
	(714, 715, 117, 'map_calculation', 'Map_calculationElement/sourceURLArray;Map_calculationElement/formula;Map_calculationElement/outputGeoTiffType', 'Map_calculationResponse/returnURL;Map_calculationResponse/returnFormat'),
	(715, 716, 118, 'openness', 'OpennessElement/sourceURL;OpennessElement/scale;OpennessElement/zunit;OpennessElement/outputGeoTiffType', 'OpennessResponse/phiReturnURL;OpennessResponse/phiReturnFormat;OpennessResponse/psiReturnURL;OpennessResponse/psiReturnFormat'),
	(716, 717, 119, 'surf_contour', 'Surf_contourElement/sourceURL;Surf_contourElement/outputGeoTiffType', 'Surf_contourResponse/returnURL;Surf_contourResponse/returnFormat'),
	(717, 718, 120, 'supervised', 'SupervisedElement/sourceURLArray;SupervisedElement/trainingImageURL;SupervisedElement/classificationMethod;SupervisedElement/outputGeoTiffType', 'SupervisedResponse/returnURL;SupervisedResponse/returnFormat'),
	(718, 719, 121, 'rgb2HIS', 'RGB2HISElement/redImageURL;RGB2HISElement/greenImageURL;RGB2HISElement/blueImageURL;RGB2HISElement/outputGeoTiffType', 'RGB2HISResponse/hueReturnURL;RGB2HISResponse/intensityReturnURL;RGB2HISResponse/saturationReturnURL;RGB2HISResponse/hueReturnFormat;RGB2HISResponse/intensityReturnFormat;RGB2HISResponse/saturationReturnFormat'),
	(719, 720, 122, 'defined_interval', 'Defined_IntervalElement/sourceURL;Defined_IntervalElement/interval_size', 'Defined_IntervalResponse/reportURL;Defined_IntervalResponse/pieGraphURL;Defined_IntervalResponse/barGraphURL;Defined_IntervalResponse/reportFormat;Defined_IntervalResponse/pieGraphFormat;Defined_IntervalResponse/barGraphFormat'),
	(720, 721, 123, 'shortest_path', 'Shortest_pathElement/sourceURL;Shortest_pathElement/flags;Shortest_pathElement/startPoint_x;Shortest_pathElement/startPoint_y;Shortest_pathElement/endPoint_x;Shortest_pathElement/endPoint_y', 'Shortest_pathResponse/returnURL;Shortest_pathResponse/returnFormat'),
	(721, 722, 124, 'edge_detection', 'Edge_detectionElement/sourceURL;Edge_detectionElement/width;Edge_detectionElement/threshold;Edge_detectionElement/orientations;Edge_detectionElement/outputGeoTiffType', 'Edge_detectionResponse/returnURL;Edge_detectionResponse/returnFormat'),
	(722, 723, 125, 'tangential_curvature', 'Tangential_curvatureElement/sourceURL;Tangential_curvatureElement/zfactor;Tangential_curvatureElement/outputGeoTiffType', 'Tangential_curvatureResponse/returnURL;Tangential_curvatureResponse/returnFormat'),
	(723, 724, 126, 'covariance', 'CovarianceElement/sourceURLArray;CovarianceElement/matrixType', 'CovarianceResponse/returnURL;CovarianceResponse/returnFormat'),
	(724, 725, 127, 'unsupervised', 'UnsupervisedElement/sourceURLArray;UnsupervisedElement/classes;UnsupervisedElement/iterations;UnsupervisedElement/convergence;UnsupervisedElement/separation;UnsupervisedElement/outputGeoTiffType', 'UnsupervisedResponse/returnURL;UnsupervisedResponse/returnFormat;UnsupervisedResponse/reportURL;UnsupervisedResponse/reportFormat'),
	(725, 726, 128, 'fft', 'FFTElement/sourceURL;FFTElement/outputGeoTiffType', 'FFTResponse/realReturnURL;FFTResponse/realReturnFormat;FFTResponse/imaginaryReturnURL;FFTResponse/imaginaryReturnFormat'),
	(726, 727, 129, 'classification_statistics', 'Classification_StatisticsElement/sourceURL', 'Classification_StatisticsResponse/returnURL;Classification_StatisticsResponse/returnFormat'),
	(727, 728, 130, 'buffer', 'BufferElement/sourceURL;BufferElement/distances;BufferElement/units;BufferElement/outputGeoTiffType', 'BufferResponse/returnURL;BufferResponse/returnFormat'),
	(728, 728, 131, 'buffer', 'BufferElement/sourceURL;BufferElement/buffer', 'BufferResponse/returnURL;BufferResponse/returnFormat'),
	(729, 730, 132, 'aspect', 'AspectElement/sourceURL;AspectElement/prec;AspectElement/zfactor;AspectElement/min_slope_allowed;AspectElement/outputGeoTiffType', 'AspectResponse/returnURL;AspectResponse/returnFormat'),
	(730, 731, 133, 'mosaic', 'MosaicElement/sourceURLArray;MosaicElement/outputFormatType', 'MosaicResponse/returnURL;MosaicResponse/returnFormat'),
	(731, 732, 134, 'shaded_relief', 'Shaded_reliefElement/sourceURL;Shaded_reliefElement/altitude;Shaded_reliefElement/azimuth;Shaded_reliefElement/zmult;Shaded_reliefElement/scale;Shaded_reliefElement/units;Shaded_reliefElement/outputGeoTiffType', 'Shaded_reliefResponse/returnURL;Shaded_reliefResponse/returnFormat'),
	(732, 733, 135, 'contour', 'ContourElement/sourceURL;ContourElement/step;ContourElement/outputGeoTiffType', 'ContourResponse/returnURL;ContourResponse/returnFormat'),
	(733, 734, 136, 'latlon_bbox_clip', 'BBOX_clipElement/sourceURL;BBOX_clipElement/northern;BBOX_clipElement/southern;BBOX_clipElement/eastern;BBOX_clipElement/western;BBOX_clipElement/outputGeoTiffType', 'BBOX_clipResponse/returnURL;BBOX_clipResponse/returnFormat'),
	(734, 735, 137, 'drainage_basin', 'DrainageBasinElement/sourceURL;DrainageBasinElement/threshold;DrainageBasinElement/outputGeoTiffType', 'DrainageBasinResponse/drainageReturnURL;DrainageBasinResponse/basinReturnURL;DrainageBasinResponse/drainageReturnFormat;DrainageBasinResponse/basinReturnFormat'),
	(735, 736, 138, 'rast_to_vect', 'Rast_to_vectElement/sourceURL;Rast_to_vectElement/flags;Rast_to_vectElement/feature;Rast_to_vectElement/outputFormatType', 'Rast_to_vectResponse/returnURL;Rast_to_vectResponse/returnFormat'),
	(736, 737, 139, 'manual_interval', 'Manual_IntervalElement/sourceURL;Manual_IntervalElement/manual_interval', 'Manual_IntervalResponse/reportURL;Manual_IntervalResponse/pieGraphURL;Manual_IntervalResponse/barGraphURL;Manual_IntervalResponse/reportFormat;Manual_IntervalResponse/pieGraphFormat;Manual_IntervalResponse/barGraphFormat'),
	(737, 738, 140, 'vect_column', 'Vect_columnElement/sourceURL', 'Vect_columnResponse/returnURL;Vect_columnResponse/returnFormat'),
	(738, 739, 141, 'flowdirection', 'FlowDirectionElement/sourceURL;FlowDirectionElement/flowModel;FlowDirectionElement/outputGeoTiffType', 'FlowDirectionResponse/returnURL;FlowDirectionResponse/returnFormat'),
	(739, 740, 142, 'matrix_filter', 'MatrixFilterElement/sourceURL;MatrixFilterElement/filterURL;MatrixFilterElement/zero;MatrixFilterElement/repeat;MatrixFilterElement/outputGeoTiffType', 'MatrixFilterResponse/returnURL;MatrixFilterResponse/returnFormat'),
	(740, 741, 143, 'his2RGB', 'HIS2RGBElement/hueImageURL;HIS2RGBElement/intensityImageURL;HIS2RGBElement/saturationImageURL;HIS2RGBElement/outputGeoTiffType', 'HIS2RGBResponse/redReturnURL;HIS2RGBResponse/greenReturnURL;HIS2RGBResponse/blueReturnURL;HIS2RGBResponse/redReturnFormat;HIS2RGBResponse/greenReturnFormat;HIS2RGBResponse/blueReturnFormat'),
	(741, 742, 144, 'area_stats', 'Area_StatsElement/rastInputURL;Area_StatsElement/vectInputURL', 'Area_StatsResponse/reportURL;Area_StatsResponse/reportFormat;Area_StatsResponse/barGraphURL;Area_StatsResponse/barGraphFormat'),
	(742, 743, 145, 'grey_scale', 'Grey_scaleElement/redImageURL;Grey_scaleElement/greenImageURL;Grey_scaleElement/blueImageURL;Grey_scaleElement/red_weights;Grey_scaleElement/green_weights;Grey_scaleElement/blue_weights;Grey_scaleElement/outputGeoTiffType', 'Grey_scaleResponse/returnURL;Grey_scaleResponse/returnFormat'),
	(743, 744, 146, 'vect_info', 'Vect_infoElement/sourceURL', 'Vect_infoResponse/returnURL;Vect_infoResponse/returnFormat'),
	(744, 745, 147, 'oif', 'OIFElement/band1URL;OIFElement/band2URL;OIFElement/band3URL;OIFElement/band4URL;OIFElement/band5URL;OIFElement/band7URL', 'OIFResponse/returnURL;OIFResponse/returnFormat'),
	(745, 746, 148, 'select_feature', 'Select_featureElement/ainputURL;Select_featureElement/binputURL;Select_featureElement/flags;Select_featureElement/atype;Select_featureElement/alayer;Select_featureElement/btype;Select_featureElement/blayer', 'Select_featureResponse/returnURL;Select_featureResponse/returnFormat'),
	(746, 747, 149, 'surf_interpolation', 'Surf_interpolationElement/sourceURL;Surf_interpolationElement/interpolationMethod;Surf_interpolationElement/npoints;Surf_interpolationElement/outputGeoTiffType', 'Surf_interpolationResponse/returnURL;Surf_interpolationResponse/returnFormat'),
	(747, 748, 150, 'userdefinedRules', 'UserdefinedRulesElement/sourceURL;UserdefinedRulesElement/userdefinedRulesURL;UserdefinedRulesElement/outputGeoTiffType', 'UserdefinedRulesResponse/returnURL;UserdefinedRulesResponse/returnFormat'),
	(748, 749, 151, 'ndvi', 'NDVIElement/nirImageURL;NDVIElement/redImageURL;NDVIElement/outputGeoTiffType', 'NDVIResponse/returnURL;NDVIResponse/returnFormat'),
	(749, 750, 152, 'patch_multiband', 'Patch_multibandElement/firstRedImageURL;Patch_multibandElement/firstGreenImageURL;Patch_multibandElement/firstBlueImageURL;Patch_multibandElement/secondRedImageURL;Patch_multibandElement/secondGreenImageURL;Patch_multibandElement/secondBlueImageURL;Patch_multibandElement/outputFormatType', 'Patch_multibandResponse/returnURL;Patch_multibandResponse/returnFormat'),
	(750, 751, 153, 'profile', 'ProfileElement/sourceURL;ProfileElement/profile;ProfileElement/res;ProfileElement/null', 'ProfileResponse/returnURL;ProfileResponse/returnFormat'),
	(751, 752, 154, 'clean_topology', 'Clean_topologyElement/sourceURL;Clean_topologyElement/tool', 'Clean_topologyResponse/returnURL;Clean_topologyResponse/returnFormat'),
	(752, 753, 155, 'bbox_clip', 'BBOX_clipElement/sourceURL;BBOX_clipElement/northern;BBOX_clipElement/southern;BBOX_clipElement/eastern;BBOX_clipElement/western;BBOX_clipElement/outputGeoTiffType', 'BBOX_clipResponse/returnURL;BBOX_clipResponse/returnFormat'),
	(753, 754, 156, 'extract_values', 'Extract_valuesElement/rasterInputURL;Extract_valuesElement/vectorInputURL', 'Extract_valuesResponse/returnURL;Extract_valuesResponse/returnFormat'),
	(754, 755, 157, 'fusion_brovey', 'Fusion_broveyElement/sensor;Fusion_broveyElement/ms1ImageURL;Fusion_broveyElement/ms2ImageURL;Fusion_broveyElement/ms3ImageURL;Fusion_broveyElement/panImageURL;Fusion_broveyElement/outputFormatType', 'Fusion_broveyResponse/returnURL;Fusion_broveyResponse/returnFormat'),
	(755, 756, 158, 'vect_to_rast', 'Vect_to_rastElement/rastInputURL;Vect_to_rastElement/vectInputURL;Vect_to_rastElement/use;Vect_to_rastElement/type;Vect_to_rastElement/layer;Vect_to_rastElement/column;Vect_to_rastElement/value;Vect_to_rastElement/rows;Vect_to_rastElement/rgbcolumn;Vect_to_rastElement/labelcolumn;Vect_to_rastElement/outputGeoTiffType', 'Vect_to_rastResponse/returnURL;Vect_to_rastResponse/returnFormat'),
	(756, 757, 159, 'flow_accumulation', 'FlowAccumElement/sourceURL;FlowAccumElement/model;FlowAccumElement/outputGeoTiffType', 'FlowAccumResponse/returnURL;FlowAccumResponse/returnFormat'),
	(757, 758, 160, 'slope', 'SlopeElement/sourceURL;SlopeElement/format;SlopeElement/prec;SlopeElement/zfactor;SlopeElement/outputGeoTiffType', 'SlopeResponse/returnURL;SlopeResponse/returnFormat'),
	(758, 759, 161, 'polygon_clip', 'Polygon_clipElement/sourceURL;Polygon_clipElement/polygonURL;Polygon_clipElement/outputGeoTiffType', 'Polygon_clipResponse/returnURL;Polygon_clipResponse/returnFormat'),
	(759, 760, 162, 'build_polylines', 'Build_polylinesElement/sourceURL', 'Build_polylinesResponse/returnURL;Build_polylinesResponse/returnFormat'),
	(760, 761, 163, 'ifft', 'IFFTElement/realImageURL;IFFTElement/imaginaryImageURL;IFFTElement/outputGeoTiffType', 'IFFTResponse/returnURL;IFFTResponse/returnFormat'),
	(761, 762, 164, 'equal_interval', 'Equal_IntervalElement/sourceURL;Equal_IntervalElement/classes', 'Equal_IntervalResponse/reportURL;Equal_IntervalResponse/pieGraphURL;Equal_IntervalResponse/barGraphURL;Equal_IntervalResponse/reportFormat;Equal_IntervalResponse/pieGraphFormat;Equal_IntervalResponse/barGraphFormat'),
	(762, 763, 165, 'curvatureBasedMethod', 'CurvatureBasedMethodElement/sourceURL;CurvatureBasedMethodElement/tcurv_threshold;CurvatureBasedMethodElement/flowaccum_threshold;CurvatureBasedMethodElement/outputFormatType;CurvatureBasedMethodElement/outputGeoTiffType', 'CurvatureBasedMethodResponse/returnURL;CurvatureBasedMethodResponse/returnFormat'),
	(763, 764, 165, 'flowDirectionBasedMethod_GRASS', 'FlowDirectionBasedMethod_GRASSElement/sourceURL;FlowDirectionBasedMethod_GRASSElement/flowaccum_threshold;FlowDirectionBasedMethod_GRASSElement/outputFormatType;FlowDirectionBasedMethod_GRASSElement/outputGeoTiffType', 'FlowDirectionBasedMethod_GRASSResponse/returnURL;FlowDirectionBasedMethod_GRASSResponse/returnFormat'),
	(764, 765, 165, 'simplifiedCurvatureMethod', 'SimplifiedCurvatureMethodElement/sourceURL;SimplifiedCurvatureMethodElement/tcurv_threshold;SimplifiedCurvatureMethodElement/flowaccum_threshold;SimplifiedCurvatureMethodElement/outputFormatType;SimplifiedCurvatureMethodElement/outputGeoTiffType', 'SimplifiedCurvatureMethodResponse/returnURL;SimplifiedCurvatureMethodResponse/returnFormat'),
	(765, 766, 166, 'topidx', 'TopIndexElement/sourceURL;TopIndexElement/outputGeoTiffType', 'TopIndexResponse/returnURL;TopIndexResponse/returnFormat'),
	(766, 767, 167, 'tasscap', 'TasscapElement/sensor;TasscapElement/band1URL;TasscapElement/band2URL;TasscapElement/band3URL;TasscapElement/band4URL;TasscapElement/band5URL;TasscapElement/band7URL;TasscapElement/outputGeoTiffType', 'TasscapResponse/brightnessReturnURL;TasscapResponse/brightnessReturnFormat;TasscapResponse/greennessReturnURL;TasscapResponse/greennessReturnFormat;TasscapResponse/wetnessReturnURL;TasscapResponse/wetnessReturnFormat;TasscapResponse/hazeReturnURL;TasscapResponse/hazeReturnFormat'),
	(767, 768, 168, 'overlay', 'OverlayElement/ainputURL;OverlayElement/binputURL;OverlayElement/operator', 'OverlayResponse/returnURL;OverlayResponse/returnFormat'),
	(768, 769, 169, 'build_topology', 'Build_topologyElement/sourceURL', 'Build_topologyResponse/returnURL;Build_topologyResponse/returnFormat'),
	(769, 770, 170, 'extract_feature', 'Extract_featureElement/sourceURL;Extract_featureElement/flags;Extract_featureElement/type;Extract_featureElement/layer;Extract_featureElement/new;Extract_featureElement/list;Extract_featureElement/where', 'Extract_featureResponse/returnURL;Extract_featureResponse/returnFormat'),
	(770, 771, 171, 'shp2gml', 'SHP2GMLElement/shapefileDataStoreURL', 'SHP2GMLResponse/returnURL;SHP2GMLResponse/returnFormat'),
	(771, 772, 172, 'pca', 'PCAElement/sourceURLArray;PCAElement/outputGeoTiffType', 'PCAResponse/returnURLArray;PCAResponse/returnFormat'),
	(772, 773, 173, 'rescale', 'RescaleElement/sourceURL;RescaleElement/scaleMethod;RescaleElement/from;RescaleElement/to;RescaleElement/outputGeoTiffType', 'RescaleResponse/returnURL;RescaleResponse/returnFormat'),
	(773, 774, 174, 'rgb_extract', 'RGB_extractElement/sourceURL;RGB_extractElement/outputGeoTiffType', 'RGB_extractResponse/redReturnURL;RGB_extractResponse/greenReturnURL;RGB_extractResponse/blueReturnURL;RGB_extractResponse/redReturnFormat;RGB_extractResponse/greenReturnFormat;RGB_extractResponse/blueReturnFormat'),
	(775, 776, 176, 'profile_curvature', 'Profile_curvatureElement/sourceURL;Profile_curvatureElement/zfactor;Profile_curvatureElement/outputGeoTiffType', 'Profile_curvatureResponse/returnURL;Profile_curvatureResponse/returnFormat'),
	(776, 777, 177, 'predefinedColor', 'PredefinedColorElement/sourceURL;PredefinedColorElement/colorType;PredefinedColorElement/outputGeoTiffType', 'PredefinedColorResponse/returnURL;PredefinedColorResponse/returnFormat');
/*!40000 ALTER TABLE `association` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.datasets
DROP TABLE IF EXISTS `datasets`;
CREATE TABLE IF NOT EXISTS `datasets` (
  `tid` int(11) NOT NULL AUTO_INCREMENT,
  `identifier` varchar(48) NOT NULL DEFAULT '',
  `name` text,
  `description` text,
  `history` text,
  `processingLevel` varchar(64) DEFAULT NULL,
  `rights` text,
  `creationDate` date DEFAULT NULL,
  `publicationDate` date DEFAULT NULL,
  `keyword` varchar(255) DEFAULT NULL,
  `beginTemporal` datetime DEFAULT NULL,
  `endTemporal` datetime DEFAULT NULL,
  `referenceSystemCode` varchar(48) DEFAULT 'EPSG:4326',
  `northBoundLatitude` double(20,6) DEFAULT '90.000000',
  `westBoundLongitude` double(20,6) DEFAULT '-180.000000',
  `eastBoundLongitude` double(20,6) DEFAULT '180.000000',
  `southBoundLatitude` double(20,6) DEFAULT '-90.000000',
  `Format` varchar(64) DEFAULT NULL,
  `sizeMB` varchar(64) DEFAULT NULL,
  `dataType` varchar(64) DEFAULT NULL,
  `featureType` varchar(64) DEFAULT NULL,
  `dataURL` text,
  `serviceURL` text,
  `sourceImage` int(11) DEFAULT NULL,
  `anytext` text,
  PRIMARY KEY (`tid`),
  KEY `identifier` (`identifier`),
  KEY `name` (`name`(255)),
  KEY `description` (`description`(255)),
  KEY `keyword` (`keyword`),
  KEY `dataType` (`dataType`),
  KEY `featureType` (`featureType`)
) ENGINE=InnoDB AUTO_INCREMENT=42 DEFAULT CHARSET=latin1 COMMENT='This tables store the metadata of individual dataset.';

-- Dumping data for table cyberconnector.datasets: ~41 rows (approximately)
DELETE FROM `datasets`;
/*!40000 ALTER TABLE `datasets` DISABLE KEYS */;
INSERT INTO `datasets` (`tid`, `identifier`, `name`, `description`, `history`, `processingLevel`, `rights`, `creationDate`, `publicationDate`, `keyword`, `beginTemporal`, `endTemporal`, `referenceSystemCode`, `northBoundLatitude`, `westBoundLongitude`, `eastBoundLongitude`, `southBoundLatitude`, `Format`, `sizeMB`, `dataType`, `featureType`, `dataURL`, `serviceURL`, `sourceImage`, `anytext`) VALUES
	(1, '98915f00-e5b6-102a-88ce-3d6b417bcb93', 'DOE test data (railroad vector)', 'Test data from DOE for iGFDS', 'originally produced by DOE', 'Level 3', 'Available free for test only.', '2012-04-04', '2012-04-04', 'iGFDS,railway,railroad', '2013-02-08 00:00:00', '2013-02-08 00:00:00', 'EPSG:4326', 38.878826, -77.276814, -77.261310, 38.876712, 'shp', '0.005', 'vector', 'railway', 'http://129.174.131.8:9006/GeoprocessingWS/temp/railway1.zip', 'http://geobrain.laits.gmu.edu:8080/geoserver/wfs?request=GetFeature&version=1.1.0&typeName=doe:railsub&outputFormat=shape-zip', NULL, 'iGFDS project portal'),
	(2, '04dcee22-76d1-11e2-9452-f23c91aec05e', 'DOE test data (Building vector)', 'Building test data for iGFDS', 'originally produced by DOE', 'Level 3', 'Available for free for test only.', '2012-12-04', '2012-12-04', 'iGFDS,building', '2013-02-08 00:00:00', '2013-02-08 00:00:00', 'EPSG:4326', 38.884963, -77.279418, -77.261667, 38.873326, 'shp', '0.45', 'vector', 'building', 'http://129.174.131.8:9006/GeoprocessingWS/temp/building1.zip', 'http://geobrain.laits.gmu.edu:8080/geoserver/wfs?request=GetFeature&version=1.1.0&typeName=doe:building&outputFormat=shape-zip', NULL, 'iGFDS project portal'),
	(3, 'e0246778-76d4-11e2-9452-f23c91aec05e', 'DOE test data (field vector)', 'Field test data for iGFDS', 'originally produced by DOE', 'Level 3', 'Available for free for test only.', '2012-12-04', '2012-12-04', 'iGFDS,field', '2013-02-08 00:00:00', '2013-02-08 00:00:00', 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, 'shp', '0.011', 'vector', 'field', 'http://129.174.131.8:9006/data/field.zip', 'http://geobrain.laits.gmu.edu:8080/geoserver/wfs?request=GetFeature&version=1.1.0&typeName=doe:field&outputFormat=shape-zip', NULL, 'iGFDS project portal'),
	(4, 'eb5294a8-76d4-11e2-9452-f23c91aec05e', 'DOE test data (Court vector)', 'Court test data for iGFDS', 'originally produced by DOE', 'Level 3', 'Available for free for test only.', '2012-12-04', '2012-12-04', 'iGFDS,court', '2013-02-08 00:00:00', '2013-02-08 00:00:00', 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, 'shp', '0.009', 'vector', 'court', 'http://129.174.131.8:9006/data/court.zip', 'http://geobrain.laits.gmu.edu:8080/geoserver/wfs?request=GetFeature&version=1.1.0&typeName=doe:court&outputFormat=shape-zip', NULL, 'iGFDS project portal'),
	(5, 'f2a1cb94-76ce-11e2-9452-f23c91aec05e', 'oakton', 'Tiff Test data for iGFDS', 'Got it from Google Map', 'Level 3', 'Available for free.', '2012-12-04', '2012-12-04', 'iGFDS,oakton satellite image', '2013-02-08 00:00:00', '2013-02-08 00:00:00', 'EPSG:4326', 38.891639, -77.288932, -77.260975, 38.873038, 'tif', '4.09', 'raster', '', 'http://129.174.131.8:9006/data/oakton.tif', 'http://geobrain.laits.gmu.edu:8080/geoserver/wcs?service=wcs&version=1.0.0&request=getcoverage&coverage=doe:okaton111&crs=EPSG:32618&bbox=301439.848,4305168.711,303928.393,4307198.014&width=1268&height=1034&format=GeoTIFF', NULL, 'iGFDS project portal'),
	(6, 'sdsdfs', '16days 250m customized Global NDVI product (MODIS)', '16days 250m customized Global NDVI product (MODIS)', 'GMU CSISS created it.', 'Level 4', 'Available for free.', '2015-08-11', '2015-08-11', 'CyberConnector, Processing Model, NDVI, Virtual Product.', '2015-08-11 17:18:06', '2015-08-11 17:18:14', 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, 'hdf', NULL, 'raster', NULL, NULL, NULL, NULL, 'VDP dataset'),
	(7, 'nd8du9gpoafox9yrby', 'PreprocessingImageObjects instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://129.174.131.8:9006/GeoprocessingWS/temp/763bca60-beda-4514-94bd-776cd2588001/cfpp_clipped.fusion.sv.esp.vector.zip', NULL, NULL, NULL),
	(8, '407lx1fsfoh4r498lc', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://129.174.131.8:9006/CubeModelWS/temp/e3f1d6b1-111d-41cb-923c-98c9c1bfb77a/crm_input_file_package.zip', NULL, NULL, NULL),
	(9, '8c3hzml1l6q5m96oo3', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://129.174.131.8:9006/CubeModelWS/temp/b4567287-fd27-425f-86d5-c9e4c4554f22/crm_input_file_package.zip', NULL, NULL, NULL),
	(10, 'xec3onjiw4gwmr54n6', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://129.174.131.8:9006/CubeModelWS/temp/696172e2-63a1-49ba-bf8d-7accec5dc215/crm_input_file_package.zip', NULL, NULL, NULL),
	(11, 'xr58nrkwnlipxfzo9m', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/b0712502-aa8a-4f4d-aadc-187f6d914826/crm_input_file_package.zip', NULL, NULL, NULL),
	(12, 'hs8gma5646mzp46yjw', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/7d5e53a5-2181-4f5d-b21d-668532eac367/crm_input_file_package.zip', NULL, NULL, NULL),
	(13, 'x6wl3lsqi4eubjs0t2', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/2c5d9c67-47c4-466a-90de-fe74fbbd150b/ecmwf_interim_2016-12-30to2016-12-31.nc', NULL, NULL, NULL),
	(14, 'tigc9xlhh2zf4knlh8', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/15dad65c-4ea5-4d33-8582-478dd9778aed/ecmwf_interim_2016-12-30to2016-12-31.nc', NULL, NULL, NULL),
	(15, 'cq61kzwl45shvj8wd0', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/73b4899e-5f24-40f9-b18a-1df0fb89fa04/ecmwf_interim_2016-12-30to2016-12-31.nc', NULL, NULL, NULL),
	(16, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/f2511781-3d4b-4b80-8fc9-ab71292a22f6/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(17, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/2d8340ed-3f7d-48d4-9514-879faf3304e8/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(18, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/fb22e285-6d62-4098-ac62-f5e478d05cb5/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(19, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/32adf15b-f803-44a5-a614-3c89632bc50b/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(20, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/25db61f4-192a-40f4-bd4e-b428219e2e4a/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(21, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/30180842-5c89-486f-a00f-19ffd675f9f7/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(22, 'iwp1iqh73b2qljuadw', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/046b5a38-cdd4-4def-bdd2-678422d078f6/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(23, '4268wq88wmhnx8kzpx', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/d52b3218-9942-4007-9a59-cb48b2478da2/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(24, 'rhlcuom7ycy02nw5oa', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/3a6af4ce-833b-41be-89a5-07760efcc48d/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(25, 'rhlcuom7ycy02nw5oa', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/59a8c72b-8e2a-44a5-b78c-eb3ab844a905/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(26, 'ww4v9ii91zjdu2db2r', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/0983c386-f866-4bf5-b7d2-431c4048ecd9/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(27, 'ww4v9ii91zjdu2db2r', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/83df51b0-7daa-403f-ae04-7d6722214cf9/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(28, 'hl0yqildqp55jrhomj', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/0279a965-2a2b-49a2-8768-a9df5c79ad07/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(29, 'hl0yqildqp55jrhomj', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/26fb20d4-4511-4a42-b373-84ef19f5224c/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(30, 'hl0yqildqp55jrhomj', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/2818c2ba-d59b-48b9-8b5e-5773314c1785/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(31, '7ac94c44me7j2j0on5', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/cacb6f9c-4216-4487-bda7-ffb41670e5ea/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(32, '7ac94c44me7j2j0on5', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/2013ab24-58bc-4c2e-a867-5134ba660d0e/ecmwf_interim_2016-12-01to2016-12-31.nc', NULL, NULL, NULL),
	(33, 'rwi1s0dcrwmhfnghtq', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/acec0657-d057-4b78-83f6-2ebcef7d6044/ecmwf_interim_2016-12-30to2016-12-31.nc', NULL, NULL, NULL),
	(34, 'rwi1s0dcrwmhfnghtq', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/2b2fd9f8-eedb-4b0b-b907-1caf5eeb4630/ecmwf_interim_2016-12-30to2016-12-31.nc', NULL, NULL, NULL),
	(35, 'uowi5541e2nz1mktu1', 'DownloadECMWFDatasets instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://cube.csiss.gmu.edu/CubeModelWS/temp/4efa38a9-9f0f-4b95-99b7-2914f56a6dd5/ecmwf_interim_2016-12-31to2016-12-31.nc', NULL, NULL, NULL),
	(36, '5fcejsqo6zzkly0cdi', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/a10e18fe-c06e-4740-a7f9-fa861c6c498a/crm_input_file_package.zip', NULL, NULL, NULL),
	(37, '5fcejsqo6zzkly0cdi', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/5ec838e1-7783-43eb-a7b9-2af216bed729/crm_input_file_package.zip', NULL, NULL, NULL),
	(38, '5fcejsqo6zzkly0cdi', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/26cbbd76-fd9a-4d5e-a1c5-1e8865b3e7c4/crm_input_file_package.zip', NULL, NULL, NULL),
	(39, '7v95ans2siyjcfnag3', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/628ebe69-0622-4bab-8a0c-39c643072ba2/crm_input_file_package.zip', NULL, NULL, NULL),
	(40, '7v95ans2siyjcfnag3', 'CRM_array_averaged_analysis_model instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'http://www3.csiss.gmu.edu/CubeModelWS/temp/9fa6f53f-2a0a-45a0-87df-c502d1f2c8c2/crm_input_file_package.zip', NULL, NULL, NULL),
	(41, 'dj8rllxkl7hvfx3yrz', 'YearsDailyNDVIModel instance product', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'EPSG:4326', 90.000000, -180.000000, 180.000000, -90.000000, NULL, NULL, NULL, NULL, 'Wrong input for argument 1 set 0. Please have the url links for b1, b2 and QA separated by comma.', NULL, NULL, NULL);
/*!40000 ALTER TABLE `datasets` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.environment
DROP TABLE IF EXISTS `environment`;
CREATE TABLE IF NOT EXISTS `environment` (
  `id` varchar(50) NOT NULL,
  `name` varchar(50) DEFAULT NULL,
  `type` varchar(50) NOT NULL,
  `bin` tinytext NOT NULL,
  `pyenv` varchar(50) DEFAULT NULL,
  `host` varchar(50) NOT NULL,
  `basedir` tinytext,
  `settings` tinytext,
  KEY `id` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='The running environment on a host, for example, python environment. ';

-- Dumping data for table cyberconnector.environment: ~0 rows (approximately)
DELETE FROM `environment`;
/*!40000 ALTER TABLE `environment` DISABLE KEYS */;
/*!40000 ALTER TABLE `environment` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.history
DROP TABLE IF EXISTS `history`;
CREATE TABLE IF NOT EXISTS `history` (
  `id` varchar(20) NOT NULL,
  `process` varchar(50) NOT NULL,
  `begin_time` datetime NOT NULL,
  `end_time` datetime DEFAULT NULL,
  `input` longtext,
  `output` longtext,
  `host` text,
  `indicator` varchar(50) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

-- Dumping data for table cyberconnector.history: ~190 rows (approximately)
DELETE FROM `history`;
/*!40000 ALTER TABLE `history` DISABLE KEYS */;
INSERT INTO `history` (`id`, `process`, `begin_time`, `end_time`, `input`, `output`, `host`, `indicator`) VALUES
	('u52mxs7zhrpx', 'degrzr', '2018-10-31 11:08:30', '2018-10-31 11:08:30', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('3d6wztccmlc7', 'degrzr', '2018-10-31 11:11:51', '2018-10-31 11:11:51', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('r9ayl7n4tz01', '199vsg', '2018-10-31 11:25:03', '2018-10-31 11:25:03', '#!/bin/sh\\necho "test geoweaver process running"\\necho "Good"\\n\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('ysncr51u0vml', 'ac4724', '2018-10-31 11:29:51', '2018-10-31 11:29:56', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('2riqyhv7diyb', 'ac4724', '2018-10-31 11:33:48', '2018-10-31 11:33:53', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('rmvkdufzhj57', 'ac4724', '2018-10-31 11:38:25', '2018-10-31 11:38:30', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('tv9s6avinvqr', 'ac4724', '2018-10-31 11:40:37', '2018-10-31 11:40:42', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('bucizu6mlnd8', 'ac4724', '2018-10-31 11:41:36', '2018-10-31 11:41:41', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('39iw4msolt66', 'ac4724', '2018-10-31 11:45:06', '2018-10-31 11:45:11', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('jtuecfneazf2', '199vsg', '2018-10-31 12:30:55', '2018-10-31 12:30:55', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('tj61qj5eim0y', 'ac4724', '2018-10-31 12:31:25', '2018-10-31 12:31:30', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('6kwatk4v5pfe', '199vsg', '2018-10-31 12:38:44', '2018-10-31 12:38:44', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('yyj527yabcdl', '199vsg', '2018-10-31 12:40:00', '2018-10-31 12:40:00', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('exppoosx3eyz', '199vsg', '2018-11-01 12:41:06', '2018-11-01 12:41:06', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('pm9ij8gac4uf', 'ac4724', '2018-11-01 12:44:10', '2018-11-01 12:44:15', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('v80mubvwlyjc', '199vsg', '2018-11-06 09:31:54', '2018-11-06 09:31:54', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-v9s6aa0ne8k1.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('h8kb4iogkmx5', 'ac4724', '2018-11-06 09:32:10', '2018-11-06 09:32:15', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n==== Geoweaver Bash Output Finished ====\n', NULL, 'Done'),
	('8fy53rga0k1j', '199vsg-oAq2d', '2018-11-19 12:01:42', '2018-11-19 12:01:42', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-xulycmqe3d05.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('844vll4w2mok', '199vsg-Xr6FZ', '2018-11-19 12:01:44', '2018-11-19 12:01:44', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-xulycmqe3d05.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('07u5j7lpklor', '199vsg-oAq2d', '2018-11-19 12:02:28', '2018-11-19 12:02:28', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-akus5uoq68bo.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('zpcg6j1duyhu', '199vsg-Xr6FZ', '2018-11-19 12:02:30', '2018-11-19 12:02:30', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-akus5uoq68bo.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('lx9fa1y3ozox', '199vsg-oAq2d', '2018-11-19 12:03:15', '2018-11-19 12:03:16', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-yo5gcqh7q07v.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('ad2rnu63jome', '199vsg-Xr6FZ', '2018-11-19 12:03:17', '2018-11-19 12:03:17', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-yo5gcqh7q07v.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('tpxlsfadmexy', '199vsg-oAq2d', '2018-11-19 12:04:08', '2018-11-19 12:04:08', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-1ct96as2m5ko.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('xl4h22nx720y', '199vsg-Xr6FZ', '2018-11-19 12:04:10', '2018-11-19 12:04:10', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-1ct96as2m5ko.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('6yvjl7744wq9', '199vsg-oAq2d', '2018-11-19 12:12:42', '2018-11-19 12:12:42', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-9xmfv6ueopfx.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('pl6xi6ttrbyp', '199vsg-Xr6FZ', '2018-11-19 12:12:43', '2018-11-19 12:12:43', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-9xmfv6ueopfx.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('5aqsn98l1g4u', '199vsg-oAq2d', '2018-11-19 13:34:41', '2018-11-19 13:34:41', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-vigsp32dco36.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('6uoy9apbuipl', '199vsg-Xr6FZ', '2018-11-19 13:34:42', '2018-11-19 13:34:43', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-vigsp32dco36.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('wngfhwdnr1jd', '199vsg-oAq2d', '2018-11-19 16:30:34', '2018-11-19 16:30:34', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-vgca9w0js8pi.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('nyi433hhnwlg', '199vsg-Xr6FZ', '2018-11-19 16:30:35', '2018-11-19 16:30:35', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-vgca9w0js8pi.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('l67lnbvkjr3k', '199vsg-oAq2d', '2018-11-19 19:31:54', '2018-11-19 19:31:54', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-gq2acoev3t5t.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('58q9z46jrhxp', '199vsg-Xr6FZ', '2018-11-19 19:31:56', '2018-11-19 19:31:56', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-gq2acoev3t5t.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('ktdkuvqrglw1', '199vsg-oAq2d', '2018-11-20 10:07:01', '2018-11-20 10:07:01', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-sfmrxexcyhoq.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('5g8gbdqxytwv', '199vsg-Xr6FZ', '2018-11-20 10:07:03', '2018-11-20 10:07:03', '#!/bin/sh<br/>echo "test geoweaver process running"<br/>echo "Good"<br/>', 'bash: ./geoweaver-sfmrxexcyhoq.sh: /bin/sh<br/>echo: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('srykugu2wxc5', '199vsg-oAq2d', '2018-11-20 10:07:53', '2018-11-20 10:07:53', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'bash: ./geoweaver-ilg86wu09spa.sh: /bin/sh^M: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('cykz65qart8u', '199vsg-Xr6FZ', '2018-11-20 10:07:55', '2018-11-20 10:07:55', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'bash: ./geoweaver-ilg86wu09spa.sh: /bin/sh^M: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('tkg2l52e41po', '199vsg-oAq2d', '2018-11-20 10:13:56', '2018-11-20 10:13:56', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'bash: ./geoweaver-bu98qxofbtds.sh: /bin/sh^M: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('rtnky161syqe', '199vsg-Xr6FZ', '2018-11-20 10:13:57', '2018-11-20 10:13:57', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'bash: ./geoweaver-bu98qxofbtds.sh: /bin/sh^M: bad interpreter: No such file or directory\n', NULL, 'Done'),
	('7qvgph8r35rq', '199vsg-oAq2d', '2018-11-20 10:17:59', '2018-11-20 10:17:59', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('8baoun74rz9r', '199vsg-Xr6FZ', '2018-11-20 10:18:01', '2018-11-20 10:18:01', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('mf3yxpzga4ud', '199vsg-oAq2d', '2018-11-20 11:26:07', '2018-11-20 11:26:07', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('qf9h67yfc2vv', '199vsg-Xr6FZ', '2018-11-20 11:26:09', '2018-11-20 11:26:09', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('slh7b1n36yyv', '199vsg-oAq2d', '2018-11-20 11:27:15', '2018-11-20 11:27:15', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('hwjkjrjwahwm', '199vsg-Xr6FZ', '2018-11-20 11:27:17', '2018-11-20 11:27:17', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('59ihagjlin9h', '199vsg-oAq2d', '2018-11-20 11:27:36', '2018-11-20 11:27:36', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('i5yxe6t9juqu', '199vsg-Xr6FZ', '2018-11-20 11:27:38', '2018-11-20 11:27:38', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('xftoix7wjitn', '199vsg-oAq2d', '2018-11-20 11:47:59', '2018-11-20 11:47:59', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('yyfkmhzg60pv', 'ac4724-jL0Ep', '2018-11-20 11:48:27', '2018-11-20 11:48:32', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('8bousxi3fkos', '199vsg-Xr6FZ', '2018-11-20 11:49:00', '2018-11-20 11:49:00', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('2m5wjh8kz7fk', '199vsg-oAq2d', '2018-11-20 11:53:45', '2018-11-20 11:53:45', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('ikmublp6iak4', 'ac4724-jL0Ep', '2018-11-20 11:53:46', '2018-11-20 11:53:51', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('ho1c5hdfhysp', '199vsg-Xr6FZ', '2018-11-20 11:53:52', '2018-11-20 11:53:52', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('vyw5o3cz3995', '199vsg-oAq2d', '2018-11-20 11:55:07', '2018-11-20 11:55:07', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('3wts0ox50q3r', 'ac4724-jL0Ep', '2018-11-20 11:55:08', '2018-11-20 11:55:13', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('j7ob419ybnkl', '199vsg-Xr6FZ', '2018-11-20 11:55:14', '2018-11-20 11:55:14', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('uvqj2ebdfc6g', '199vsg-oAq2d', '2018-11-20 11:58:35', '2018-11-20 11:58:35', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('q2tq8hbxyazn', 'ac4724-jL0Ep', '2018-11-20 11:58:36', '2018-11-20 11:58:41', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('vo76l4zqw1oa', '199vsg-Xr6FZ', '2018-11-20 11:58:42', '2018-11-20 11:58:42', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('potgq0uap9c0', '199vsg-oAq2d', '2018-11-20 11:59:51', '2018-11-20 11:59:51', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('mlgpqps05f64', 'ac4724-jL0Ep', '2018-11-20 11:59:52', '2018-11-20 11:59:57', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('1zye1jl78eft', '199vsg-oAq2d', '2018-11-20 12:01:40', '2018-11-20 12:01:40', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('g15x65bd4jd7', 'ac4724-jL0Ep', '2018-11-20 12:01:41', '2018-11-20 12:01:46', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('xtccizdicyhm', '199vsg-oAq2d', '2018-11-20 12:31:48', '2018-11-20 12:31:48', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('3vlp4n5rnvh8', 'ac4724-jL0Ep', '2018-11-20 12:31:49', '2018-11-20 12:31:54', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('8ciyni9vbf2', '5k56d9vcx4ip3tr5pj26', '2018-11-20 12:31:46', '2018-11-20 12:31:54', '199vsg-oAq2d;ac4724-jL0Ep;', 'xtccizdicyhm;3vlp4n5rnvh8;', NULL, 'Done'),
	('a6jte2d6mjn7', '199vsg-oAq2d', '2018-11-20 12:33:00', '2018-11-20 12:33:00', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('7zg503bigeff', 'ac4724-jL0Ep', '2018-11-20 12:33:00', '2018-11-20 12:33:05', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('4qmdprhczxhh', '199vsg-Xr6FZ', '2018-11-20 12:33:06', '2018-11-20 12:33:06', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('j2ly2mx5d1e', '5k56d9vcx4ip3tr5pj26', '2018-11-20 12:32:57', '2018-11-20 12:33:06', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'a6jte2d6mjn7;7zg503bigeff;4qmdprhczxhh;', NULL, 'Done'),
	('cr8x8udbyd9h', '199vsg-oAq2d', '2018-11-20 16:05:45', '2018-11-20 16:05:45', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('gcrpzkj32xe9', 'ac4724-jL0Ep', '2018-11-20 16:05:46', '2018-11-20 16:05:51', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('b91q0ykhgtkr', '199vsg-Xr6FZ', '2018-11-20 16:05:52', '2018-11-20 16:05:52', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('739d3hk3472', '5k56d9vcx4ip3tr5pj26', '2018-11-20 16:05:44', '2018-11-20 16:05:52', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'cr8x8udbyd9h;gcrpzkj32xe9;b91q0ykhgtkr;', NULL, 'Done'),
	('5comb64nimf5', 'ac4724', '2018-11-20 16:39:58', '2018-11-20 16:40:03', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('ks7y4cb2ixaa', 'ac4724', '2018-11-20 16:42:40', '2018-11-20 16:42:45', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 5s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('khbi0zohc6xu', '199vsg-oAq2d', '2018-11-20 16:55:12', '2018-11-20 16:55:12', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('apy3s7htoryv', 'ac4724-jL0Ep', '2018-11-20 16:55:13', '2018-11-20 16:55:28', '#!/bin/bash\necho "test run bash function"\necho "sleep for 5 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 5 seconds\ngreat now end\n', NULL, 'Done'),
	('ery62lkn5h45', '199vsg-Xr6FZ', '2018-11-20 16:55:29', '2018-11-20 16:55:29', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('v22d3dwk3a6', '5k56d9vcx4ip3tr5pj26', '2018-11-20 16:55:11', '2018-11-20 16:55:29', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'khbi0zohc6xu;apy3s7htoryv;ery62lkn5h45;', NULL, 'Done'),
	('oymv48830j6h', '199vsg-oAq2d', '2018-11-20 16:56:11', '2018-11-20 16:56:11', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('hgjuwwjt9x5g', 'ac4724-jL0Ep', '2018-11-20 16:56:12', '2018-11-20 16:56:27', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('ey0rkbar9tka', '199vsg-Xr6FZ', '2018-11-20 16:56:28', '2018-11-20 16:56:28', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('yzjpgl1lgeq', '5k56d9vcx4ip3tr5pj26', '2018-11-20 16:56:10', '2018-11-20 16:56:28', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'oymv48830j6h;hgjuwwjt9x5g;ey0rkbar9tka;', NULL, 'Done'),
	('wmvihz1aogno', 'nhi96d-7VZhh', '2018-11-20 16:56:57', '2018-11-20 16:56:57', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2018-11-20 21:56:57--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', NULL, 'Done'),
	('m78t01zsmw93', 'rh1u8q-4sCmg', '2018-11-20 16:56:58', '2018-11-20 16:56:58', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', NULL, 'Done'),
	('63ynkhkuonma', 'rpnhlg-JZfyQ', '2018-11-20 16:56:59', '2018-11-20 16:56:59', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', NULL, 'Done'),
	('p4ep910w2nk2', 'omop8l-1p5x1', '2018-11-20 16:57:00', '2018-11-20 16:57:00', '#!/bin/bash', '', NULL, 'Done'),
	('tm87rqjr1df', 't0ie2loym6u46u8mlgr3', '2018-11-20 16:56:56', '2018-11-20 16:57:00', 'nhi96d-7VZhh;rh1u8q-4sCmg;rpnhlg-JZfyQ;omop8l-1p5x1;', 'wmvihz1aogno;m78t01zsmw93;63ynkhkuonma;p4ep910w2nk2;', NULL, 'Done'),
	('qoc5sm5z9ngh', '199vsg', '2018-11-20 17:30:32', '2018-11-20 17:30:32', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('xd8vi4e2od6n', 'ac4724', '2018-11-20 17:30:33', '2018-11-20 17:30:48', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('d59aj71nkzbi', '199vsg', '2018-11-20 17:30:49', '2018-11-20 17:30:49', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('p3juza5tccs', '5k56d9vcx4ip3tr5pj26', '2018-11-20 17:30:31', '2018-11-20 17:30:49', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'qoc5sm5z9ngh;xd8vi4e2od6n;d59aj71nkzbi;', NULL, 'Done'),
	('mesipwawqi9d', '199vsg', '2018-11-20 17:56:28', '2018-11-20 17:56:28', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('cr659ssfrydk', 'ac4724', '2018-11-20 17:56:29', '2018-11-20 17:56:44', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('ku4v5xuvorvq', '199vsg', '2018-11-20 17:56:45', '2018-11-20 17:56:45', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('70nszflz0pm', '5k56d9vcx4ip3tr5pj26', '2018-11-20 17:56:27', '2018-11-20 17:56:45', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'mesipwawqi9d;cr659ssfrydk;ku4v5xuvorvq;', NULL, 'Done'),
	('46s7du5hf1fx', '199vsg', '2018-11-20 17:56:53', '2018-11-20 17:56:53', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('sai532o0ao4l', 'ac4724', '2018-11-20 17:56:54', '2018-11-20 17:57:09', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('kmgvpbp5hvns', '199vsg', '2018-11-20 17:57:10', '2018-11-20 17:57:10', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('wyotapgip8y', '5k56d9vcx4ip3tr5pj26', '2018-11-20 17:56:51', '2018-11-20 17:57:10', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '46s7du5hf1fx;sai532o0ao4l;kmgvpbp5hvns;', NULL, 'Done'),
	('pmthqm9u51xc', 'degrzr', '2018-11-20 17:59:07', '2018-11-20 17:59:07', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('xdtucmca5j0y', 'ac4724', '2018-11-20 17:59:08', '2018-11-20 17:59:23', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('7u4h6g7lw5r', 'qrb8eyx0kx9vk84iaf39', '2018-11-20 17:59:06', '2018-11-20 17:59:23', 'degrzr-LKHuh;ac4724-AJVWV;', 'pmthqm9u51xc;xdtucmca5j0y;', NULL, 'Done'),
	('6aks5yeivme7', '199vsg', '2018-11-21 09:45:03', '2018-11-21 09:45:03', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('vufjl99vq66v', 'ac4724', '2018-11-21 09:45:04', '2018-11-21 09:45:19', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('v3umzxyxkukr', '199vsg', '2018-11-21 09:45:20', '2018-11-21 09:45:21', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('wqkpkpartum', '5k56d9vcx4ip3tr5pj26', '2018-11-21 09:45:01', '2018-11-21 09:45:21', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '6aks5yeivme7;vufjl99vq66v;v3umzxyxkukr;', NULL, 'Done'),
	('ypv20w6lop5f', 'nhi96d', '2018-11-21 10:24:01', '2018-11-21 10:24:01', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2018-11-21 15:24:01--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', NULL, 'Done'),
	('fm3eh3p8he52', 'rh1u8q', '2018-11-21 10:24:02', '2018-11-21 10:24:02', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', NULL, 'Done'),
	('ao60rf0clk22', 'rpnhlg', '2018-11-21 10:24:03', '2018-11-21 10:24:03', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', NULL, 'Done'),
	('ssgi5a9q3qx5', 'omop8l', '2018-11-21 10:24:05', '2018-11-21 10:24:05', '#!/bin/bash', '', NULL, 'Done'),
	('jf7kgwvoa41', 't0ie2loym6u46u8mlgr3', '2018-11-21 10:23:59', '2018-11-21 10:24:05', 'nhi96d-7VZhh;rh1u8q-4sCmg;rpnhlg-JZfyQ;omop8l-1p5x1;', 'ypv20w6lop5f;fm3eh3p8he52;ao60rf0clk22;ssgi5a9q3qx5;', NULL, 'Done'),
	('42mlc7oc5grs', '199vsg', '2018-11-21 10:56:14', '2018-11-21 10:56:14', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('ub6d0l82znmb', 'ac4724', '2018-11-21 10:56:15', '2018-11-21 10:56:30', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('k70oo0irdqf6', '199vsg', '2018-11-21 10:56:31', '2018-11-21 10:56:31', '#!/bin/sh\r\necho "test geoweaver process running"\r\necho "Good"\r\n', 'test geoweaver process running\nGood\n', NULL, 'Done'),
	('q8jlalf2m70', '5k56d9vcx4ip3tr5pj26', '2018-11-21 10:56:11', '2018-11-21 10:56:31', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '42mlc7oc5grs;ub6d0l82znmb;k70oo0irdqf6;', NULL, 'Done'),
	('xrqet55oykzz', '199vsg', '2018-11-22 22:46:44', '2018-11-22 22:46:44', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('hk80xtuyhvph', 'ac4724', '2018-11-22 22:46:46', '2018-11-22 22:47:01', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('5xd6v6okdzun', '199vsg', '2018-11-22 22:47:02', '2018-11-22 22:47:02', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('8xb32jl4z0x', '5k56d9vcx4ip3tr5pj26', '2018-11-22 22:46:42', '2018-11-22 22:47:02', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'xrqet55oykzz;hk80xtuyhvph;5xd6v6okdzun;', NULL, 'Done'),
	('kw4v6qy7jlu6', '199vsg', '2018-11-22 22:50:31', '2018-11-22 22:50:31', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('cebv9aolnuyh', 'ac4724', '2018-11-22 22:50:32', '2018-11-22 22:50:47', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('bivw3fgwenin', '199vsg', '2018-11-22 22:50:48', '2018-11-22 22:50:48', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('mrwjljktuyx', '5k56d9vcx4ip3tr5pj26', '2018-11-22 22:50:29', '2018-11-22 22:50:48', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'kw4v6qy7jlu6;cebv9aolnuyh;bivw3fgwenin;', NULL, 'Done'),
	('918214qcdozz', '199vsg', '2018-11-22 22:52:49', '2018-11-22 22:52:49', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('952uwg47i09g', 'ac4724', '2018-11-22 22:52:50', '2018-11-22 22:53:05', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('cc4afbtw3uno', '199vsg', '2018-11-22 22:53:07', '2018-11-22 22:53:07', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('y27lfmxz8xi', '5k56d9vcx4ip3tr5pj26', '2018-11-22 22:52:48', '2018-11-22 22:53:07', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '918214qcdozz;952uwg47i09g;cc4afbtw3uno;', NULL, 'Done'),
	('gkzk2hllcfpn', '199vsg', '2018-11-22 22:53:36', '2018-11-22 22:53:36', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('nu4pno4xmib8', 'ac4724', '2018-11-22 22:53:37', '2018-11-22 22:53:52', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('2ungq3vqpnqf', '199vsg', '2018-11-22 22:53:53', '2018-11-22 22:53:53', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('3mbrm0kmvhm', '5k56d9vcx4ip3tr5pj26', '2018-11-22 22:53:35', '2018-11-22 22:53:53', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'gkzk2hllcfpn;nu4pno4xmib8;2ungq3vqpnqf;', NULL, 'Done'),
	('s1ijvwy6rgv', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:03:05', '2018-11-22 23:04:35', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', NULL, 'Done'),
	('h0ho2a3udsq6', '199vsg', '2018-11-22 23:08:59', '2018-11-22 23:09:00', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('ldh0iizldl4j', 'ac4724', '2018-11-22 23:09:01', '2018-11-22 23:09:16', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('n87uzhgidffc', '199vsg', '2018-11-22 23:09:17', '2018-11-22 23:09:17', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('euchwzeescb', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:08:58', '2018-11-22 23:09:17', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'h0ho2a3udsq6;ldh0iizldl4j;n87uzhgidffc;', NULL, 'Done'),
	('5a43k96mj5j3', '199vsg', '2018-11-22 23:10:01', '2018-11-22 23:10:01', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('8jlvzmev6iwi', 'ac4724', '2018-11-22 23:10:02', '2018-11-22 23:10:17', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('i3bpg2pygtsq', '199vsg', '2018-11-22 23:10:18', '2018-11-22 23:10:18', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('60mwjuz0e88', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:09:59', '2018-11-22 23:10:18', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '5a43k96mj5j3;8jlvzmev6iwi;i3bpg2pygtsq;', NULL, 'Done'),
	('oowk4y49lskx', '199vsg', '2018-11-22 23:12:48', '2018-11-22 23:12:48', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('nw6siffaazek', 'ac4724', '2018-11-22 23:12:49', '2018-11-22 23:13:04', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('q394e6vmv9eb', '199vsg', '2018-11-22 23:13:06', '2018-11-22 23:13:06', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('4hthsh8n9sy', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:12:47', '2018-11-22 23:13:06', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'oowk4y49lskx;nw6siffaazek;q394e6vmv9eb;', NULL, 'Done'),
	('std2f4fhezgx', '199vsg', '2018-11-22 23:14:19', '2018-11-22 23:14:19', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('icswmi7etd4w', 'ac4724', '2018-11-22 23:14:21', '2018-11-22 23:14:36', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('3bayj0498ikj', '199vsg', '2018-11-22 23:14:37', '2018-11-22 23:14:37', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('bci4civgabk', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:14:18', '2018-11-22 23:14:37', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'std2f4fhezgx;icswmi7etd4w;3bayj0498ikj;', NULL, 'Done'),
	('cnlgi7i87n06', '199vsg', '2018-11-22 23:16:15', '2018-11-22 23:16:15', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('cqp0aq85egmc', '199vsg', '2018-11-22 23:16:28', '2018-11-22 23:16:28', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('np2abwo0ecak', 'ac4724', '2018-11-22 23:16:16', '2018-11-22 23:16:31', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('wmhaixmav9c3', '199vsg', '2018-11-22 23:16:32', '2018-11-22 23:16:32', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('2vrlx82bhji', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:16:13', '2018-11-22 23:16:32', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'cnlgi7i87n06;np2abwo0ecak;wmhaixmav9c3;', NULL, 'Done'),
	('omp6yf0p84hq', 'ac4724', '2018-11-22 23:16:29', '2018-11-22 23:16:44', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('xziim1ol1vde', '199vsg', '2018-11-22 23:16:45', '2018-11-22 23:16:45', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('z77oaycknce', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:16:27', '2018-11-22 23:16:45', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'cqp0aq85egmc;omp6yf0p84hq;xziim1ol1vde;', NULL, 'Done'),
	('5u3m7mzhpiev', '199vsg', '2018-11-22 23:20:34', '2018-11-22 23:20:34', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('4cj4nz0c3qfa', 'ac4724', '2018-11-22 23:20:35', '2018-11-22 23:20:50', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('27qk5l1bubgl', '199vsg', '2018-11-22 23:20:52', '2018-11-22 23:20:52', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('ch2oak0cu10', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:20:33', '2018-11-22 23:20:52', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '5u3m7mzhpiev;4cj4nz0c3qfa;27qk5l1bubgl;', NULL, 'Done'),
	('cb3gxw79m2eg', '199vsg', '2018-11-22 23:23:30', '2018-11-22 23:23:30', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('fe1dnrxocuc8', 'ac4724', '2018-11-22 23:23:31', '2018-11-22 23:23:46', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('8us80whyw91r', '199vsg', '2018-11-22 23:23:47', '2018-11-22 23:23:47', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('yruh3tqznrf', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:23:28', '2018-11-22 23:23:47', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'cb3gxw79m2eg;fe1dnrxocuc8;8us80whyw91r;', NULL, 'Done'),
	('5rddcu7ml3bu', '199vsg', '2018-11-22 23:25:23', '2018-11-22 23:25:23', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('4o8018xta8mh', 'ac4724', '2018-11-22 23:25:24', '2018-11-22 23:25:39', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('jw42g4y0pbqi', '199vsg', '2018-11-22 23:25:40', '2018-11-22 23:25:40', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('biwtjykofg4', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:25:21', '2018-11-22 23:25:40', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '5rddcu7ml3bu;4o8018xta8mh;jw42g4y0pbqi;', NULL, 'Done'),
	('bmuxd2cbb7e2', '199vsg', '2018-11-22 23:27:45', '2018-11-22 23:27:45', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('z4no3tp8pzz6', 'ac4724', '2018-11-22 23:27:46', '2018-11-22 23:28:01', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('2bzh4w6qn5i2', '199vsg', '2018-11-22 23:28:02', '2018-11-22 23:28:02', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('cfceqrq55hi', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:27:44', '2018-11-22 23:28:02', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'bmuxd2cbb7e2;z4no3tp8pzz6;2bzh4w6qn5i2;', NULL, 'Done'),
	('pwce8qt6ufl6', '199vsg', '2018-11-22 23:30:27', '2018-11-22 23:30:27', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('a9qd5d9k2pvo', 'ac4724', '2018-11-22 23:30:28', '2018-11-22 23:30:43', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('toeza48tph0l', '199vsg', '2018-11-22 23:30:44', '2018-11-22 23:30:44', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('4yn5k5brqh8', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:30:25', '2018-11-22 23:30:44', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'pwce8qt6ufl6;a9qd5d9k2pvo;toeza48tph0l;', NULL, 'Done'),
	('kaasklgcv5xp', '199vsg', '2018-11-22 23:36:18', '2018-11-22 23:36:18', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('iaem22qwrr3o', 'ac4724', '2018-11-22 23:36:19', '2018-11-22 23:36:34', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('011tfvoe46nm', '199vsg', '2018-11-22 23:36:36', '2018-11-22 23:36:36', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('uvrxfjqbov0', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:36:17', '2018-11-22 23:36:36', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'kaasklgcv5xp;iaem22qwrr3o;011tfvoe46nm;', NULL, 'Done'),
	('64twrebf1tao', '199vsg', '2018-11-22 23:38:07', '2018-11-22 23:38:07', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('pv4j4yjjy6ax', 'ac4724', '2018-11-22 23:38:09', '2018-11-22 23:38:24', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('2vxptuxpghl5', '199vsg', '2018-11-22 23:38:25', '2018-11-22 23:38:25', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('q5ruqbqusn4', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:38:06', '2018-11-22 23:38:25', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '64twrebf1tao;pv4j4yjjy6ax;2vxptuxpghl5;', NULL, 'Done'),
	('myqrqfzjeqqy', '199vsg', '2018-11-22 23:38:35', '2018-11-22 23:38:35', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('oui96kq7sw70', 'ac4724', '2018-11-22 23:38:37', '2018-11-22 23:38:52', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('p32r13hq1bap', '199vsg', '2018-11-22 23:38:53', '2018-11-22 23:38:53', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('p93g01pyi6j', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:38:34', '2018-11-22 23:38:53', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'myqrqfzjeqqy;oui96kq7sw70;p32r13hq1bap;', NULL, 'Done'),
	('8ogh9yiuemm3', '199vsg', '2018-11-22 23:57:30', '2018-11-22 23:57:30', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('t7tohnptt4dn', 'ac4724', '2018-11-22 23:57:32', '2018-11-22 23:57:47', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('ak6pxg9u3r60', '199vsg', '2018-11-22 23:57:48', '2018-11-22 23:57:48', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('8uaxkiszco8', '5k56d9vcx4ip3tr5pj26', '2018-11-22 23:57:29', '2018-11-22 23:57:48', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '8ogh9yiuemm3;t7tohnptt4dn;ak6pxg9u3r60;', NULL, 'Done'),
	('is5mqejqydgm', 'nhi96d', '2018-11-22 23:58:02', '2018-11-22 23:58:02', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2018-11-23 04:58:02--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', NULL, 'Done'),
	('r052epyvdq4h', 'rh1u8q', '2018-11-22 23:58:04', '2018-11-22 23:58:04', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', NULL, 'Done'),
	('55w9j57m5scz', 'rpnhlg', '2018-11-22 23:58:05', '2018-11-22 23:58:05', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', NULL, 'Done'),
	('3nkalqyno1rk', 'omop8l', '2018-11-22 23:58:06', '2018-11-22 23:58:06', '#!/bin/bash', '', NULL, 'Done'),
	('zwhkj5qo4pv', 't0ie2loym6u46u8mlgr3', '2018-11-22 23:58:01', '2018-11-22 23:58:06', 'nhi96d-7VZhh;rh1u8q-4sCmg;rpnhlg-JZfyQ;omop8l-1p5x1;', 'is5mqejqydgm;r052epyvdq4h;55w9j57m5scz;3nkalqyno1rk;', NULL, 'Done'),
	('n2u9c3nhem51', '199vsg', '2018-11-23 00:21:54', '2018-11-23 00:21:54', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('xt1gzktxyicg', '199vsg', '2018-11-23 00:22:08', '2018-11-23 00:22:08', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('haexlhe68otd', 'ac4724', '2018-11-23 00:21:55', '2018-11-23 00:22:10', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('jrqlfnip97bq', '199vsg', '2018-11-23 00:22:11', '2018-11-23 00:22:11', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('gst8kplb7ck', '5k56d9vcx4ip3tr5pj26', '2018-11-23 00:21:52', '2018-11-23 00:22:11', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'n2u9c3nhem51;haexlhe68otd;jrqlfnip97bq;', NULL, 'Done'),
	('7y14lyq9186z', 'ac4724', '2018-11-23 00:22:10', '2018-11-23 00:22:25', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('x237mqk3xuz2', '199vsg', '2018-11-23 00:22:26', '2018-11-23 00:22:26', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('1n614yvhbxr', '5k56d9vcx4ip3tr5pj26', '2018-11-23 00:22:07', '2018-11-23 00:22:26', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'xt1gzktxyicg;7y14lyq9186z;x237mqk3xuz2;', NULL, 'Done'),
	('jllssdbvth92', '199vsg', '2018-11-23 00:23:12', '2018-11-23 00:23:12', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('yj2n4qcml9c8', 'ac4724', '2018-11-23 00:23:13', '2018-11-23 00:23:28', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('t00p9juz4i8a', '199vsg', '2018-11-23 00:23:29', '2018-11-23 00:23:29', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('4rt6pr8krx2', '5k56d9vcx4ip3tr5pj26', '2018-11-23 00:23:11', '2018-11-23 00:23:29', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'jllssdbvth92;yj2n4qcml9c8;t00p9juz4i8a;', NULL, 'Done'),
	('f6tveyrpifun', '199vsg', '2018-11-23 00:32:56', '2018-11-23 00:32:56', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('r0udft690kx5', 'ac4724', '2018-11-23 00:32:57', '2018-11-23 00:33:12', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('x7x1hbj1p0w6', '199vsg', '2018-11-23 00:33:14', '2018-11-23 00:33:14', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('dxmh0ywy9d4', '5k56d9vcx4ip3tr5pj26', '2018-11-23 00:32:54', '2018-11-23 00:33:14', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'f6tveyrpifun;r0udft690kx5;x7x1hbj1p0w6;', NULL, 'Done'),
	('5tlzcoteo44', 'q3ttwjbql5d49bffsl94', '2018-11-23 01:19:42', '2018-11-23 01:20:43', 'rh1u8q-0MNeQ;oax563-i2WdG;', 'null;null;', NULL, 'Done'),
	('ogq62fbi6ufg', '199vsg', '2018-11-23 02:33:29', '2018-11-23 02:33:29', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('03680gsux2ni', 'ac4724', '2018-11-23 02:33:31', '2018-11-23 02:33:46', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', NULL, 'Done'),
	('ovzqvw89pjsi', '199vsg', '2018-11-23 02:33:47', '2018-11-23 02:33:47', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', NULL, 'Done'),
	('fz42celuk8f', '5k56d9vcx4ip3tr5pj26', '2018-11-23 02:33:27', '2018-11-23 02:33:47', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'ogq62fbi6ufg;03680gsux2ni;ovzqvw89pjsi;', '', 'Done'),
	('0kiyz22uvgtw', '199vsg', '2018-11-23 02:47:12', '2018-11-23 02:47:12', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('7bw5dwby0umu', 'ac4724', '2018-11-23 02:47:13', '2018-11-23 02:47:28', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('3ww0rzzrpemi', '199vsg', '2018-11-23 02:47:29', '2018-11-23 02:47:29', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('r44tb4ua475', '5k56d9vcx4ip3tr5pj26', '2018-11-23 02:47:09', '2018-11-23 02:47:29', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '0kiyz22uvgtw;7bw5dwby0umu;3ww0rzzrpemi;', 'kps1gf;kps1gf;kps1gf;', 'Done'),
	('94bk7fsuouwv', 'nhi96d', '2018-11-26 10:13:29', '2018-11-26 10:13:29', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2018-11-26 15:13:22--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('0pp6oo6pgh5w', 'rh1u8q', '2018-11-26 10:13:30', '2018-11-26 10:13:30', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('9h86cbzwfsqa', 'rpnhlg', '2018-11-26 10:13:31', '2018-11-26 10:13:31', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('udj1kx6uia7d', 'omop8l', '2018-11-26 10:13:32', '2018-11-26 10:13:32', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('1zbjcvbjvl3', 't0ie2loym6u46u8mlgr3', '2018-11-26 10:13:27', '2018-11-26 10:13:32', 'nhi96d-7VZhh;rh1u8q-4sCmg;rpnhlg-JZfyQ;omop8l-1p5x1;', '94bk7fsuouwv;0pp6oo6pgh5w;9h86cbzwfsqa;udj1kx6uia7d;', 'kps1gf;', 'Done'),
	('s2jots05m58', '5k56d9vcx4ip3tr5pj26', '2018-11-26 10:55:51', '2018-11-26 10:55:51', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('vf47rkx2xn6l', '199vsg', '2018-11-26 10:57:09', '2018-11-26 10:57:09', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('8tu24z9k5rwb', 'ac4724', '2018-11-26 10:57:10', '2018-11-26 10:57:25', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('ppusa2bt8sfb', '199vsg', '2018-11-26 10:57:26', '2018-11-26 10:57:26', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('gmldlihci7p', '5k56d9vcx4ip3tr5pj26', '2018-11-26 10:57:08', '2018-11-26 10:57:26', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'vf47rkx2xn6l;8tu24z9k5rwb;ppusa2bt8sfb;', 'kps1gf;', 'Done'),
	('mhnn1ye9em5r', 'nhi96d', '2018-11-26 11:34:31', '2018-11-26 11:34:31', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2018-11-26 16:34:23--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('npdbjo5b2bbw', 'rh1u8q', '2018-11-26 11:34:32', '2018-11-26 11:34:32', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('3auh48llyjr2', 'rpnhlg', '2018-11-26 11:34:32', '2018-11-26 11:34:32', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('6lnxoez1juzh', 'omop8l', '2018-11-26 11:34:33', '2018-11-26 11:34:33', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('7svzs98c76y', 't0ie2loym6u46u8mlgr3', '2018-11-26 11:34:29', '2018-11-26 11:34:33', 'nhi96d-7VZhh;rh1u8q-4sCmg;rpnhlg-JZfyQ;omop8l-1p5x1;', 'mhnn1ye9em5r;npdbjo5b2bbw;3auh48llyjr2;6lnxoez1juzh;', 'kps1gf;', 'Done'),
	('x337onrgn76i', '199vsg', '2018-11-26 11:57:04', '2018-11-26 11:57:04', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('q2jij38ywckq', 'o634zj', '2018-11-26 11:57:05', '2018-11-26 11:57:05', '#!/bin/bash\n#write your bash script\necho "this is a test"\nls -l\necho "end of process"\n', 'this is a test\ntotal 452\n-rw-rw-r-- 1 zsun zsun 184221 Nov 23 07:09 demo1.png\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:23 geoweaver-0rmh5n2ggump.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:13 geoweaver-0t2cusmor1qq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:05 geoweaver-0y810a4b2w4h.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:04 geoweaver-1ct96as2m5ko.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:50 geoweaver-2vlkq4a417xb.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov  6 16:32 geoweaver-3x0wfjqkh9u8.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:48 geoweaver-4qyah08exnn2.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-4uoir5yg170b.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:57 geoweaver-5nvyprat2ymg.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:09 geoweaver-5srebnv73rr6.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-6tkk4h4t79ju.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:10 geoweaver-76vr0i303l97.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 21 15:24 geoweaver-7qvheb9t9qai.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 20 21:57 geoweaver-8ie1ac19x0op.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:55 geoweaver-9rl7gi2os0h9.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:12 geoweaver-9xmfv6ueopfx.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:36 geoweaver-9yzmx2eb7tdq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:23 geoweaver-abmxpesljy7w.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:53 geoweaver-ac6bz13nlp93.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 15:56 geoweaver-ajgv0xpipmsa.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:56 geoweaver-akiwy0v8yr20.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:02 geoweaver-akus5uoq68bo.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 16:34 geoweaver-bkvcbc4u37t7.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:13 geoweaver-bu98qxofbtds.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 15:17 geoweaver-d2hb2xee2koq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:47 geoweaver-dm92hncavt84.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:58 geoweaver-eag79fly25gm.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:30 geoweaver-f1anqnfjha38.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 20 22:59 geoweaver-fxgl1jf3c87i.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 16:59 geoweaver-gnpqdtbash32.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 00:31 geoweaver-gq2acoev3t5t.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:55 geoweaver-h0xhutw9n432.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:07 geoweaver-ilg86wu09spa.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:42 geoweaver-im12ifmijwbl.sh\n-rwxrwxr-x 1 zsun zsun     87 Nov 26 16:56 geoweaver-it542dtbzkoo.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 14:45 geoweaver-jjbzmi54qxu7.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-kj9hn0j4nn4n.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-l2jcaadlr7uq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:20 geoweaver-lld30tuheslb.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-lqjhc5mtos83.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-m4m94i6up3dn.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:25 geoweaver-mol6b3txylj0.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:01 geoweaver-nf0jhr0s7jzs.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-oq4yaqzcjawr.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:33 geoweaver-os0tji11psj0.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:47 geoweaver-oyl19u24m9ok.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 15:13 geoweaver-ozdh9no6ej7e.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:56 geoweaver-p4pr4t5uiqcu.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 23 04:58 geoweaver-pci39zijg5rq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 17:33 geoweaver-pnmgmnw8b475.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:57 geoweaver-qhzauxlcpail.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:28 geoweaver-qi8v32hnou87.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:14 geoweaver-r5t9iu0rqen5.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-r6i1npcbgelg.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:30 geoweaver-r77sepls8im1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 15:07 geoweaver-sfmrxexcyhoq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:26 geoweaver-tuf5skypkxrk.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-unwhx8uiefka.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:39 geoweaver-v6u7kkortde2.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov  6 16:31 geoweaver-v9s6aa0ne8k1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 21:30 geoweaver-vgca9w0js8pi.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 26 15:57 geoweaver-vhnbgsehizs7.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 18:34 geoweaver-vigsp32dco36.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:33 geoweaver-vu69ojb2m65i.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-wqmouveixiq8.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:31 geoweaver-wsg26wee1wnw.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:01 geoweaver-xulycmqe3d05.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:03 geoweaver-yo5gcqh7q07v.sh\nend of process\n', 'kps1gf', 'Done'),
	('ibsiasnir5uj', 'ac4724', '2018-11-26 11:57:06', '2018-11-26 11:57:21', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('fexkiplab2t', '7w0ga6df6x6xhex588pk', '2018-11-26 11:57:03', '2018-11-26 11:57:21', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'x337onrgn76i;q2jij38ywckq;ibsiasnir5uj;', 'kps1gf;', 'Done'),
	('yls1f2p00ha6', '199vsg', '2018-11-26 11:58:57', '2018-11-26 11:58:57', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('lkvpwe9el4z3', 'o634zj', '2018-11-26 11:58:58', '2018-11-26 11:58:58', '#!/bin/bash\n#write your bash script\necho "this is a test"\nls -l\necho "end of process"\n', 'this is a test\ntotal 456\n-rw-rw-r-- 1 zsun zsun 184221 Nov 23 07:09 demo1.png\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:23 geoweaver-0rmh5n2ggump.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:13 geoweaver-0t2cusmor1qq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:05 geoweaver-0y810a4b2w4h.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:04 geoweaver-1ct96as2m5ko.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:50 geoweaver-2vlkq4a417xb.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov  6 16:32 geoweaver-3x0wfjqkh9u8.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:48 geoweaver-4qyah08exnn2.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-4uoir5yg170b.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:57 geoweaver-5nvyprat2ymg.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:09 geoweaver-5srebnv73rr6.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-6tkk4h4t79ju.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:10 geoweaver-76vr0i303l97.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 21 15:24 geoweaver-7qvheb9t9qai.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 20 21:57 geoweaver-8ie1ac19x0op.sh\n-rwxrwxr-x 1 zsun zsun     87 Nov 26 16:58 geoweaver-9qpzjlsetway.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:55 geoweaver-9rl7gi2os0h9.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:12 geoweaver-9xmfv6ueopfx.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:36 geoweaver-9yzmx2eb7tdq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:23 geoweaver-abmxpesljy7w.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:53 geoweaver-ac6bz13nlp93.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 15:56 geoweaver-ajgv0xpipmsa.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:56 geoweaver-akiwy0v8yr20.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:02 geoweaver-akus5uoq68bo.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 16:34 geoweaver-bkvcbc4u37t7.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:13 geoweaver-bu98qxofbtds.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 15:17 geoweaver-d2hb2xee2koq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:47 geoweaver-dm92hncavt84.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:58 geoweaver-eag79fly25gm.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:30 geoweaver-f1anqnfjha38.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 20 22:59 geoweaver-fxgl1jf3c87i.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 16:59 geoweaver-gnpqdtbash32.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 00:31 geoweaver-gq2acoev3t5t.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:55 geoweaver-h0xhutw9n432.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:07 geoweaver-ilg86wu09spa.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:42 geoweaver-im12ifmijwbl.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 26 16:56 geoweaver-it542dtbzkoo.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 14:45 geoweaver-jjbzmi54qxu7.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-kj9hn0j4nn4n.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-l2jcaadlr7uq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:20 geoweaver-lld30tuheslb.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-lqjhc5mtos83.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-m4m94i6up3dn.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:25 geoweaver-mol6b3txylj0.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:01 geoweaver-nf0jhr0s7jzs.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-oq4yaqzcjawr.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:33 geoweaver-os0tji11psj0.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:47 geoweaver-oyl19u24m9ok.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 15:13 geoweaver-ozdh9no6ej7e.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:56 geoweaver-p4pr4t5uiqcu.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 23 04:58 geoweaver-pci39zijg5rq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 17:33 geoweaver-pnmgmnw8b475.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:57 geoweaver-qhzauxlcpail.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:28 geoweaver-qi8v32hnou87.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:14 geoweaver-r5t9iu0rqen5.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-r6i1npcbgelg.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:30 geoweaver-r77sepls8im1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 15:07 geoweaver-sfmrxexcyhoq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:26 geoweaver-tuf5skypkxrk.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-unwhx8uiefka.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:39 geoweaver-v6u7kkortde2.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov  6 16:31 geoweaver-v9s6aa0ne8k1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 21:30 geoweaver-vgca9w0js8pi.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 26 15:57 geoweaver-vhnbgsehizs7.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 18:34 geoweaver-vigsp32dco36.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:33 geoweaver-vu69ojb2m65i.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-wqmouveixiq8.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:31 geoweaver-wsg26wee1wnw.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:01 geoweaver-xulycmqe3d05.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:03 geoweaver-yo5gcqh7q07v.sh\nend of process\n', 'kps1gf', 'Done'),
	('lae0ylvrrohu', 'ac4724', '2018-11-26 11:58:59', '2018-11-26 11:59:14', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('vnimz8ttb36', '7w0ga6df6x6xhex588pk', '2018-11-26 11:58:56', '2018-11-26 11:59:14', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'yls1f2p00ha6;lkvpwe9el4z3;lae0ylvrrohu;', 'kps1gf;', 'Done'),
	('wq0dpnfutfng', '199vsg', '2018-11-26 11:59:41', '2018-11-26 11:59:41', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('aauf3uu6dpr1', 'o634zj', '2018-11-26 11:59:42', '2018-11-26 11:59:42', '#!/bin/bash\n#write your bash script\necho "this is a test"\nls -l\necho "end of process"\n', 'this is a test\ntotal 460\n-rw-rw-r-- 1 zsun zsun 184221 Nov 23 07:09 demo1.png\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:23 geoweaver-0rmh5n2ggump.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:13 geoweaver-0t2cusmor1qq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:05 geoweaver-0y810a4b2w4h.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:04 geoweaver-1ct96as2m5ko.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:50 geoweaver-2vlkq4a417xb.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov  6 16:32 geoweaver-3x0wfjqkh9u8.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:48 geoweaver-4qyah08exnn2.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-4uoir5yg170b.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:57 geoweaver-5nvyprat2ymg.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:09 geoweaver-5srebnv73rr6.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-6tkk4h4t79ju.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:10 geoweaver-76vr0i303l97.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 21 15:24 geoweaver-7qvheb9t9qai.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 20 21:57 geoweaver-8ie1ac19x0op.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 26 16:58 geoweaver-9qpzjlsetway.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:55 geoweaver-9rl7gi2os0h9.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:12 geoweaver-9xmfv6ueopfx.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:36 geoweaver-9yzmx2eb7tdq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:23 geoweaver-abmxpesljy7w.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:53 geoweaver-ac6bz13nlp93.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 15:56 geoweaver-ajgv0xpipmsa.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:56 geoweaver-akiwy0v8yr20.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:02 geoweaver-akus5uoq68bo.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 16:34 geoweaver-bkvcbc4u37t7.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:13 geoweaver-bu98qxofbtds.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 15:17 geoweaver-d2hb2xee2koq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:47 geoweaver-dm92hncavt84.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:58 geoweaver-eag79fly25gm.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:30 geoweaver-f1anqnfjha38.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 20 22:59 geoweaver-fxgl1jf3c87i.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 16:59 geoweaver-gnpqdtbash32.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 00:31 geoweaver-gq2acoev3t5t.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:55 geoweaver-h0xhutw9n432.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:07 geoweaver-ilg86wu09spa.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:42 geoweaver-im12ifmijwbl.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 26 16:56 geoweaver-it542dtbzkoo.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 14:45 geoweaver-jjbzmi54qxu7.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-kj9hn0j4nn4n.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-l2jcaadlr7uq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:20 geoweaver-lld30tuheslb.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-lqjhc5mtos83.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-m4m94i6up3dn.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:25 geoweaver-mol6b3txylj0.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:01 geoweaver-nf0jhr0s7jzs.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-oq4yaqzcjawr.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:33 geoweaver-os0tji11psj0.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:47 geoweaver-oyl19u24m9ok.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 15:13 geoweaver-ozdh9no6ej7e.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:56 geoweaver-p4pr4t5uiqcu.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 23 04:58 geoweaver-pci39zijg5rq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 17:33 geoweaver-pnmgmnw8b475.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:57 geoweaver-qhzauxlcpail.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:28 geoweaver-qi8v32hnou87.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:14 geoweaver-r5t9iu0rqen5.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-r6i1npcbgelg.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:30 geoweaver-r77sepls8im1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 15:07 geoweaver-sfmrxexcyhoq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:26 geoweaver-tuf5skypkxrk.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-unwhx8uiefka.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:39 geoweaver-v6u7kkortde2.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov  6 16:31 geoweaver-v9s6aa0ne8k1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 21:30 geoweaver-vgca9w0js8pi.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 26 15:57 geoweaver-vhnbgsehizs7.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 18:34 geoweaver-vigsp32dco36.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:33 geoweaver-vu69ojb2m65i.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-wqmouveixiq8.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:31 geoweaver-wsg26wee1wnw.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:01 geoweaver-xulycmqe3d05.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:03 geoweaver-yo5gcqh7q07v.sh\n-rwxrwxr-x 1 zsun zsun     87 Nov 26 16:59 geoweaver-zic9yhhjw082.sh\nend of process\n', 'kps1gf', 'Done'),
	('8lm1r2v10dby', 'ac4724', '2018-11-26 11:59:43', '2018-11-26 11:59:58', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('gwxbwl5gqxq', '7w0ga6df6x6xhex588pk', '2018-11-26 11:59:40', '2018-11-26 11:59:58', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'wq0dpnfutfng;aauf3uu6dpr1;8lm1r2v10dby;', 'kps1gf;', 'Done'),
	('i4oflx4lk54p', '199vsg', '2018-11-26 12:13:26', '2018-11-26 12:13:26', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('dqmvoqkv8uwh', 'o634zj', '2018-11-26 12:13:27', '2018-11-26 12:13:27', '#!/bin/bash\n#write your bash script\necho "this is a test"\nls -l\necho "end of process"\n', 'this is a test\ntotal 464\n-rw-rw-r-- 1 zsun zsun 184221 Nov 23 07:09 demo1.png\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:23 geoweaver-0rmh5n2ggump.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:13 geoweaver-0t2cusmor1qq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:05 geoweaver-0y810a4b2w4h.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:04 geoweaver-1ct96as2m5ko.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:50 geoweaver-2vlkq4a417xb.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov  6 16:32 geoweaver-3x0wfjqkh9u8.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:48 geoweaver-4qyah08exnn2.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-4uoir5yg170b.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:57 geoweaver-5nvyprat2ymg.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:09 geoweaver-5srebnv73rr6.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-6tkk4h4t79ju.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:10 geoweaver-76vr0i303l97.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 21 15:24 geoweaver-7qvheb9t9qai.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 20 21:57 geoweaver-8ie1ac19x0op.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 26 16:58 geoweaver-9qpzjlsetway.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:55 geoweaver-9rl7gi2os0h9.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:12 geoweaver-9xmfv6ueopfx.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:36 geoweaver-9yzmx2eb7tdq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:23 geoweaver-abmxpesljy7w.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:53 geoweaver-ac6bz13nlp93.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 15:56 geoweaver-ajgv0xpipmsa.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:56 geoweaver-akiwy0v8yr20.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:02 geoweaver-akus5uoq68bo.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 16:34 geoweaver-bkvcbc4u37t7.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:13 geoweaver-bu98qxofbtds.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 15:17 geoweaver-d2hb2xee2koq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:47 geoweaver-dm92hncavt84.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:58 geoweaver-eag79fly25gm.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:30 geoweaver-f1anqnfjha38.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 20 22:59 geoweaver-fxgl1jf3c87i.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 16:59 geoweaver-gnpqdtbash32.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 00:31 geoweaver-gq2acoev3t5t.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:55 geoweaver-h0xhutw9n432.sh\n-rwxrwxr-x 1 zsun zsun     64 Nov 20 15:07 geoweaver-ilg86wu09spa.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:42 geoweaver-im12ifmijwbl.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 26 16:56 geoweaver-it542dtbzkoo.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 21 14:45 geoweaver-jjbzmi54qxu7.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-kj9hn0j4nn4n.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-l2jcaadlr7uq.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:20 geoweaver-lld30tuheslb.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:16 geoweaver-lqjhc5mtos83.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:22 geoweaver-m4m94i6up3dn.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:25 geoweaver-mol6b3txylj0.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:01 geoweaver-nf0jhr0s7jzs.sh\n-rwxrwxr-x 1 zsun zsun     87 Nov 26 17:13 geoweaver-o71ih46en8vm.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-oq4yaqzcjawr.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 05:33 geoweaver-os0tji11psj0.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:47 geoweaver-oyl19u24m9ok.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 26 15:13 geoweaver-ozdh9no6ej7e.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 21:56 geoweaver-p4pr4t5uiqcu.sh\n-rwxrwxr-x 1 zsun zsun     12 Nov 23 04:58 geoweaver-pci39zijg5rq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 17:33 geoweaver-pnmgmnw8b475.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:57 geoweaver-qhzauxlcpail.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:28 geoweaver-qi8v32hnou87.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:14 geoweaver-r5t9iu0rqen5.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 04:38 geoweaver-r6i1npcbgelg.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 22:30 geoweaver-r77sepls8im1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 20 15:07 geoweaver-sfmrxexcyhoq.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:26 geoweaver-tuf5skypkxrk.sh\n-rwxrwxr-x 1 zsun zsun     61 Nov 20 16:27 geoweaver-unwhx8uiefka.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 21:39 geoweaver-v6u7kkortde2.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov  6 16:31 geoweaver-v9s6aa0ne8k1.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 21:30 geoweaver-vgca9w0js8pi.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 26 15:57 geoweaver-vhnbgsehizs7.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 18:34 geoweaver-vigsp32dco36.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 07:33 geoweaver-vu69ojb2m65i.sh\n-rwxrwxr-x 1 zsun zsun     63 Nov 23 03:53 geoweaver-wqmouveixiq8.sh\n-rwxrwxr-x 1 zsun zsun     99 Nov 20 17:31 geoweaver-wsg26wee1wnw.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:01 geoweaver-xulycmqe3d05.sh\n-rwxrwxr-x 1 zsun zsun     73 Nov 19 17:03 geoweaver-yo5gcqh7q07v.sh\n-rwxrwxr-x 1 zsun zsun    101 Nov 26 16:59 geoweaver-zic9yhhjw082.sh\nend of process\n', 'kps1gf', 'Done'),
	('au35voq9srai', 'ac4724', '2018-11-26 12:13:28', '2018-11-26 12:13:43', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('jp8wwku6tqi', '7w0ga6df6x6xhex588pk', '2018-11-26 12:13:25', '2018-11-26 12:13:43', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'i4oflx4lk54p;dqmvoqkv8uwh;au35voq9srai;', 'kps1gf;', 'Done'),
	('udwaii1ebdyh', '199vsg', '2018-12-17 16:37:58', '2018-12-17 16:37:58', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('zoqvibf248wz', '199vsg', '2018-12-17 16:39:11', '2018-12-17 16:39:11', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('yew5700qspwm', '199vsg', '2018-12-17 16:39:46', '2018-12-17 16:39:46', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('nnjxmrxrbxhq', '199vsg', '2018-12-17 17:11:56', '2018-12-17 17:11:56', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('i2okdvfym98x', '199vsg', '2018-12-19 09:45:27', '2018-12-19 09:45:27', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('7nfpoj3m2d2', '7sb7xj', '2019-01-07 10:21:55', '2019-01-07 10:21:57', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'qnrerqw0', 'kps1gf', 'Done'),
	('hpb3on6ja31', '7sb7xj', '2019-01-07 10:22:57', '2019-01-07 10:22:58', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'ep18fho9', 'kps1gf', 'Done'),
	('jt57x6tgakwp', '199vsg', '2019-01-07 10:35:33', '2019-01-07 10:35:33', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('5j9lmoa3kjkt', 'ac4724', '2019-01-07 10:35:34', '2019-01-07 10:35:49', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('2qd0jiqpxof', '7w0ga6df6x6xhex588pk', '2019-01-07 10:35:32', '2019-01-07 10:35:49', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'jt57x6tgakwp;null;5j9lmoa3kjkt;', 'kps1gf;', 'Done'),
	('r111uuc0v4rj', '199vsg', '2019-01-07 10:36:36', '2019-01-07 10:36:36', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('h3yxbeaeo8f7', 'o634zj', '2019-01-07 10:36:37', '2019-01-07 10:36:37', '#!/bin/bash\n#write your bash script\necho "TestProcess 1"\nps -ef\npwd', 'TestProcess 1\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0  2018 ?        00:05:31 /lib/systemd/systemd --system --\nroot         2     0  0  2018 ?        00:00:12 [kthreadd]\nroot         4     2  0  2018 ?        00:00:00 [kworker/0:0H]\nroot         7     2  0  2018 ?        00:00:00 [mm_percpu_wq]\nroot         8     2  0  2018 ?        00:00:31 [ksoftirqd/0]\nroot         9     2  0  2018 ?        01:57:25 [rcu_sched]\nroot        10     2  0  2018 ?        00:00:00 [rcu_bh]\nroot        11     2  0  2018 ?        00:00:13 [migration/0]\nroot        12     2  0  2018 ?        00:00:17 [watchdog/0]\nroot        13     2  0  2018 ?        00:00:00 [cpuhp/0]\nroot        14     2  0  2018 ?        00:00:00 [cpuhp/1]\nroot        15     2  0  2018 ?        00:00:23 [watchdog/1]\nroot        16     2  0  2018 ?        00:00:18 [migration/1]\nroot        17     2  0  2018 ?        00:00:07 [ksoftirqd/1]\nroot        19     2  0  2018 ?        00:00:00 [kworker/1:0H]\nroot        21     2  0  2018 ?        00:00:00 [cpuhp/2]\nroot        22     2  0  2018 ?        00:00:17 [watchdog/2]\nroot        23     2  0  2018 ?        00:00:04 [migration/2]\nroot        24     2  0  2018 ?        00:00:07 [ksoftirqd/2]\nroot        26     2  0  2018 ?        00:00:00 [kworker/2:0H]\nroot        27     2  0  2018 ?        00:00:00 [cpuhp/3]\nroot        28     2  0  2018 ?        00:00:18 [watchdog/3]\nroot        29     2  0  2018 ?        00:00:04 [migration/3]\nroot        30     2  0  2018 ?        00:00:04 [ksoftirqd/3]\nroot        32     2  0  2018 ?        00:00:00 [kworker/3:0H]\nroot        33     2  0  2018 ?        00:00:00 [cpuhp/4]\nroot        34     2  0  2018 ?        00:00:16 [watchdog/4]\nroot        35     2  0  2018 ?        00:00:02 [migration/4]\nroot        36     2  0  2018 ?        00:00:08 [ksoftirqd/4]\nroot        38     2  0  2018 ?        00:00:00 [kworker/4:0H]\nroot        39     2  0  2018 ?        00:00:00 [cpuhp/5]\nroot        40     2  0  2018 ?        00:00:17 [watchdog/5]\nroot        41     2  0  2018 ?        00:00:02 [migration/5]\nroot        42     2  0  2018 ?        00:00:03 [ksoftirqd/5]\nroot        44     2  0  2018 ?        00:00:00 [kworker/5:0H]\nroot        45     2  0  2018 ?        00:00:00 [cpuhp/6]\nroot        46     2  0  2018 ?        00:00:15 [watchdog/6]\nroot        47     2  0  2018 ?        00:00:01 [migration/6]\nroot        48     2  0  2018 ?        00:00:04 [ksoftirqd/6]\nroot        50     2  0  2018 ?        00:00:00 [kworker/6:0H]\nroot        51     2  0  2018 ?        00:00:00 [cpuhp/7]\nroot        52     2  0  2018 ?        00:00:16 [watchdog/7]\nroot        53     2  0  2018 ?        00:00:01 [migration/7]\nroot        54     2  0  2018 ?        00:00:02 [ksoftirqd/7]\nroot        56     2  0  2018 ?        00:00:00 [kworker/7:0H]\nroot        57     2  0  2018 ?        00:00:00 [cpuhp/8]\nroot        58     2  0  2018 ?        00:00:15 [watchdog/8]\nroot        59     2  0  2018 ?        00:00:01 [migration/8]\nroot        60     2  0  2018 ?        00:00:03 [ksoftirqd/8]\nroot        62     2  0  2018 ?        00:00:00 [kworker/8:0H]\nroot        63     2  0  2018 ?        00:00:00 [cpuhp/9]\nroot        64     2  0  2018 ?        00:00:16 [watchdog/9]\nroot        65     2  0  2018 ?        00:00:01 [migration/9]\nroot        66     2  0  2018 ?        00:00:02 [ksoftirqd/9]\nroot        68     2  0  2018 ?        00:00:00 [kworker/9:0H]\nroot        69     2  0  2018 ?        00:00:00 [cpuhp/10]\nroot        70     2  0  2018 ?        00:00:14 [watchdog/10]\nroot        71     2  0  2018 ?        00:00:01 [migration/10]\nroot        72     2  0  2018 ?        00:00:03 [ksoftirqd/10]\nroot        74     2  0  2018 ?        00:00:00 [kworker/10:0H]\nroot        75     2  0  2018 ?        00:00:00 [cpuhp/11]\nroot        76     2  0  2018 ?        00:00:16 [watchdog/11]\nroot        77     2  0  2018 ?        00:00:01 [migration/11]\nroot        78     2  0  2018 ?        00:00:01 [ksoftirqd/11]\nroot        80     2  0  2018 ?        00:00:00 [kworker/11:0H]\nroot        81     2  0  2018 ?        00:00:00 [cpuhp/12]\nroot        82     2  0  2018 ?        00:00:13 [watchdog/12]\nroot        83     2  0  2018 ?        00:00:01 [migration/12]\nroot        84     2  0  2018 ?        00:00:02 [ksoftirqd/12]\nroot        86     2  0  2018 ?        00:00:00 [kworker/12:0H]\nroot        87     2  0  2018 ?        00:00:00 [cpuhp/13]\nroot        88     2  0  2018 ?        00:00:14 [watchdog/13]\nroot        89     2  0  2018 ?        00:00:01 [migration/13]\nroot        90     2  0  2018 ?        00:00:02 [ksoftirqd/13]\nroot        92     2  0  2018 ?        00:00:00 [kworker/13:0H]\nroot        93     2  0  2018 ?        00:00:00 [cpuhp/14]\nroot        94     2  0  2018 ?        00:00:15 [watchdog/14]\nroot        95     2  0  2018 ?        00:00:01 [migration/14]\nroot        96     2  0  2018 ?        00:00:03 [ksoftirqd/14]\nroot        98     2  0  2018 ?        00:00:00 [kworker/14:0H]\nroot        99     2  0  2018 ?        00:00:00 [cpuhp/15]\nroot       100     2  0  2018 ?        00:00:16 [watchdog/15]\nroot       101     2  0  2018 ?        00:00:00 [migration/15]\nroot       102     2  0  2018 ?        00:00:02 [ksoftirqd/15]\nroot       104     2  0  2018 ?        00:00:00 [kworker/15:0H]\nroot       105     2  0  2018 ?        00:00:00 [cpuhp/16]\nroot       106     2  0  2018 ?        00:00:14 [watchdog/16]\nroot       107     2  0  2018 ?        00:00:01 [migration/16]\nroot       108     2  0  2018 ?        00:00:20 [ksoftirqd/16]\nroot       110     2  0  2018 ?        00:00:00 [kworker/16:0H]\nroot       111     2  0  2018 ?        00:00:00 [cpuhp/17]\nroot       112     2  0  2018 ?        00:00:16 [watchdog/17]\nroot       113     2  0  2018 ?        00:00:00 [migration/17]\nroot       114     2  0  2018 ?        00:00:02 [ksoftirqd/17]\nroot       116     2  0  2018 ?        00:00:00 [kworker/17:0H]\nroot       117     2  0  2018 ?        00:00:00 [cpuhp/18]\nroot       118     2  0  2018 ?        00:00:15 [watchdog/18]\nroot       119     2  0  2018 ?        00:00:01 [migration/18]\nroot       120     2  0  2018 ?        00:03:48 [ksoftirqd/18]\nroot       122     2  0  2018 ?        00:00:00 [kworker/18:0H]\nroot       123     2  0  2018 ?        00:00:00 [cpuhp/19]\nroot       124     2  0  2018 ?        00:00:16 [watchdog/19]\nroot       125     2  0  2018 ?        00:00:00 [migration/19]\nroot       126     2  0  2018 ?        00:00:02 [ksoftirqd/19]\nroot       128     2  0  2018 ?        00:00:00 [kworker/19:0H]\nroot       129     2  0  2018 ?        00:00:00 [cpuhp/20]\nroot       130     2  0  2018 ?        00:00:14 [watchdog/20]\nroot       131     2  0  2018 ?        00:00:01 [migration/20]\nroot       132     2  0  2018 ?        00:00:03 [ksoftirqd/20]\nroot       134     2  0  2018 ?        00:00:00 [kworker/20:0H]\nroot       135     2  0  2018 ?        00:00:00 [cpuhp/21]\nroot       136     2  0  2018 ?        00:00:15 [watchdog/21]\nroot       137     2  0  2018 ?        00:00:00 [migration/21]\nroot       138     2  0  2018 ?        00:00:01 [ksoftirqd/21]\nroot       140     2  0  2018 ?        00:00:00 [kworker/21:0H]\nroot       141     2  0  2018 ?        00:00:00 [cpuhp/22]\nroot       142     2  0  2018 ?        00:00:13 [watchdog/22]\nroot       143     2  0  2018 ?        00:00:01 [migration/22]\nroot       144     2  0  2018 ?        00:00:07 [ksoftirqd/22]\nroot       146     2  0  2018 ?        00:00:00 [kworker/22:0H]\nroot       147     2  0  2018 ?        00:00:00 [cpuhp/23]\nroot       148     2  0  2018 ?        00:00:15 [watchdog/23]\nroot       149     2  0  2018 ?        00:00:00 [migration/23]\nroot       150     2  0  2018 ?        00:00:01 [ksoftirqd/23]\nroot       152     2  0  2018 ?        00:00:00 [kworker/23:0H]\nroot       153     2  0  2018 ?        00:00:00 [cpuhp/24]\nroot       154     2  0  2018 ?        00:00:13 [watchdog/24]\nroot       155     2  0  2018 ?        00:00:01 [migration/24]\nroot       156     2  0  2018 ?        00:00:25 [ksoftirqd/24]\nroot       159     2  0  2018 ?        00:00:00 [cpuhp/25]\nroot       160     2  0  2018 ?        00:00:12 [watchdog/25]\nroot       161     2  0  2018 ?        00:00:01 [migration/25]\nroot       162     2  0  2018 ?        00:00:01 [ksoftirqd/25]\nroot       164     2  0  2018 ?        00:00:00 [kworker/25:0H]\nroot       165     2  0  2018 ?        00:00:00 [cpuhp/26]\nroot       166     2  0  2018 ?        00:00:13 [watchdog/26]\nroot       167     2  0  2018 ?        00:00:01 [migration/26]\nroot       168     2  0  2018 ?        00:02:47 [ksoftirqd/26]\nroot       170     2  0  2018 ?        00:00:00 [kworker/26:0H]\nroot       171     2  0  2018 ?        00:00:00 [cpuhp/27]\nroot       172     2  0  2018 ?        00:00:14 [watchdog/27]\nroot       173     2  0  2018 ?        00:00:00 [migration/27]\nroot       174     2  0  2018 ?        00:00:01 [ksoftirqd/27]\nroot       176     2  0  2018 ?        00:00:00 [kworker/27:0H]\nroot       177     2  0  2018 ?        00:00:00 [cpuhp/28]\nroot       178     2  0  2018 ?        00:00:13 [watchdog/28]\nroot       179     2  0  2018 ?        00:00:00 [migration/28]\nroot       180     2  0  2018 ?        00:00:03 [ksoftirqd/28]\nroot       182     2  0  2018 ?        00:00:00 [kworker/28:0H]\nroot       183     2  0  2018 ?        00:00:00 [cpuhp/29]\nroot       184     2  0  2018 ?        00:00:13 [watchdog/29]\nroot       185     2  0  2018 ?        00:00:00 [migration/29]\nroot       186     2  0  2018 ?        00:00:02 [ksoftirqd/29]\nroot       188     2  0  2018 ?        00:00:00 [kworker/29:0H]\nroot       189     2  0  2018 ?        00:00:00 [cpuhp/30]\nroot       190     2  0  2018 ?        00:00:13 [watchdog/30]\nroot       191     2  0  2018 ?        00:00:00 [migration/30]\nroot       192     2  0  2018 ?        00:00:04 [ksoftirqd/30]\nroot       194     2  0  2018 ?        00:00:00 [kworker/30:0H]\nroot       195     2  0  2018 ?        00:00:00 [cpuhp/31]\nroot       196     2  0  2018 ?        00:00:14 [watchdog/31]\nroot       197     2  0  2018 ?        00:00:00 [migration/31]\nroot       198     2  0  2018 ?        00:00:01 [ksoftirqd/31]\nroot       200     2  0  2018 ?        00:00:00 [kworker/31:0H]\nroot       201     2  0  2018 ?        00:00:00 [cpuhp/32]\nroot       202     2  0  2018 ?        00:00:12 [watchdog/32]\nroot       203     2  0  2018 ?        00:00:00 [migration/32]\nroot       204     2  0  2018 ?        00:00:11 [ksoftirqd/32]\nroot       206     2  0  2018 ?        00:00:00 [kworker/32:0H]\nroot       207     2  0  2018 ?        00:00:00 [cpuhp/33]\nroot       208     2  0  2018 ?        00:00:14 [watchdog/33]\nroot       209     2  0  2018 ?        00:00:00 [migration/33]\nroot       210     2  0  2018 ?        00:00:01 [ksoftirqd/33]\nroot       212     2  0  2018 ?        00:00:00 [kworker/33:0H]\nroot       213     2  0  2018 ?        00:00:00 [cpuhp/34]\nroot       214     2  0  2018 ?        00:00:13 [watchdog/34]\nroot       215     2  0  2018 ?        00:00:00 [migration/34]\nroot       216     2  0  2018 ?        00:00:05 [ksoftirqd/34]\nroot       218     2  0  2018 ?        00:00:00 [kworker/34:0H]\nroot       219     2  0  2018 ?        00:00:00 [cpuhp/35]\nroot       220     2  0  2018 ?        00:00:14 [watchdog/35]\nroot       221     2  0  2018 ?        00:00:00 [migration/35]\nroot       222     2  0  2018 ?        00:00:01 [ksoftirqd/35]\nroot       224     2  0  2018 ?        00:00:00 [kworker/35:0H]\nroot       225     2  0  2018 ?        00:00:00 [cpuhp/36]\nroot       226     2  0  2018 ?        00:00:13 [watchdog/36]\nroot       227     2  0  2018 ?        00:00:00 [migration/36]\nroot       228     2  0  2018 ?        00:00:13 [ksoftirqd/36]\nroot       230     2  0  2018 ?        00:00:00 [kworker/36:0H]\nroot       231     2  0  2018 ?        00:00:00 [cpuhp/37]\nroot       232     2  0  2018 ?        00:00:14 [watchdog/37]\nroot       233     2  0  2018 ?        00:00:00 [migration/37]\nroot       234     2  0  2018 ?        00:00:01 [ksoftirqd/37]\nroot       236     2  0  2018 ?        00:00:00 [kworker/37:0H]\nroot       237     2  0  2018 ?        00:00:00 [cpuhp/38]\nroot       238     2  0  2018 ?        00:00:13 [watchdog/38]\nroot       239     2  0  2018 ?        00:00:00 [migration/38]\nroot       240     2  0  2018 ?        00:00:03 [ksoftirqd/38]\nroot       242     2  0  2018 ?        00:00:00 [kworker/38:0H]\nroot       243     2  0  2018 ?        00:00:00 [cpuhp/39]\nroot       244     2  0  2018 ?        00:00:14 [watchdog/39]\nroot       245     2  0  2018 ?        00:00:00 [migration/39]\nroot       246     2  0  2018 ?        00:00:02 [ksoftirqd/39]\nroot       248     2  0  2018 ?        00:00:00 [kworker/39:0H]\nroot       249     2  0  2018 ?        00:00:00 [cpuhp/40]\nroot       250     2  0  2018 ?        00:00:13 [watchdog/40]\nroot       251     2  0  2018 ?        00:00:00 [migration/40]\nroot       252     2  0  2018 ?        00:00:05 [ksoftirqd/40]\nroot       254     2  0  2018 ?        00:00:00 [kworker/40:0H]\nroot       255     2  0  2018 ?        00:00:00 [cpuhp/41]\nroot       256     2  0  2018 ?        00:00:13 [watchdog/41]\nroot       257     2  0  2018 ?        00:00:00 [migration/41]\nroot       258     2  0  2018 ?        00:00:02 [ksoftirqd/41]\nroot       260     2  0  2018 ?        00:00:00 [kworker/41:0H]\nroot       261     2  0  2018 ?        00:00:00 [cpuhp/42]\nroot       262     2  0  2018 ?        00:00:13 [watchdog/42]\nroot       263     2  0  2018 ?        00:00:00 [migration/42]\nroot       264     2  0  2018 ?        00:00:31 [ksoftirqd/42]\nroot       266     2  0  2018 ?        00:00:00 [kworker/42:0H]\nroot       267     2  0  2018 ?        00:00:00 [cpuhp/43]\nroot       268     2  0  2018 ?        00:00:13 [watchdog/43]\nroot       269     2  0  2018 ?        00:00:00 [migration/43]\nroot       270     2  0  2018 ?        00:00:02 [ksoftirqd/43]\nroot       272     2  0  2018 ?        00:00:00 [kworker/43:0H]\nroot       273     2  0  2018 ?        00:00:00 [cpuhp/44]\nroot       274     2  0  2018 ?        00:00:13 [watchdog/44]\nroot       275     2  0  2018 ?        00:00:00 [migration/44]\nroot       276     2  0  2018 ?        00:00:12 [ksoftirqd/44]\nroot       278     2  0  2018 ?        00:00:00 [kworker/44:0H]\nroot       279     2  0  2018 ?        00:00:00 [cpuhp/45]\nroot       280     2  0  2018 ?        00:00:14 [watchdog/45]\nroot       281     2  0  2018 ?        00:00:00 [migration/45]\nroot       282     2  0  2018 ?        00:00:02 [ksoftirqd/45]\nroot       284     2  0  2018 ?        00:00:00 [kworker/45:0H]\nroot       285     2  0  2018 ?        00:00:00 [cpuhp/46]\nroot       286     2  0  2018 ?        00:00:14 [watchdog/46]\nroot       287     2  0  2018 ?        00:00:00 [migration/46]\nroot       288     2  0  2018 ?        00:02:31 [ksoftirqd/46]\nroot       290     2  0  2018 ?        00:00:00 [kworker/46:0H]\nroot       291     2  0  2018 ?        00:00:00 [cpuhp/47]\nroot       292     2  0  2018 ?        00:00:13 [watchdog/47]\nroot       293     2  0  2018 ?        00:00:00 [migration/47]\nroot       294     2  0  2018 ?        00:00:02 [ksoftirqd/47]\nroot       296     2  0  2018 ?        00:00:00 [kworker/47:0H]\nroot       297     2  0  2018 ?        00:00:00 [kdevtmpfs]\nroot       298     2  0  2018 ?        00:00:00 [netns]\nroot       299     2  0  2018 ?        00:00:00 [rcu_tasks_kthre]\nroot       300     2  0  2018 ?        00:00:00 [kauditd]\nroot       305     2  0  2018 ?        00:00:15 [khungtaskd]\nroot       306     2  0  2018 ?        00:00:38 [oom_reaper]\nroot       307     2  0  2018 ?        00:00:00 [writeback]\nroot       308     2  0  2018 ?        00:00:00 [kcompactd0]\nroot       309     2  0  2018 ?        00:00:00 [kcompactd1]\nroot       310     2  0  2018 ?        09:13:53 [ksmd]\nroot       311     2  0  2018 ?        00:00:34 [khugepaged]\nroot       312     2  0  2018 ?        00:00:00 [crypto]\nroot       313     2  0  2018 ?        00:00:00 [kintegrityd]\nroot       314     2  0  2018 ?        00:00:00 [kblockd]\nroot       360     2  0  2018 ?        00:00:00 [ata_sff]\nroot       361     2  0  2018 ?        00:00:00 [md]\nroot       362     2  0  2018 ?        00:00:00 [edac-poller]\nroot       363     2  0  2018 ?        00:00:00 [devfreq_wq]\nroot       364     2  0  2018 ?        00:00:00 [watchdogd]\nroot       367     2  0  2018 ?        00:07:13 [kswapd0]\nroot       368     2  0  2018 ?        00:04:59 [kswapd1]\nroot       369     2  0  2018 ?        00:00:00 [ecryptfs-kthrea]\nroot       397     2  0 Jan06 ?        00:00:00 [kworker/39:0]\nroot       411     2  0  2018 ?        00:00:00 [kthrotld]\nroot       412     2  0  2018 ?        00:00:00 [acpi_thermal_pm]\nroot       416     2  0  2018 ?        00:00:00 [ipv6_addrconf]\nroot       425     2  0  2018 ?        00:00:00 [kstrp]\nroot       448     2  0  2018 ?        00:00:00 [charger_manager]\nroot       571     2  0  2018 ?        00:00:00 [scsi_eh_0]\nroot       572     2  0  2018 ?        00:00:00 [scsi_tmf_0]\nroot       573     2  0  2018 ?        00:00:00 [scsi_eh_1]\nroot       574     2  0  2018 ?        00:00:00 [scsi_tmf_1]\nroot       575     2  0  2018 ?        00:00:00 [scsi_eh_2]\nroot       576     2  0  2018 ?        00:00:00 [scsi_tmf_2]\nroot       577     2  0  2018 ?        00:00:00 [scsi_eh_3]\nroot       578     2  0  2018 ?        00:00:00 [scsi_tmf_3]\nroot       579     2  0  2018 ?        00:00:00 [scsi_eh_4]\nroot       580     2  0  2018 ?        00:00:00 [scsi_tmf_4]\nroot       581     2  0  2018 ?        00:00:00 [scsi_eh_5]\nroot       582     2  0  2018 ?        00:00:00 [scsi_tmf_5]\nroot       583     2  0  2018 ?        00:00:00 [scsi_eh_6]\nroot       584     2  0  2018 ?        00:00:00 [scsi_tmf_6]\nroot       592     2  0  2018 ?        00:00:00 [bnxt_pf_wq]\nroot       594     2  0  2018 ?        00:00:00 [scsi_eh_7]\nroot       595     2  0  2018 ?        00:00:00 [scsi_tmf_7]\nroot       596     2  0  2018 ?        00:00:00 [scsi_eh_8]\nroot       597     2  0  2018 ?        00:00:00 [scsi_tmf_8]\nroot       598     2  0  2018 ?        00:00:00 [scsi_eh_9]\nroot       600     2  0  2018 ?        00:00:00 [scsi_tmf_9]\nroot       601     2  0  2018 ?        00:00:00 [scsi_eh_10]\nroot       602     2  0  2018 ?        00:00:00 [scsi_tmf_10]\nroot       603     2  0  2018 ?        00:00:00 [scsi_eh_11]\nroot       604     2  0  2018 ?        00:00:00 [scsi_tmf_11]\nroot       605     2  0  2018 ?        00:00:00 [scsi_eh_12]\nroot       606     2  0  2018 ?        00:00:00 [scsi_tmf_12]\nroot       607     2  0  2018 ?        00:00:00 [scsi_eh_13]\nroot       608     2  0  2018 ?        00:00:00 [scsi_tmf_13]\nroot       609     2  0  2018 ?        00:00:00 [scsi_eh_14]\nroot       610     2  0  2018 ?        00:00:00 [scsi_tmf_14]\nroot       636     2  0  2018 ?        00:00:04 [kworker/34:1H]\nroot       638     2  0  2018 ?        00:00:12 [kworker/24:1H]\nroot       660     2  0  2018 ?        00:01:34 [kworker/30:1H]\nroot       668     2  0  2018 ?        00:00:00 [ttm_swap]\nroot       669     2  0  2018 ?        00:00:40 [kworker/44:1H]\nroot       671     2  0  2018 ?        00:00:02 [kworker/45:1H]\nroot       672     2  0  2018 ?        00:00:01 [kworker/21:1H]\nroot       674     2  0  2018 ?        00:00:02 [kworker/27:1H]\nroot       676     2  0  2018 ?        00:00:02 [kworker/37:1H]\nroot       689     2  0  2018 ?        00:00:02 [kworker/43:1H]\nroot       691     2  0  2018 ?        00:00:00 [nvidia-modeset]\nroot       757     2  0  2018 ?        00:00:00 [raid5wq]\nroot       790     2  0  2018 ?        00:00:04 [kworker/36:1H]\nroot       799     2  0  2018 ?        00:00:03 [kworker/41:1H]\nroot       803     2  0  2018 ?        00:00:03 [kworker/38:1H]\nroot       808     2  0  2018 ?        00:00:02 [kworker/47:1H]\nroot       809     2  0  2018 ?        00:03:52 [jbd2/sda2-8]\nroot       810     2  0  2018 ?        00:00:00 [ext4-rsv-conver]\nroot       812     2  0  2018 ?        00:00:03 [kworker/3:1H]\nroot       813     2  0  2018 ?        00:00:01 [kworker/17:1H]\nroot       828     2  0  2018 ?        00:00:02 [kworker/11:1H]\nroot       829     2  0  2018 ?        00:00:01 [kworker/29:1H]\nroot       834     2  0  2018 ?        00:00:05 [kworker/46:1H]\nroot       839     2  0  2018 ?        00:00:02 [kworker/19:1H]\nroot       843     2  0  2018 ?        00:00:02 [kworker/33:1H]\nroot       847     2  0  2018 ?        00:00:03 [kworker/12:1H]\nroot       849     2  0  2018 ?        00:00:02 [kworker/31:1H]\nroot       865     2  0  2018 ?        00:00:01 [kworker/23:1H]\nroot       866     2  0  2018 ?        00:00:02 [kworker/35:1H]\nroot       869     2  0  2018 ?        00:00:11 [kworker/0:1H]\nroot       870     2  0  2018 ?        00:00:02 [kworker/39:1H]\nroot       871     2  0  2018 ?        00:00:01 [kworker/15:1H]\nroot       875     2  0  2018 ?        00:00:07 [kworker/4:1H]\nroot       880     2  0  2018 ?        00:00:02 [kworker/5:1H]\nroot       882     2  0  2018 ?        00:00:12 [kworker/2:1H]\nroot       884     2  0  2018 ?        00:00:03 [kworker/1:1H]\nroot       885     2  0  2018 ?        00:00:01 [kworker/25:1H]\nroot       887     2  0  2018 ?        00:00:03 [kworker/8:1H]\nroot       892     2  0  2018 ?        00:00:04 [kworker/26:1H]\nroot       899     2  0  2018 ?        00:00:02 [kworker/9:1H]\nroot       904     2  0  2018 ?        00:00:13 [kworker/16:1H]\nroot       911     2  0  2018 ?        00:00:04 [kworker/20:1H]\nroot       912     2  0  2018 ?        00:00:05 [kworker/18:1H]\nroot       913     2  0  2018 ?        00:00:00 [iscsi_eh]\nroot       915     2  0  2018 ?        00:00:00 [ib-comp-wq]\nroot       916     2  0  2018 ?        00:00:00 [ib_mcast]\nroot       917     2  0  2018 ?        00:00:00 [ib_nl_sa_wq]\nroot       921     2  0  2018 ?        00:00:00 [rdma_cm]\nroot       924     2  0  2018 ?        00:00:00 [rpciod]\nroot       925     2  0  2018 ?        00:00:00 [xprtiod]\nroot       926     2  0  2018 ?        00:00:04 [kworker/6:1H]\nroot       934     1  0  2018 ?        00:00:00 /usr/sbin/blkmapd\nroot       935     1  0  2018 ?        00:00:00 /sbin/lvmetad -f\nroot       942     2  0  2018 ?        00:00:03 [kworker/14:1H]\nroot       958     2  0  2018 ?        00:00:03 [kworker/28:1H]\nroot       981     2  0 Jan06 ?        00:00:01 [kworker/16:2]\nroot      1053     2  0 Jan05 ?        00:00:01 [kworker/8:3]\nroot      1071     2  0  2018 ?        00:00:02 [kworker/13:1H]\nroot      1077     2  0  2018 ?        00:00:08 [kworker/32:1H]\nroot      1078     2  0  2018 ?        00:00:03 [kworker/40:1H]\nroot      1092     2  0  2018 ?        00:00:08 [kworker/42:1H]\nroot      1110     2  0  2018 ?        00:00:00 [UVM global queu]\nroot      1111     2  0  2018 ?        00:00:00 [UVM Tools Event]\nroot      1121     2  0  2018 ?        00:00:00 [irq/245-mei_me]\nroot      1123     2  0  2018 ?        00:00:03 [kworker/10:1H]\nroot      1241     2  0  2018 ?        00:00:04 [kworker/22:1H]\nroot      1435     1  0  2018 ?        00:00:12 /sbin/rpcbind -f -w\nroot      1440     1  0  2018 ?        00:00:00 /usr/sbin/rpc.idmapd\nroot      1489     1  0  2018 ?        00:00:10 /usr/sbin/rpc.mountd -p 892 --ma\nroot      1492     2  0  2018 ?        00:00:02 [kworker/7:1H]\nroot      1493     2  0  2018 ?        00:00:00 [lockd]\nroot      1495     2  0  2018 ?        00:00:00 [nfsd]\nroot      1496     2  0  2018 ?        00:00:00 [nfsd]\nroot      1497     2  0  2018 ?        00:00:01 [nfsd]\nroot      1498     2  0  2018 ?        00:00:00 [nfsd]\nroot      1499     2  0  2018 ?        00:00:01 [nfsd]\nroot      1500     2  0  2018 ?        00:00:01 [nfsd]\nroot      1501     2  0  2018 ?        00:00:43 [nfsd]\nroot      1502     2  0  2018 ?        00:03:31 [nfsd]\nroot      1595     1  0  2018 ?        00:02:21 /sbin/iscsid\nroot      1597     1  0  2018 ?        00:00:00 /sbin/iscsid\nroot      1602     1  0  2018 ?        00:01:00 /usr/sbin/cron -f\nroot      1618     1  0  2018 ?        00:00:00 /usr/bin/python3 /usr/bin/networ\nroot      1631     1  0  2018 ?        00:01:31 /usr/bin/lxcfs /var/lib/lxcfs/\nroot      1655     1  0  2018 ?        01:24:25 /usr/sbin/irqbalance --foregroun\nroot      1681     1  0  2018 ?        00:10:51 /usr/sbin/atopacctd\nsyslog    1694     1  0  2018 ?        00:12:22 /usr/sbin/rsyslogd -n\nmessage+  1701     1  0  2018 ?        00:03:31 /usr/bin/dbus-daemon --system --\nroot      1764     1  0  2018 ?        00:00:26 /lib/systemd/systemd-logind\ndaemon    1791     1  0  2018 ?        00:00:00 /usr/sbin/atd -f\nroot      1801     1  0  2018 ?        00:11:25 /usr/lib/accountsservice/account\nroot      1962     1  0  2018 tty1     00:00:00 /sbin/agetty -o -p -- \\u --nocle\nroot      1990     1  0  2018 ?        00:01:36 /usr/lib/policykit-1/polkitd --n\nroot      2248     2  0 Jan05 ?        00:00:00 [kworker/7:0]\nroot      2271     2  0 Jan06 ?        00:00:00 [kworker/0:9]\nlibvirt+  2385     1  0  2018 ?        00:00:17 /usr/sbin/dnsmasq --conf-file=/v\nroot      2386  2385  0  2018 ?        00:00:00 /usr/sbin/dnsmasq --conf-file=/v\nroot      2540     2  0 Jan06 ?        00:00:00 [kworker/37:1]\nroot      2711     2  0 Jan06 ?        00:00:01 [kworker/14:1]\nroot      3588     2  0 Jan05 ?        00:00:01 [kworker/40:7]\nroot      3605     2  0 Jan05 ?        00:00:00 [kworker/43:5]\nroot      3617     2  0 Jan05 ?        00:00:00 [kworker/43:6]\nroot      3951     2  0 02:56 ?        00:00:03 [kworker/41:2]\nzyu       4151 13303  0  2018 ?        00:03:40 /home/zyu/miniconda3/envs/gee/bi\nroot      4284     2  0 03:00 ?        00:00:00 [kworker/2:1]\nroot      4929     2  0 03:05 ?        00:00:03 [kworker/12:1]\nroot      5630     2  0  2018 ?        00:00:00 [loop3]\nroot      5772     1  0  2018 ?        00:06:50 /usr/lib/snapd/snapd\nroot      6034     2  0 03:16 ?        00:00:01 [kworker/41:1]\nroot      6188     2  0 03:17 ?        00:00:00 [kworker/28:1]\nroot      6750     2  0 03:23 ?        00:00:01 [kworker/13:1]\nroot      7284     2  0 03:29 ?        00:00:01 [kworker/13:2]\nroot      7597     2  0 03:32 ?        00:00:00 [kworker/14:2]\nroot      8108     2  0  2018 ?        00:00:00 [nfsiod]\nstatd     8160     1  0  2018 ?        00:00:00 /sbin/rpc.statd --no-notify --po\nroot      8270     2  0 03:40 ?        00:00:00 [kworker/12:2]\nroot      8580     2  0 03:43 ?        00:00:00 [kworker/19:1]\nroot      8659     2  0 Jan06 ?        00:00:00 [kworker/6:2]\nroot      8668     2  0 Jan06 ?        00:00:00 [kworker/9:1]\nroot      8677     2  0 Jan06 ?        00:00:00 [kworker/33:5]\nroot      8681     2  0 Jan06 ?        00:00:00 [kworker/33:6]\nroot      8694     2  0 03:45 ?        00:00:00 [kworker/9:0]\nroot      8720     2  0 Jan06 ?        00:00:00 [kworker/27:1]\nroot      8726     2  0 Jan06 ?        00:00:00 [kworker/42:1]\nroot      8736     2  0 Jan06 ?        00:00:00 [kworker/36:1]\nroot      8753     2  0 Jan06 ?        00:00:02 [kworker/0:3]\nroot      8763     2  0 Jan06 ?        00:00:01 [kworker/30:2]\nroot      8783     2  0 Jan06 ?        00:00:00 [kworker/25:0]\nroot      8785     2  0 Jan06 ?        00:00:00 [kworker/1:7]\nroot      8790     2  0 Jan06 ?        00:00:00 [kworker/1:8]\nroot      9092     2  0  2018 ?        00:00:00 [NFSv4 callback]\nroot     10810     2  0 Jan06 ?        00:00:00 [kworker/38:0]\nroot     11013     2  0 Jan06 ?        00:00:00 [kworker/42:0]\nroot     11592     2  0 Jan06 ?        00:00:00 [kworker/2:2]\nroot     11963     2  0 Jan02 ?        00:00:01 [kworker/35:1]\nroot     12251     2  0 Jan06 ?        00:00:00 [kworker/32:0]\nroot     12455     2  0 04:38 ?        00:00:00 [kworker/26:1]\nroot     12567     2  0 Jan06 ?        00:00:00 [kworker/34:0]\nzyu      13303     1  0  2018 ?        00:38:14 /home/zyu/miniconda3/envs/gee/bi\nroot     13908     1 10  2018 ?        2-14:24:33 qemu-system-x86_64 -enable-kvm\nroot     13921     2  0  2018 ?        00:01:09 [vhost-13908]\nroot     13923     2  0  2018 ?        00:00:02 [vhost-13908]\nroot     13928     2  0  2018 ?        00:00:00 [kvm-pit/13908]\nroot     14201     2  0 05:09 ?        00:00:00 [kworker/26:2]\nroot     14495     2  0 Jan01 ?        00:00:01 [kworker/7:1]\nroot     14767     2  0 Jan04 ?        00:00:00 [kworker/19:0]\nzyu      14867 13303  0  2018 ?        00:04:59 /home/zyu/miniconda3/envs/gee/bi\nroot     15033     2  0 Jan06 ?        00:00:00 [kworker/5:2]\nroot     15538     2  0 Jan05 ?        00:00:00 [kworker/15:2]\nroot     15676     2  0 Jan05 ?        00:00:02 [kworker/47:1]\nroot     16919     2  0 Jan03 ?        00:00:00 [kworker/17:2]\nroot     17500     1  9  2018 ?        1-15:48:50 qemu-system-x86_64 -enable-kvm\nroot     17512     2  0  2018 ?        00:00:54 [vhost-17500]\nroot     17519     2  0  2018 ?        00:00:00 [kvm-pit/17500]\nroot     17555     2  0 Jan03 ?        00:00:00 [kworker/31:3]\nroot     17556     2  0 Jan03 ?        00:00:00 [kworker/31:4]\nroot     17559     2  0 Jan03 ?        00:00:00 [kworker/27:2]\nroot     18118     2  0  2018 ?        00:00:00 [loop0]\nroot     18135     2  0 06:21 ?        00:00:00 [kworker/35:0]\nwww-data 18378 47081  0 06:25 ?        00:00:00 /usr/sbin/apache2 -k start\nwww-data 18379 47081  0 06:25 ?        00:00:00 /usr/sbin/apache2 -k start\nroot     18504     2  0 06:25 ?        00:00:00 [kworker/8:1]\nroot     18557     2  0 06:25 ?        00:00:00 [kworker/20:2]\nroot     18689     2  0 Jan06 ?        00:00:02 [kworker/5:1]\nroot     19521     2  0 06:40 ?        00:00:00 [kworker/38:1]\nroot     21446     2  0 Jan06 ?        00:00:00 [kworker/4:1]\nroot     21705     2  0  2018 ?        00:00:30 [kworker/24:2H]\nroot     22457     2  0 Jan05 ?        00:00:01 [kworker/10:1]\nroot     24100     2  0 08:02 ?        00:00:00 [kworker/22:2]\nroot     24432     2  0 Jan06 ?        00:00:00 [kworker/21:0]\nzyu      24831 13303  0  2018 ?        00:37:12 /home/zyu/miniconda3/envs/gee/bi\nroot     24934     1  0  2018 ?        00:00:00 /usr/sbin/virtlogd\nroot     25921     1  0  2018 ?        00:00:17 /lib/systemd/systemd-udevd\nroot     26624     2  0 08:52 ?        00:00:00 [kworker/24:2]\nroot     26681     2  0 08:54 ?        00:00:00 [kworker/30:0]\nroot     28094     2  0 Jan04 ?        00:00:00 [kworker/45:1]\nroot     28095     2  0 Jan04 ?        00:00:00 [kworker/45:3]\nroot     28096     2  0 Jan04 ?        00:00:00 [kworker/21:2]\nroot     28462     2  0 Jan04 ?        00:00:00 [kworker/23:2]\nroot     28722     2  0  2018 ?        00:00:00 [loop2]\nroot     28909     2  0  2018 ?        00:00:01 [kworker/u96:1]\nroot     29598     1  9  2018 ?        2-11:45:18 qemu-system-x86_64 -enable-kvm\nroot     29609     2  0  2018 ?        00:01:04 [vhost-29598]\nroot     29613     2  0  2018 ?        00:00:00 [kvm-pit/29598]\nroot     29630     2  0 Jan06 ?        00:00:00 [kworker/3:0]\nroot     29651     2  0 09:53 ?        00:00:00 [kworker/10:0]\nroot     29798     1 99  2018 ?        26-17:23:08 qemu-system-x86_64 -enable-kv\nroot     29808     2  0  2018 ?        00:00:00 [vhost-29798]\nroot     29812     2  0  2018 ?        00:15:16 [kvm-pit/29798]\nroot     30015     2  0  2018 ?        00:00:00 [kworker/u96:0]\nroot     30224 41673  0  2018 ?        00:00:00 /usr/bin/docker-proxy -proto tcp\nroot     30232 40529  0  2018 ?        00:00:56 containerd-shim -namespace moby \n999      30258 30232  0  2018 ?        00:10:29 mysqld\nroot     30361 41673  0  2018 ?        00:01:08 /usr/bin/docker-proxy -proto tcp\nroot     30376 40529  0  2018 ?        00:00:55 containerd-shim -namespace moby \nroot     30436 30376  0  2018 ?        00:46:09 /docker-java-home/jre/bin/java -\nroot     31368     2  0 Jan01 ?        00:00:01 [kworker/29:2]\nroot     31370     2  0  2018 ?        00:00:00 [kworker/11:4]\nroot     31421     2  0 Jan06 ?        00:00:00 [kworker/17:1]\nroot     31643     2  0 Jan04 ?        00:00:00 [kworker/39:2]\nroot     32665     2  0 Jan06 ?        00:00:00 [kworker/47:0]\nsystemd+ 34406     1  0  2018 ?        00:00:47 /lib/systemd/systemd-networkd\nsystemd+ 34435     1  0  2018 ?        00:04:07 /lib/systemd/systemd-resolved\nroot     34453     2  0 Jan04 ?        00:00:00 [kworker/15:0]\nsystemd+ 34504     1  0  2018 ?        00:00:15 /lib/systemd/systemd-timesyncd\nroot     34526     1  0  2018 ?        00:30:35 /lib/systemd/systemd-journald\nroot     35831     2  0 Jan06 ?        00:00:00 [kworker/25:1]\nroot     35930     2  0 Jan06 ?        00:00:00 [kworker/36:2]\nroot     35953     2  0 00:00 ?        00:00:00 [kworker/34:2]\nroot     35960     1  0 00:00 ?        00:00:47 /usr/bin/atop -R -w /var/log/ato\nroot     35997     2  0 Jan06 ?        00:00:01 [kworker/37:2]\nroot     36486     2  0 00:05 ?        00:00:00 [kworker/46:1]\nroot     36669     2  0 Jan04 ?        00:00:00 [kworker/23:0]\nroot     36744     2  0 Jan06 ?        00:00:00 [kworker/29:1]\nroot     36754     2  0 Jan06 ?        00:00:00 [kworker/4:0]\nroot     37635     1  0  2018 ?        01:22:09 /usr/sbin/libvirtd\nroot     37731     1  9  2018 ?        1-23:31:55 qemu-system-x86_64 -enable-kvm\nroot     37742     2  0  2018 ?        00:00:50 [vhost-37731]\nroot     37746     2  0  2018 ?        00:00:00 [kvm-pit/37731]\nroot     37755     2  0 12:27 ?        00:00:00 [kworker/20:0]\nroot     37906     1  0  2018 ?        00:00:00 /bin/sh -ec      export ACP=`ls \nroot     37919 37906  0  2018 ?        01:07:55 /usr/bin/java -Djava.io.tmpdir=/\nzyu      39770 13303  0  2018 ?        00:04:26 /home/zyu/miniconda3/envs/gee/bi\nroot     40336     2  0 13:17 ?        00:00:00 [kworker/22:0]\nroot     40529     1  0  2018 ?        06:44:46 /usr/bin/containerd\nroot     40670     2  0 Jan06 ?        00:00:00 [kworker/28:0]\nroot     41016     2  0 Jan06 ?        00:00:00 [kworker/40:1]\nzyu      41436     1  0  2018 ?        00:00:03 /lib/systemd/systemd --user\nzyu      41438 41436  0  2018 ?        00:00:00 (sd-pam)\nroot     41673     1  0  2018 ?        01:03:23 /usr/bin/dockerd -H unix://\nroot     43088     2  0 01:11 ?        00:00:00 [kworker/46:0]\nroot     43468     2  0 14:18 ?        00:00:00 [kworker/44:1]\nroot     44747     2  0 14:44 ?        00:00:00 [kworker/u98:2]\nroot     45262     1  0  2018 ?        00:05:49 /usr/sbin/sshd -D\nroot     45379     2  0 Jan06 ?        00:00:00 [kworker/32:2]\nroot     45698     2  0 15:01 ?        00:00:00 [kworker/18:2]\nroot     45712     2  0 Jan04 ?        00:00:00 [kworker/3:1]\nroot     45803     2  0 Jan03 ?        00:00:01 [kworker/11:0]\nroot     46270     2  0 15:10 ?        00:00:00 [kworker/u97:0]\nroot     46331     2  0 Jan06 ?        00:00:01 [kworker/6:1]\nroot     46370     2  0 15:12 ?        00:00:00 [kworker/44:0]\nroot     46375     2  0 15:12 ?        00:00:00 [kworker/u98:0]\nroot     46819     2  0 15:20 ?        00:00:00 [kworker/24:0]\nroot     46823     2  0 15:20 ?        00:00:00 [kworker/u97:2]\nroot     46883 45262  0 15:21 ?        00:00:00 sshd: zsun [priv]\nzsun     46885     1  0 15:21 ?        00:00:00 /lib/systemd/systemd --user\nzsun     46886 46885  0 15:21 ?        00:00:00 (sd-pam)\nzsun     47002 46883  0 15:21 ?        00:00:00 sshd: zsun@pts/6\nroot     47052 45262  0 15:22 ?        00:00:00 sshd: zsun [priv]\nroot     47081     1  0  2018 ?        00:00:48 /usr/sbin/apache2 -k start\nzsun     47138 47052  0 15:22 ?        00:00:00 sshd: zsun@pts/7\nroot     47240     2  0 15:24 ?        00:00:00 [kworker/18:1]\nroot     47513     2  0 Jan06 ?        00:00:00 [kworker/16:1]\nroot     47657     2  0 15:32 ?        00:00:00 [kworker/u98:1]\nroot     47756     2  0 15:34 ?        00:00:00 [kworker/24:1]\nroot     47757     2  0 15:34 ?        00:00:00 [kworker/u97:1]\nroot     48016 45262  0 15:36 ?        00:00:00 sshd: root [priv]\nsshd     48017 48016  0 15:36 ?        00:00:00 sshd: root [net]\nroot     48118 45262  2 15:36 ?        00:00:00 sshd: zsun [priv]\nroot     48142     2  0 15:36 ?        00:00:00 [kworker/0:0]\nzsun     48227 48118  0 15:36 ?        00:00:00 sshd: zsun@pts/8\nzsun     48228 48227  0 15:36 pts/8    00:00:00 bash -c echo "#!/bin/bash #write\nzsun     48230 48228  0 15:36 pts/8    00:00:00 /bin/bash ./geoweaver-6k6g0bijgn\nzsun     48231 48230  0 15:36 pts/8    00:00:00 ps -ef\n/home/zsun\n', 'kps1gf', 'Done'),
	('y1wzkdrgep6g', 'ac4724', '2019-01-07 10:36:38', '2019-01-07 10:36:53', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('rhekxu4r2fy', '7w0ga6df6x6xhex588pk', '2019-01-07 10:36:35', '2019-01-07 10:36:53', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'r111uuc0v4rj;h3yxbeaeo8f7;y1wzkdrgep6g;', 'kps1gf;', 'Done'),
	('w6xl7t941xy', '7sb7xj', '2019-01-07 15:15:38', '2019-01-07 15:15:40', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', '564v42o2', 'kps1gf', 'Done'),
	('4xd1gcikxj4', '7sb7xj', '2019-01-08 09:41:18', '2019-01-08 09:41:20', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'ni6xwe2e', 'kps1gf', 'Done'),
	('qjuk56z1n1e', '7sb7xj', '2019-01-08 09:41:54', '2019-01-08 09:41:55', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', '4whyloi8', 'kps1gf', 'Done'),
	('vnfo1fvk24k0', '199vsg', '2019-01-08 09:42:04', '2019-01-08 09:42:04', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('60v8zp061ieo', 'o634zj', '2019-01-08 09:42:05', '2019-01-08 09:42:05', '#!/bin/bash\n#write your bash script\necho "TestProcess 1"\nps -ef\npwd', 'TestProcess 1\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0  2018 ?        00:05:37 /lib/systemd/systemd --system --\nroot         2     0  0  2018 ?        00:00:13 [kthreadd]\nroot         4     2  0  2018 ?        00:00:00 [kworker/0:0H]\nroot         7     2  0  2018 ?        00:00:00 [mm_percpu_wq]\nroot         8     2  0  2018 ?        00:00:31 [ksoftirqd/0]\nroot         9     2  0  2018 ?        01:58:02 [rcu_sched]\nroot        10     2  0  2018 ?        00:00:00 [rcu_bh]\nroot        11     2  0  2018 ?        00:00:13 [migration/0]\nroot        12     2  0  2018 ?        00:00:17 [watchdog/0]\nroot        13     2  0  2018 ?        00:00:00 [cpuhp/0]\nroot        14     2  0  2018 ?        00:00:00 [cpuhp/1]\nroot        15     2  0  2018 ?        00:00:23 [watchdog/1]\nroot        16     2  0  2018 ?        00:00:18 [migration/1]\nroot        17     2  0  2018 ?        00:00:07 [ksoftirqd/1]\nroot        19     2  0  2018 ?        00:00:00 [kworker/1:0H]\nroot        21     2  0  2018 ?        00:00:00 [cpuhp/2]\nroot        22     2  0  2018 ?        00:00:17 [watchdog/2]\nroot        23     2  0  2018 ?        00:00:04 [migration/2]\nroot        24     2  0  2018 ?        00:00:07 [ksoftirqd/2]\nroot        26     2  0  2018 ?        00:00:00 [kworker/2:0H]\nroot        27     2  0  2018 ?        00:00:00 [cpuhp/3]\nroot        28     2  0  2018 ?        00:00:18 [watchdog/3]\nroot        29     2  0  2018 ?        00:00:04 [migration/3]\nroot        30     2  0  2018 ?        00:00:04 [ksoftirqd/3]\nroot        32     2  0  2018 ?        00:00:00 [kworker/3:0H]\nroot        33     2  0  2018 ?        00:00:00 [cpuhp/4]\nroot        34     2  0  2018 ?        00:00:16 [watchdog/4]\nroot        35     2  0  2018 ?        00:00:02 [migration/4]\nroot        36     2  0  2018 ?        00:00:08 [ksoftirqd/4]\nroot        38     2  0  2018 ?        00:00:00 [kworker/4:0H]\nroot        39     2  0  2018 ?        00:00:00 [cpuhp/5]\nroot        40     2  0  2018 ?        00:00:17 [watchdog/5]\nroot        41     2  0  2018 ?        00:00:02 [migration/5]\nroot        42     2  0  2018 ?        00:00:03 [ksoftirqd/5]\nroot        44     2  0  2018 ?        00:00:00 [kworker/5:0H]\nroot        45     2  0  2018 ?        00:00:00 [cpuhp/6]\nroot        46     2  0  2018 ?        00:00:16 [watchdog/6]\nroot        47     2  0  2018 ?        00:00:01 [migration/6]\nroot        48     2  0  2018 ?        00:00:04 [ksoftirqd/6]\nroot        50     2  0  2018 ?        00:00:00 [kworker/6:0H]\nroot        51     2  0  2018 ?        00:00:00 [cpuhp/7]\nroot        52     2  0  2018 ?        00:00:16 [watchdog/7]\nroot        53     2  0  2018 ?        00:00:01 [migration/7]\nroot        54     2  0  2018 ?        00:00:02 [ksoftirqd/7]\nroot        56     2  0  2018 ?        00:00:00 [kworker/7:0H]\nroot        57     2  0  2018 ?        00:00:00 [cpuhp/8]\nroot        58     2  0  2018 ?        00:00:15 [watchdog/8]\nroot        59     2  0  2018 ?        00:00:01 [migration/8]\nroot        60     2  0  2018 ?        00:00:03 [ksoftirqd/8]\nroot        62     2  0  2018 ?        00:00:00 [kworker/8:0H]\nroot        63     2  0  2018 ?        00:00:00 [cpuhp/9]\nroot        64     2  0  2018 ?        00:00:16 [watchdog/9]\nroot        65     2  0  2018 ?        00:00:01 [migration/9]\nroot        66     2  0  2018 ?        00:00:02 [ksoftirqd/9]\nroot        68     2  0  2018 ?        00:00:00 [kworker/9:0H]\nroot        69     2  0  2018 ?        00:00:00 [cpuhp/10]\nroot        70     2  0  2018 ?        00:00:15 [watchdog/10]\nroot        71     2  0  2018 ?        00:00:01 [migration/10]\nroot        72     2  0  2018 ?        00:00:03 [ksoftirqd/10]\nroot        74     2  0  2018 ?        00:00:00 [kworker/10:0H]\nroot        75     2  0  2018 ?        00:00:00 [cpuhp/11]\nroot        76     2  0  2018 ?        00:00:16 [watchdog/11]\nroot        77     2  0  2018 ?        00:00:01 [migration/11]\nroot        78     2  0  2018 ?        00:00:01 [ksoftirqd/11]\nroot        80     2  0  2018 ?        00:00:00 [kworker/11:0H]\nroot        81     2  0  2018 ?        00:00:00 [cpuhp/12]\nroot        82     2  0  2018 ?        00:00:14 [watchdog/12]\nroot        83     2  0  2018 ?        00:00:01 [migration/12]\nroot        84     2  0  2018 ?        00:00:02 [ksoftirqd/12]\nroot        86     2  0  2018 ?        00:00:00 [kworker/12:0H]\nroot        87     2  0  2018 ?        00:00:00 [cpuhp/13]\nroot        88     2  0  2018 ?        00:00:14 [watchdog/13]\nroot        89     2  0  2018 ?        00:00:01 [migration/13]\nroot        90     2  0  2018 ?        00:00:02 [ksoftirqd/13]\nroot        92     2  0  2018 ?        00:00:00 [kworker/13:0H]\nroot        93     2  0  2018 ?        00:00:00 [cpuhp/14]\nroot        94     2  0  2018 ?        00:00:15 [watchdog/14]\nroot        95     2  0  2018 ?        00:00:01 [migration/14]\nroot        96     2  0  2018 ?        00:00:03 [ksoftirqd/14]\nroot        98     2  0  2018 ?        00:00:00 [kworker/14:0H]\nroot        99     2  0  2018 ?        00:00:00 [cpuhp/15]\nroot       100     2  0  2018 ?        00:00:16 [watchdog/15]\nroot       101     2  0  2018 ?        00:00:00 [migration/15]\nroot       102     2  0  2018 ?        00:00:02 [ksoftirqd/15]\nroot       104     2  0  2018 ?        00:00:00 [kworker/15:0H]\nroot       105     2  0  2018 ?        00:00:00 [cpuhp/16]\nroot       106     2  0  2018 ?        00:00:15 [watchdog/16]\nroot       107     2  0  2018 ?        00:00:01 [migration/16]\nroot       108     2  0  2018 ?        00:00:21 [ksoftirqd/16]\nroot       110     2  0  2018 ?        00:00:00 [kworker/16:0H]\nroot       111     2  0  2018 ?        00:00:00 [cpuhp/17]\nroot       112     2  0  2018 ?        00:00:16 [watchdog/17]\nroot       113     2  0  2018 ?        00:00:00 [migration/17]\nroot       114     2  0  2018 ?        00:00:02 [ksoftirqd/17]\nroot       116     2  0  2018 ?        00:00:00 [kworker/17:0H]\nroot       117     2  0  2018 ?        00:00:00 [cpuhp/18]\nroot       118     2  0  2018 ?        00:00:15 [watchdog/18]\nroot       119     2  0  2018 ?        00:00:01 [migration/18]\nroot       120     2  0  2018 ?        00:03:49 [ksoftirqd/18]\nroot       122     2  0  2018 ?        00:00:00 [kworker/18:0H]\nroot       123     2  0  2018 ?        00:00:00 [cpuhp/19]\nroot       124     2  0  2018 ?        00:00:16 [watchdog/19]\nroot       125     2  0  2018 ?        00:00:00 [migration/19]\nroot       126     2  0  2018 ?        00:00:02 [ksoftirqd/19]\nroot       128     2  0  2018 ?        00:00:00 [kworker/19:0H]\nroot       129     2  0  2018 ?        00:00:00 [cpuhp/20]\nroot       130     2  0  2018 ?        00:00:14 [watchdog/20]\nroot       131     2  0  2018 ?        00:00:01 [migration/20]\nroot       132     2  0  2018 ?        00:00:03 [ksoftirqd/20]\nroot       134     2  0  2018 ?        00:00:00 [kworker/20:0H]\nroot       135     2  0  2018 ?        00:00:00 [cpuhp/21]\nroot       136     2  0  2018 ?        00:00:16 [watchdog/21]\nroot       137     2  0  2018 ?        00:00:00 [migration/21]\nroot       138     2  0  2018 ?        00:00:01 [ksoftirqd/21]\nroot       140     2  0  2018 ?        00:00:00 [kworker/21:0H]\nroot       141     2  0  2018 ?        00:00:00 [cpuhp/22]\nroot       142     2  0  2018 ?        00:00:13 [watchdog/22]\nroot       143     2  0  2018 ?        00:00:01 [migration/22]\nroot       144     2  0  2018 ?        00:00:07 [ksoftirqd/22]\nroot       146     2  0  2018 ?        00:00:00 [kworker/22:0H]\nroot       147     2  0  2018 ?        00:00:00 [cpuhp/23]\nroot       148     2  0  2018 ?        00:00:15 [watchdog/23]\nroot       149     2  0  2018 ?        00:00:00 [migration/23]\nroot       150     2  0  2018 ?        00:00:01 [ksoftirqd/23]\nroot       152     2  0  2018 ?        00:00:00 [kworker/23:0H]\nroot       153     2  0  2018 ?        00:00:00 [cpuhp/24]\nroot       154     2  0  2018 ?        00:00:13 [watchdog/24]\nroot       155     2  0  2018 ?        00:00:01 [migration/24]\nroot       156     2  0  2018 ?        00:00:25 [ksoftirqd/24]\nroot       159     2  0  2018 ?        00:00:00 [cpuhp/25]\nroot       160     2  0  2018 ?        00:00:12 [watchdog/25]\nroot       161     2  0  2018 ?        00:00:01 [migration/25]\nroot       162     2  0  2018 ?        00:00:01 [ksoftirqd/25]\nroot       164     2  0  2018 ?        00:00:00 [kworker/25:0H]\nroot       165     2  0  2018 ?        00:00:00 [cpuhp/26]\nroot       166     2  0  2018 ?        00:00:13 [watchdog/26]\nroot       167     2  0  2018 ?        00:00:01 [migration/26]\nroot       168     2  0  2018 ?        00:02:51 [ksoftirqd/26]\nroot       170     2  0  2018 ?        00:00:00 [kworker/26:0H]\nroot       171     2  0  2018 ?        00:00:00 [cpuhp/27]\nroot       172     2  0  2018 ?        00:00:14 [watchdog/27]\nroot       173     2  0  2018 ?        00:00:00 [migration/27]\nroot       174     2  0  2018 ?        00:00:01 [ksoftirqd/27]\nroot       176     2  0  2018 ?        00:00:00 [kworker/27:0H]\nroot       177     2  0  2018 ?        00:00:00 [cpuhp/28]\nroot       178     2  0  2018 ?        00:00:13 [watchdog/28]\nroot       179     2  0  2018 ?        00:00:00 [migration/28]\nroot       180     2  0  2018 ?        00:00:03 [ksoftirqd/28]\nroot       182     2  0  2018 ?        00:00:00 [kworker/28:0H]\nroot       183     2  0  2018 ?        00:00:00 [cpuhp/29]\nroot       184     2  0  2018 ?        00:00:13 [watchdog/29]\nroot       185     2  0  2018 ?        00:00:00 [migration/29]\nroot       186     2  0  2018 ?        00:00:02 [ksoftirqd/29]\nroot       188     2  0  2018 ?        00:00:00 [kworker/29:0H]\nroot       189     2  0  2018 ?        00:00:00 [cpuhp/30]\nroot       190     2  0  2018 ?        00:00:13 [watchdog/30]\nroot       191     2  0  2018 ?        00:00:00 [migration/30]\nroot       192     2  0  2018 ?        00:00:04 [ksoftirqd/30]\nroot       194     2  0  2018 ?        00:00:00 [kworker/30:0H]\nroot       195     2  0  2018 ?        00:00:00 [cpuhp/31]\nroot       196     2  0  2018 ?        00:00:14 [watchdog/31]\nroot       197     2  0  2018 ?        00:00:00 [migration/31]\nroot       198     2  0  2018 ?        00:00:01 [ksoftirqd/31]\nroot       200     2  0  2018 ?        00:00:00 [kworker/31:0H]\nroot       201     2  0  2018 ?        00:00:00 [cpuhp/32]\nroot       202     2  0  2018 ?        00:00:12 [watchdog/32]\nroot       203     2  0  2018 ?        00:00:00 [migration/32]\nroot       204     2  0  2018 ?        00:00:11 [ksoftirqd/32]\nroot       206     2  0  2018 ?        00:00:00 [kworker/32:0H]\nroot       207     2  0  2018 ?        00:00:00 [cpuhp/33]\nroot       208     2  0  2018 ?        00:00:14 [watchdog/33]\nroot       209     2  0  2018 ?        00:00:00 [migration/33]\nroot       210     2  0  2018 ?        00:00:01 [ksoftirqd/33]\nroot       212     2  0  2018 ?        00:00:00 [kworker/33:0H]\nroot       213     2  0  2018 ?        00:00:00 [cpuhp/34]\nroot       214     2  0  2018 ?        00:00:14 [watchdog/34]\nroot       215     2  0  2018 ?        00:00:00 [migration/34]\nroot       216     2  0  2018 ?        00:00:05 [ksoftirqd/34]\nroot       218     2  0  2018 ?        00:00:00 [kworker/34:0H]\nroot       219     2  0  2018 ?        00:00:00 [cpuhp/35]\nroot       220     2  0  2018 ?        00:00:14 [watchdog/35]\nroot       221     2  0  2018 ?        00:00:00 [migration/35]\nroot       222     2  0  2018 ?        00:00:01 [ksoftirqd/35]\nroot       224     2  0  2018 ?        00:00:00 [kworker/35:0H]\nroot       225     2  0  2018 ?        00:00:00 [cpuhp/36]\nroot       226     2  0  2018 ?        00:00:14 [watchdog/36]\nroot       227     2  0  2018 ?        00:00:00 [migration/36]\nroot       228     2  0  2018 ?        00:00:13 [ksoftirqd/36]\nroot       230     2  0  2018 ?        00:00:00 [kworker/36:0H]\nroot       231     2  0  2018 ?        00:00:00 [cpuhp/37]\nroot       232     2  0  2018 ?        00:00:15 [watchdog/37]\nroot       233     2  0  2018 ?        00:00:00 [migration/37]\nroot       234     2  0  2018 ?        00:00:02 [ksoftirqd/37]\nroot       236     2  0  2018 ?        00:00:00 [kworker/37:0H]\nroot       237     2  0  2018 ?        00:00:00 [cpuhp/38]\nroot       238     2  0  2018 ?        00:00:13 [watchdog/38]\nroot       239     2  0  2018 ?        00:00:00 [migration/38]\nroot       240     2  0  2018 ?        00:00:03 [ksoftirqd/38]\nroot       242     2  0  2018 ?        00:00:00 [kworker/38:0H]\nroot       243     2  0  2018 ?        00:00:00 [cpuhp/39]\nroot       244     2  0  2018 ?        00:00:14 [watchdog/39]\nroot       245     2  0  2018 ?        00:00:00 [migration/39]\nroot       246     2  0  2018 ?        00:00:02 [ksoftirqd/39]\nroot       248     2  0  2018 ?        00:00:00 [kworker/39:0H]\nroot       249     2  0  2018 ?        00:00:00 [cpuhp/40]\nroot       250     2  0  2018 ?        00:00:13 [watchdog/40]\nroot       251     2  0  2018 ?        00:00:00 [migration/40]\nroot       252     2  0  2018 ?        00:00:05 [ksoftirqd/40]\nroot       254     2  0  2018 ?        00:00:00 [kworker/40:0H]\nroot       255     2  0  2018 ?        00:00:00 [cpuhp/41]\nroot       256     2  0  2018 ?        00:00:13 [watchdog/41]\nroot       257     2  0  2018 ?        00:00:00 [migration/41]\nroot       258     2  0  2018 ?        00:00:02 [ksoftirqd/41]\nroot       260     2  0  2018 ?        00:00:00 [kworker/41:0H]\nroot       261     2  0  2018 ?        00:00:00 [cpuhp/42]\nroot       262     2  0  2018 ?        00:00:13 [watchdog/42]\nroot       263     2  0  2018 ?        00:00:00 [migration/42]\nroot       264     2  0  2018 ?        00:00:33 [ksoftirqd/42]\nroot       266     2  0  2018 ?        00:00:00 [kworker/42:0H]\nroot       267     2  0  2018 ?        00:00:00 [cpuhp/43]\nroot       268     2  0  2018 ?        00:00:13 [watchdog/43]\nroot       269     2  0  2018 ?        00:00:00 [migration/43]\nroot       270     2  0  2018 ?        00:00:02 [ksoftirqd/43]\nroot       272     2  0  2018 ?        00:00:00 [kworker/43:0H]\nroot       273     2  0  2018 ?        00:00:00 [cpuhp/44]\nroot       274     2  0  2018 ?        00:00:13 [watchdog/44]\nroot       275     2  0  2018 ?        00:00:00 [migration/44]\nroot       276     2  0  2018 ?        00:00:12 [ksoftirqd/44]\nroot       278     2  0  2018 ?        00:00:00 [kworker/44:0H]\nroot       279     2  0  2018 ?        00:00:00 [cpuhp/45]\nroot       280     2  0  2018 ?        00:00:14 [watchdog/45]\nroot       281     2  0  2018 ?        00:00:00 [migration/45]\nroot       282     2  0  2018 ?        00:00:02 [ksoftirqd/45]\nroot       284     2  0  2018 ?        00:00:00 [kworker/45:0H]\nroot       285     2  0  2018 ?        00:00:00 [cpuhp/46]\nroot       286     2  0  2018 ?        00:00:14 [watchdog/46]\nroot       287     2  0  2018 ?        00:00:00 [migration/46]\nroot       288     2  0  2018 ?        00:02:34 [ksoftirqd/46]\nroot       290     2  0  2018 ?        00:00:00 [kworker/46:0H]\nroot       291     2  0  2018 ?        00:00:00 [cpuhp/47]\nroot       292     2  0  2018 ?        00:00:14 [watchdog/47]\nroot       293     2  0  2018 ?        00:00:00 [migration/47]\nroot       294     2  0  2018 ?        00:00:02 [ksoftirqd/47]\nroot       296     2  0  2018 ?        00:00:00 [kworker/47:0H]\nroot       297     2  0  2018 ?        00:00:00 [kdevtmpfs]\nroot       298     2  0  2018 ?        00:00:00 [netns]\nroot       299     2  0  2018 ?        00:00:00 [rcu_tasks_kthre]\nroot       300     2  0  2018 ?        00:00:00 [kauditd]\nroot       305     2  0  2018 ?        00:00:16 [khungtaskd]\nroot       306     2  0  2018 ?        00:00:38 [oom_reaper]\nroot       307     2  0  2018 ?        00:00:00 [writeback]\nroot       308     2  0  2018 ?        00:00:00 [kcompactd0]\nroot       309     2  0  2018 ?        00:00:00 [kcompactd1]\nroot       310     2  0  2018 ?        09:25:26 [ksmd]\nroot       311     2  0  2018 ?        00:00:37 [khugepaged]\nroot       312     2  0  2018 ?        00:00:00 [crypto]\nroot       313     2  0  2018 ?        00:00:00 [kintegrityd]\nroot       314     2  0  2018 ?        00:00:00 [kblockd]\nroot       360     2  0  2018 ?        00:00:00 [ata_sff]\nroot       361     2  0  2018 ?        00:00:00 [md]\nroot       362     2  0  2018 ?        00:00:00 [edac-poller]\nroot       363     2  0  2018 ?        00:00:00 [devfreq_wq]\nroot       364     2  0  2018 ?        00:00:00 [watchdogd]\nroot       367     2  0  2018 ?        00:07:21 [kswapd0]\nroot       368     2  0  2018 ?        00:05:04 [kswapd1]\nroot       369     2  0  2018 ?        00:00:00 [ecryptfs-kthrea]\nroot       397     2  0 Jan06 ?        00:00:00 [kworker/39:0]\nroot       411     2  0  2018 ?        00:00:00 [kthrotld]\nroot       412     2  0  2018 ?        00:00:00 [acpi_thermal_pm]\nroot       416     2  0  2018 ?        00:00:00 [ipv6_addrconf]\nroot       425     2  0  2018 ?        00:00:00 [kstrp]\nroot       448     2  0  2018 ?        00:00:00 [charger_manager]\nroot       571     2  0  2018 ?        00:00:00 [scsi_eh_0]\nroot       572     2  0  2018 ?        00:00:00 [scsi_tmf_0]\nroot       573     2  0  2018 ?        00:00:00 [scsi_eh_1]\nroot       574     2  0  2018 ?        00:00:00 [scsi_tmf_1]\nroot       575     2  0  2018 ?        00:00:00 [scsi_eh_2]\nroot       576     2  0  2018 ?        00:00:00 [scsi_tmf_2]\nroot       577     2  0  2018 ?        00:00:00 [scsi_eh_3]\nroot       578     2  0  2018 ?        00:00:00 [scsi_tmf_3]\nroot       579     2  0  2018 ?        00:00:00 [scsi_eh_4]\nroot       580     2  0  2018 ?        00:00:00 [scsi_tmf_4]\nroot       581     2  0  2018 ?        00:00:00 [scsi_eh_5]\nroot       582     2  0  2018 ?        00:00:00 [scsi_tmf_5]\nroot       583     2  0  2018 ?        00:00:00 [scsi_eh_6]\nroot       584     2  0  2018 ?        00:00:00 [scsi_tmf_6]\nroot       592     2  0  2018 ?        00:00:00 [bnxt_pf_wq]\nroot       594     2  0  2018 ?        00:00:00 [scsi_eh_7]\nroot       595     2  0  2018 ?        00:00:00 [scsi_tmf_7]\nroot       596     2  0  2018 ?        00:00:00 [scsi_eh_8]\nroot       597     2  0  2018 ?        00:00:00 [scsi_tmf_8]\nroot       598     2  0  2018 ?        00:00:00 [scsi_eh_9]\nroot       600     2  0  2018 ?        00:00:00 [scsi_tmf_9]\nroot       601     2  0  2018 ?        00:00:00 [scsi_eh_10]\nroot       602     2  0  2018 ?        00:00:00 [scsi_tmf_10]\nroot       603     2  0  2018 ?        00:00:00 [scsi_eh_11]\nroot       604     2  0  2018 ?        00:00:00 [scsi_tmf_11]\nroot       605     2  0  2018 ?        00:00:00 [scsi_eh_12]\nroot       606     2  0  2018 ?        00:00:00 [scsi_tmf_12]\nroot       607     2  0  2018 ?        00:00:00 [scsi_eh_13]\nroot       608     2  0  2018 ?        00:00:00 [scsi_tmf_13]\nroot       609     2  0  2018 ?        00:00:00 [scsi_eh_14]\nroot       610     2  0  2018 ?        00:00:00 [scsi_tmf_14]\nroot       636     2  0  2018 ?        00:00:04 [kworker/34:1H]\nroot       638     2  0  2018 ?        00:00:12 [kworker/24:1H]\nroot       660     2  0  2018 ?        00:01:35 [kworker/30:1H]\nroot       668     2  0  2018 ?        00:00:00 [ttm_swap]\nroot       669     2  0  2018 ?        00:00:40 [kworker/44:1H]\nroot       671     2  0  2018 ?        00:00:02 [kworker/45:1H]\nroot       672     2  0  2018 ?        00:00:01 [kworker/21:1H]\nroot       674     2  0  2018 ?        00:00:02 [kworker/27:1H]\nroot       676     2  0  2018 ?        00:00:02 [kworker/37:1H]\nroot       689     2  0  2018 ?        00:00:02 [kworker/43:1H]\nroot       691     2  0  2018 ?        00:00:00 [nvidia-modeset]\nroot       757     2  0  2018 ?        00:00:00 [raid5wq]\nroot       790     2  0  2018 ?        00:00:04 [kworker/36:1H]\nroot       799     2  0  2018 ?        00:00:03 [kworker/41:1H]\nroot       803     2  0  2018 ?        00:00:03 [kworker/38:1H]\nroot       808     2  0  2018 ?        00:00:02 [kworker/47:1H]\nroot       809     2  0  2018 ?        00:03:55 [jbd2/sda2-8]\nroot       810     2  0  2018 ?        00:00:00 [ext4-rsv-conver]\nroot       812     2  0  2018 ?        00:00:03 [kworker/3:1H]\nroot       813     2  0  2018 ?        00:00:01 [kworker/17:1H]\nroot       828     2  0  2018 ?        00:00:02 [kworker/11:1H]\nroot       829     2  0  2018 ?        00:00:01 [kworker/29:1H]\nroot       834     2  0  2018 ?        00:00:05 [kworker/46:1H]\nroot       839     2  0  2018 ?        00:00:02 [kworker/19:1H]\nroot       843     2  0  2018 ?        00:00:02 [kworker/33:1H]\nroot       847     2  0  2018 ?        00:00:03 [kworker/12:1H]\nroot       849     2  0  2018 ?        00:00:02 [kworker/31:1H]\nroot       865     2  0  2018 ?        00:00:01 [kworker/23:1H]\nroot       866     2  0  2018 ?        00:00:02 [kworker/35:1H]\nroot       869     2  0  2018 ?        00:00:11 [kworker/0:1H]\nroot       870     2  0  2018 ?        00:00:02 [kworker/39:1H]\nroot       871     2  0  2018 ?        00:00:01 [kworker/15:1H]\nroot       875     2  0  2018 ?        00:00:07 [kworker/4:1H]\nroot       880     2  0  2018 ?        00:00:02 [kworker/5:1H]\nroot       882     2  0  2018 ?        00:00:12 [kworker/2:1H]\nroot       884     2  0  2018 ?        00:00:04 [kworker/1:1H]\nroot       885     2  0  2018 ?        00:00:01 [kworker/25:1H]\nroot       887     2  0  2018 ?        00:00:03 [kworker/8:1H]\nroot       892     2  0  2018 ?        00:00:04 [kworker/26:1H]\nroot       899     2  0  2018 ?        00:00:02 [kworker/9:1H]\nroot       904     2  0  2018 ?        00:00:13 [kworker/16:1H]\nroot       911     2  0  2018 ?        00:00:04 [kworker/20:1H]\nroot       912     2  0  2018 ?        00:00:05 [kworker/18:1H]\nroot       913     2  0  2018 ?        00:00:00 [iscsi_eh]\nroot       915     2  0  2018 ?        00:00:00 [ib-comp-wq]\nroot       916     2  0  2018 ?        00:00:00 [ib_mcast]\nroot       917     2  0  2018 ?        00:00:00 [ib_nl_sa_wq]\nroot       921     2  0  2018 ?        00:00:00 [rdma_cm]\nroot       924     2  0  2018 ?        00:00:00 [rpciod]\nroot       925     2  0  2018 ?        00:00:00 [xprtiod]\nroot       926     2  0  2018 ?        00:00:04 [kworker/6:1H]\nroot       934     1  0  2018 ?        00:00:00 /usr/sbin/blkmapd\nroot       935     1  0  2018 ?        00:00:00 /sbin/lvmetad -f\nroot       942     2  0  2018 ?        00:00:03 [kworker/14:1H]\nroot       958     2  0  2018 ?        00:00:03 [kworker/28:1H]\nroot      1071     2  0  2018 ?        00:00:02 [kworker/13:1H]\nroot      1077     2  0  2018 ?        00:00:08 [kworker/32:1H]\nroot      1078     2  0  2018 ?        00:00:03 [kworker/40:1H]\nroot      1092     2  0  2018 ?        00:00:08 [kworker/42:1H]\nroot      1110     2  0  2018 ?        00:00:00 [UVM global queu]\nroot      1111     2  0  2018 ?        00:00:00 [UVM Tools Event]\nroot      1121     2  0  2018 ?        00:00:00 [irq/245-mei_me]\nroot      1123     2  0  2018 ?        00:00:03 [kworker/10:1H]\nroot      1241     2  0  2018 ?        00:00:04 [kworker/22:1H]\nroot      1435     1  0  2018 ?        00:00:12 /sbin/rpcbind -f -w\nroot      1440     1  0  2018 ?        00:00:00 /usr/sbin/rpc.idmapd\nroot      1489     1  0  2018 ?        00:00:10 /usr/sbin/rpc.mountd -p 892 --ma\nroot      1492     2  0  2018 ?        00:00:02 [kworker/7:1H]\nroot      1493     2  0  2018 ?        00:00:00 [lockd]\nroot      1495     2  0  2018 ?        00:00:00 [nfsd]\nroot      1496     2  0  2018 ?        00:00:00 [nfsd]\nroot      1497     2  0  2018 ?        00:00:01 [nfsd]\nroot      1498     2  0  2018 ?        00:00:00 [nfsd]\nroot      1499     2  0  2018 ?        00:00:01 [nfsd]\nroot      1500     2  0  2018 ?        00:00:01 [nfsd]\nroot      1501     2  0  2018 ?        00:00:44 [nfsd]\nroot      1502     2  0  2018 ?        00:03:36 [nfsd]\nroot      1595     1  0  2018 ?        00:02:23 /sbin/iscsid\nroot      1597     1  0  2018 ?        00:00:00 /sbin/iscsid\nroot      1602     1  0  2018 ?        00:01:01 /usr/sbin/cron -f\nroot      1618     1  0  2018 ?        00:00:00 /usr/bin/python3 /usr/bin/networ\nroot      1631     1  0  2018 ?        00:01:33 /usr/bin/lxcfs /var/lib/lxcfs/\nroot      1655     1  0  2018 ?        01:25:25 /usr/sbin/irqbalance --foregroun\nroot      1681     1  0  2018 ?        00:11:00 /usr/sbin/atopacctd\nsyslog    1694     1  0  2018 ?        00:12:41 /usr/sbin/rsyslogd -n\nmessage+  1701     1  0  2018 ?        00:03:34 /usr/bin/dbus-daemon --system --\nroot      1764     1  0  2018 ?        00:00:27 /lib/systemd/systemd-logind\ndaemon    1791     1  0  2018 ?        00:00:00 /usr/sbin/atd -f\nroot      1801     1  0  2018 ?        00:11:41 /usr/lib/accountsservice/account\nroot      1962     1  0  2018 tty1     00:00:00 /sbin/agetty -o -p -- \\u --nocle\nroot      1990     1  0  2018 ?        00:01:38 /usr/lib/policykit-1/polkitd --n\nlibvirt+  2385     1  0  2018 ?        00:00:17 /usr/sbin/dnsmasq --conf-file=/v\nroot      2386  2385  0  2018 ?        00:00:00 /usr/sbin/dnsmasq --conf-file=/v\nroot      2540     2  0 Jan06 ?        00:00:00 [kworker/37:1]\nroot      2711     2  0 Jan06 ?        00:00:02 [kworker/14:1]\nroot      3588     2  0 Jan05 ?        00:00:02 [kworker/40:7]\nroot      3605     2  0 Jan05 ?        00:00:00 [kworker/43:5]\nzyu       4151 13303  0  2018 ?        00:03:44 /home/zyu/miniconda3/envs/gee/bi\nroot      5630     2  0  2018 ?        00:00:00 [loop3]\nroot      5772     1  0  2018 ?        00:07:12 /usr/lib/snapd/snapd\nroot      6630     2  0 Jan07 ?        00:00:00 [kworker/38:2]\nroot      7102     2  0 Jan07 ?        00:00:00 [kworker/47:2]\nroot      7489     2  0 10:17 ?        00:00:00 [kworker/34:0]\nroot      8108     2  0  2018 ?        00:00:00 [nfsiod]\nstatd     8160     1  0  2018 ?        00:00:00 /sbin/rpc.statd --no-notify --po\nroot      8580     2  0 Jan07 ?        00:00:00 [kworker/19:1]\nroot      8668     2  0 Jan06 ?        00:00:00 [kworker/9:1]\nroot      8681     2  0 Jan06 ?        00:00:00 [kworker/33:6]\nroot      8720     2  0 Jan06 ?        00:00:00 [kworker/27:1]\nroot      8736     2  0 Jan06 ?        00:00:00 [kworker/36:1]\nroot      8763     2  0 Jan06 ?        00:00:03 [kworker/30:2]\nroot      9092     2  0  2018 ?        00:00:00 [NFSv4 callback]\nroot     10810     2  0 Jan06 ?        00:00:01 [kworker/38:0]\nroot     11013     2  0 Jan06 ?        00:00:01 [kworker/42:0]\nroot     11517     2  0 01:48 ?        00:00:00 [kworker/29:2]\nroot     11934     2  0 11:24 ?        00:00:00 [kworker/46:0]\nroot     11954     2  0 01:51 ?        00:00:00 [kworker/5:1]\nroot     11963     2  0 Jan02 ?        00:00:01 [kworker/35:1]\nroot     12061     2  0 11:25 ?        00:00:00 [kworker/43:0]\nroot     13016     2  0 11:37 ?        00:00:00 [kworker/32:0]\nroot     13076     2  0 Jan07 ?        00:00:00 [kworker/30:1]\nzyu      13303     1  0  2018 ?        00:38:51 /home/zyu/miniconda3/envs/gee/bi\nroot     13450     2  0 11:43 ?        00:00:00 [kworker/32:1]\nroot     13495     2  0 Jan07 ?        00:00:00 [kworker/35:2]\nroot     13774     2  0 11:48 ?        00:00:00 [kworker/8:0]\nroot     13908     1 10  2018 ?        2-17:06:05 qemu-system-x86_64 -enable-kvm\nroot     13921     2  0  2018 ?        00:01:11 [vhost-13908]\nroot     13923     2  0  2018 ?        00:00:02 [vhost-13908]\nroot     13928     2  0  2018 ?        00:00:00 [kvm-pit/13908]\nroot     14298     2  0 11:56 ?        00:00:00 [kworker/26:0]\nroot     14767     2  0 Jan04 ?        00:00:00 [kworker/19:0]\nzyu      14867 13303  0  2018 ?        00:05:02 /home/zyu/miniconda3/envs/gee/bi\nroot     15128     2  0 Jan07 ?        00:00:00 [kworker/45:0]\nroot     15161     2  0 Jan07 ?        00:00:00 [kworker/3:3]\nroot     15167     2  0 Jan07 ?        00:00:00 [kworker/15:1]\nroot     15294     2  0 Jan07 ?        00:00:00 [kworker/20:1]\nroot     15538     2  0 Jan05 ?        00:00:00 [kworker/15:2]\nroot     15890     2  0 Jan07 ?        00:00:00 [kworker/31:0]\nroot     15891     2  0 Jan07 ?        00:00:00 [kworker/31:1]\nroot     16281     2  0 Jan07 ?        00:00:00 [kworker/3:0]\nroot     16307     2  0 Jan07 ?        00:00:00 [kworker/47:0]\nroot     16400     2  0 Jan07 ?        00:00:00 [kworker/7:2]\nroot     16401     2  0 Jan07 ?        00:00:00 [kworker/7:3]\nroot     16919     2  0 Jan03 ?        00:00:00 [kworker/17:2]\nroot     17500     1  9  2018 ?        1-18:20:00 qemu-system-x86_64 -enable-kvm\nroot     17512     2  0  2018 ?        00:00:57 [vhost-17500]\nroot     17519     2  0  2018 ?        00:00:00 [kvm-pit/17500]\nroot     17559     2  0 Jan03 ?        00:00:00 [kworker/27:2]\nroot     17635     2  0 02:45 ?        00:00:00 [kworker/10:0]\nroot     18118     2  0  2018 ?        00:00:00 [loop0]\nroot     18342     2  0 Jan07 ?        00:00:00 [kworker/20:0]\nroot     18491     2  0 Jan07 ?        00:00:00 [kworker/25:0]\nroot     18495     2  0 Jan07 ?        00:00:00 [kworker/25:1]\nroot     18504     2  0 Jan07 ?        00:00:01 [kworker/8:1]\nroot     18868     2  0 13:10 ?        00:00:00 [kworker/u98:0]\nroot     21138     2  0 13:45 ?        00:00:00 [kworker/2:2]\nroot     21446     2  0 Jan06 ?        00:00:02 [kworker/4:1]\nroot     21621     2  0 13:53 ?        00:00:00 [kworker/u97:0]\nroot     21705     2  0  2018 ?        00:00:31 [kworker/24:2H]\nzsun     21729     1  0 Jan07 ?        00:00:00 /lib/systemd/systemd --user\nzsun     21730 21729  0 Jan07 ?        00:00:00 (sd-pam)\nztan6    22161     1  0 14:03 ?        00:00:00 /lib/systemd/systemd --user\nztan6    22162 22161  0 14:03 ?        00:00:00 (sd-pam)\nztan6    22439     1  0 14:05 ?        00:00:00 bash run.sh\nroot     22461     2  0 14:05 ?        00:00:03 [kworker/12:2]\nroot     22462     2  0 14:05 ?        00:00:00 [kworker/0:1]\nroot     22472     2  0 14:05 ?        00:00:00 [kworker/24:4]\nroot     22480     2  0 14:05 ?        00:00:00 [kworker/6:0]\nroot     22482     2  0 14:05 ?        00:00:00 [kworker/33:3]\nroot     22490     2  0 14:05 ?        00:00:00 [kworker/37:2]\nztan6    22625 22439 99 14:07 ?        00:34:59 python run.py --lr 5e-4 --num_wo\nroot     22627     2  0 14:07 ?        00:00:00 [kworker/39:2]\nroot     22640     2  0 14:07 ?        00:00:04 [irq/256-nvidia]\nroot     22641     2  0 14:07 ?        00:00:00 [nvidia]\nnvidia-+ 22645     1  0 14:07 ?        00:00:00 /usr/bin/nvidia-persistenced --u\nroot     22654     2  0 14:07 ?        00:00:00 [kworker/40:0]\nroot     22655     2  0 14:07 ?        00:00:04 [irq/257-nvidia]\nroot     22656     2  0 14:07 ?        00:00:00 [nvidia]\nroot     22657     2  0 14:07 ?        00:00:00 [kworker/16:0]\nroot     22660     2  0 14:07 ?        00:00:05 [irq/258-nvidia]\nroot     22661     2  0 14:07 ?        00:00:00 [nvidia]\nroot     22664     2  0 14:07 ?        00:00:04 [irq/259-nvidia]\nroot     22665     2  0 14:07 ?        00:00:00 [nvidia]\nroot     22666     2  0 14:07 ?        00:00:00 [kworker/5:0]\nroot     22667     2  0 14:07 ?        00:00:00 [kworker/1:4]\nroot     22671     2  0 14:07 ?        00:00:00 [kworker/1:5]\nroot     22725     2  0 14:07 ?        00:00:00 [kworker/u97:3]\nroot     22810     2  0 14:08 ?        00:00:00 [kworker/u98:2]\nroot     23585     2  0 14:15 ?        00:00:00 [kworker/24:0]\nroot     23974     2  0 14:19 ?        00:00:01 [kworker/22:0]\nroot     24007     2  0 14:19 ?        00:00:00 [kworker/34:1]\nroot     24327     2  0 14:22 ?        00:00:00 [kworker/u97:2]\nroot     24365     2  0 14:23 ?        00:00:00 [kworker/12:0]\nroot     24423     2  0 14:23 ?        00:00:01 [kworker/41:0]\nroot     24432     2  0 Jan06 ?        00:00:00 [kworker/21:0]\nroot     24646     2  0 Jan07 ?        00:00:02 [kworker/0:0]\nroot     24656     2  0 Jan07 ?        00:00:00 [kworker/10:2]\nroot     24667     2  0 Jan07 ?        00:00:00 [kworker/u96:2]\nroot     24679     2  0 Jan07 ?        00:00:00 [kworker/17:0]\nroot     24769 41673  0 Jan07 ?        00:00:00 /usr/bin/docker-proxy -proto tcp\nroot     24779 40529  0 Jan07 ?        00:00:03 containerd-shim -namespace moby \n999      24806 24779  0 Jan07 ?        00:00:39 mysqld\nzyu      24831 13303  0  2018 ?        00:37:15 /home/zyu/miniconda3/envs/gee/bi\nroot     24929 41673  0 Jan07 ?        00:00:01 /usr/bin/docker-proxy -proto tcp\nroot     24934     1  0  2018 ?        00:00:00 /usr/sbin/virtlogd\nroot     24949 40529  0 Jan07 ?        00:00:04 containerd-shim -namespace moby \nroot     24999 24949  0 Jan07 ?        00:02:27 /docker-java-home/jre/bin/java -\nroot     25248     2  0 14:30 ?        00:00:01 [kworker/13:2]\nroot     25322 45262  0 Jan07 ?        00:00:00 sshd: zsun [priv]\nzsun     25424 25322  0 Jan07 ?        00:00:00 sshd: zsun@pts/8\nroot     25518 45262  0 Jan07 ?        00:00:00 sshd: zsun [priv]\nroot     25601     2  0 14:33 ?        00:00:00 [kworker/46:1]\nzsun     25604 25518  0 Jan07 ?        00:00:00 sshd: zsun@pts/9\nroot     25703 45262  0 Jan07 ?        00:00:00 sshd: zsun [priv]\nroot     25768     2  0 14:34 ?        00:00:00 [kworker/16:2]\nzsun     25814 25703  0 Jan07 ?        00:00:00 sshd: zsun@pts/10\nroot     25831     2  0 14:34 ?        00:00:00 [kworker/41:2]\nroot     25867     2  0 14:35 ?        00:00:00 [kworker/44:2]\nroot     25921     1  0  2018 ?        00:00:18 /lib/systemd/systemd-udevd\nroot     25996     2  0 14:36 ?        00:00:00 [kworker/22:1]\nroot     26211     2  0 14:38 ?        00:00:00 [kworker/24:1]\nroot     26256     2  0 14:38 ?        00:00:00 [kworker/u97:1]\nroot     26294     2  0 14:39 ?        00:00:00 [kworker/32:2]\nroot     26388 45262  0 Jan07 ?        00:00:00 sshd: zsun [priv]\nroot     26405     2  0 14:40 ?        00:00:00 [kworker/41:1]\nzsun     26474 26388  0 Jan07 ?        00:00:00 sshd: zsun@pts/11\nroot     26503 45262  0 14:41 ?        00:00:00 sshd: zsun [priv]\nzsun     26592 26503  0 14:41 ?        00:00:00 sshd: zsun@pts/6\nroot     26598 45262  0 Jan07 ?        00:00:00 sshd: zsun [priv]\nroot     26664 45262  0 14:41 ?        00:00:00 sshd: zsun [priv]\nzsun     26684 26598  0 Jan07 ?        00:00:00 sshd: zsun@pts/12\nzsun     26750 26664  0 14:41 ?        00:00:00 sshd: zsun@pts/7\nroot     26752 45262  0 14:41 ?        00:00:00 sshd: root [priv]\nsshd     26753 26752  0 14:41 ?        00:00:00 sshd: root [net]\nroot     26754     2  0 14:41 ?        00:00:00 [kworker/13:0]\nroot     26859 45262  2 14:42 ?        00:00:00 sshd: zsun [priv]\nzsun     26944 26859  0 14:42 ?        00:00:00 sshd: zsun@pts/13\nzsun     26945 26944  0 14:42 pts/13   00:00:00 bash -c echo "#!/bin/bash #write\nzsun     26947 26945  0 14:42 pts/13   00:00:00 /bin/bash ./geoweaver-knxfodqb6p\nzsun     26948 26947  0 14:42 pts/13   00:00:00 ps -ef\nroot     28095     2  0 Jan04 ?        00:00:00 [kworker/45:3]\nroot     28096     2  0 Jan04 ?        00:00:00 [kworker/21:2]\nroot     28462     2  0 Jan04 ?        00:00:00 [kworker/23:2]\nroot     28510     2  0 04:24 ?        00:00:00 [kworker/44:1]\nroot     28722     2  0  2018 ?        00:00:00 [loop2]\nroot     28909     2  0  2018 ?        00:00:01 [kworker/u96:1]\nroot     29598     1  9  2018 ?        2-14:13:58 qemu-system-x86_64 -enable-kvm\nroot     29609     2  0  2018 ?        00:01:06 [vhost-29598]\nroot     29613     2  0  2018 ?        00:00:00 [kvm-pit/29598]\nroot     29798     1 99  2018 ?        27-16:28:45 qemu-system-x86_64 -enable-kv\nroot     29808     2  0  2018 ?        00:00:00 [vhost-29798]\nroot     29812     2  0  2018 ?        00:15:47 [kvm-pit/29798]\nroot     31370     2  0  2018 ?        00:00:00 [kworker/11:4]\nroot     31882     2  0 04:55 ?        00:00:00 [kworker/9:2]\nroot     33820     2  0 05:13 ?        00:00:03 [kworker/13:1]\nroot     33824     2  0 05:13 ?        00:00:00 [kworker/14:2]\nsystemd+ 34406     1  0  2018 ?        00:00:48 /lib/systemd/systemd-networkd\nsystemd+ 34435     1  0  2018 ?        00:04:15 /lib/systemd/systemd-resolved\nsystemd+ 34504     1  0  2018 ?        00:00:15 /lib/systemd/systemd-timesyncd\nroot     34526     1  0  2018 ?        00:31:44 /lib/systemd/systemd-journald\nroot     36669     2  0 Jan04 ?        00:00:00 [kworker/23:0]\nroot     36744     2  0 Jan06 ?        00:00:00 [kworker/29:1]\nroot     37570     2  0 06:06 ?        00:00:00 [kworker/42:2]\nroot     37635     1  0  2018 ?        01:24:13 /usr/sbin/libvirtd\nroot     37731     1 10  2018 ?        2-02:10:53 qemu-system-x86_64 -enable-kvm\nroot     37742     2  0  2018 ?        00:00:52 [vhost-37731]\nroot     37746     2  0  2018 ?        00:00:00 [kvm-pit/37731]\nroot     37906     1  0  2018 ?        00:00:00 /bin/sh -ec      export ACP=`ls \nroot     37919 37906  0  2018 ?        01:10:20 /usr/bin/java -Djava.io.tmpdir=/\nroot     38198     2  0 06:09 ?        00:00:00 [kworker/28:0]\nroot     39236     2  0 Jan07 ?        00:00:00 [kworker/36:0]\nwww-data 39383 47081  0 06:25 ?        00:00:00 /usr/sbin/apache2 -k start\nwww-data 39384 47081  0 06:25 ?        00:00:00 /usr/sbin/apache2 -k start\nroot     39517     2  0 06:25 ?        00:00:00 [kworker/2:0]\nzyu      39770 13303  0  2018 ?        00:04:30 /home/zyu/miniconda3/envs/gee/bi\nroot     40529     1  0  2018 ?        06:56:55 /usr/bin/containerd\nzyu      41436     1  0  2018 ?        00:00:03 /lib/systemd/systemd --user\nzyu      41438 41436  0  2018 ?        00:00:00 (sd-pam)\nroot     41673     1  0  2018 ?        01:05:30 /usr/bin/dockerd -H unix://\nroot     43040     2  0 07:09 ?        00:00:00 [kworker/4:0]\nroot     45262     1  0  2018 ?        00:06:00 /usr/sbin/sshd -D\nroot     45684     2  0 07:39 ?        00:00:00 [kworker/18:1]\nroot     45803     2  0 Jan03 ?        00:00:01 [kworker/11:0]\nroot     46148     2  0 07:46 ?        00:00:00 [kworker/18:2]\nroot     46232     2  0 Jan07 ?        00:00:00 [kworker/28:2]\nroot     46331     2  0 Jan06 ?        00:00:02 [kworker/6:1]\nroot     46763     2  0 07:56 ?        00:00:00 [kworker/26:1]\nroot     46923     2  0 07:59 ?        00:00:02 [kworker/12:1]\nroot     47081     1  0  2018 ?        00:00:51 /usr/sbin/apache2 -k start\nroot     48037     1  0 00:00 ?        00:00:45 /usr/bin/atop -R -w /var/log/ato\n/home/zsun\n', 'kps1gf', 'Done'),
	('tq48lt3kvn8r', 'ac4724', '2019-01-08 09:42:06', '2019-01-08 09:42:21', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('r5sra59bxwn', '7w0ga6df6x6xhex588pk', '2019-01-08 09:42:03', '2019-01-08 09:42:21', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'vnfo1fvk24k0;60v8zp061ieo;tq48lt3kvn8r;', 'kps1gf;', 'Done'),
	('r9ap9k7hutyh', '199vsg', '2019-01-08 09:44:06', '2019-01-08 09:44:06', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('hovxs74h414l', 'ac4724', '2019-01-08 09:44:07', '2019-01-08 09:44:22', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('s8ciztb4bufq', '199vsg', '2019-01-08 09:44:23', '2019-01-08 09:44:23', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('cb1awdbv4j4', '5k56d9vcx4ip3tr5pj26', '2019-01-08 09:44:05', '2019-01-08 09:44:23', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'r9ap9k7hutyh;hovxs74h414l;s8ciztb4bufq;', 'kps1gf;', 'Done'),
	('cnnaoaxbco8s', 'nhi96d', '2019-01-09 10:56:39', '2019-01-09 10:56:39', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 15:56:40--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('rp987pg3c3bn', 'umv6tx', '2019-01-09 10:56:40', '2019-01-09 10:56:40', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('xv4aktz3a0h1', 'rh1u8q', '2019-01-09 10:56:41', '2019-01-09 10:56:41', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('ag3as2w4guhe', 'rpnhlg', '2019-01-09 10:56:42', '2019-01-09 10:56:42', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('r4syodfwiq7k', 'wsxeps', '2019-01-09 10:56:43', '2019-01-09 10:56:43', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('n11qjwidgibs', 'qp820f', '2019-01-09 10:56:44', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('n11qjwidgibs', 'qp820f', '2019-01-09 10:56:44', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('md3a56venbhe', 'ew8pku', '2019-01-09 10:56:45', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('md3a56venbhe', 'ew8pku', '2019-01-09 10:56:45', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('u0shskloxq8o', 'spz3b5', '2019-01-09 10:56:46', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('u0shskloxq8o', 'spz3b5', '2019-01-09 10:56:46', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('rwxyz6wjzq95', 'omop8l', '2019-01-09 10:56:47', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('rwxyz6wjzq95', 'omop8l', '2019-01-09 10:56:47', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('dhtn457dofb6', 'm6bbrf', '2019-01-09 10:56:48', '2019-01-09 10:56:48', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('aigk1fyq5md', '7sb7xj', '2019-01-09 10:56:48', '2019-01-09 10:56:49', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'cxkf7lgj', 'kps1gf', 'Done'),
	('m498syu46pd', 'vke2yf47hyot7ae7np7h', '2019-01-09 10:56:38', '2019-01-09 10:56:50', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'cnnaoaxbco8s;rp987pg3c3bn;xv4aktz3a0h1;ag3as2w4guhe;r4syodfwiq7k;n11qjwidgibs;md3a56venbhe;u0shskloxq8o;rwxyz6wjzq95;dhtn457dofb6;aigk1fyq5md;', 'kps1gf;', 'Done'),
	('dtuz5qzary1y', 'nhi96d', '2019-01-09 10:57:38', '2019-01-09 10:57:38', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 15:57:39--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('16xva6iyjn5m', 'umv6tx', '2019-01-09 10:57:39', '2019-01-09 10:57:39', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('u7q7bm73wwcw', 'rh1u8q', '2019-01-09 10:57:40', '2019-01-09 10:57:40', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('6uaw3r9y9iho', 'rpnhlg', '2019-01-09 10:57:41', '2019-01-09 10:57:41', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('c2i5uyalfb6b', 'wsxeps', '2019-01-09 10:57:42', '2019-01-09 10:57:42', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('1qkv7uekk7fl', 'qp820f', '2019-01-09 10:57:43', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('1qkv7uekk7fl', 'qp820f', '2019-01-09 10:57:43', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('5o0lwyvaji0g', 'ew8pku', '2019-01-09 10:57:44', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('5o0lwyvaji0g', 'ew8pku', '2019-01-09 10:57:44', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('0kb3ubds0fk4', 'spz3b5', '2019-01-09 10:57:45', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('0kb3ubds0fk4', 'spz3b5', '2019-01-09 10:57:45', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('fuu8vnazkyke', 'omop8l', '2019-01-09 10:57:46', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('fuu8vnazkyke', 'omop8l', '2019-01-09 10:57:46', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('w4x9y0put798', 'm6bbrf', '2019-01-09 10:57:47', '2019-01-09 10:57:47', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('za4lbyzek5k', '7sb7xj', '2019-01-09 10:57:47', '2019-01-09 10:57:48', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'sybd20yz', 'kps1gf', 'Done'),
	('65zesle7we8', 'vke2yf47hyot7ae7np7h', '2019-01-09 10:57:37', '2019-01-09 10:57:49', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'dtuz5qzary1y;16xva6iyjn5m;u7q7bm73wwcw;6uaw3r9y9iho;c2i5uyalfb6b;1qkv7uekk7fl;5o0lwyvaji0g;0kb3ubds0fk4;fuu8vnazkyke;w4x9y0put798;za4lbyzek5k;', 'kps1gf;', 'Done'),
	('yptfv2z2gp79', 'nhi96d', '2019-01-09 10:59:23', '2019-01-09 10:59:23', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 15:59:23--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('rykevktp9wuo', 'umv6tx', '2019-01-09 10:59:24', '2019-01-09 10:59:24', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('qm7znsjpo59u', 'rh1u8q', '2019-01-09 10:59:25', '2019-01-09 10:59:25', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('rykioo5tperx', 'rpnhlg', '2019-01-09 10:59:26', '2019-01-09 10:59:26', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('v5xqbwutlrzd', 'wsxeps', '2019-01-09 10:59:26', '2019-01-09 10:59:26', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('ofrliy5418u8', 'qp820f', '2019-01-09 10:59:27', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('ofrliy5418u8', 'qp820f', '2019-01-09 10:59:27', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('hv6596onb9ab', 'ew8pku', '2019-01-09 10:59:28', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('hv6596onb9ab', 'ew8pku', '2019-01-09 10:59:28', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('lzf42bxgwwpx', 'spz3b5', '2019-01-09 10:59:29', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('lzf42bxgwwpx', 'spz3b5', '2019-01-09 10:59:29', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('vnj22epxee14', 'omop8l', '2019-01-09 10:59:30', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('vnj22epxee14', 'omop8l', '2019-01-09 10:59:30', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('vrbsx66ajiqj', 'm6bbrf', '2019-01-09 10:59:31', '2019-01-09 10:59:31', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('mysvzo41g08', '7sb7xj', '2019-01-09 10:59:31', '2019-01-09 10:59:32', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', '6d01q87f', 'kps1gf', 'Done'),
	('d2pgtwczaka', 'vke2yf47hyot7ae7np7h', '2019-01-09 10:59:22', '2019-01-09 10:59:33', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'yptfv2z2gp79;rykevktp9wuo;qm7znsjpo59u;rykioo5tperx;v5xqbwutlrzd;ofrliy5418u8;hv6596onb9ab;lzf42bxgwwpx;vnj22epxee14;vrbsx66ajiqj;mysvzo41g08;', 'kps1gf;', 'Done'),
	('imd3fhqg5mq9', 'nhi96d', '2019-01-09 11:17:17', '2019-01-09 11:17:18', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 16:17:18--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('ufqncpkeuses', 'umv6tx', '2019-01-09 11:17:18', '2019-01-09 11:17:19', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('dzrxzhy60qqz', 'rh1u8q', '2019-01-09 11:17:19', '2019-01-09 11:17:19', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('di2u8e5g8jyg', 'rpnhlg', '2019-01-09 11:17:20', '2019-01-09 11:17:20', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('ig5ckf3c6za3', 'wsxeps', '2019-01-09 11:17:21', '2019-01-09 11:17:21', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('dnvf6pck6f2u', 'qp820f', '2019-01-09 11:17:22', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('dnvf6pck6f2u', 'qp820f', '2019-01-09 11:17:22', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('oo6px9j7tx6j', 'ew8pku', '2019-01-09 11:17:23', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('oo6px9j7tx6j', 'ew8pku', '2019-01-09 11:17:23', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('qn3sn3zkn9uj', 'spz3b5', '2019-01-09 11:17:24', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('qn3sn3zkn9uj', 'spz3b5', '2019-01-09 11:17:24', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('e9r7acyrrr34', 'omop8l', '2019-01-09 11:17:25', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('e9r7acyrrr34', 'omop8l', '2019-01-09 11:17:25', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('t6zy19zy02q7', 'm6bbrf', '2019-01-09 11:17:26', '2019-01-09 11:17:26', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('2snm90wyx0g', '7sb7xj', '2019-01-09 11:17:26', '2019-01-09 11:17:27', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'jk6lhn57', 'kps1gf', 'Done'),
	('a4mxlqqdotp', 'vke2yf47hyot7ae7np7h', '2019-01-09 11:17:16', '2019-01-09 11:17:28', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'imd3fhqg5mq9;ufqncpkeuses;dzrxzhy60qqz;di2u8e5g8jyg;ig5ckf3c6za3;dnvf6pck6f2u;oo6px9j7tx6j;qn3sn3zkn9uj;e9r7acyrrr34;t6zy19zy02q7;2snm90wyx0g;', 'kps1gf;', 'Done'),
	('s857jv75t21i', 'nhi96d', '2019-01-09 11:17:40', '2019-01-09 11:17:40', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 16:17:41--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('ucua9hri1wsf', 'umv6tx', '2019-01-09 11:17:41', '2019-01-09 11:17:41', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('ynknpizt77os', 'rh1u8q', '2019-01-09 11:17:42', '2019-01-09 11:17:42', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('untta3e0yd7h', 'rpnhlg', '2019-01-09 11:17:43', '2019-01-09 11:17:43', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('xnblc78pvrej', 'wsxeps', '2019-01-09 11:17:44', '2019-01-09 11:17:44', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('9l3sgk3blqx6', 'qp820f', '2019-01-09 11:17:45', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('9l3sgk3blqx6', 'qp820f', '2019-01-09 11:17:45', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('yerd432yrpuw', 'ew8pku', '2019-01-09 11:17:46', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('yerd432yrpuw', 'ew8pku', '2019-01-09 11:17:46', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('fgjep1rhbqnj', 'spz3b5', '2019-01-09 11:17:47', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('fgjep1rhbqnj', 'spz3b5', '2019-01-09 11:17:47', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('fjhxt2twkho3', 'omop8l', '2019-01-09 11:17:48', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('fjhxt2twkho3', 'omop8l', '2019-01-09 11:17:48', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('5p7hfxdpouv8', 'm6bbrf', '2019-01-09 11:17:49', '2019-01-09 11:17:49', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('eo8c55312d8', '7sb7xj', '2019-01-09 11:17:49', '2019-01-09 11:17:51', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', '28vjgslk', 'kps1gf', 'Done'),
	('vcgq9avtj1d', 'vke2yf47hyot7ae7np7h', '2019-01-09 11:17:39', '2019-01-09 11:17:52', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 's857jv75t21i;ucua9hri1wsf;ynknpizt77os;untta3e0yd7h;xnblc78pvrej;9l3sgk3blqx6;yerd432yrpuw;fgjep1rhbqnj;fjhxt2twkho3;5p7hfxdpouv8;eo8c55312d8;', 'kps1gf;', 'Done'),
	('r645etgo54fx', 'nhi96d', '2019-01-09 11:31:10', '2019-01-09 11:31:10', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 16:31:10--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('lfipuhvual3y', 'umv6tx', '2019-01-09 11:31:11', '2019-01-09 11:31:11', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('vvc0aclgd7vc', 'rh1u8q', '2019-01-09 11:31:12', '2019-01-09 11:31:12', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('h0gdan8wg1ia', 'rpnhlg', '2019-01-09 11:31:13', '2019-01-09 11:31:13', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('jau20ly269kv', 'wsxeps', '2019-01-09 11:31:13', '2019-01-09 11:31:13', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('gv7lqmifqv8k', 'qp820f', '2019-01-09 11:31:14', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('gv7lqmifqv8k', 'qp820f', '2019-01-09 11:31:14', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('xq7udo4ke455', 'ew8pku', '2019-01-09 11:31:15', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('xq7udo4ke455', 'ew8pku', '2019-01-09 11:31:15', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('8kazbufs82iy', 'spz3b5', '2019-01-09 11:31:16', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('8kazbufs82iy', 'spz3b5', '2019-01-09 11:31:16', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('znhbbd2f0wof', 'omop8l', '2019-01-09 11:31:17', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('znhbbd2f0wof', 'omop8l', '2019-01-09 11:31:17', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('bdhovk7jo3ig', 'm6bbrf', '2019-01-09 11:31:18', '2019-01-09 11:31:18', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('dwwpzlwux7i', '7sb7xj', '2019-01-09 11:31:18', '2019-01-09 11:31:19', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'wbg2l3br', 'kps1gf', 'Done'),
	('levvy2qqmhg', 'vke2yf47hyot7ae7np7h', '2019-01-09 11:31:09', '2019-01-09 11:31:20', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'r645etgo54fx;lfipuhvual3y;vvc0aclgd7vc;h0gdan8wg1ia;jau20ly269kv;gv7lqmifqv8k;xq7udo4ke455;8kazbufs82iy;znhbbd2f0wof;bdhovk7jo3ig;dwwpzlwux7i;', 'kps1gf;', 'Done'),
	('l2rw43py068x', 'nhi96d', '2019-01-09 11:33:01', '2019-01-09 11:33:01', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-09 16:33:01--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('kx4o9dr14r0z', 'umv6tx', '2019-01-09 11:33:02', '2019-01-09 11:33:02', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('5b0cf1ubtwyb', 'rh1u8q', '2019-01-09 11:33:03', '2019-01-09 11:33:03', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('pskqu8qjt6c2', 'rpnhlg', '2019-01-09 11:33:04', '2019-01-09 11:33:04', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('dpna73toghdb', 'wsxeps', '2019-01-09 11:33:05', '2019-01-09 11:33:05', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('n3irhb1cac4g', 'qp820f', '2019-01-09 11:33:06', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('n3irhb1cac4g', 'qp820f', '2019-01-09 11:33:06', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('2a9zw4dioqgx', 'ew8pku', '2019-01-09 11:33:07', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('2a9zw4dioqgx', 'ew8pku', '2019-01-09 11:33:07', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('qfcjce0tzaw3', 'spz3b5', '2019-01-09 11:33:07', NULL, '#!/bin/bash', NULL, 'kps1gf', 'Done'),
	('qfcjce0tzaw3', 'spz3b5', '2019-01-09 11:33:07', NULL, '#!/bin/bash', '', 'kps1gf', 'Done'),
	('z1ivlodr4wit', 'omop8l', '2019-01-09 11:33:08', NULL, '#!/bin/bash\nsleep 10s', NULL, 'kps1gf', 'Done'),
	('z1ivlodr4wit', 'omop8l', '2019-01-09 11:33:08', NULL, '#!/bin/bash\nsleep 10s', '', 'kps1gf', 'Done'),
	('5arwle7n9seb', 'm6bbrf', '2019-01-09 11:33:19', '2019-01-09 11:33:19', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('k0skmayhx4k', '7sb7xj', '2019-01-09 11:33:19', '2019-01-09 11:33:20', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'ja2sf83j', 'kps1gf', 'Done'),
	('34m4fr404pv', 'vke2yf47hyot7ae7np7h', '2019-01-09 11:33:00', '2019-01-09 11:33:21', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'l2rw43py068x;kx4o9dr14r0z;5b0cf1ubtwyb;pskqu8qjt6c2;dpna73toghdb;n3irhb1cac4g;2a9zw4dioqgx;qfcjce0tzaw3;z1ivlodr4wit;5arwle7n9seb;k0skmayhx4k;', 'kps1gf;', 'Done'),
	('a43w3c5b3bz9', '199vsg', '2019-01-29 22:33:43', '2019-01-29 22:33:43', '#!/bin/sh\necho "test bash script process running"\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('iv2fjc303bqy', '199vsg', '2019-01-29 22:34:11', '2019-01-29 22:34:26', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('gh3prrxp43cl', '199vsg', '2019-01-29 22:36:28', '2019-01-29 22:36:43', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('sbv80qypivps', 'oax563', '2019-01-29 22:38:46', '2019-01-29 22:38:46', '#!%*%bin%*%sh%>%echo %%test geoweaver process running%%%>%echo %%Good%%%>%', 'bash: ./geoweaver-uucsmrc3m66b.sh: %*%bin%*%sh%>%echo: bad interpreter: No such file or directory\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('jif3t2punym4', '199vsg', '2019-01-29 22:39:01', '2019-01-29 22:39:16', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('ntsl2w865r1d', 'ac4724', '2019-01-29 22:39:17', '2019-01-29 22:39:32', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('hbhwcra741ia', '199vsg', '2019-01-29 22:39:33', '2019-01-29 22:39:48', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('6cyzxnrz79o', '5k56d9vcx4ip3tr5pj26', '2019-01-29 22:38:59', '2019-01-29 22:39:48', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'jif3t2punym4;ntsl2w865r1d;hbhwcra741ia;', 'kps1gf;', 'Done'),
	('qwmoopeens9h', '199vsg', '2019-01-29 22:40:23', '2019-01-29 22:40:38', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('213pdm712ges', 'ac4724', '2019-01-29 22:40:39', '2019-01-29 22:40:54', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('8853nl61o0fb', '199vsg', '2019-01-29 22:40:56', '2019-01-29 22:41:11', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('bka6ojsxw9x', '5k56d9vcx4ip3tr5pj26', '2019-01-29 22:40:21', '2019-01-29 22:41:11', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'qwmoopeens9h;213pdm712ges;8853nl61o0fb;', 'kps1gf;', 'Done'),
	('5g4nockuur0r', '199vsg', '2019-01-29 22:47:12', '2019-01-29 22:47:27', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('15elc3kvpuqx', 'ac4724', '2019-01-29 22:47:29', '2019-01-29 22:47:44', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('03nseo7eseiv', '199vsg', '2019-01-29 22:47:45', '2019-01-29 22:48:00', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('smly4rufv2e', '5k56d9vcx4ip3tr5pj26', '2019-01-29 22:47:10', '2019-01-29 22:48:00', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '5g4nockuur0r;15elc3kvpuqx;03nseo7eseiv;', 'kps1gf;', 'Done'),
	('vkm1203wdn31', '199vsg', '2019-01-29 22:48:12', '2019-01-29 22:48:28', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('mwigx2ejjd07', 'ac4724', '2019-01-29 22:48:29', '2019-01-29 22:48:44', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('wzgrh3iibudp', '199vsg', '2019-01-29 22:48:45', '2019-01-29 22:49:00', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('nyd2m0d8tjw', '5k56d9vcx4ip3tr5pj26', '2019-01-29 22:48:11', '2019-01-29 22:49:00', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'vkm1203wdn31;mwigx2ejjd07;wzgrh3iibudp;', 'kps1gf;', 'Done'),
	('8kuj5g9jtuj', '5k56d9vcx4ip3tr5pj26', '2019-01-29 22:59:07', '2019-01-29 23:00:37', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('houaf7w02kz', '5k56d9vcx4ip3tr5pj26', '2019-01-29 22:59:38', '2019-01-29 23:01:08', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('gyhefrtqbmk', 'zdwtvinusmo536sla94v', '2019-01-29 23:49:10', '2019-01-29 23:50:10', 'zdh3ll-yneyR;ac4724-7KQLl;', 'null;null;', 'kps1gf;', 'Done'),
	('ugyblpeuerx', 'zdwtvinusmo536sla94v', '2019-01-29 23:53:16', '2019-01-29 23:54:16', 'zdh3ll-yneyR;ac4724-7KQLl;', 'null;null;', 'kps1gf;', 'Done'),
	('glzhozcwf9nu', '199vsg', '2019-01-30 00:49:31', '2019-01-30 00:49:46', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('cuuipngcxny1', '199vsg', '2019-01-30 00:51:45', '2019-01-30 00:52:00', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('2awj6mj0inc1', '199vsg', '2019-01-30 00:52:35', '2019-01-30 00:52:50', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('42uvt4tz2v4u', 'ac4724', '2019-01-30 00:52:51', '2019-01-30 00:53:06', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('h187w92i5m37', '199vsg', '2019-01-30 00:53:07', '2019-01-30 00:53:23', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('tagiyzt5thr', '5k56d9vcx4ip3tr5pj26', '2019-01-30 00:52:34', '2019-01-30 00:53:23', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', '2awj6mj0inc1;42uvt4tz2v4u;h187w92i5m37;', 'kps1gf;', 'Done'),
	('sc1tkbfbejy1', 'nhi96d', '2019-01-30 00:55:28', '2019-01-30 00:55:28', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-30 05:55:28--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('7zd894y3ovpz', 'umv6tx', '2019-01-30 00:55:30', '2019-01-30 00:55:30', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('fu1iolhr99ct', 'rh1u8q', '2019-01-30 00:55:31', '2019-01-30 00:55:31', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('a7onz54pokrm', 'rpnhlg', '2019-01-30 00:55:32', '2019-01-30 00:55:32', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('3plqtekcrjog', 'wsxeps', '2019-01-30 00:55:33', '2019-01-30 00:55:33', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('gmysw9n8h6ro', 'qp820f', '2019-01-30 00:55:35', '2019-01-30 00:55:35', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('gnh478qo9ky6', 'ew8pku', '2019-01-30 00:55:36', '2019-01-30 00:55:36', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('a8jmcuf4lj6k', 'spz3b5', '2019-01-30 00:55:37', '2019-01-30 00:55:37', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('cb6yi7p9u277', 'omop8l', '2019-01-30 00:55:38', '2019-01-30 00:55:48', '#!/bin/bash\nsleep 10s', '', 'kps1gf', 'Done'),
	('jdencmlfpjze', 'm6bbrf', '2019-01-30 00:55:50', '2019-01-30 00:55:50', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('6fhivn2kv5f', '7sb7xj', '2019-01-30 00:55:50', '2019-01-30 00:55:51', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'demo1.png', 'kps1gf', 'Done'),
	('b0nzlji02tr', 'vke2yf47hyot7ae7np7h', '2019-01-30 00:55:27', '2019-01-30 00:55:52', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'sc1tkbfbejy1;7zd894y3ovpz;fu1iolhr99ct;a7onz54pokrm;3plqtekcrjog;gmysw9n8h6ro;gnh478qo9ky6;a8jmcuf4lj6k;cb6yi7p9u277;jdencmlfpjze;6fhivn2kv5f;', 'kps1gf;', 'Done'),
	('zk59gwozlk04', '199vsg', '2019-01-31 15:32:18', '2019-01-31 15:32:33', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('swrr8iuvlha1', 'o634zj', '2019-01-31 15:32:34', '2019-01-31 15:32:42', '#!/bin/bash\n#write your bash script\necho "TestProcess 1"\nps -ef\npwd', 'TestProcess 1\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0  2018 ?        00:07:38 /lib/systemd/systemd --system --\nroot         2     0  0  2018 ?        00:00:18 [kthreadd]\nroot         7     2  0  2018 ?        00:00:00 [mm_percpu_wq]\nroot         8     2  0  2018 ?        00:00:50 [ksoftirqd/0]\nroot         9     2  0  2018 ?        02:22:32 [rcu_sched]\nroot        10     2  0  2018 ?        00:00:00 [rcu_bh]\nroot        11     2  0  2018 ?        00:00:14 [migration/0]\nroot        12     2  0  2018 ?        00:00:21 [watchdog/0]\nroot        13     2  0  2018 ?        00:00:00 [cpuhp/0]\nroot        14     2  0  2018 ?        00:00:00 [cpuhp/1]\nroot        15     2  0  2018 ?        00:00:28 [watchdog/1]\nroot        16     2  0  2018 ?        00:00:19 [migration/1]\nroot        17     2  0  2018 ?        00:00:07 [ksoftirqd/1]\nroot        19     2  0  2018 ?        00:00:00 [kworker/1:0H]\nroot        21     2  0  2018 ?        00:00:00 [cpuhp/2]\nroot        22     2  0  2018 ?        00:00:21 [watchdog/2]\nroot        23     2  0  2018 ?        00:00:04 [migration/2]\nroot        24     2  0  2018 ?        00:00:10 [ksoftirqd/2]\nroot        26     2  0  2018 ?        00:00:00 [kworker/2:0H]\nroot        27     2  0  2018 ?        00:00:00 [cpuhp/3]\nroot        28     2  0  2018 ?        00:00:23 [watchdog/3]\nroot        29     2  0  2018 ?        00:00:04 [migration/3]\nroot        30     2  0  2018 ?        00:00:05 [ksoftirqd/3]\nroot        32     2  0  2018 ?        00:00:00 [kworker/3:0H]\nroot        33     2  0  2018 ?        00:00:00 [cpuhp/4]\nroot        34     2  0  2018 ?        00:00:20 [watchdog/4]\nroot        35     2  0  2018 ?        00:00:02 [migration/4]\nroot        36     2  0  2018 ?        00:00:11 [ksoftirqd/4]\nroot        38     2  0  2018 ?        00:00:00 [kworker/4:0H]\nroot        39     2  0  2018 ?        00:00:00 [cpuhp/5]\nroot        40     2  0  2018 ?        00:00:21 [watchdog/5]\nroot        41     2  0  2018 ?        00:00:02 [migration/5]\nroot        42     2  0  2018 ?        00:00:04 [ksoftirqd/5]\nroot        44     2  0  2018 ?        00:00:00 [kworker/5:0H]\nroot        45     2  0  2018 ?        00:00:00 [cpuhp/6]\nroot        46     2  0  2018 ?        00:00:19 [watchdog/6]\nroot        47     2  0  2018 ?        00:00:01 [migration/6]\nroot        48     2  0  2018 ?        00:00:05 [ksoftirqd/6]\nroot        50     2  0  2018 ?        00:00:00 [kworker/6:0H]\nroot        51     2  0  2018 ?        00:00:00 [cpuhp/7]\nroot        52     2  0  2018 ?        00:00:21 [watchdog/7]\nroot        53     2  0  2018 ?        00:00:01 [migration/7]\nroot        54     2  0  2018 ?        00:00:03 [ksoftirqd/7]\nroot        56     2  0  2018 ?        00:00:00 [kworker/7:0H]\nroot        57     2  0  2018 ?        00:00:00 [cpuhp/8]\nroot        58     2  0  2018 ?        00:00:19 [watchdog/8]\nroot        59     2  0  2018 ?        00:00:01 [migration/8]\nroot        60     2  0  2018 ?        00:00:05 [ksoftirqd/8]\nroot        62     2  0  2018 ?        00:00:00 [kworker/8:0H]\nroot        63     2  0  2018 ?        00:00:00 [cpuhp/9]\nroot        64     2  0  2018 ?        00:00:20 [watchdog/9]\nroot        65     2  0  2018 ?        00:00:01 [migration/9]\nroot        66     2  0  2018 ?        00:00:02 [ksoftirqd/9]\nroot        68     2  0  2018 ?        00:00:00 [kworker/9:0H]\nroot        69     2  0  2018 ?        00:00:00 [cpuhp/10]\nroot        70     2  0  2018 ?        00:00:18 [watchdog/10]\nroot        71     2  0  2018 ?        00:00:01 [migration/10]\nroot        72     2  0  2018 ?        00:00:04 [ksoftirqd/10]\nroot        74     2  0  2018 ?        00:00:00 [kworker/10:0H]\nroot        75     2  0  2018 ?        00:00:00 [cpuhp/11]\nroot        76     2  0  2018 ?        00:00:20 [watchdog/11]\nroot        77     2  0  2018 ?        00:00:01 [migration/11]\nroot        78     2  0  2018 ?        00:00:02 [ksoftirqd/11]\nroot        80     2  0  2018 ?        00:00:00 [kworker/11:0H]\nroot        81     2  0  2018 ?        00:00:00 [cpuhp/12]\nroot        82     2  0  2018 ?        00:00:18 [watchdog/12]\nroot        83     2  0  2018 ?        00:00:01 [migration/12]\nroot        84     2  0  2018 ?        00:00:04 [ksoftirqd/12]\nroot        86     2  0  2018 ?        00:00:00 [kworker/12:0H]\nroot        87     2  0  2018 ?        00:00:00 [cpuhp/13]\nroot        88     2  0  2018 ?        00:00:18 [watchdog/13]\nroot        89     2  0  2018 ?        00:00:01 [migration/13]\nroot        90     2  0  2018 ?        00:00:02 [ksoftirqd/13]\nroot        92     2  0  2018 ?        00:00:00 [kworker/13:0H]\nroot        93     2  0  2018 ?        00:00:00 [cpuhp/14]\nroot        94     2  0  2018 ?        00:00:19 [watchdog/14]\nroot        95     2  0  2018 ?        00:00:01 [migration/14]\nroot        96     2  0  2018 ?        00:00:05 [ksoftirqd/14]\nroot        98     2  0  2018 ?        00:00:00 [kworker/14:0H]\nroot        99     2  0  2018 ?        00:00:00 [cpuhp/15]\nroot       100     2  0  2018 ?        00:00:20 [watchdog/15]\nroot       101     2  0  2018 ?        00:00:01 [migration/15]\nroot       102     2  0  2018 ?        00:00:02 [ksoftirqd/15]\nroot       104     2  0  2018 ?        00:00:00 [kworker/15:0H]\nroot       105     2  0  2018 ?        00:00:00 [cpuhp/16]\nroot       106     2  0  2018 ?        00:00:18 [watchdog/16]\nroot       107     2  0  2018 ?        00:00:01 [migration/16]\nroot       108     2  0  2018 ?        00:00:23 [ksoftirqd/16]\nroot       110     2  0  2018 ?        00:00:00 [kworker/16:0H]\nroot       111     2  0  2018 ?        00:00:00 [cpuhp/17]\nroot       112     2  0  2018 ?        00:00:20 [watchdog/17]\nroot       113     2  0  2018 ?        00:00:01 [migration/17]\nroot       114     2  0  2018 ?        00:00:02 [ksoftirqd/17]\nroot       116     2  0  2018 ?        00:00:00 [kworker/17:0H]\nroot       117     2  0  2018 ?        00:00:00 [cpuhp/18]\nroot       118     2  0  2018 ?        00:00:18 [watchdog/18]\nroot       119     2  0  2018 ?        00:00:01 [migration/18]\nroot       120     2  0  2018 ?        00:04:26 [ksoftirqd/18]\nroot       122     2  0  2018 ?        00:00:00 [kworker/18:0H]\nroot       123     2  0  2018 ?        00:00:00 [cpuhp/19]\nroot       124     2  0  2018 ?        00:00:20 [watchdog/19]\nroot       125     2  0  2018 ?        00:00:01 [migration/19]\nroot       126     2  0  2018 ?        00:00:02 [ksoftirqd/19]\nroot       128     2  0  2018 ?        00:00:00 [kworker/19:0H]\nroot       129     2  0  2018 ?        00:00:00 [cpuhp/20]\nroot       130     2  0  2018 ?        00:00:18 [watchdog/20]\nroot       131     2  0  2018 ?        00:00:01 [migration/20]\nroot       132     2  0  2018 ?        00:00:05 [ksoftirqd/20]\nroot       134     2  0  2018 ?        00:00:00 [kworker/20:0H]\nroot       135     2  0  2018 ?        00:00:00 [cpuhp/21]\nroot       136     2  0  2018 ?        00:00:20 [watchdog/21]\nroot       137     2  0  2018 ?        00:00:00 [migration/21]\nroot       138     2  0  2018 ?        00:00:01 [ksoftirqd/21]\nroot       140     2  0  2018 ?        00:00:00 [kworker/21:0H]\nroot       141     2  0  2018 ?        00:00:00 [cpuhp/22]\nroot       142     2  0  2018 ?        00:00:17 [watchdog/22]\nroot       143     2  0  2018 ?        00:00:01 [migration/22]\nroot       144     2  0  2018 ?        00:00:09 [ksoftirqd/22]\nroot       146     2  0  2018 ?        00:00:00 [kworker/22:0H]\nroot       147     2  0  2018 ?        00:00:00 [cpuhp/23]\nroot       148     2  0  2018 ?        00:00:20 [watchdog/23]\nroot       149     2  0  2018 ?        00:00:00 [migration/23]\nroot       150     2  0  2018 ?        00:00:02 [ksoftirqd/23]\nroot       152     2  0  2018 ?        00:00:00 [kworker/23:0H]\nroot       153     2  0  2018 ?        00:00:00 [cpuhp/24]\nroot       154     2  0  2018 ?        00:00:16 [watchdog/24]\nroot       155     2  0  2018 ?        00:00:01 [migration/24]\nroot       156     2  0  2018 ?        00:00:47 [ksoftirqd/24]\nroot       159     2  0  2018 ?        00:00:00 [cpuhp/25]\nroot       160     2  0  2018 ?        00:00:16 [watchdog/25]\nroot       161     2  0  2018 ?        00:00:01 [migration/25]\nroot       162     2  0  2018 ?        00:00:02 [ksoftirqd/25]\nroot       164     2  0  2018 ?        00:00:00 [kworker/25:0H]\nroot       165     2  0  2018 ?        00:00:00 [cpuhp/26]\nroot       166     2  0  2018 ?        00:00:16 [watchdog/26]\nroot       167     2  0  2018 ?        00:00:01 [migration/26]\nroot       168     2  0  2018 ?        00:03:31 [ksoftirqd/26]\nroot       170     2  0  2018 ?        00:00:00 [kworker/26:0H]\nroot       171     2  0  2018 ?        00:00:00 [cpuhp/27]\nroot       172     2  0  2018 ?        00:00:18 [watchdog/27]\nroot       173     2  0  2018 ?        00:00:00 [migration/27]\nroot       174     2  0  2018 ?        00:00:02 [ksoftirqd/27]\nroot       176     2  0  2018 ?        00:00:00 [kworker/27:0H]\nroot       177     2  0  2018 ?        00:00:00 [cpuhp/28]\nroot       178     2  0  2018 ?        00:00:16 [watchdog/28]\nroot       179     2  0  2018 ?        00:00:01 [migration/28]\nroot       180     2  0  2018 ?        00:00:05 [ksoftirqd/28]\nroot       182     2  0  2018 ?        00:00:00 [kworker/28:0H]\nroot       183     2  0  2018 ?        00:00:00 [cpuhp/29]\nroot       184     2  0  2018 ?        00:00:17 [watchdog/29]\nroot       185     2  0  2018 ?        00:00:00 [migration/29]\nroot       186     2  0  2018 ?        00:00:02 [ksoftirqd/29]\nroot       188     2  0  2018 ?        00:00:00 [kworker/29:0H]\nroot       189     2  0  2018 ?        00:00:00 [cpuhp/30]\nroot       190     2  0  2018 ?        00:00:17 [watchdog/30]\nroot       191     2  0  2018 ?        00:00:01 [migration/30]\nroot       192     2  0  2018 ?        00:00:09 [ksoftirqd/30]\nroot       195     2  0  2018 ?        00:00:00 [cpuhp/31]\nroot       196     2  0  2018 ?        00:00:17 [watchdog/31]\nroot       197     2  0  2018 ?        00:00:00 [migration/31]\nroot       198     2  0  2018 ?        00:00:02 [ksoftirqd/31]\nroot       200     2  0  2018 ?        00:00:00 [kworker/31:0H]\nroot       201     2  0  2018 ?        00:00:00 [cpuhp/32]\nroot       202     2  0  2018 ?        00:00:16 [watchdog/32]\nroot       203     2  0  2018 ?        00:00:01 [migration/32]\nroot       204     2  0  2018 ?        00:00:27 [ksoftirqd/32]\nroot       206     2  0  2018 ?        00:00:00 [kworker/32:0H]\nroot       207     2  0  2018 ?        00:00:00 [cpuhp/33]\nroot       208     2  0  2018 ?        00:00:17 [watchdog/33]\nroot       209     2  0  2018 ?        00:00:00 [migration/33]\nroot       210     2  0  2018 ?        00:00:02 [ksoftirqd/33]\nroot       212     2  0  2018 ?        00:00:00 [kworker/33:0H]\nroot       213     2  0  2018 ?        00:00:00 [cpuhp/34]\nroot       214     2  0  2018 ?        00:00:17 [watchdog/34]\nroot       215     2  0  2018 ?        00:00:00 [migration/34]\nroot       216     2  0  2018 ?        00:00:07 [ksoftirqd/34]\nroot       218     2  0  2018 ?        00:00:00 [kworker/34:0H]\nroot       219     2  0  2018 ?        00:00:00 [cpuhp/35]\nroot       220     2  0  2018 ?        00:00:17 [watchdog/35]\nroot       221     2  0  2018 ?        00:00:00 [migration/35]\nroot       222     2  0  2018 ?        00:00:01 [ksoftirqd/35]\nroot       224     2  0  2018 ?        00:00:00 [kworker/35:0H]\nroot       225     2  0  2018 ?        00:00:00 [cpuhp/36]\nroot       226     2  0  2018 ?        00:00:17 [watchdog/36]\nroot       227     2  0  2018 ?        00:00:00 [migration/36]\nroot       228     2  0  2018 ?        00:00:19 [ksoftirqd/36]\nroot       230     2  0  2018 ?        00:00:00 [kworker/36:0H]\nroot       231     2  0  2018 ?        00:00:00 [cpuhp/37]\nroot       232     2  0  2018 ?        00:00:19 [watchdog/37]\nroot       233     2  0  2018 ?        00:00:00 [migration/37]\nroot       234     2  0  2018 ?        00:00:02 [ksoftirqd/37]\nroot       236     2  0  2018 ?        00:00:00 [kworker/37:0H]\nroot       237     2  0  2018 ?        00:00:00 [cpuhp/38]\nroot       238     2  0  2018 ?        00:00:16 [watchdog/38]\nroot       239     2  0  2018 ?        00:00:00 [migration/38]\nroot       240     2  0  2018 ?        00:00:05 [ksoftirqd/38]\nroot       242     2  0  2018 ?        00:00:00 [kworker/38:0H]\nroot       243     2  0  2018 ?        00:00:00 [cpuhp/39]\nroot       244     2  0  2018 ?        00:00:18 [watchdog/39]\nroot       245     2  0  2018 ?        00:00:00 [migration/39]\nroot       246     2  0  2018 ?        00:00:02 [ksoftirqd/39]\nroot       248     2  0  2018 ?        00:00:00 [kworker/39:0H]\nroot       249     2  0  2018 ?        00:00:00 [cpuhp/40]\nroot       250     2  0  2018 ?        00:00:16 [watchdog/40]\nroot       251     2  0  2018 ?        00:00:00 [migration/40]\nroot       252     2  0  2018 ?        00:00:06 [ksoftirqd/40]\nroot       254     2  0  2018 ?        00:00:00 [kworker/40:0H]\nroot       255     2  0  2018 ?        00:00:00 [cpuhp/41]\nroot       256     2  0  2018 ?        00:00:16 [watchdog/41]\nroot       257     2  0  2018 ?        00:00:00 [migration/41]\nroot       258     2  0  2018 ?        00:00:03 [ksoftirqd/41]\nroot       260     2  0  2018 ?        00:00:00 [kworker/41:0H]\nroot       261     2  0  2018 ?        00:00:00 [cpuhp/42]\nroot       262     2  0  2018 ?        00:00:16 [watchdog/42]\nroot       263     2  0  2018 ?        00:00:00 [migration/42]\nroot       264     2  0  2018 ?        00:00:38 [ksoftirqd/42]\nroot       266     2  0  2018 ?        00:00:00 [kworker/42:0H]\nroot       267     2  0  2018 ?        00:00:00 [cpuhp/43]\nroot       268     2  0  2018 ?        00:00:17 [watchdog/43]\nroot       269     2  0  2018 ?        00:00:00 [migration/43]\nroot       270     2  0  2018 ?        00:00:02 [ksoftirqd/43]\nroot       272     2  0  2018 ?        00:00:00 [kworker/43:0H]\nroot       273     2  0  2018 ?        00:00:00 [cpuhp/44]\nroot       274     2  0  2018 ?        00:00:16 [watchdog/44]\nroot       275     2  0  2018 ?        00:00:00 [migration/44]\nroot       276     2  0  2018 ?        00:00:30 [ksoftirqd/44]\nroot       279     2  0  2018 ?        00:00:00 [cpuhp/45]\nroot       280     2  0  2018 ?        00:00:18 [watchdog/45]\nroot       281     2  0  2018 ?        00:00:00 [migration/45]\nroot       282     2  0  2018 ?        00:00:02 [ksoftirqd/45]\nroot       284     2  0  2018 ?        00:00:00 [kworker/45:0H]\nroot       285     2  0  2018 ?        00:00:00 [cpuhp/46]\nroot       286     2  0  2018 ?        00:00:17 [watchdog/46]\nroot       287     2  0  2018 ?        00:00:00 [migration/46]\nroot       288     2  0  2018 ?        00:03:12 [ksoftirqd/46]\nroot       290     2  0  2018 ?        00:00:00 [kworker/46:0H]\nroot       291     2  0  2018 ?        00:00:00 [cpuhp/47]\nroot       292     2  0  2018 ?        00:00:17 [watchdog/47]\nroot       293     2  0  2018 ?        00:00:00 [migration/47]\nroot       294     2  0  2018 ?        00:00:02 [ksoftirqd/47]\nroot       296     2  0  2018 ?        00:00:00 [kworker/47:0H]\nroot       297     2  0  2018 ?        00:00:00 [kdevtmpfs]\nroot       298     2  0  2018 ?        00:00:00 [netns]\nroot       299     2  0  2018 ?        00:00:00 [rcu_tasks_kthre]\nroot       300     2  0  2018 ?        00:00:00 [kauditd]\nroot       305     2  0  2018 ?        00:00:21 [khungtaskd]\nroot       306     2  0  2018 ?        00:00:38 [oom_reaper]\nroot       307     2  0  2018 ?        00:00:00 [writeback]\nroot       308     2  0  2018 ?        00:00:00 [kcompactd0]\nroot       309     2  0  2018 ?        00:00:00 [kcompactd1]\nroot       310     2  0  2018 ?        14:07:02 [ksmd]\nroot       311     2  0  2018 ?        00:01:17 [khugepaged]\nroot       312     2  0  2018 ?        00:00:00 [crypto]\nroot       313     2  0  2018 ?        00:00:00 [kintegrityd]\nroot       314     2  0  2018 ?        00:00:00 [kblockd]\nroot       360     2  0  2018 ?        00:00:00 [ata_sff]\nroot       361     2  0  2018 ?        00:00:00 [md]\nroot       362     2  0  2018 ?        00:00:00 [edac-poller]\nroot       363     2  0  2018 ?        00:00:00 [devfreq_wq]\nroot       364     2  0  2018 ?        00:00:00 [watchdogd]\nroot       367     2  0  2018 ?        00:07:37 [kswapd0]\nroot       368     2  0  2018 ?        00:05:22 [kswapd1]\nroot       369     2  0  2018 ?        00:00:00 [ecryptfs-kthrea]\nroot       411     2  0  2018 ?        00:00:00 [kthrotld]\nroot       412     2  0  2018 ?        00:00:00 [acpi_thermal_pm]\nroot       416     2  0  2018 ?        00:00:00 [ipv6_addrconf]\nroot       425     2  0  2018 ?        00:00:00 [kstrp]\nroot       448     2  0  2018 ?        00:00:00 [charger_manager]\nroot       571     2  0  2018 ?        00:00:00 [scsi_eh_0]\nroot       572     2  0  2018 ?        00:00:00 [scsi_tmf_0]\nroot       573     2  0  2018 ?        00:00:00 [scsi_eh_1]\nroot       574     2  0  2018 ?        00:00:00 [scsi_tmf_1]\nroot       575     2  0  2018 ?        00:00:00 [scsi_eh_2]\nroot       576     2  0  2018 ?        00:00:00 [scsi_tmf_2]\nroot       577     2  0  2018 ?        00:00:00 [scsi_eh_3]\nroot       578     2  0  2018 ?        00:00:00 [scsi_tmf_3]\nroot       579     2  0  2018 ?        00:00:00 [scsi_eh_4]\nroot       580     2  0  2018 ?        00:00:00 [scsi_tmf_4]\nroot       581     2  0  2018 ?        00:00:00 [scsi_eh_5]\nroot       582     2  0  2018 ?        00:00:00 [scsi_tmf_5]\nroot       583     2  0  2018 ?        00:00:00 [scsi_eh_6]\nroot       584     2  0  2018 ?        00:00:00 [scsi_tmf_6]\nroot       592     2  0  2018 ?        00:00:00 [bnxt_pf_wq]\nroot       594     2  0  2018 ?        00:00:00 [scsi_eh_7]\nroot       595     2  0  2018 ?        00:00:00 [scsi_tmf_7]\nroot       596     2  0  2018 ?        00:00:00 [scsi_eh_8]\nroot       597     2  0  2018 ?        00:00:00 [scsi_tmf_8]\nroot       598     2  0  2018 ?        00:00:00 [scsi_eh_9]\nroot       600     2  0  2018 ?        00:00:00 [scsi_tmf_9]\nroot       601     2  0  2018 ?        00:00:00 [scsi_eh_10]\nroot       602     2  0  2018 ?        00:00:00 [scsi_tmf_10]\nroot       603     2  0  2018 ?        00:00:00 [scsi_eh_11]\nroot       604     2  0  2018 ?        00:00:00 [scsi_tmf_11]\nroot       605     2  0  2018 ?        00:00:00 [scsi_eh_12]\nroot       606     2  0  2018 ?        00:00:00 [scsi_tmf_12]\nroot       607     2  0  2018 ?        00:00:00 [scsi_eh_13]\nroot       608     2  0  2018 ?        00:00:00 [scsi_tmf_13]\nroot       609     2  0  2018 ?        00:00:00 [scsi_eh_14]\nroot       610     2  0  2018 ?        00:00:00 [scsi_tmf_14]\nroot       636     2  0  2018 ?        00:00:12 [kworker/34:1H]\nroot       638     2  0  2018 ?        00:00:12 [kworker/24:1H]\nroot       643     2  0 Jan29 ?        00:00:00 [kworker/u96:2]\nroot       660     2  0  2018 ?        00:01:56 [kworker/30:1H]\nroot       668     2  0  2018 ?        00:00:00 [ttm_swap]\nroot       671     2  0  2018 ?        00:00:03 [kworker/45:1H]\nroot       672     2  0  2018 ?        00:00:03 [kworker/21:1H]\nroot       674     2  0  2018 ?        00:00:03 [kworker/27:1H]\nroot       676     2  0  2018 ?        00:00:03 [kworker/37:1H]\nroot       689     2  0  2018 ?        00:00:03 [kworker/43:1H]\nroot       691     2  0  2018 ?        00:00:00 [nvidia-modeset]\nroot       757     2  0  2018 ?        00:00:00 [raid5wq]\nroot       790     2  0  2018 ?        00:00:12 [kworker/36:1H]\nroot       799     2  0  2018 ?        00:00:04 [kworker/41:1H]\nroot       808     2  0  2018 ?        00:00:04 [kworker/47:1H]\nroot       809     2  0  2018 ?        00:05:15 [jbd2/sda2-8]\nroot       810     2  0  2018 ?        00:00:00 [ext4-rsv-conver]\nroot       812     2  0  2018 ?        00:00:04 [kworker/3:1H]\nroot       813     2  0  2018 ?        00:00:03 [kworker/17:1H]\nroot       828     2  0  2018 ?        00:00:03 [kworker/11:1H]\nroot       829     2  0  2018 ?        00:00:03 [kworker/29:1H]\nroot       839     2  0  2018 ?        00:00:03 [kworker/19:1H]\nroot       843     2  0  2018 ?        00:00:03 [kworker/33:1H]\nroot       847     2  0  2018 ?        00:00:10 [kworker/12:1H]\nroot       849     2  0  2018 ?        00:00:03 [kworker/31:1H]\nroot       865     2  0  2018 ?        00:00:03 [kworker/23:1H]\nroot       866     2  0  2018 ?        00:00:03 [kworker/35:1H]\nroot       870     2  0  2018 ?        00:00:03 [kworker/39:1H]\nroot       871     2  0  2018 ?        00:00:03 [kworker/15:1H]\nroot       875     2  0  2018 ?        00:00:15 [kworker/4:1H]\nroot       882     2  0  2018 ?        00:00:22 [kworker/2:1H]\nroot       884     2  0  2018 ?        00:00:05 [kworker/1:1H]\nroot       885     2  0  2018 ?        00:00:02 [kworker/25:1H]\nroot       887     2  0  2018 ?        00:00:10 [kworker/8:1H]\nroot       892     2  0  2018 ?        00:00:11 [kworker/26:1H]\nroot       899     2  0  2018 ?        00:00:03 [kworker/9:1H]\nroot       904     2  0  2018 ?        00:00:19 [kworker/16:1H]\nroot       911     2  0  2018 ?        00:00:10 [kworker/20:1H]\nroot       912     2  0  2018 ?        00:00:14 [kworker/18:1H]\nroot       913     2  0  2018 ?        00:00:00 [iscsi_eh]\nroot       915     2  0  2018 ?        00:00:00 [ib-comp-wq]\nroot       916     2  0  2018 ?        00:00:00 [ib_mcast]\nroot       917     2  0  2018 ?        00:00:00 [ib_nl_sa_wq]\nroot       921     2  0  2018 ?        00:00:00 [rdma_cm]\nroot       924     2  0  2018 ?        00:00:00 [rpciod]\nroot       925     2  0  2018 ?        00:00:00 [xprtiod]\nroot       926     2  0  2018 ?        00:00:11 [kworker/6:1H]\nroot       934     1  0  2018 ?        00:00:00 /usr/sbin/blkmapd\nroot       935     1  0  2018 ?        00:00:00 /sbin/lvmetad -f\nroot       942     2  0  2018 ?        00:00:09 [kworker/14:1H]\nroot       958     2  0  2018 ?        00:00:10 [kworker/28:1H]\nroot      1071     2  0  2018 ?        00:00:03 [kworker/13:1H]\nroot      1077     2  0  2018 ?        00:00:21 [kworker/32:1H]\nroot      1078     2  0  2018 ?        00:00:09 [kworker/40:1H]\nroot      1092     2  0  2018 ?        00:00:18 [kworker/42:1H]\nroot      1110     2  0  2018 ?        00:00:00 [UVM global queu]\nroot      1111     2  0  2018 ?        00:00:00 [UVM Tools Event]\nroot      1121     2  0  2018 ?        00:00:00 [irq/245-mei_me]\nroot      1123     2  0  2018 ?        00:00:10 [kworker/10:1H]\nwww-data  1190 47081  0 06:25 ?        00:00:00 /usr/sbin/apache2 -k start\nwww-data  1191 47081  0 06:25 ?        00:00:00 /usr/sbin/apache2 -k start\nroot      1435     1  0  2018 ?        00:00:15 /sbin/rpcbind -f -w\nroot      1440     1  0  2018 ?        00:00:00 /usr/sbin/rpc.idmapd\nroot      1489     1  0  2018 ?        00:00:15 /usr/sbin/rpc.mountd -p 892 --ma\nroot      1492     2  0  2018 ?        00:00:04 [kworker/7:1H]\nroot      1493     2  0  2018 ?        00:00:00 [lockd]\nroot      1495     2  0  2018 ?        00:00:13 [nfsd]\nroot      1496     2  0  2018 ?        00:00:16 [nfsd]\nroot      1497     2  0  2018 ?        00:00:24 [nfsd]\nroot      1498     2  0  2018 ?        00:00:38 [nfsd]\nroot      1499     2  0  2018 ?        00:01:04 [nfsd]\nroot      1500     2  0  2018 ?        00:01:41 [nfsd]\nroot      1501     2  0  2018 ?        00:04:40 [nfsd]\nroot      1502     2  0  2018 ?        00:13:11 [nfsd]\nroot      1595     1  0  2018 ?        00:03:05 /sbin/iscsid\nroot      1597     1  0  2018 ?        00:00:00 /sbin/iscsid\nroot      1602     1  0  2018 ?        00:01:21 /usr/sbin/cron -f\nroot      1618     1  0  2018 ?        00:00:00 /usr/bin/python3 /usr/bin/networ\nroot      1631     1  0  2018 ?        00:02:03 /usr/bin/lxcfs /var/lib/lxcfs/\nroot      1655     1  0  2018 ?        01:50:21 /usr/sbin/irqbalance --foregroun\nroot      1681     1  0  2018 ?        00:17:25 /usr/sbin/atopacctd\nsyslog    1694     1  0  2018 ?        00:18:22 /usr/sbin/rsyslogd -n\nmessage+  1701     1  0  2018 ?        00:05:04 /usr/bin/dbus-daemon --system --\nroot      1764     1  0  2018 ?        00:00:34 /lib/systemd/systemd-logind\ndaemon    1791     1  0  2018 ?        00:00:00 /usr/sbin/atd -f\nroot      1801     1  0  2018 ?        00:16:17 /usr/lib/accountsservice/account\nroot      1813     2  0 18:20 ?        00:00:00 [kworker/8:2]\nroot      1962     1  0  2018 tty1     00:00:00 /sbin/agetty -o -p -- \\u --nocle\nlibvirt+  2385     1  0  2018 ?        00:00:23 /usr/sbin/dnsmasq --conf-file=/v\nroot      2386  2385  0  2018 ?        00:00:00 /usr/sbin/dnsmasq --conf-file=/v\nroot      5630     2  0  2018 ?        00:00:00 [loop3]\nroot      6497     2  0 06:39 ?        00:00:00 [kworker/39:2]\nroot      8108     2  0  2018 ?        00:00:00 [nfsiod]\nstatd     8160     1  0  2018 ?        00:00:00 /sbin/rpc.statd --no-notify --po\nroot      8727     2  0 19:13 ?        00:00:04 [kworker/41:1]\nroot      9092     2  0  2018 ?        00:00:00 [NFSv4 callback]\nroot      9404     2  0 Jan10 ?        00:00:05 [kworker/0:1H]\nroot      9412     2  0 Jan23 ?        00:00:00 [kworker/u96:1]\nroot      9518     1 10 Jan29 ?        04:36:22 qemu-system-x86_64 -enable-kvm -\nroot      9530     2  0 Jan29 ?        00:00:31 [vhost-9518]\nroot      9537     2  0 Jan29 ?        00:00:00 [kvm-pit/9518]\nroot      9965     2  0 19:22 ?        00:00:05 [kworker/22:2]\nroot     10922     2  0 19:30 ?        00:00:01 [kworker/41:0]\nroot     12123     2  0 19:39 ?        00:00:00 [kworker/46:2]\nroot     12148     2  0 19:39 ?        00:00:00 [kworker/33:0]\nroot     12163     2  0 19:39 ?        00:00:00 [kworker/9:0]\nroot     12183     2  0 19:39 ?        00:00:00 [kworker/26:1]\nroot     12994     2  0 19:46 ?        00:00:02 [kworker/22:3]\nroot     13251     1 99 Jan23 ?        19-00:17:38 qemu-system-x86_64 -enable-kv\nroot     13265     2  0 Jan23 ?        00:01:00 [vhost-13251]\nroot     13272     2  0 Jan23 ?        00:00:00 [kvm-pit/13251]\nroot     13505     2  0 01:48 ?        00:00:01 [kworker/26:0]\nroot     13772     2  0 19:56 ?        00:00:01 [kworker/u97:0]\nroot     13892     2  0 19:56 ?        00:00:01 [kworker/22:0]\nroot     13908     1 10  2018 ?        5-02:04:07 qemu-system-x86_64 -enable-kvm\nroot     13916     2  0 19:57 ?        00:00:02 [kworker/41:2]\nroot     13921     2  0  2018 ?        00:02:28 [vhost-13908]\nroot     13923     2  0  2018 ?        00:00:04 [vhost-13908]\nroot     13928     2  0  2018 ?        00:00:00 [kvm-pit/13908]\nroot     13943     2  0 19:57 ?        00:00:01 [kworker/22:1]\nroot     14390     2  0 19:59 ?        00:00:00 [kworker/33:1]\nroot     14427     2  0 Jan10 ?        00:00:09 [kworker/46:2H]\nroot     14570     2  0 20:01 ?        00:00:00 [kworker/27:3]\nroot     14578     2  0 20:01 ?        00:00:00 [kworker/27:4]\nroot     14616     2  0 20:01 ?        00:00:00 [kworker/19:14]\nroot     14617     2  0 20:01 ?        00:00:00 [kworker/19:15]\nroot     14624     2  0 20:01 ?        00:00:00 [kworker/43:18]\nroot     14630     2  0 20:01 ?        00:00:00 [kworker/17:4]\nroot     14631     2  0 20:01 ?        00:00:00 [kworker/17:5]\nroot     14663     2  0 20:01 ?        00:00:01 [kworker/13:41]\nroot     14665     2  0 20:01 ?        00:00:00 [kworker/13:43]\nroot     14667     2  0 20:01 ?        00:00:01 [kworker/13:44]\nroot     14687     2  0 20:01 ?        00:00:00 [kworker/31:4]\nroot     14691     2  0 20:01 ?        00:00:00 [kworker/7:17]\nroot     14695     2  0 20:01 ?        00:00:00 [kworker/31:5]\nroot     14700     2  0 20:01 ?        00:00:00 [kworker/3:25]\nroot     14704     2  0 20:01 ?        00:00:00 [kworker/35:0]\nroot     14706     2  0 20:01 ?        00:00:00 [kworker/35:3]\nroot     14919     2  0 20:02 ?        00:00:00 [kworker/20:1]\nroot     15159     2  0 20:04 ?        00:00:00 [kworker/34:2]\nroot     15188     1 10 Jan10 ?        2-05:59:43 qemu-system-x86_64 -enable-kvm\nroot     15199     2  0 Jan10 ?        00:02:30 [vhost-15188]\nroot     15203     2  0 Jan10 ?        00:00:00 [kvm-pit/15188]\nroot     15208     2  0 20:05 ?        00:00:00 [kworker/47:4]\nroot     15210     2  0 20:05 ?        00:00:00 [kworker/21:9]\nroot     15471     2  0 20:07 ?        00:00:00 [kworker/46:0]\nroot     15575     2  0 20:08 ?        00:00:00 [kworker/3:0]\nroot     15669     2  0 20:09 ?        00:00:00 [kworker/42:3]\nroot     15670     2  0 20:09 ?        00:00:00 [kworker/42:4]\nroot     15671     2  0 20:09 ?        00:00:00 [kworker/18:5]\nroot     15673     2  0 20:09 ?        00:00:00 [kworker/18:6]\nroot     15861     2  0 20:10 ?        00:00:00 [kworker/41:4]\nroot     15868     2  0 20:10 ?        00:00:00 [kworker/21:0]\nroot     15904     2  0 20:10 ?        00:00:00 [kworker/9:2]\nroot     15954     2  0 20:10 ?        00:00:00 [kworker/37:0]\nroot     15955     2  0 20:10 ?        00:00:00 [kworker/37:1]\nroot     16093     2  0 20:11 ?        00:00:00 [kworker/u98:0]\nroot     16164     2  0 20:12 ?        00:00:00 [kworker/8:3]\nroot     16183     2  0 20:12 ?        00:00:00 [kworker/7:2]\nroot     16185     2  0 20:12 ?        00:00:00 [kworker/36:6]\nroot     16298     2  0 20:13 ?        00:00:00 [kworker/47:0]\nroot     16336     2  0 20:13 ?        00:00:00 [kworker/34:1]\nroot     16529     2  0 20:14 ?        00:00:00 [kworker/30:0]\nroot     16531     2  0 20:14 ?        00:00:00 [kworker/30:2]\nroot     16536     2  0 20:14 ?        00:00:00 [kworker/6:7]\nroot     16540     2  0 20:14 ?        00:00:00 [kworker/32:2]\nroot     16541     2  0 20:14 ?        00:00:00 [kworker/32:3]\nroot     16546     2  0 20:14 ?        00:00:00 [kworker/2:5]\nroot     16547     2  0 20:14 ?        00:00:00 [kworker/2:6]\nroot     16560     2  0 20:14 ?        00:00:00 [kworker/24:2]\nroot     16564     2  0 20:14 ?        00:00:00 [kworker/24:3]\nroot     16566     2  0 20:14 ?        00:00:00 [kworker/38:3]\nroot     16579     2  0 20:14 ?        00:00:00 [kworker/14:11]\nroot     16581     2  0 20:14 ?        00:00:00 [kworker/14:12]\nroot     16623     2  0 20:15 ?        00:00:00 [kworker/28:5]\nroot     16624     2  0 20:15 ?        00:00:00 [kworker/4:15]\nroot     16638     2  0 20:15 ?        00:00:00 [kworker/28:6]\nroot     16647     2  0 20:15 ?        00:00:00 [kworker/10:12]\nroot     16648     2  0 20:15 ?        00:00:00 [kworker/6:10]\nroot     16655     2  0 20:15 ?        00:00:00 [kworker/10:13]\nroot     16675     2  0 20:15 ?        00:00:00 [kworker/0:6]\nroot     16677     2  0 20:15 ?        00:00:00 [kworker/0:7]\nroot     16678     2  0 20:15 ?        00:00:00 [kworker/0:8]\nroot     16679     2  0 20:15 ?        00:00:00 [kworker/0:9]\nroot     16680     2  0 20:15 ?        00:00:00 [kworker/0:10]\nroot     16681     2  0 20:15 ?        00:00:00 [kworker/0:11]\nroot     16851     2  0 20:16 ?        00:00:00 [kworker/43:1]\nroot     16857     2  0 20:16 ?        00:00:00 [kworker/44:5]\nroot     16858     2  0 20:16 ?        00:00:00 [kworker/44:6]\nroot     17183     2  0 20:18 ?        00:00:00 [kworker/16:13]\nroot     17187     2  0 20:18 ?        00:00:00 [kworker/40:7]\nroot     17188     2  0 20:18 ?        00:00:00 [kworker/40:8]\nroot     17189     2  0 20:18 ?        00:00:00 [kworker/16:14]\nroot     17190     2  0 20:18 ?        00:00:00 [kworker/36:1]\nroot     17194     2  0 20:18 ?        00:00:00 [kworker/12:14]\nroot     17202     2  0 20:19 ?        00:00:00 [kworker/12:15]\nroot     17208     2  0 20:19 ?        00:00:01 [kworker/12:16]\nroot     17209     2  0 20:19 ?        00:00:00 [kworker/12:17]\nroot     17266     2  0 20:19 ?        00:00:00 [kworker/11:2]\nroot     17267     2  0 20:19 ?        00:00:00 [kworker/11:3]\nroot     17269     2  0 20:19 ?        00:00:00 [kworker/1:14]\nroot     17273     2  0 20:19 ?        00:00:00 [kworker/25:40]\nroot     17274     2  0 20:19 ?        00:00:00 [kworker/25:41]\nroot     17275     2  0 20:19 ?        00:00:00 [kworker/1:15]\nroot     17285     2  0 20:19 ?        00:00:00 [kworker/5:10]\nroot     17293     2  0 20:19 ?        00:00:00 [kworker/29:12]\nroot     17299     2  0 Jan23 ?        00:00:03 [kworker/44:1H]\nroot     17300     2  0 20:19 ?        00:00:00 [kworker/29:13]\nroot     17500     1  9  2018 ?        3-23:16:24 qemu-system-x86_64 -enable-kvm\nroot     17512     2  0  2018 ?        00:02:07 [vhost-17500]\nroot     17519     2  0  2018 ?        00:00:00 [kvm-pit/17500]\nroot     17582     2  0 20:21 ?        00:00:00 [kworker/u98:3]\nroot     17673     2  0 Jan28 ?        00:00:00 [loop1]\nroot     17712     1  0 Jan28 ?        00:01:00 /usr/lib/snapd/snapd\nroot     17945     2  0 20:24 ?        00:00:00 [kworker/20:2]\nroot     17950     2  0 20:24 ?        00:00:00 [kworker/4:0]\nroot     17956     2  0 20:24 ?        00:00:00 [kworker/1:0]\nroot     17957     2  0 20:24 ?        00:00:00 [kworker/1:1]\nroot     17958     2  0 20:24 ?        00:00:00 [kworker/0:0]\nroot     17961     2  0 20:24 ?        00:00:00 [kworker/1:2]\nroot     17962     2  0 20:24 ?        00:00:00 [kworker/1:3]\nroot     17970     2  0 20:24 ?        00:00:00 [kworker/0:1]\nroot     17971     2  0 20:24 ?        00:00:00 [kworker/0:2]\nroot     17974     2  0 20:24 ?        00:00:00 [kworker/5:0]\nroot     17975     2  0 20:24 ?        00:00:00 [kworker/25:0]\nroot     17976     2  0 20:24 ?        00:00:00 [kworker/1:4]\nroot     17977     2  0 20:24 ?        00:00:00 [kworker/1:5]\nroot     17979     2  0 20:24 ?        00:00:00 [kworker/25:1]\nroot     18098     2  0 20:26 ?        00:00:00 [kworker/u97:1]\nroot     18118     2  0  2018 ?        00:00:00 [loop0]\nroot     18153     1  0 Jan17 ?        00:00:28 /usr/lib/policykit-1/polkitd --n\nroot     18280     2  0 20:27 ?        00:00:00 [kworker/40:0]\nroot     18287     2  0 20:27 ?        00:00:00 [kworker/7:0]\nroot     18344     2  0 20:27 ?        00:00:00 [kworker/28:0]\nroot     18396 45262  0 20:28 ?        00:00:00 sshd: ztan6 [priv]\nztan6    18398     1  0 20:28 ?        00:00:00 /lib/systemd/systemd --user\nztan6    18399 18398  0 20:28 ?        00:00:00 (sd-pam)\nztan6    18492 18396  0 20:28 ?        00:00:00 sshd: ztan6@pts/7\nztan6    18493 18492  0 20:28 pts/7    00:00:00 -bash\nroot     18562     2  0 20:29 ?        00:00:00 [kworker/35:1]\nroot     18563     2  0 20:29 ?        00:00:00 [kworker/34:0]\nroot     18564     2  0 20:29 ?        00:00:00 [kworker/34:3]\nroot     18568     2  0 20:29 ?        00:00:00 [kworker/34:4]\nroot     18569     2  0 20:29 ?        00:00:00 [kworker/34:5]\nroot     18570     2  0 20:29 ?        00:00:00 [kworker/34:6]\nroot     18571     2  0 20:29 ?        00:00:00 [kworker/34:7]\nroot     18574     2  0 20:29 ?        00:00:00 [kworker/2:0]\nroot     18583     2  0 20:29 ?        00:00:00 [kworker/0:3]\nroot     18584     2  0 20:29 ?        00:00:00 [kworker/0:4]\nroot     18585     2  0 20:29 ?        00:00:00 [kworker/34:8]\nroot     18657     2  0 20:30 ?        00:00:00 [kworker/13:0]\nroot     18794     2  0 20:31 ?        00:00:00 [kworker/8:0]\nroot     18795     2  0 20:31 ?        00:00:00 [kworker/8:1]\nroot     18796     2  0 20:31 ?        00:00:00 [kworker/8:4]\nroot     18797     2  0 20:31 ?        00:00:00 [kworker/8:5]\nroot     18798     2  0 20:31 ?        00:00:00 [kworker/8:6]\nroot     18799     2  0 20:31 ?        00:00:00 [kworker/8:7]\nroot     18800     2  0 20:31 ?        00:00:00 [kworker/8:8]\nroot     18801     2  0 20:31 ?        00:00:00 [kworker/8:9]\nroot     18802     2  0 20:31 ?        00:00:00 [kworker/8:10]\nroot     18803     2  0 20:31 ?        00:00:00 [kworker/14:0]\nroot     18804     2  0 20:31 ?        00:00:00 [kworker/14:1]\nroot     18805     2  0 20:31 ?        00:00:00 [kworker/14:2]\nroot     18806     2  0 20:31 ?        00:00:00 [kworker/14:3]\nroot     18807     2  0 20:31 ?        00:00:00 [kworker/12:0]\nroot     18808     2  0 20:31 ?        00:00:00 [kworker/41:3]\nroot     18809     2  0 20:31 ?        00:00:00 [kworker/13:1]\nroot     18810     2  0 20:31 ?        00:00:00 [kworker/22:4]\nroot     18811     2  0 20:31 ?        00:00:00 [kworker/26:2]\nztan6    18893 18493  0 20:32 pts/7    00:00:00 bash run.sh\nztan6    18895 18893 54 20:32 pts/7    00:00:11 python run.py --lr 8e-4 --num_wo\nroot     18899     2 13 20:32 ?        00:00:02 [irq/256-nvidia]\nroot     18900     2  0 20:32 ?        00:00:00 [nvidia]\nnvidia-+ 18910     1  0 20:32 ?        00:00:00 /usr/bin/nvidia-persistenced --u\nroot     18912     2  0 20:32 ?        00:00:00 [kworker/26:3]\nroot     18913     2  0 20:32 ?        00:00:00 [kworker/26:4]\nroot     18914     2  0 20:32 ?        00:00:00 [kworker/26:5]\nroot     18947     2 11 20:32 ?        00:00:02 [irq/257-nvidia]\nroot     18948     2  0 20:32 ?        00:00:00 [nvidia]\nroot     18970     2  0 20:32 ?        00:00:00 [kworker/30:1]\nroot     19022     2  0 20:32 ?        00:00:00 [kworker/10:0]\nroot     19023     2  0 20:32 ?        00:00:00 [kworker/10:1]\nroot     19026     2  0 20:32 ?        00:00:00 [kworker/10:2]\nroot     19027     2  0 20:32 ?        00:00:00 [kworker/26:6]\nroot     19028     2  0 20:32 ?        00:00:00 [kworker/10:3]\nroot     19029     2 18 20:32 ?        00:00:02 [irq/258-nvidia]\nroot     19030     2  0 20:32 ?        00:00:00 [nvidia]\nroot     19031     2  0 20:32 ?        00:00:00 [kworker/32:0]\nroot     19032 45262  0 20:32 ?        00:00:00 sshd: root [priv]\nsshd     19033 19032  0 20:32 ?        00:00:00 sshd: root [net]\nroot     19034     2  0 20:32 ?        00:00:00 [kworker/10:4]\nroot     19035     2 16 20:32 ?        00:00:02 [irq/259-nvidia]\nroot     19036     2  0 20:32 ?        00:00:00 [nvidia]\nroot     19037     2  0 20:32 ?        00:00:00 [kworker/5:1]\nroot     19038     2  0 20:32 ?        00:00:00 [kworker/1:6]\nroot     19047 45262  2 20:32 ?        00:00:00 sshd: zsun [priv]\nroot     19049     2  0 20:32 ?        00:00:00 [kworker/4:1]\nzsun     19050     1  3 20:32 ?        00:00:00 /lib/systemd/systemd --user\nzsun     19051 19050  0 20:32 ?        00:00:00 (sd-pam)\nzsun     19145 19047  0 20:32 ?        00:00:00 sshd: zsun@pts/10\nzsun     19146 19145  0 20:32 pts/10   00:00:00 bash -c echo "#!/bin/bash #write\nzsun     19148 19146  0 20:32 pts/10   00:00:00 /bin/bash ./geoweaver-xzhcyqhqci\nzsun     19149 19148  0 20:32 pts/10   00:00:00 ps -ef\nroot     20993     2  0 14:36 ?        00:00:00 [kworker/23:1]\nroot     21245     2  0 Jan20 ?        00:00:27 [kworker/24:0H]\nroot     21895 41673  0 Jan15 ?        00:00:01 /usr/bin/docker-proxy -proto tcp\nroot     21903 40529  0 Jan15 ?        00:01:24 containerd-shim -namespace moby \n999      21927 21903  0 Jan15 ?        00:17:00 mysqld\nroot     22041 41673  0 Jan15 ?        00:01:03 /usr/bin/docker-proxy -proto tcp\nroot     22060 40529  0 Jan15 ?        00:01:25 containerd-shim -namespace moby \nroot     22110 22060  0 Jan15 ?        01:06:00 /docker-java-home/jre/bin/java -\nroot     24934     1  0  2018 ?        00:00:00 /usr/sbin/virtlogd\nroot     29598     1  9  2018 ?        4-18:30:52 qemu-system-x86_64 -enable-kvm\nroot     29609     2  0  2018 ?        00:02:04 [vhost-29598]\nroot     29613     2  0  2018 ?        00:00:00 [kvm-pit/29598]\nroot     29798     1 99  2018 ?        50-22:21:55 qemu-system-x86_64 -enable-kv\nroot     29808     2  0  2018 ?        00:00:00 [vhost-29798]\nroot     29812     2  0  2018 ?        00:33:06 [kvm-pit/29798]\nroot     30386     2  0 Jan30 ?        00:00:00 [kworker/45:0]\nroot     30937     2  0 Jan23 ?        00:00:01 [kworker/38:2H]\nroot     31795     2  0 Jan18 ?        00:00:31 [kworker/30:2H]\nroot     32036     2  0 Jan30 ?        00:00:00 [kworker/45:1]\nroot     32317     2  0 Jan30 ?        00:00:00 [kworker/15:0]\nroot     32355     1  0 Jan12 ?        00:00:10 /lib/systemd/systemd-udevd\nroot     36344     2  0 Jan26 ?        00:00:00 [kworker/5:2H]\nroot     37013     2  0 16:36 ?        00:00:00 [kworker/u97:3]\nroot     37567     2  0 Jan30 ?        00:00:00 [kworker/23:3]\nroot     37635     1  0  2018 ?        02:31:13 /usr/sbin/libvirtd\nroot     37731     1 10  2018 ?        4-10:35:35 qemu-system-x86_64 -enable-kvm\nroot     37742     2  0  2018 ?        00:02:02 [vhost-37731]\nroot     37746     2  0  2018 ?        00:00:00 [kvm-pit/37731]\nroot     37799     2  0 Jan30 ?        00:00:00 [kworker/39:0]\nroot     37906     1  0  2018 ?        00:00:00 /bin/sh -ec      export ACP=`ls \nroot     37919 37906  0  2018 ?        02:18:19 /usr/bin/java -Djava.io.tmpdir=/\nroot     39032     2  0 Jan23 ?        00:00:09 [kworker/44:2H]\nroot     40529     1  0  2018 ?        13:04:13 /usr/bin/containerd\nsystemd+ 41071     1  0 Jan12 ?        00:00:16 /lib/systemd/systemd-networkd\nsystemd+ 41236     1  0 Jan12 ?        00:02:42 /lib/systemd/systemd-resolved\nsystemd+ 41248     1  0 Jan12 ?        00:00:06 /lib/systemd/systemd-timesyncd\nroot     41308     1  0 Jan12 ?        00:17:48 /lib/systemd/systemd-journald\nroot     41383     2  0 Jan30 ?        00:00:00 [kworker/15:2]\nzyu      41436     1  0  2018 ?        00:00:03 /lib/systemd/systemd --user\nzyu      41438 41436  0  2018 ?        00:00:00 (sd-pam)\nroot     41673     1  0  2018 ?        01:52:43 /usr/bin/dockerd -H unix://\nroot     44110     2  0 Jan10 ?        00:00:02 [kworker/0:2H]\nroot     44819     2  0 11:25 ?        00:00:00 [kworker/38:1]\nroot     45262     1  0  2018 ?        00:09:25 /usr/sbin/sshd -D\nzyu      46024     1  0 Jan22 ?        00:00:00 /home/zyu/miniconda3/envs/gee/bi\nroot     47081     1  0  2018 ?        00:02:05 /usr/sbin/apache2 -k start\nroot     47553     2  0 17:57 ?        00:00:00 [kworker/u98:1]\nroot     47620     1  0 00:00 ?        00:01:23 /usr/bin/atop -R -w /var/log/ato\nroot     48906     2  0 Jan29 ?        00:00:00 [kworker/22:2H]\n/home/zsun\n', 'kps1gf', 'Done'),
	('ke128jtq304q', 'ac4724', '2019-01-31 15:32:43', '2019-01-31 15:32:58', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('rytk9tyqltd', '7w0ga6df6x6xhex588pk', '2019-01-31 15:32:16', '2019-01-31 15:32:58', '199vsg-rQe87;o634zj-XHZMP;ac4724-K7xEA;', 'zk59gwozlk04;swrr8iuvlha1;ke128jtq304q;', 'kps1gf;', 'Done'),
	('4p7l9pdf8zp', '5k56d9vcx4ip3tr5pj26', '2019-01-31 16:53:45', '2019-01-31 16:55:16', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('s5kmstum8tz', '5k56d9vcx4ip3tr5pj26', '2019-01-31 17:31:22', '2019-01-31 17:32:52', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('jqu690ul7qz', '5k56d9vcx4ip3tr5pj26', '2019-01-31 17:49:50', '2019-01-31 17:51:21', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('uxxab1hcu9z', '5k56d9vcx4ip3tr5pj26', '2019-01-31 17:52:07', '2019-01-31 17:53:37', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('f0h4k4nvvqs', '5k56d9vcx4ip3tr5pj26', '2019-01-31 17:52:32', '2019-01-31 17:54:02', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('t9uopmdslsj', '7sb7xj', '2019-01-31 18:07:08', '2019-01-31 18:07:10', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'Exhausted available authentication methods', 'kps1gf', 'Done'),
	('qxin8zv5l8s', 'vke2yf47hyot7ae7np7h', '2019-01-31 18:06:47', '2019-01-31 18:07:11', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'null;null;null;null;null;null;null;null;null;null;t9uopmdslsj;', 'kps1gf;', 'Done'),
	('a09ur3wo6ano', 'nhi96d', '2019-01-31 18:10:28', '2019-01-31 18:10:28', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-31 23:10:28--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('0ysapgx5eatq', 'umv6tx', '2019-01-31 18:10:29', '2019-01-31 18:10:29', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('vl5w02hre844', 'rh1u8q', '2019-01-31 18:10:30', '2019-01-31 18:10:30', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('b1ma12kqcun5', 'rpnhlg', '2019-01-31 18:10:31', '2019-01-31 18:10:31', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('7g72jgko6l52', 'wsxeps', '2019-01-31 18:10:32', '2019-01-31 18:10:32', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('suodcxljhpt7', 'qp820f', '2019-01-31 18:10:33', '2019-01-31 18:10:33', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('btmjdmkgi8fq', 'ew8pku', '2019-01-31 18:10:34', '2019-01-31 18:10:35', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('tald5co31dj5', 'spz3b5', '2019-01-31 18:10:36', '2019-01-31 18:10:36', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('xh6h1934tu94', 'omop8l', '2019-01-31 18:10:37', '2019-01-31 18:10:47', '#!/bin/bash\nsleep 10s', '', 'kps1gf', 'Done'),
	('pg9acysy75z9', 'm6bbrf', '2019-01-31 18:10:48', '2019-01-31 18:10:48', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('1xy1vmb0r5o', '7sb7xj', '2019-01-31 18:10:48', '2019-01-31 18:10:49', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'demo1.png', 'kps1gf', 'Done'),
	('0exa10oehpk', 'vke2yf47hyot7ae7np7h', '2019-01-31 18:10:27', '2019-01-31 18:10:50', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'a09ur3wo6ano;0ysapgx5eatq;vl5w02hre844;b1ma12kqcun5;7g72jgko6l52;suodcxljhpt7;btmjdmkgi8fq;tald5co31dj5;xh6h1934tu94;pg9acysy75z9;1xy1vmb0r5o;', 'kps1gf;', 'Done'),
	('9t6ocaoqywww', '199vsg', '2019-01-31 18:19:29', '2019-01-31 18:19:44', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good"\n', 'test bash script process running\nGood\n', 'kps1gf', 'Done'),
	('3ng9x7gie1pt', '199vsg', '2019-01-31 18:21:45', '2019-01-31 18:22:00', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good, end mark"\n', 'test bash script process running\nGood, end mark\n', 'kps1gf', 'Done'),
	('3j24srae7nvq', 'nhi96d', '2019-01-31 18:33:35', '2019-01-31 18:33:36', '#!/bin/bash\n\nwget --version\n\n# download landsat data from geobrain\n\nwget "_landsat_scene_url" -O /tmp/testlandsat.tif\n\necho "download complete"', 'GNU Wget 1.19.4 built on linux-gnu.\n\n-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls \n+ntlm +opie +psl +ssl/openssl \n\nWgetrc: \n    /etc/wgetrc (system)\nLocale: \n    /usr/share/locale \nCompile: \n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" \n    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib \n    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG \n    -g -O2 -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall \nLink: \n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 \n    -fdebug-prefix-map=/build/wget-LB8XFP/wget-1.19.4=. \n    -fstack-protector-strong -Wformat -Werror=format-security \n    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions \n    -Wl,-z,relro -Wl,-z,now -lpcre -luuid -lidn2 -lssl -lcrypto -lpsl \n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a \n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n<http://www.gnu.org/licenses/gpl.html>.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic <hniksic@xemacs.org>.\nPlease send bug reports and questions to <bug-wget@gnu.org>.\n--2019-01-31 23:33:35--  http://_landsat_scene_url/\nResolving _landsat_scene_url (_landsat_scene_url)... failed: Temporary failure in name resolution.\nwget: unable to resolve host address _landsat_scene_url\ndownload complete\n', 'kps1gf', 'Done'),
	('3b3eov22aack', 'umv6tx', '2019-01-31 18:33:37', '2019-01-31 18:33:37', '#!/bin/bash\necho "remove bad pixels"', 'remove bad pixels\n', 'kps1gf', 'Done'),
	('iw5mo028nfx6', 'rh1u8q', '2019-01-31 18:33:38', '2019-01-31 18:33:38', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('pqatxbippi0j', 'rpnhlg', '2019-01-31 18:33:39', '2019-01-31 18:33:39', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('kvw49txz3tpr', 'wsxeps', '2019-01-31 18:33:40', '2019-01-31 18:33:40', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('pa5k1pnullwb', 'qp820f', '2019-01-31 18:33:41', '2019-01-31 18:33:41', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('w14andov75ag', 'ew8pku', '2019-01-31 18:33:42', '2019-01-31 18:33:42', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('56kn20t36j6g', 'spz3b5', '2019-01-31 18:33:43', '2019-01-31 18:33:43', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('nyqfq424es3p', 'omop8l', '2019-01-31 18:33:44', '2019-01-31 18:33:54', '#!/bin/bash\nsleep 10s', '', 'kps1gf', 'Done'),
	('whh9xzupwyim', 'm6bbrf', '2019-01-31 18:33:55', '2019-01-31 18:33:55', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'test segnet\n', 'kps1gf', 'Done'),
	('uiqiqilne2u', '7sb7xj', '2019-01-31 18:33:55', '2019-01-31 18:33:56', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'demo1.png', 'kps1gf', 'Done'),
	('f1pca4lcd7q', 'vke2yf47hyot7ae7np7h', '2019-01-31 18:33:34', '2019-01-31 18:33:57', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', '3j24srae7nvq;3b3eov22aack;iw5mo028nfx6;pqatxbippi0j;kvw49txz3tpr;pa5k1pnullwb;w14andov75ag;56kn20t36j6g;nyqfq424es3p;whh9xzupwyim;uiqiqilne2u;', 'kps1gf;', 'Done'),
	('kzheer8yrpfm', '71u4k0', '2019-02-01 10:23:53', '2019-02-01 10:23:53', '#!/bin/bash\necho "test update"', 'test update\n', 'kps1gf', 'Done'),
	('itsmy6azxnd3', '199vsg', '2019-02-13 11:36:33', '2019-02-13 11:36:48', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good, end mark"\n', 'test bash script process running\nGood, end mark\n', 'kps1gf', 'Done'),
	('1faijab6vhhg', 'ac4724', '2019-02-13 11:36:49', '2019-02-13 11:37:04', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('4qsyh96lixyu', '199vsg', '2019-02-13 11:37:05', '2019-02-13 11:37:20', '#!/bin/sh\necho "test bash script process running"\nsleep 15s\necho "Good, end mark"\n', 'test bash script process running\nGood, end mark\n', 'kps1gf', 'Done'),
	('r5nsj9ljn7a', '5k56d9vcx4ip3tr5pj26', '2019-02-13 11:36:31', '2019-02-13 11:37:20', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'itsmy6azxnd3;1faijab6vhhg;4qsyh96lixyu;', 'kps1gf;', 'Done'),
	('y4wcii6oz0zv', 'wssh33', '2019-02-13 15:42:21', '2019-02-13 15:42:21', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 3: syntax error near unexpected token `done\'\nbash: -c: line 3: `done; rm ./jupyter-testjupyter.ipynb; \'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('fcba1c8fsrxx', 'wssh33', '2019-02-13 15:44:00', '2019-02-13 15:44:00', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 3: syntax error near unexpected token `done\'\nbash: -c: line 3: `done; \'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('old8iklann9d', 'wssh33', '2019-02-13 15:44:49', '2019-02-13 15:44:49', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: ipython: command not found\nbash: jupyter: command not found\nbash: jupyter: command not found\nbash: jupyter: command not found\nbash: ??: command not found\nbash: line 0: fg: no job control\nbash: line 0: fg: no job control\nbash: jupyter: command not found\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('u3fz3qgchpq9', 'wssh33', '2019-02-13 17:44:20', '2019-02-13 17:46:29', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('6js5g80jd4ia', 'wssh33', '2019-02-13 17:50:07', '2019-02-13 17:51:13', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('dn6w52bf1c99', 'wssh33', '2019-02-13 17:57:46', '2019-02-13 17:59:34', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('t858uc3dp0bz', 'wssh33', '2019-02-13 18:05:25', '2019-02-13 18:06:29', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('yvf76o92l9p9', 'wssh33', '2019-02-18 17:25:50', '2019-02-18 17:28:01', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('nbx51kil3y8w', 'wssh33', '2019-02-19 09:53:08', '2019-02-19 09:53:47', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('y9nr6ojy7vx1', 'wssh33', '2019-02-19 12:04:14', '2019-02-19 12:05:50', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'null\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('fe58gmx8g2jk', 'wssh33', '2019-02-19 12:07:30', NULL, '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'started', 'kps1gf', 'Done'),
	('a80fr4blky3i', 'wssh33', '2019-02-19 12:10:44', '2019-02-19 12:10:44', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('55n6sf7ngx03', 'wssh33', '2019-02-19 12:15:14', NULL, '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'started', 'kps1gf', 'Done'),
	('njcf475nugml', 'wssh33', '2019-02-19 12:16:37', NULL, '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'started', 'kps1gf', 'Done'),
	('mwq0l8p7j3vy', 'wssh33', '2019-02-19 12:17:40', NULL, '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'started', 'kps1gf', 'Done'),
	('432iaoplqg7m', 'wssh33', '2019-02-19 12:21:24', '2019-02-19 12:21:24', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: unexpected EOF while looking for matching `\'\'\nbash: -c: line 1: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('zou35oue4y5e', 'wssh33', '2019-02-19 12:22:02', NULL, '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'started', 'kps1gf', 'Done'),
	('5tur1r96b2hu', 'wssh33', '2019-02-19 12:22:25', '2019-02-19 12:22:25', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: unexpected EOF while looking for matching `\'\'\nbash: -c: line 1: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('dcw7u8n1aei5', 'wssh33', '2019-02-19 12:24:47', '2019-02-19 12:24:47', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: unexpected EOF while looking for matching `\'\'\nbash: -c: line 1: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('ehj02t07clix', 'wssh33', '2019-02-19 12:25:31', '2019-02-19 12:25:31', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: unexpected EOF while looking for matching `\'\'\nbash: -c: line 1: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('mfnhwnyoj9gv', 'wssh33', '2019-02-19 12:26:23', '2019-02-19 12:26:23', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: unexpected EOF while looking for matching `\'\'\nbash: -c: line 1: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('ku4e4gyd10ul', 'wssh33', '2019-02-19 12:27:47', '2019-02-19 12:27:48', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('p07dlpapt125', 'wssh33', '2019-02-19 12:29:35', '2019-02-19 12:29:35', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('wc9yacpwfqke', 'wssh33', '2019-02-19 12:38:53', '2019-02-19 12:38:53', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('d1adgg4dvzw0', 'wssh33', '2019-02-19 12:47:08', '2019-02-19 12:47:08', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('6fcvzulghdki', 'wssh33', '2019-02-19 12:48:22', '2019-02-19 12:48:22', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('etc65p292kp4', 'wssh33', '2019-02-19 12:52:03', '2019-02-19 12:52:03', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'bash: -c: line 0: unexpected EOF while looking for matching `\'\'\nbash: -c: line 1: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('lfk81koywkkb', 'wssh33', '2019-02-19 12:52:40', '2019-02-19 12:52:40', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('mfh94urf43jb', 'wssh33', '2019-02-19 12:53:46', '2019-02-19 12:53:46', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('745utoaonz7j', 'wssh33', '2019-02-19 12:54:24', '2019-02-19 12:54:24', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('kbwbh1lwokbi', 'wssh33', '2019-02-19 12:54:39', '2019-02-19 12:54:39', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('lc7k2m69pnks', 'wssh33', '2019-02-19 12:55:29', '2019-02-19 12:55:29', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('o1ehq4fvnivr', 'wssh33', '2019-02-19 12:56:15', '2019-02-19 12:56:15', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '', 'kps1gf', 'Done'),
	('f652dqg6ykcl', 'wssh33', '2019-02-19 15:13:24', '2019-02-19 15:13:26', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '[NbConvertApp] Converting notebook jupyter-f652dqg6ykcl.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1147 (char 1146)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('ul7lhp0iqcws', 'h2xbof', '2019-02-19 15:23:07', '2019-02-19 15:23:09', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["<!--BOOK_INFORMATION-->\\n","<img align=\\"left\\" style=\\"padding-right:10px;\\" src=\\"figures/PDSH-cover-small.png\\">\\n","\\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\\n","\\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]},{"cell_type":"markdown","metadata":{},"source":["# IPython: Beyond Normal Python"]},{"cell_type":"markdown","metadata":{},"source":["There are many options for development environments for Python, and I\'m often asked which one I use in my own work.\\n","My answer sometimes surprises people: my preferred environment is [IPython](http://ipython.org/) plus a text editor (in my case, Emacs or Atom depending on my mood).\\n","IPython (short for *Interactive Python*) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez\'s words, \\"Tools for the entire life cycle of research computing.\\"\\n","If Python is the engine of our data science task, you might think of IPython as the interactive control panel.\\n","\\n","As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we\'ll cover the most useful of these additions here.\\n","In addition, IPython is closely tied with the [Jupyter project](http://jupyter.org), which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.\\n","The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.\\n","As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.\\n","\\n","IPython is about using Python effectively for interactive scientific and data-intensive computing.\\n","This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.\\n","Next, we will go into a bit more depth on some of the more useful \\"magic commands\\" that can speed-up common tasks in creating and using data science code.\\n","Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results."]},{"cell_type":"markdown","metadata":{},"source":["## Shell or Notebook?\\n","\\n","There are two primary means of using IPython that we\'ll discuss in this chapter: the IPython shell and the IPython notebook.\\n","The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.\\n","In the few sections that are relevant to just one or the other, we will explicitly state that fact.\\n","Before we start, some words on how to launch the IPython shell and IPython notebook."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the IPython Shell\\n","\\n","This chapter, like most of this book, is not designed to be absorbed passively.\\n","I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.\\n","Start by launching the IPython interpreter by typing **``ipython``** on the command-line; alternatively, if you\'ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we\'ll discuss this more fully in [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\\n","\\n","Once you do this, you should see a prompt like the following:\\n","```\\n","IPython 4.0.1 -- An enhanced Interactive Python.\\n","?         -> Introduction and overview of IPython\'s features.\\n","%quickref -> Quick reference.\\n","help      -> Python\'s own help system.\\n","object?   -> Details about \'object\', use \'object??\' for extra details.\\n","In [1]:\\n","```\\n","With that, you\'re ready to follow along."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the Jupyter Notebook\\n","\\n","The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.\\n","As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.\\n","Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.\\n","\\n","Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.\\n","This process (known as a \\"kernel\\") can be started by running the following command in your system shell:\\n","\\n","```\\n","$ jupyter notebook\\n","```\\n","\\n","This command will launch a local web server that will be visible to your browser.\\n","It immediately spits out a log showing what it is doing; that log will look something like this:\\n","\\n","```\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","```\\n","\\n","Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;\\n","the exact address will depend on your system.\\n","If the browser does not open automatically, you can open a window and manually open this address (*http://localhost:8888/* in this example)."]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-ul7lhp0iqcws.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1514 (char 1513)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('bqw4ls18z3fp', 'biw0my', '2019-02-19 15:40:10', '2019-02-19 15:40:10', '#!/bin/bash\n#write your bash script\ncd /home/zsun/data/\n#unzip 2014_30m_cdls.zip\nunzip 2015_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'unzip:  cannot find or open 2015_30m_cdls.zip, 2015_30m_cdls.zip.zip or 2015_30m_cdls.zip.ZIP.\n', 'kps1gf', 'Done'),
	('bwdpbgil4dwh', 'biw0my', '2019-02-19 15:41:20', '2019-02-19 15:41:21', '#!/bin/bash\n#write your bash script\ncd /home/zsun/data/\n#unzip 2014_30m_cdls.zip\nunzip 2015_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'Archive:  2015_30m_cdls.zip\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nunzip:  cannot find zipfile directory in one of 2015_30m_cdls.zip or\n        2015_30m_cdls.zip.zip, and cannot find 2015_30m_cdls.zip.ZIP, period.\n', 'kps1gf', 'Done'),
	('el3r2zet649m', 'biw0my', '2019-02-19 15:42:15', '2019-02-19 15:42:15', '#!/bin/bash\n#write your bash script\ncd /home/zsun/data/\nchmod 777 2015_30m_cdls.zip\n#unzip 2014_30m_cdls.zip\nunzip 2015_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'Archive:  2015_30m_cdls.zip\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nnote:  2015_30m_cdls.zip may be a plain executable, not an archive\nunzip:  cannot find zipfile directory in one of 2015_30m_cdls.zip or\n        2015_30m_cdls.zip.zip, and cannot find 2015_30m_cdls.zip.ZIP, period.\n', 'kps1gf', 'Done'),
	('8aabxu9e3sv2', 'biw0my', '2019-02-19 16:39:08', '2019-02-19 16:39:09', '#!/bin/bash\n#write your bash script\ncd /home/zsun/data/\nchmod 777 2015_30m_cdls.zip\n#unzip 2014_30m_cdls.zip\nunzip 2015_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'chmod: changing permissions of \'2015_30m_cdls.zip\': Operation not permitted\nArchive:  2015_30m_cdls.zip\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nunzip:  cannot find zipfile directory in one of 2015_30m_cdls.zip or\n        2015_30m_cdls.zip.zip, and cannot find 2015_30m_cdls.zip.ZIP, period.\n', 'kps1gf', 'Done'),
	('8pjmcgps48xq', 'biw0my', '2019-02-19 16:39:51', '2019-02-19 16:39:51', '#!/bin/bash\n#write your bash script\ncd /home/zsun/data/\nchmod 777 2015_30m_cdls.zip\n#unzip 2014_30m_cdls.zip\nunzip 2017_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'chmod: changing permissions of \'2015_30m_cdls.zip\': Operation not permitted\nArchive:  2017_30m_cdls.zip\nerror:  cannot create 2017_30m_cdls.ige\n        Permission denied\nerror:  cannot create 2017_30m_cdls.img\n        Permission denied\nerror:  cannot create 2017_30m_cdls.img.vat.cpg\n        Permission denied\nerror:  cannot create 2017_30m_cdls.img.vat.dbf\n        Permission denied\nerror:  cannot create 2017_30m_cdls.rde\n        Permission denied\nerror:  cannot create 2017_30m_cdls.rrd\n        Permission denied\nerror:  cannot create metadata_CropScape_CDL.htm\n        Permission denied\n', 'kps1gf', 'Done'),
	('hjf9k0pk8784', 'biw0my', '2019-02-19 16:40:40', '2019-02-19 16:40:45', '#!/bin/bash\n#write your bash script\nsleep 5s\ncd /home/zsun/data/\nchmod 777 2015_30m_cdls.zip\n#unzip 2014_30m_cdls.zip\nunzip 2017_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'chmod: changing permissions of \'2015_30m_cdls.zip\': Operation not permitted\nArchive:  2017_30m_cdls.zip\nerror:  cannot create 2017_30m_cdls.ige\n        Permission denied\nerror:  cannot create 2017_30m_cdls.img\n        Permission denied\nerror:  cannot create 2017_30m_cdls.img.vat.cpg\n        Permission denied\nerror:  cannot create 2017_30m_cdls.img.vat.dbf\n        Permission denied\nerror:  cannot create 2017_30m_cdls.rde\n        Permission denied\nerror:  cannot create 2017_30m_cdls.rrd\n        Permission denied\nerror:  cannot create metadata_CropScape_CDL.htm\n        Permission denied\n', 'kps1gf', 'Done'),
	('r11zriys1hr6', '4ng18f', '2019-02-23 12:02:35', '2019-02-23 12:02:35', '#!/bin/bash\n#write your bash script\nbasedir=/home/zsun/data/\ngdalwarp -overwrite -t_srs EPSG:32614 -of GTiff D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38.tif D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif\ngdaltindex -tileindex location D:/workspace/ec-deep/data/cdl/tileindex/2015213/LC80310272015213LGN00.shp D:\\workspace\\ec-deep\\data\\cdl\\tileindex\\2015213/LC80310272015213LGN00_sr_band1.tif\ngdalwarp -q -cutline D:/workspace/ec-deep/data/cdl/tileindex/20110907/LT05_L1TP_031027_20110907_20160830_01_T1/LT05_L1TP_031027_20110907_20160830_01_T1.shp -crop_to_cutline -tr 30.0 30.0 -of GTiff D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_20110907.tif\n', './geoweaver-kqxnqog72nis.sh: line 4: gdalwarp: command not found\n./geoweaver-kqxnqog72nis.sh: line 5: gdaltindex: command not found\n./geoweaver-kqxnqog72nis.sh: line 6: gdalwarp: command not found\n', 'kps1gf', 'Done'),
	('hzbc6lr8z4xr', '71u4k0', '2019-02-23 12:17:33', '2019-02-23 12:17:48', '#!/bin/bash\necho "test update"\nsleep 15s', 'test update\n', 'kps1gf', 'Done'),
	('xfcwkzojukar', 'wssh33', '2019-02-23 12:29:11', '2019-02-23 12:29:12', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '[NbConvertApp] Converting notebook jupyter-xfcwkzojukar.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1147 (char 1146)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('8dfcnalt9qko', 'wssh33', '2019-02-23 12:31:24', '2019-02-23 12:31:25', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', '[NbConvertApp] Converting notebook jupyter-8dfcnalt9qko.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1147 (char 1146)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('c1fk9fdag91p', 'h2xbof', '2019-02-24 14:43:00', '2019-02-24 14:43:01', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["<!--BOOK_INFORMATION-->\\n","<img align=\\"left\\" style=\\"padding-right:10px;\\" src=\\"figures/PDSH-cover-small.png\\">\\n","\\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\\n","\\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]},{"cell_type":"markdown","metadata":{},"source":["# IPython: Beyond Normal Python"]},{"cell_type":"markdown","metadata":{},"source":["There are many options for development environments for Python, and I\'m often asked which one I use in my own work.\\n","My answer sometimes surprises people: my preferred environment is [IPython](http://ipython.org/) plus a text editor (in my case, Emacs or Atom depending on my mood).\\n","IPython (short for *Interactive Python*) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez\'s words, \\"Tools for the entire life cycle of research computing.\\"\\n","If Python is the engine of our data science task, you might think of IPython as the interactive control panel.\\n","\\n","As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we\'ll cover the most useful of these additions here.\\n","In addition, IPython is closely tied with the [Jupyter project](http://jupyter.org), which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.\\n","The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.\\n","As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.\\n","\\n","IPython is about using Python effectively for interactive scientific and data-intensive computing.\\n","This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.\\n","Next, we will go into a bit more depth on some of the more useful \\"magic commands\\" that can speed-up common tasks in creating and using data science code.\\n","Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results."]},{"cell_type":"markdown","metadata":{},"source":["## Shell or Notebook?\\n","\\n","There are two primary means of using IPython that we\'ll discuss in this chapter: the IPython shell and the IPython notebook.\\n","The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.\\n","In the few sections that are relevant to just one or the other, we will explicitly state that fact.\\n","Before we start, some words on how to launch the IPython shell and IPython notebook."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the IPython Shell\\n","\\n","This chapter, like most of this book, is not designed to be absorbed passively.\\n","I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.\\n","Start by launching the IPython interpreter by typing **``ipython``** on the command-line; alternatively, if you\'ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we\'ll discuss this more fully in [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\\n","\\n","Once you do this, you should see a prompt like the following:\\n","```\\n","IPython 4.0.1 -- An enhanced Interactive Python.\\n","?         -> Introduction and overview of IPython\'s features.\\n","%quickref -> Quick reference.\\n","help      -> Python\'s own help system.\\n","object?   -> Details about \'object\', use \'object??\' for extra details.\\n","In [1]:\\n","```\\n","With that, you\'re ready to follow along."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the Jupyter Notebook\\n","\\n","The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.\\n","As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.\\n","Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.\\n","\\n","Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.\\n","This process (known as a \\"kernel\\") can be started by running the following command in your system shell:\\n","\\n","```\\n","$ jupyter notebook\\n","```\\n","\\n","This command will launch a local web server that will be visible to your browser.\\n","It immediately spits out a log showing what it is doing; that log will look something like this:\\n","\\n","```\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","```\\n","\\n","Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;\\n","the exact address will depend on your system.\\n","If the browser does not open automatically, you can open a window and manually open this address (*http://localhost:8888/* in this example)."]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-c1fk9fdag91p.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1514 (char 1513)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('1782y2tkefwf', 'h2xbof', '2019-02-24 14:43:18', '2019-02-24 14:43:19', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["<!--BOOK_INFORMATION-->\\n","<img align=\\"left\\" style=\\"padding-right:10px;\\" src=\\"figures/PDSH-cover-small.png\\">\\n","\\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\\n","\\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]},{"cell_type":"markdown","metadata":{},"source":["# IPython: Beyond Normal Python"]},{"cell_type":"markdown","metadata":{},"source":["There are many options for development environments for Python, and I\'m often asked which one I use in my own work.\\n","My answer sometimes surprises people: my preferred environment is [IPython](http://ipython.org/) plus a text editor (in my case, Emacs or Atom depending on my mood).\\n","IPython (short for *Interactive Python*) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez\'s words, \\"Tools for the entire life cycle of research computing.\\"\\n","If Python is the engine of our data science task, you might think of IPython as the interactive control panel.\\n","\\n","As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we\'ll cover the most useful of these additions here.\\n","In addition, IPython is closely tied with the [Jupyter project](http://jupyter.org), which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.\\n","The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.\\n","As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.\\n","\\n","IPython is about using Python effectively for interactive scientific and data-intensive computing.\\n","This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.\\n","Next, we will go into a bit more depth on some of the more useful \\"magic commands\\" that can speed-up common tasks in creating and using data science code.\\n","Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results."]},{"cell_type":"markdown","metadata":{},"source":["## Shell or Notebook?\\n","\\n","There are two primary means of using IPython that we\'ll discuss in this chapter: the IPython shell and the IPython notebook.\\n","The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.\\n","In the few sections that are relevant to just one or the other, we will explicitly state that fact.\\n","Before we start, some words on how to launch the IPython shell and IPython notebook."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the IPython Shell\\n","\\n","This chapter, like most of this book, is not designed to be absorbed passively.\\n","I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.\\n","Start by launching the IPython interpreter by typing **``ipython``** on the command-line; alternatively, if you\'ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we\'ll discuss this more fully in [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\\n","\\n","Once you do this, you should see a prompt like the following:\\n","```\\n","IPython 4.0.1 -- An enhanced Interactive Python.\\n","?         -> Introduction and overview of IPython\'s features.\\n","%quickref -> Quick reference.\\n","help      -> Python\'s own help system.\\n","object?   -> Details about \'object\', use \'object??\' for extra details.\\n","In [1]:\\n","```\\n","With that, you\'re ready to follow along."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the Jupyter Notebook\\n","\\n","The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.\\n","As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.\\n","Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.\\n","\\n","Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.\\n","This process (known as a \\"kernel\\") can be started by running the following command in your system shell:\\n","\\n","```\\n","$ jupyter notebook\\n","```\\n","\\n","This command will launch a local web server that will be visible to your browser.\\n","It immediately spits out a log showing what it is doing; that log will look something like this:\\n","\\n","```\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","```\\n","\\n","Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;\\n","the exact address will depend on your system.\\n","If the browser does not open automatically, you can open a window and manually open this address (*http://localhost:8888/* in this example)."]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-1782y2tkefwf.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1514 (char 1513)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('5s20zci81a4j', 'h2xbof', '2019-02-24 14:43:53', '2019-02-24 14:43:55', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["<!--BOOK_INFORMATION-->\\n","<img align=\\"left\\" style=\\"padding-right:10px;\\" src=\\"figures/PDSH-cover-small.png\\">\\n","\\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\\n","\\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]},{"cell_type":"markdown","metadata":{},"source":["# IPython: Beyond Normal Python"]},{"cell_type":"markdown","metadata":{},"source":["There are many options for development environments for Python, and I\'m often asked which one I use in my own work.\\n","My answer sometimes surprises people: my preferred environment is [IPython](http://ipython.org/) plus a text editor (in my case, Emacs or Atom depending on my mood).\\n","IPython (short for *Interactive Python*) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez\'s words, \\"Tools for the entire life cycle of research computing.\\"\\n","If Python is the engine of our data science task, you might think of IPython as the interactive control panel.\\n","\\n","As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we\'ll cover the most useful of these additions here.\\n","In addition, IPython is closely tied with the [Jupyter project](http://jupyter.org), which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.\\n","The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.\\n","As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.\\n","\\n","IPython is about using Python effectively for interactive scientific and data-intensive computing.\\n","This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.\\n","Next, we will go into a bit more depth on some of the more useful \\"magic commands\\" that can speed-up common tasks in creating and using data science code.\\n","Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results."]},{"cell_type":"markdown","metadata":{},"source":["## Shell or Notebook?\\n","\\n","There are two primary means of using IPython that we\'ll discuss in this chapter: the IPython shell and the IPython notebook.\\n","The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.\\n","In the few sections that are relevant to just one or the other, we will explicitly state that fact.\\n","Before we start, some words on how to launch the IPython shell and IPython notebook."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the IPython Shell\\n","\\n","This chapter, like most of this book, is not designed to be absorbed passively.\\n","I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.\\n","Start by launching the IPython interpreter by typing **``ipython``** on the command-line; alternatively, if you\'ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we\'ll discuss this more fully in [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\\n","\\n","Once you do this, you should see a prompt like the following:\\n","```\\n","IPython 4.0.1 -- An enhanced Interactive Python.\\n","?         -> Introduction and overview of IPython\'s features.\\n","%quickref -> Quick reference.\\n","help      -> Python\'s own help system.\\n","object?   -> Details about \'object\', use \'object??\' for extra details.\\n","In [1]:\\n","```\\n","With that, you\'re ready to follow along."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the Jupyter Notebook\\n","\\n","The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.\\n","As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.\\n","Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.\\n","\\n","Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.\\n","This process (known as a \\"kernel\\") can be started by running the following command in your system shell:\\n","\\n","```\\n","$ jupyter notebook\\n","```\\n","\\n","This command will launch a local web server that will be visible to your browser.\\n","It immediately spits out a log showing what it is doing; that log will look something like this:\\n","\\n","```\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","```\\n","\\n","Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;\\n","the exact address will depend on your system.\\n","If the browser does not open automatically, you can open a window and manually open this address (*http://localhost:8888/* in this example)."]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-5s20zci81a4j.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 1514 (char 1513)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('x50zsgw7yeik', '199vsg', '2019-02-25 12:18:42', '2019-02-25 12:18:42', NULL, './geoweaver-b9wn1oc1qjhr.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('5mjg8aot9cis', 'ac4724', '2019-02-25 12:18:43', '2019-02-25 12:18:58', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('2wxd5e1su7wi', '199vsg', '2019-02-25 12:18:59', '2019-02-25 12:18:59', NULL, './geoweaver-b9wn1oc1qjhr.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('bv8gpix2ofx', '5k56d9vcx4ip3tr5pj26', '2019-02-25 12:18:41', '2019-02-25 12:18:59', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'x50zsgw7yeik;5mjg8aot9cis;2wxd5e1su7wi;', 'kps1gf;', 'Done'),
	('fpl42spsr3hv', '199vsg', '2019-02-25 12:19:24', '2019-02-25 12:19:24', NULL, './geoweaver-a2w9zsfxm5q4.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('f8w8dotho0ii', '199vsg', '2019-02-25 12:19:24', '2019-02-25 12:19:24', NULL, './geoweaver-9dvvf973ezs5.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('ibx4805abxfx', 'ac4724', '2019-02-25 12:19:25', '2019-02-25 12:19:40', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('nn550ps9xveg', 'ac4724', '2019-02-25 12:19:25', '2019-02-25 12:19:40', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('gg2adkbxlx2q', '199vsg', '2019-02-25 12:19:41', '2019-02-25 12:19:41', NULL, './geoweaver-a2w9zsfxm5q4.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('13affq0qrfn5', '199vsg', '2019-02-25 12:19:41', '2019-02-25 12:19:41', NULL, './geoweaver-9dvvf973ezs5.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('2gf6hoo9ov3', '5k56d9vcx4ip3tr5pj26', '2019-02-25 12:19:23', '2019-02-25 12:19:41', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'fpl42spsr3hv;nn550ps9xveg;gg2adkbxlx2q;', 'kps1gf;', 'Done'),
	('cka4ym5gl7y', '5k56d9vcx4ip3tr5pj26', '2019-02-25 12:19:23', '2019-02-25 12:19:41', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'f8w8dotho0ii;ibx4805abxfx;13affq0qrfn5;', 'kps1gf;', 'Done'),
	('x3qlpjepasrs', '199vsg', '2019-02-25 12:20:06', '2019-02-25 12:20:06', NULL, './geoweaver-svzi7aqak083.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('2xk3skew9tvk', 'ac4724', '2019-02-25 12:20:07', '2019-02-25 12:20:22', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('k2ypgmhcbmgu', '199vsg', '2019-02-25 12:20:23', '2019-02-25 12:20:23', NULL, './geoweaver-svzi7aqak083.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('6okvme86rua', '5k56d9vcx4ip3tr5pj26', '2019-02-25 12:20:05', '2019-02-25 12:20:23', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'x3qlpjepasrs;2xk3skew9tvk;k2ypgmhcbmgu;', 'kps1gf;', 'Done'),
	('54gs9wq42m9g', 'j9pxl1', '2019-02-25 15:19:53', '2019-02-25 15:19:54', '{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["\'2.0.8\'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import keras\\n","keras.__version__"]},{"cell_type":"markdown","metadata":{},"source":["# Classifying movie reviews: a binary classification example\\n","\\n","This notebook contains the code samples found in Chapter 3, Section 5 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\\n","\\n","----\\n","\\n","\\n","Two-class classification, or binary classification, may be the most widely applied kind of machine learning problem. In this example, we \\n","will learn to classify movie reviews into \\"positive\\" reviews and \\"negative\\" reviews, just based on the text content of the reviews."]},{"cell_type":"markdown","metadata":{},"source":["## The IMDB dataset\\n","\\n","\\n","We\'ll be working with \\"IMDB dataset\\", a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 \\n","reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews.\\n","\\n","Why do we have these two separate training and test sets? You should never test a machine learning model on the same data that you used to \\n","train it! Just because a model performs well on its training data doesn\'t mean that it will perform well on data it has never seen, and \\n","what you actually care about is your model\'s performance on new data (since you already know the labels of your training data -- obviously \\n","you don\'t need your model to predict those). For instance, it is possible that your model could end up merely _memorizing_ a mapping between \\n","your training samples and their targets -- which would be completely useless for the task of predicting targets for data never seen before. \\n","We will go over this point in much more detail in the next chapter.\\n","\\n","Just like the MNIST dataset, the IMDB dataset comes packaged with Keras. It has already been preprocessed: the reviews (sequences of words) \\n","have been turned into sequences of integers, where each integer stands for a specific word in a dictionary.\\n","\\n","The following code will load the dataset (when you run it for the first time, about 80MB of data will be downloaded to your machine):"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":true},"outputs":[],"source":["from keras.datasets import imdb\\n","\\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"]},{"cell_type":"markdown","metadata":{},"source":["\\n","The argument `num_words=10000` means that we will only keep the top 10,000 most frequently occurring words in the training data. Rare words \\n","will be discarded. This allows us to work with vector data of manageable size.\\n","\\n","The variables `train_data` and `test_data` are lists of reviews, each review being a list of word indices (encoding a sequence of words). \\n","`train_labels` and `test_labels` are lists of 0s and 1s, where 0 stands for \\"negative\\" and 1 stands for \\"positive\\":"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["[1,\\n"," 14,\\n"," 22,\\n"," 16,\\n"," 43,\\n"," 530,\\n"," 973,\\n"," 1622,\\n"," 1385,\\n"," 65,\\n"," 458,\\n"," 4468,\\n"," 66,\\n"," 3941,\\n"," 4,\\n"," 173,\\n"," 36,\\n"," 256,\\n"," 5,\\n"," 25,\\n"," 100,\\n"," 43,\\n"," 838,\\n"," 112,\\n"," 50,\\n"," 670,\\n"," 2,\\n"," 9,\\n"," 35,\\n"," 480,\\n"," 284,\\n"," 5,\\n"," 150,\\n"," 4,\\n"," 172,\\n"," 112,\\n"," 167,\\n"," 2,\\n"," 336,\\n"," 385,\\n"," 39,\\n"," 4,\\n"," 172,\\n"," 4536,\\n"," 1111,\\n"," 17,\\n"," 546,\\n"," 38,\\n"," 13,\\n"," 447,\\n"," 4,\\n"," 192,\\n"," 50,\\n"," 16,\\n"," 6,\\n"," 147,\\n"," 2025,\\n"," 19,\\n"," 14,\\n"," 22,\\n"," 4,\\n"," 1920,\\n"," 4613,\\n"," 469,\\n"," 4,\\n"," 22,\\n"," 71,\\n"," 87,\\n"," 12,\\n"," 16,\\n"," 43,\\n"," 530,\\n"," 38,\\n"," 76,\\n"," 15,\\n"," 13,\\n"," 1247,\\n"," 4,\\n"," 22,\\n"," 17,\\n"," 515,\\n"," 17,\\n"," 12,\\n"," 16,\\n"," 626,\\n"," 18,\\n"," 2,\\n"," 5,\\n"," 62,\\n"," 386,\\n"," 12,\\n"," 8,\\n"," 316,\\n"," 8,\\n"," 106,\\n"," 5,\\n"," 4,\\n"," 2223,\\n"," 5244,\\n"," 16,\\n"," 480,\\n"," 66,\\n"," 3785,\\n"," 33,\\n"," 4,\\n"," 130,\\n"," 12,\\n"," 16,\\n"," 38,\\n"," 619,\\n"," 5,\\n"," 25,\\n"," 124,\\n"," 51,\\n"," 36,\\n"," 135,\\n"," 48,\\n"," 25,\\n"," 1415,\\n"," 33,\\n"," 6,\\n"," 22,\\n"," 12,\\n"," 215,\\n"," 28,\\n"," 77,\\n"," 52,\\n"," 5,\\n"," 14,\\n"," 407,\\n"," 16,\\n"," 82,\\n"," 2,\\n"," 8,\\n"," 4,\\n"," 107,\\n"," 117,\\n"," 5952,\\n"," 15,\\n"," 256,\\n"," 4,\\n"," 2,\\n"," 7,\\n"," 3766,\\n"," 5,\\n"," 723,\\n"," 36,\\n"," 71,\\n"," 43,\\n"," 530,\\n"," 476,\\n"," 26,\\n"," 400,\\n"," 317,\\n"," 46,\\n"," 7,\\n"," 4,\\n"," 2,\\n"," 1029,\\n"," 13,\\n"," 104,\\n"," 88,\\n"," 4,\\n"," 381,\\n"," 15,\\n"," 297,\\n"," 98,\\n"," 32,\\n"," 2071,\\n"," 56,\\n"," 26,\\n"," 141,\\n"," 6,\\n"," 194,\\n"," 7486,\\n"," 18,\\n"," 4,\\n"," 226,\\n"," 22,\\n"," 21,\\n"," 134,\\n"," 476,\\n"," 26,\\n"," 480,\\n"," 5,\\n"," 144,\\n"," 30,\\n"," 5535,\\n"," 18,\\n"," 51,\\n"," 36,\\n"," 28,\\n"," 224,\\n"," 92,\\n"," 25,\\n"," 104,\\n"," 4,\\n"," 226,\\n"," 65,\\n"," 16,\\n"," 38,\\n"," 1334,\\n"," 88,\\n"," 12,\\n"," 16,\\n"," 283,\\n"," 5,\\n"," 16,\\n"," 4472,\\n"," 113,\\n"," 103,\\n"," 32,\\n"," 15,\\n"," 16,\\n"," 5345,\\n"," 19,\\n"," 178,\\n"," 32]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[0]"]},{"cell_type":"markdown","metadata":{},"source":["Since we restricted ourselves to the top 10,000 most frequent words, no word index will exceed 10,000:"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["9999"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["max([max(sequence) for sequence in train_data])"]},{"cell_type":"markdown","metadata":{},"source":["For kicks, here\'s how you can quickly decode one of these reviews back to English words:"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":true},"outputs":[],"source":["# word_index is a dictionary mapping words to an integer index\\n","word_index = imdb.get_word_index()\\n","# We reverse it, mapping integer indices to words\\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\\n","# We decode the review; note that our indices were offset by 3\\n","# because 0, 1 and 2 are reserved indices for \\"padding\\", \\"start of sequence\\", and \\"unknown\\".\\n","decoded_review = \' \'.join([reverse_word_index.get(i - 3, \'?\') for i in train_data[0]])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["\\"? this film was just brilliant casting location scenery story direction everyone\'s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy\'s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don\'t you think the whole story was so lovely because it was true and was someone\'s life after all that was shared with us all\\""]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["decoded_review"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing the data\\n","\\n","\\n","We cannot feed lists of integers into a neural network. We have to turn our lists into tensors. There are two ways we could do that:\\n","\\n","* We could pad our lists so that they all have the same length, and turn them into an integer tensor of shape `(samples, word_indices)`, \\n","then use as first layer in our network a layer capable of handling such integer tensors (the `Embedding` layer, which we will cover in \\n","detail later in the book).\\n","* We could one-hot-encode our lists to turn them into vectors of 0s and 1s. Concretely, this would mean for instance turning the sequence \\n","`[3, 5]` into a 10,000-dimensional vector that would be all-zeros except for indices 3 and 5, which would be ones. Then we could use as \\n","first layer in our network a `Dense` layer, capable of handling floating point vector data.\\n","\\n","We will go with the latter solution. Let\'s vectorize our data, which we will do manually for maximum clarity:"]},{"cell_type":"code","execution_count":27,"metadata":{"collapsed":true},"outputs":[],"source":["import numpy as np\\n","\\n","def vectorize_sequences(sequences, dimension=10000):\\n","    # Create an all-zero matrix of shape (len(sequences), dimension)\\n","    results = np.zeros((len(sequences), dimension))\\n","    for i, sequence in enumerate(sequences):\\n","        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\\n","    return results\\n","\\n","# Our vectorized training data\\n","x_train = vectorize_sequences(train_data)\\n","# Our vectorized test data\\n","x_test = vectorize_sequences(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["Here\'s what our samples look like now:"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 0.,  1.,  1., ...,  0.,  0.,  0.])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0]"]},{"cell_type":"markdown","metadata":{},"source":["We should also vectorize our labels, which is straightforward:"]},{"cell_type":"code","execution_count":29,"metadata":{"collapsed":true},"outputs":[],"source":["# Our vectorized labels\\n","y_train = np.asarray(train_labels).astype(\'float32\')\\n","y_test = np.asarray(test_labels).astype(\'float32\')"]},{"cell_type":"markdown","metadata":{},"source":["Now our data is ready to be fed into a neural network."]},{"cell_type":"markdown","metadata":{},"source":["## Building our network\\n","\\n","\\n","Our input data is simply vectors, and our labels are scalars (1s and 0s): this is the easiest setup you will ever encounter. A type of \\n","network that performs well on such a problem would be a simple stack of fully-connected (`Dense`) layers with `relu` activations: `Dense(16, \\n","activation=\'relu\')`\\n","\\n","The argument being passed to each `Dense` layer (16) is the number of \\"hidden units\\" of the layer. What\'s a hidden unit? It\'s a dimension \\n","in the representation space of the layer. You may remember from the previous chapter that each such `Dense` layer with a `relu` activation implements \\n","the following chain of tensor operations:\\n","\\n","`output = relu(dot(W, input) + b)`\\n","\\n","Having 16 hidden units means that the weight matrix `W` will have shape `(input_dimension, 16)`, i.e. the dot product with `W` will project the \\n","input data onto a 16-dimensional representation space (and then we would add the bias vector `b` and apply the `relu` operation). You can \\n","intuitively understand the dimensionality of your representation space as \\"how much freedom you are allowing the network to have when \\n","learning internal representations\\". Having more hidden units (a higher-dimensional representation space) allows your network to learn more \\n","complex representations, but it makes your network more computationally expensive and may lead to learning unwanted patterns (patterns that \\n","will improve performance on the training data but not on the test data).\\n","\\n","There are two key architecture decisions to be made about such stack of dense layers:\\n","\\n","* How many layers to use.\\n","* How many \\"hidden units\\" to chose for each layer.\\n","\\n","In the next chapter, you will learn formal principles to guide you in making these choices. \\n","For the time being, you will have to trust us with the following architecture choice: \\n","two intermediate layers with 16 hidden units each, \\n","and a third layer which will output the scalar prediction regarding the sentiment of the current review. \\n","The intermediate layers will use `relu` as their \\"activation function\\", \\n","and the final layer will use a sigmoid activation so as to output a probability \\n","(a score between 0 and 1, indicating how likely the sample is to have the target \\"1\\", i.e. how likely the review is to be positive). \\n","A `relu` (rectified linear unit) is a function meant to zero-out negative values, \\n","while a sigmoid \\"squashes\\" arbitrary values into the `[0, 1]` interval, thus outputting something that can be interpreted as a probability."]},{"cell_type":"markdown","metadata":{},"source":["Here\'s what our network looks like:\\n","\\n","![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"]},{"cell_type":"markdown","metadata":{},"source":["And here\'s the Keras implementation, very similar to the MNIST example you saw previously:"]},{"cell_type":"code","execution_count":30,"metadata":{"collapsed":true},"outputs":[],"source":["from keras import models\\n","from keras import layers\\n","\\n","model = models.Sequential()\\n","model.add(layers.Dense(16, activation=\'relu\', input_shape=(10000,)))\\n","model.add(layers.Dense(16, activation=\'relu\'))\\n","model.add(layers.Dense(1, activation=\'sigmoid\'))"]},{"cell_type":"markdown","metadata":{},"source":["\\n","Lastly, we need to pick a loss function and an optimizer. Since we are facing a binary classification problem and the output of our network \\n","is a probability (we end our network with a single-unit layer with a sigmoid activation), is it best to use the `binary_crossentropy` loss. \\n","It isn\'t the only viable choice: you could use, for instance, `mean_squared_error`. But crossentropy is usually the best choice when you \\n","are dealing with models that output probabilities. Crossentropy is a quantity from the field of Information Theory, that measures the \\"distance\\" \\n","between probability distributions, or in our case, between the ground-truth distribution and our predictions.\\n","\\n","Here\'s the step where we configure our model with the `rmsprop` optimizer and the `binary_crossentropy` loss function. Note that we will \\n","also monitor accuracy during training."]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":true},"outputs":[],"source":["model.compile(optimizer=\'rmsprop\',\\n","              loss=\'binary_crossentropy\',\\n","              metrics=[\'accuracy\'])"]},{"cell_type":"markdown","metadata":{},"source":["We are passing our optimizer, loss function and metrics as strings, which is possible because `rmsprop`, `binary_crossentropy` and \\n","`accuracy` are packaged as part of Keras. Sometimes you may want to configure the parameters of your optimizer, or pass a custom loss \\n","function or metric function. This former can be done by passing an optimizer class instance as the `optimizer` argument:"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true},"outputs":[],"source":["from keras import optimizers\\n","\\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\\n","              loss=\'binary_crossentropy\',\\n","              metrics=[\'accuracy\'])"]},{"cell_type":"markdown","metadata":{},"source":["The latter can be done by passing function objects as the `loss` or `metrics` arguments:"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true},"outputs":[],"source":["from keras import losses\\n","from keras import metrics\\n","\\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\\n","              loss=losses.binary_crossentropy,\\n","              metrics=[metrics.binary_accuracy])"]},{"cell_type":"markdown","metadata":{},"source":["## Validating our approach\\n","\\n","In order to monitor during training the accuracy of the model on data that it has never seen before, we will create a \\"validation set\\" by \\n","setting apart 10,000 samples from the original training data:"]},{"cell_type":"code","execution_count":32,"metadata":{"collapsed":true},"outputs":[],"source":["x_val = x_train[:10000]\\n","partial_x_train = x_train[10000:]\\n","\\n","y_val = y_train[:10000]\\n","partial_y_train = y_train[10000:]"]},{"cell_type":"markdown","metadata":{"collapsed":true},"source":["We will now train our model for 20 epochs (20 iterations over all samples in the `x_train` and `y_train` tensors), in mini-batches of 512 \\n","samples. At this same time we will monitor loss and accuracy on the 10,000 samples that we set apart. This is done by passing the \\n","validation data as the `validation_data` argument:"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 15000 samples, validate on 10000 samples\\n","Epoch 1/20\\n","15000/15000 [==============================] - 1s - loss: 0.5103 - acc: 0.7911 - val_loss: 0.4016 - val_acc: 0.8628\\n","Epoch 2/20\\n","15000/15000 [==============================] - 1s - loss: 0.3110 - acc: 0.9031 - val_loss: 0.3085 - val_acc: 0.8870\\n","Epoch 3/20\\n","15000/15000 [==============================] - 1s - loss: 0.2309 - acc: 0.9235 - val_loss: 0.2803 - val_acc: 0.8908\\n","Epoch 4/20\\n","15000/15000 [==============================] - 1s - loss: 0.1795 - acc: 0.9428 - val_loss: 0.2735 - val_acc: 0.8893\\n","Epoch 5/20\\n","15000/15000 [==============================] - 1s - loss: 0.1475 - acc: 0.9526 - val_loss: 0.2788 - val_acc: 0.8890\\n","Epoch 6/20\\n","15000/15000 [==============================] - 1s - loss: 0.1185 - acc: 0.9638 - val_loss: 0.3330 - val_acc: 0.8764\\n","Epoch 7/20\\n","15000/15000 [==============================] - 1s - loss: 0.1005 - acc: 0.9703 - val_loss: 0.3055 - val_acc: 0.8838\\n","Epoch 8/20\\n","15000/15000 [==============================] - 1s - loss: 0.0818 - acc: 0.9773 - val_loss: 0.3344 - val_acc: 0.8769\\n","Epoch 9/20\\n","15000/15000 [==============================] - 1s - loss: 0.0696 - acc: 0.9814 - val_loss: 0.3607 - val_acc: 0.8800\\n","Epoch 10/20\\n","15000/15000 [==============================] - 1s - loss: 0.0547 - acc: 0.9873 - val_loss: 0.3776 - val_acc: 0.8785\\n","Epoch 11/20\\n","15000/15000 [==============================] - 1s - loss: 0.0453 - acc: 0.9895 - val_loss: 0.4035 - val_acc: 0.8765\\n","Epoch 12/20\\n","15000/15000 [==============================] - 1s - loss: 0.0353 - acc: 0.9930 - val_loss: 0.4437 - val_acc: 0.8766\\n","Epoch 13/20\\n","15000/15000 [==============================] - 1s - loss: 0.0269 - acc: 0.9956 - val_loss: 0.4637 - val_acc: 0.8747\\n","Epoch 14/20\\n","15000/15000 [==============================] - 1s - loss: 0.0212 - acc: 0.9968 - val_loss: 0.4877 - val_acc: 0.8714\\n","Epoch 15/20\\n","15000/15000 [==============================] - 1s - loss: 0.0162 - acc: 0.9977 - val_loss: 0.6080 - val_acc: 0.8625\\n","Epoch 16/20\\n","15000/15000 [==============================] - 1s - loss: 0.0115 - acc: 0.9993 - val_loss: 0.5778 - val_acc: 0.8698\\n","Epoch 17/20\\n","15000/15000 [==============================] - 1s - loss: 0.0116 - acc: 0.9979 - val_loss: 0.5906 - val_acc: 0.8702\\n","Epoch 18/20\\n","15000/15000 [==============================] - 1s - loss: 0.0054 - acc: 0.9998 - val_loss: 0.6204 - val_acc: 0.8639\\n","Epoch 19/20\\n","15000/15000 [==============================] - 1s - loss: 0.0083 - acc: 0.9984 - val_loss: 0.6419 - val_acc: 0.8676\\n","Epoch 20/20\\n","15000/15000 [==============================] - 1s - loss: 0.0031 - acc: 0.9998 - val_loss: 0.6796 - val_acc: 0.8683\\n"]}],"source":["history = model.fit(partial_x_train,\\n","                    partial_y_train,\\n","                    epochs=20,\\n","                    batch_size=512,\\n","                    validation_data=(x_val, y_val))"]},{"cell_type":"markdown","metadata":{},"source":["On CPU, this will take less than two seconds per epoch -- training is over in 20 seconds. At the end of every epoch, there is a slight pause \\n","as the model computes its loss and accuracy on the 10,000 samples of the validation data.\\n","\\n","Note that the call to `model.fit()` returns a `History` object. This object has a member `history`, which is a dictionary containing data \\n","about everything that happened during training. Let\'s take a look at it:"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["dict_keys([\'val_acc\', \'acc\', \'val_loss\', \'loss\'])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["history_dict = history.history\\n","history_dict.keys()"]},{"cell_type":"markdown","metadata":{},"source":["It contains 4 entries: one per metric that was being monitored, during training and during validation. Let\'s use Matplotlib to plot the \\n","training and validation loss side by side, as well as the training and validation accuracy:"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\\n","text/plain":["<matplotlib.figure.Figure at 0x7f9e8b6b6588>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\\n","\\n","acc = history.history[\'acc\']\\n","val_acc = history.history[\'val_acc\']\\n","loss = history.history[\'loss\']\\n","val_loss = history.history[\'val_loss\']\\n","\\n","epochs = range(1, len(acc) + 1)\\n","\\n","# \\"bo\\" is for \\"blue dot\\"\\n","plt.plot(epochs, loss, \'bo\', label=\'Training loss\')\\n","# b is for \\"solid blue line\\"\\n","plt.plot(epochs, val_loss, \'b\', label=\'Validation loss\')\\n","plt.title(\'Training and validation loss\')\\n","plt.xlabel(\'Epochs\')\\n","plt.ylabel(\'Loss\')\\n","plt.legend()\\n","\\n","plt.show()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\\n","text/plain":["<matplotlib.figure.Figure at 0x7f9e8b6b6080>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.clf()   # clear figure\\n","acc_values = history_dict[\'acc\']\\n","val_acc_values = history_dict[\'val_acc\']\\n","\\n","plt.plot(epochs, acc, \'bo\', label=\'Training acc\')\\n","plt.plot(epochs, val_acc, \'b\', label=\'Validation acc\')\\n","plt.title(\'Training and validation accuracy\')\\n","plt.xlabel(\'Epochs\')\\n","plt.ylabel(\'Loss\')\\n","plt.legend()\\n","\\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\\n","The dots are the training loss and accuracy, while the solid lines are the validation loss and accuracy. Note that your own results may vary \\n","slightly due to a different random initialization of your network.\\n","\\n","As you can see, the training loss decreases with every epoch and the training accuracy increases with every epoch. That\'s what you would \\n","expect when running gradient descent optimization -- the quantity you are trying to minimize should get lower with every iteration. But that \\n","isn\'t the case for the validation loss and accuracy: they seem to peak at the fourth epoch. This is an example of what we were warning \\n","against earlier: a model that performs better on the training data isn\'t necessarily a model that will do better on data it has never seen \\n","before. In precise terms, what you are seeing is \\"overfitting\\": after the second epoch, we are over-optimizing on the training data, and we \\n","ended up learning representations that are specific to the training data and do not generalize to data outside of the training set.\\n","\\n","In this case, to prevent overfitting, we could simply stop training after three epochs. In general, there is a range of techniques you can \\n","leverage to mitigate overfitting, which we will cover in the next chapter.\\n","\\n","Let\'s train a new network from scratch for four epochs, then evaluate it on our test data:"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\\n","25000/25000 [==============================] - 1s - loss: 0.4738 - acc: 0.8044     \\n","Epoch 2/4\\n","25000/25000 [==============================] - 1s - loss: 0.2660 - acc: 0.9076     \\n","Epoch 3/4\\n","25000/25000 [==============================] - 1s - loss: 0.2028 - acc: 0.9277     \\n","Epoch 4/4\\n","25000/25000 [==============================] - 1s - loss: 0.1700 - acc: 0.9397     \\n","24544/25000 [============================>.] - ETA: 0s"]}],"source":["model = models.Sequential()\\n","model.add(layers.Dense(16, activation=\'relu\', input_shape=(10000,)))\\n","model.add(layers.Dense(16, activation=\'relu\'))\\n","model.add(layers.Dense(1, activation=\'sigmoid\'))\\n","\\n","model.compile(optimizer=\'rmsprop\',\\n","              loss=\'binary_crossentropy\',\\n","              metrics=[\'accuracy\'])\\n","\\n","model.fit(x_train, y_train, epochs=4, batch_size=512)\\n","results = model.evaluate(x_test, y_test)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["[0.29184698499679568, 0.88495999999999997]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"markdown","metadata":{},"source":["Our fairly naive approach achieves an accuracy of 88%. With state-of-the-art approaches, one should be able to get close to 95%."]},{"cell_type":"markdown","metadata":{},"source":["## Using a trained network to generate predictions on new data\\n","\\n","After having trained a network, you will want to use it in a practical setting. You can generate the likelihood of reviews being positive \\n","by using the `predict` method:"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.91966152],\\n","       [ 0.86563045],\\n","       [ 0.99936908],\\n","       ..., \\n","       [ 0.45731062],\\n","       [ 0.0038014 ],\\n","       [ 0.79525089]], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(x_test)"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, the network is very confident for some samples (0.99 or more, or 0.01 or less) but less confident for others (0.6, 0.4). \\n"]},{"cell_type":"markdown","metadata":{},"source":["## Further experiments\\n","\\n","\\n","* We were using 2 hidden layers. Try to use 1 or 3 hidden layers and see how it affects validation and test accuracy.\\n","* Try to use layers with more hidden units or less hidden units: 32 units, 64 units...\\n","* Try to use the `mse` loss function instead of `binary_crossentropy`.\\n","* Try to use the `tanh` activation (an activation that was popular in the early days of neural networks) instead of `relu`.\\n","\\n","These experiments will help convince you that the architecture choices we have made are all fairly reasonable, although they can still be \\n","improved!"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusions\\n","\\n","\\n","Here\'s what you should take away from this example:\\n","\\n","* There\'s usually quite a bit of preprocessing you need to do on your raw data in order to be able to feed it -- as tensors -- into a neural \\n","network. In the case of sequences of words, they can be encoded as binary vectors -- but there are other encoding options too.\\n","* Stacks of `Dense` layers with `relu` activations can solve a wide range of problems (including sentiment classification), and you will \\n","likely use them frequently.\\n","* In a binary classification problem (two output classes), your network should end with a `Dense` layer with 1 unit and a `sigmoid` activation, \\n","i.e. the output of your network should be a scalar between 0 and 1, encoding a probability.\\n","* With such a scalar sigmoid output, on a binary classification problem, the loss function you should use is `binary_crossentropy`.\\n","* The `rmsprop` optimizer is generally a good enough choice of optimizer, whatever your problem. That\'s one less thing for you to worry \\n","about.\\n","* As they get better on their training data, neural networks eventually start _overfitting_ and end up obtaining increasingly worse results on data \\n","never-seen-before. Make sure to always monitor performance on data that is outside of the training set.\\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":2}', '[NbConvertApp] Converting notebook jupyter-54gs9wq42m9g.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 102 (char 101)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"code","executio...\n', 'kps1gf', 'Done'),
	('vcmv8kviazm1', 'b6deul', '2019-02-25 15:19:55', '2019-02-25 15:19:56', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-vcmv8kviazm1.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 608 (char 607)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('eqqk1insvd0o', '4hf60x', '2019-02-25 15:19:57', '2019-02-25 15:19:57', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\\n","from suds.client import Client\\n","from pandas import Series\\n","import matplotlib.pyplot as plt\\n","import matplotlib.dates as mdates"]},{"cell_type":"markdown","metadata":{},"source":["#### Connect to website "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["now = datetime.datetime.now() # Use now function to get current time. \\n","now1 = now.strftime(\\"%Y-%m-%d %H:%M:%S\\")\\n","\\n","wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09315000\' # Can change to different site if desired.  Format: \'NWISUV:########\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = now1  # Can change to less recent date if desired. "]},{"cell_type":"markdown","metadata":{},"source":["#### Create a new object named NWIS for calling the web service "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["#### Call the GetValuesObject method to return the datavalues"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["#### Get the site name from the response "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName\\n","values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["#### Load called objects into a pandas series. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create blank lists in which to put the values and dates\\n","a = []  \\n","b = []\\n","\\n","# Loop through the values and load into the blank lists using append\\n","for v in values:\\n","    a.append(float(v.value))\\n","    b.append(v._dateTime)\\n","    \\n","# Set the index of the series object to the dates\\n","ts = Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["#### Resample data on daily interval with mean/min/max functions <br>\\n","#### create hourly max, min, and avg series "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create hourly max, min, and avg series \\n","hourlyTotDisAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","hourlyTotDisMax = ts.resample(rule=\'1D\', base=0).max()\\n","hourlyTotDisMin = ts.resample(rule=\'1D\', base=0).min()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot stuff\\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a figure object and add a subplot\\n","fig = plt.figure(figsize=(12,8))\\n","ax = fig.add_subplot(1, 1, 1)  # arguments for add_subplot - add_subplot(nrows, ncols, plot_number)\\n","\\n","# Call the plot() methods on the series object to plot the data\\n","ts.plot(color=\'grey\', linestyle=\'solid\', label=\'15-minute streamflow values\', alpha=0.5, linewidth=0.5)\\n","hourlyTotDisAvg.plot(color=\'green\', linestyle=\'solid\', label=\'Daily avg flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMax.plot(color=\'red\', linestyle=\'solid\', label=\'Daily max flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMin.plot(color=\'blue\', linestyle=\'solid\', label=\'Daily min flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","# Set some properties of the subplot to make it look nice\\n","ax.set_ylabel(\'Discharge, cubic feet per second\')\\n","ax.set_xlabel(\'Date (YYYY-MM-DD)\')\\n","ax.grid(True)\\n","ax.set_title(\'Daily Max, Min, & Avg Flows for: \' + siteName + \', \' + siteCode)\\n","ax.set_xlim(beginDate, endDate) #set limits with date variables\\n","# Add a legend with some customizations\\n","legend = ax.legend(loc=\'upper left\', shadow=True)\\n","fig.autofmt_xdate()  # use auto-formatter to enable accurate date representation with mouse\\n","ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # set ticks interval for every 15 days.\\n","\\n","# Create a frame around the legend.\\n","frame = legend.get_frame()\\n","frame.set_facecolor(\'0.95\')\\n","\\n","# Set the font size in the legend\\n","for label in legend.get_texts():\\n","    label.set_fontsize(\'large\')\\n","\\n","for label in legend.get_lines():\\n","    label.set_linewidth(1.5)  # the legend line width"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\'done!\')"]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-eqqk1insvd0o.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 613 (char 612)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('6ruameaohfn7', 't0cqqj', '2019-02-25 15:19:58', '2019-02-25 15:19:59', '{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false},"outputs":[],"source":["%matplotlib inline\\n","import os\\n","import sys\\n","module_path = os.path.abspath(os.path.join(\'..\'))\\n","if module_path not in sys.path:\\n","    sys.path.append(module_path)\\n","import pandas as pd\\n","import numpy as np\\n","import sqlite3\\n","from main_db_script import db_filename\\n","from hr_db_scripts.main_db_script import get_table_for_variable_code, get_db_table_as_df"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true},"outputs":[],"source":["def round_down_near_24(datetimes): # round down the times near midnight so the tide levels stay on the correct day\\n","    close_time_idx = datetimes.indexer_between_time(\'23:29\', \'23:59\')\\n","    adjusted_times = datetimes[close_time_idx] - pd.Timedelta(minutes=15)\\n","    dt = pd.Series(datetimes)\\n","    dt[close_time_idx] = adjusted_times\\n","    dt = pd.DatetimeIndex(dt)\\n","    return dt"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true},"outputs":[],"source":["def cln_n_rnd_times(df):\\n","    for i in range(df.shape[1]):\\n","        datetimes = df.iloc[:, i]\\n","        times = pd.DatetimeIndex(datetimes)\\n","        rnd_dn = round_down_near_24(times)\\n","        df.iloc[:, i] = rnd_dn\\n","    return df"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false},"outputs":[],"source":["def pivot_dv_df(df):\\n","    return df.pivot(columns=\'SiteID\', values=\'Value\')"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true},"outputs":[],"source":["def rename_cols(df, var_abbrev):\\n","    if var_abbrev != \\"\\":\\n","        new_df = df.copy()\\n","        cols = df.columns.tolist()\\n","        new_cols = [\'{}-{}\'.format(var_abbrev, c) for c in cols]\\n","        new_df.columns = new_cols\\n","        return new_df\\n","    else:\\n","        return df"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true},"outputs":[],"source":["def filter_max_rain_time_dfs(rain_daily_df, time_df):\\n","    timemx_filt = pd.DataFrame(np.where(rain_daily_df>0, time_df, np.datetime64(\'NaT\')))\\n","    timemx_filt.columns = time_df.columns\\n","    timemx_filt.index = time_df.index\\n","    return timemx_filt"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true},"outputs":[],"source":["def tide_when_rain_max(rn_mx_time_df):\\n","    td_df = get_table_for_variable_code(\'six_min_tide\')\\n","    td_df = pivot_dv_df(td_df)\\n","    td_df = td_df.resample(\'15T\').mean()\\n","    rn_mx_time_rnd = cln_n_rnd_times(rn_mx_time_df)\\n","    l = []\\n","    for c in rn_mx_time_rnd.columns:\\n","        times = rn_mx_time_rnd.loc[:, c]\\n","        tides = td_df.loc[times].resample(\'D\').max()\\n","        rain_var = c.split(\'_\')[0]\\n","        rain_site = c.split(\'-\')[-1]\\n","        new_cols = [\'{}-{}_td-{}\'.format(rain_var, rain_site, col) for col in tides.columns]\\n","        tides.columns = new_cols\\n","        l.append(tides)\\n","    new_df = pd.concat(l, axis=1)\\n","    new_df.sort_index(inplace=True)\\n","    return new_df"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true},"outputs":[],"source":["def daily_pivot_table(var_code, agg_function, abbreviation):\\n","    df = get_table_for_variable_code(var_code)\\n","    dfp = pivot_dv_df(df)\\n","    dfd = dfp.resample(\'D\')\\n","    aggrd = dfd.agg(agg_function)\\n","    rnmed = rename_cols(aggrd, abbreviation)\\n","    return rnmed"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true},"outputs":[],"source":["sites = get_db_table_as_df(\'sites\')"]},{"cell_type":"markdown","metadata":{},"source":["#  Rainfall"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true},"outputs":[],"source":["# get rainfall data at 15 min interval\\n","rain_df = get_table_for_variable_code(\'rainfall\')"]},{"cell_type":"markdown","metadata":{},"source":["## Daily Rainfall"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rd-19</th>\\n","      <th>rd-20</th>\\n","      <th>rd-1</th>\\n","      <th>rd-2</th>\\n","      <th>rd-7</th>\\n","      <th>rd-11</th>\\n","      <th>rd-12</th>\\n","      <th>rd-13</th>\\n","      <th>rd-14</th>\\n","      <th>rd-15</th>\\n","      <th>rd-16</th>\\n","      <th>rd-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.05</td>\\n","      <td>0.03</td>\\n","      <td>0.06</td>\\n","      <td>0.02</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","      <td>0.03</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.01</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.02</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.10</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.12</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            rd-19  rd-20  rd-1  rd-2  rd-7  rd-11  rd-12  rd-13  rd-14  rd-15  \\\\\\n","Datetime                                                                        \\n","2010-01-01   0.01   0.01   NaN   NaN  0.05   0.03   0.06   0.02   0.01   0.01   \\n","2010-01-02   0.00   0.00   NaN   NaN  0.00   0.01   0.00   0.00   0.00   0.00   \\n","2010-01-03   0.00   0.00   NaN   NaN  0.00   0.00   0.00   0.02   0.00   0.00   \\n","2010-01-04   0.00   0.00   NaN   NaN  0.10   0.10   0.00   0.11   0.00   0.00   \\n","2010-01-05   0.00   0.00   NaN   NaN  0.00   0.00   0.00   0.00   0.12   0.00   \\n","\\n","            rd-16  rd-21  \\n","Datetime                  \\n","2010-01-01   0.02   0.03  \\n","2010-01-02   0.00   0.00  \\n","2010-01-03   0.00   0.00  \\n","2010-01-04   0.00   0.00  \\n","2010-01-05   0.00   0.11  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["rain_daily15 = daily_pivot_table(\'rainfall\', np.sum, \'\')\\n","rain_daily = daily_pivot_table(\'daily_rainfall\', np.sum, \'\')\\n","rain_daily_comb_no_name = pd.concat([rain_daily, rain_daily15], axis=1)\\n","rain_daily_comb_named = rename_cols(rain_daily_comb_no_name, \'rd\')\\n","rain_daily_comb_named.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Hourly Rainfall"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rhrmx-1</th>\\n","      <th>rhrmx-2</th>\\n","      <th>rhrmx-7</th>\\n","      <th>rhrmx-11</th>\\n","      <th>rhrmx-12</th>\\n","      <th>rhrmx-13</th>\\n","      <th>rhrmx-14</th>\\n","      <th>rhrmx-15</th>\\n","      <th>rhrmx-16</th>\\n","      <th>rhrmx-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.04</td>\\n","      <td>0.01</td>\\n","      <td>0.04</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.01</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.02</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.10</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.12</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            rhrmx-1  rhrmx-2  rhrmx-7  rhrmx-11  rhrmx-12  rhrmx-13  rhrmx-14  \\\\\\n","Datetime                                                                        \\n","2010-01-01      NaN      NaN     0.04      0.01      0.04      0.01      0.01   \\n","2010-01-02      NaN      NaN     0.00      0.01      0.00      0.00      0.00   \\n","2010-01-03      NaN      NaN     0.00      0.00      0.00      0.02      0.00   \\n","2010-01-04      NaN      NaN     0.10      0.10      0.00      0.11      0.00   \\n","2010-01-05      NaN      NaN     0.00      0.00      0.00      0.00      0.12   \\n","\\n","            rhrmx-15  rhrmx-16  rhrmx-21  \\n","Datetime                                  \\n","2010-01-01      0.01      0.01      0.02  \\n","2010-01-02      0.00      0.00      0.00  \\n","2010-01-03      0.00      0.00      0.00  \\n","2010-01-04      0.00      0.00      0.00  \\n","2010-01-05      0.00      0.00      0.11  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["rain15 = pivot_dv_df(rain_df)\\n","rain_hourly_totals = rain15.rolling(window=\'H\').sum()\\n","rhr_mx = rain_hourly_totals.resample(\'D\').max()\\n","rhr_mx = rename_cols(rhr_mx, \'rhrmx\')\\n","rhr_mx.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rhr_mxtime-1</th>\\n","      <th>rhr_mxtime-2</th>\\n","      <th>rhr_mxtime-7</th>\\n","      <th>rhr_mxtime-11</th>\\n","      <th>rhr_mxtime-12</th>\\n","      <th>rhr_mxtime-13</th>\\n","      <th>rhr_mxtime-14</th>\\n","      <th>rhr_mxtime-15</th>\\n","      <th>rhr_mxtime-16</th>\\n","      <th>rhr_mxtime-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-01 22:45:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 23:00:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 05:00:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 23:00:00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-02 13:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-03 07:00:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 13:30:00</td>\\n","      <td>2010-01-04 13:00:00</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 12:45:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:30:00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["           rhr_mxtime-1 rhr_mxtime-2        rhr_mxtime-7       rhr_mxtime-11  \\\\\\n","Datetime                                                                       \\n","2010-01-01          NaT          NaT 2010-01-01 22:45:00 2010-01-01 00:15:00   \\n","2010-01-02          NaT          NaT                 NaT 2010-01-02 13:15:00   \\n","2010-01-03          NaT          NaT                 NaT                 NaT   \\n","2010-01-04          NaT          NaT 2010-01-04 13:30:00 2010-01-04 13:00:00   \\n","2010-01-05          NaT          NaT                 NaT                 NaT   \\n","\\n","                 rhr_mxtime-12       rhr_mxtime-13       rhr_mxtime-14  \\\\\\n","Datetime                                                                 \\n","2010-01-01 2010-01-01 23:00:00 2010-01-01 00:45:00 2010-01-01 00:15:00   \\n","2010-01-02                 NaT                 NaT                 NaT   \\n","2010-01-03                 NaT 2010-01-03 07:00:00                 NaT   \\n","2010-01-04                 NaT 2010-01-04 12:45:00                 NaT   \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:15:00   \\n","\\n","                 rhr_mxtime-15       rhr_mxtime-16       rhr_mxtime-21  \\n","Datetime                                                                \\n","2010-01-01 2010-01-01 05:00:00 2010-01-01 00:45:00 2010-01-01 23:00:00  \\n","2010-01-02                 NaT                 NaT                 NaT  \\n","2010-01-03                 NaT                 NaT                 NaT  \\n","2010-01-04                 NaT                 NaT                 NaT  \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:30:00  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["rhr_timemx = rain_hourly_totals.groupby(pd.TimeGrouper(\'D\')).idxmax()\\n","rhr_timemx = rename_cols(rhr_timemx, \'rhr_mxtime\')\\n","rhr_timemx = filter_max_rain_time_dfs(rain_daily15, rhr_timemx)\\n","rhr_timemx.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 15-min max rainfall"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r15mx-1</th>\\n","      <th>r15mx-2</th>\\n","      <th>r15mx-7</th>\\n","      <th>r15mx-11</th>\\n","      <th>r15mx-12</th>\\n","      <th>r15mx-13</th>\\n","      <th>r15mx-14</th>\\n","      <th>r15mx-15</th>\\n","      <th>r15mx-16</th>\\n","      <th>r15mx-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.02</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.01</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.02</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.10</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.12</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            r15mx-1  r15mx-2  r15mx-7  r15mx-11  r15mx-12  r15mx-13  r15mx-14  \\\\\\n","Datetime                                                                        \\n","2010-01-01      NaN      NaN     0.02      0.01      0.02      0.01      0.01   \\n","2010-01-02      NaN      NaN     0.00      0.01      0.00      0.00      0.00   \\n","2010-01-03      NaN      NaN     0.00      0.00      0.00      0.02      0.00   \\n","2010-01-04      NaN      NaN     0.10      0.10      0.00      0.11      0.00   \\n","2010-01-05      NaN      NaN     0.00      0.00      0.00      0.00      0.12   \\n","\\n","            r15mx-15  r15mx-16  r15mx-21  \\n","Datetime                                  \\n","2010-01-01      0.01      0.01      0.02  \\n","2010-01-02      0.00      0.00      0.00  \\n","2010-01-03      0.00      0.00      0.00  \\n","2010-01-04      0.00      0.00      0.00  \\n","2010-01-05      0.00      0.00      0.11  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["r15_mx = rain15.resample(\'D\').max()\\n","r15_mx = rename_cols(r15_mx, \'r15mx\')\\n","r15_mx.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r15_mxtime-1</th>\\n","      <th>r15_mxtime-2</th>\\n","      <th>r15_mxtime-7</th>\\n","      <th>r15_mxtime-11</th>\\n","      <th>r15_mxtime-12</th>\\n","      <th>r15_mxtime-13</th>\\n","      <th>r15_mxtime-14</th>\\n","      <th>r15_mxtime-15</th>\\n","      <th>r15_mxtime-16</th>\\n","      <th>r15_mxtime-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-01 22:30:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 22:45:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 05:00:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 23:00:00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-02 13:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-03 07:00:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 13:30:00</td>\\n","      <td>2010-01-04 13:00:00</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 12:45:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:30:00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["           r15_mxtime-1 r15_mxtime-2        r15_mxtime-7       r15_mxtime-11  \\\\\\n","Datetime                                                                       \\n","2010-01-01          NaT          NaT 2010-01-01 22:30:00 2010-01-01 00:15:00   \\n","2010-01-02          NaT          NaT                 NaT 2010-01-02 13:15:00   \\n","2010-01-03          NaT          NaT                 NaT                 NaT   \\n","2010-01-04          NaT          NaT 2010-01-04 13:30:00 2010-01-04 13:00:00   \\n","2010-01-05          NaT          NaT                 NaT                 NaT   \\n","\\n","                 r15_mxtime-12       r15_mxtime-13       r15_mxtime-14  \\\\\\n","Datetime                                                                 \\n","2010-01-01 2010-01-01 22:45:00 2010-01-01 00:45:00 2010-01-01 00:15:00   \\n","2010-01-02                 NaT                 NaT                 NaT   \\n","2010-01-03                 NaT 2010-01-03 07:00:00                 NaT   \\n","2010-01-04                 NaT 2010-01-04 12:45:00                 NaT   \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:15:00   \\n","\\n","                 r15_mxtime-15       r15_mxtime-16       r15_mxtime-21  \\n","Datetime                                                                \\n","2010-01-01 2010-01-01 05:00:00 2010-01-01 00:45:00 2010-01-01 23:00:00  \\n","2010-01-02                 NaT                 NaT                 NaT  \\n","2010-01-03                 NaT                 NaT                 NaT  \\n","2010-01-04                 NaT                 NaT                 NaT  \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:30:00  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["r15_timemx = rain15.groupby(pd.TimeGrouper(\'D\')).idxmax()\\n","r15_timemx = rename_cols(r15_timemx, \'r15_mxtime\')\\n","r15_timemx = filter_max_rain_time_dfs(rain_daily15, r15_timemx)\\n","r15_timemx.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Rain prev 3 days"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r3d-19</th>\\n","      <th>r3d-20</th>\\n","      <th>r3d-1</th>\\n","      <th>r3d-2</th>\\n","      <th>r3d-7</th>\\n","      <th>r3d-11</th>\\n","      <th>r3d-12</th>\\n","      <th>r3d-13</th>\\n","      <th>r3d-14</th>\\n","      <th>r3d-15</th>\\n","      <th>r3d-16</th>\\n","      <th>r3d-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.05</td>\\n","      <td>0.04</td>\\n","      <td>0.06</td>\\n","      <td>0.04</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","      <td>0.03</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.13</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            r3d-19  r3d-20  r3d-1  r3d-2  r3d-7  r3d-11  r3d-12  r3d-13  \\\\\\n","Datetime                                                                  \\n","2010-01-01     NaN     NaN    NaN    NaN    NaN     NaN     NaN     NaN   \\n","2010-01-02     NaN     NaN    NaN    NaN    NaN     NaN     NaN     NaN   \\n","2010-01-03     NaN     NaN    NaN    NaN    NaN     NaN     NaN     NaN   \\n","2010-01-04    0.01    0.01    NaN    NaN   0.05    0.04    0.06    0.04   \\n","2010-01-05    0.00    0.00    NaN    NaN   0.10    0.11    0.00    0.13   \\n","\\n","            r3d-14  r3d-15  r3d-16  r3d-21  \\n","Datetime                                    \\n","2010-01-01     NaN     NaN     NaN     NaN  \\n","2010-01-02     NaN     NaN     NaN     NaN  \\n","2010-01-03     NaN     NaN     NaN     NaN  \\n","2010-01-04    0.01    0.01    0.02    0.03  \\n","2010-01-05    0.00    0.00    0.00    0.00  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["rain_prev_3_days = rain_daily_comb_no_name.shift(1).rolling(window=3).sum()\\n","rain_prev_3_days = rename_cols(rain_prev_3_days, \'r3d\')\\n","rain_prev_3_days.head()"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":false},"outputs":[{"data":{"text/plain":["Series([], Freq: D, Name: rd-14, dtype: float64)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["rain_daily_comb_named[\'rd-14\'][rain_daily_comb_named[\'rd-14\']<0]"]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th>SiteID</th>\\n","      <th>1</th>\\n","      <th>2</th>\\n","      <th>7</th>\\n","      <th>11</th>\\n","      <th>12</th>\\n","      <th>13</th>\\n","      <th>14</th>\\n","      <th>15</th>\\n","      <th>16</th>\\n","      <th>21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2014-06-24 00:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:01:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:02:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:03:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:04:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:05:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:06:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:07:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:08:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:09:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:10:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:11:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:12:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:13:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:14:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:16:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:17:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:18:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:19:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:20:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:21:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:22:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:23:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:24:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:25:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:26:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:27:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:28:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:29:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>...</th>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 16:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 16:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","<p>531 rows  10 columns</p>\\n","</div>"],"text/plain":["SiteID                1   2    7    11   12   13   14   15   16   21\\n","Datetime                                                            \\n","2014-06-24 00:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 00:01:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:02:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:03:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:04:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:05:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:06:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:07:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:08:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:09:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:10:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:11:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:12:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:13:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:14:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 00:16:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:17:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:18:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:19:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:20:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:21:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:22:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:23:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:24:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:25:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:26:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:27:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:28:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:29:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","...                  ...  ..  ...  ...  ...  ...  ...  ...  ...  ...\\n","2014-06-24 16:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 16:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","\\n","[531 rows x 10 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["rain15.loc[\'2014-06-24\']"]},{"cell_type":"code","execution_count":19,"metadata":{"collapsed":false},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x362cdc88>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\\nCSroiqIolqCCriiKYgkq6IqiKJbw/wGiRsm9GzhRmgAAAABJRU5ErkJggg==\\n","text/plain":["<matplotlib.figure.Figure at 0x362cd4a8>"]},"metadata":{},"output_type":"display_data"}],"source":["rain_prev_3_days.plot.box()"]},{"cell_type":"markdown","metadata":{},"source":["#  Groundwater"]},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>gw_av-4</th>\\n","      <th>gw_av-5</th>\\n","      <th>gw_av-6</th>\\n","      <th>gw_av-8</th>\\n","      <th>gw_av-9</th>\\n","      <th>gw_av-10</th>\\n","      <th>gw_av-11</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>0.181510</td>\\n","      <td>3.924140</td>\\n","      <td>NaN</td>\\n","      <td>6.050129</td>\\n","      <td>2.858511</td>\\n","      <td>3.167374</td>\\n","      <td>3.509806</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>0.051690</td>\\n","      <td>3.548121</td>\\n","      <td>NaN</td>\\n","      <td>5.990354</td>\\n","      <td>2.745979</td>\\n","      <td>3.238457</td>\\n","      <td>3.637924</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>-0.075826</td>\\n","      <td>3.103997</td>\\n","      <td>NaN</td>\\n","      <td>5.910525</td>\\n","      <td>2.650683</td>\\n","      <td>3.127058</td>\\n","      <td>3.511233</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>-0.186996</td>\\n","      <td>2.882649</td>\\n","      <td>NaN</td>\\n","      <td>5.770411</td>\\n","      <td>2.579872</td>\\n","      <td>2.990989</td>\\n","      <td>3.348661</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>-0.251922</td>\\n","      <td>2.772379</td>\\n","      <td>NaN</td>\\n","      <td>5.648158</td>\\n","      <td>2.538736</td>\\n","      <td>2.873044</td>\\n","      <td>3.232544</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["             gw_av-4   gw_av-5  gw_av-6   gw_av-8   gw_av-9  gw_av-10  \\\\\\n","Datetime                                                                \\n","2010-01-01  0.181510  3.924140      NaN  6.050129  2.858511  3.167374   \\n","2010-01-02  0.051690  3.548121      NaN  5.990354  2.745979  3.238457   \\n","2010-01-03 -0.075826  3.103997      NaN  5.910525  2.650683  3.127058   \\n","2010-01-04 -0.186996  2.882649      NaN  5.770411  2.579872  2.990989   \\n","2010-01-05 -0.251922  2.772379      NaN  5.648158  2.538736  2.873044   \\n","\\n","            gw_av-11  \\n","Datetime              \\n","2010-01-01  3.509806  \\n","2010-01-02  3.637924  \\n","2010-01-03  3.511233  \\n","2010-01-04  3.348661  \\n","2010-01-05  3.232544  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["gw_df = daily_pivot_table(\'shallow_well_depth\', np.mean, \'gw_av\')\\n","gw_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#  Tide"]},{"cell_type":"markdown","metadata":{},"source":["## Average daily tide"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>td_av-17</th>\\n","      <th>td_av-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>0.675800</td>\\n","      <td>0.679987</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>0.604608</td>\\n","      <td>0.707200</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>-0.608692</td>\\n","      <td>-0.579467</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>-0.515733</td>\\n","      <td>-0.522700</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>0.020037</td>\\n","      <td>0.017379</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            td_av-17  td_av-18\\n","Datetime                      \\n","2010-01-01  0.675800  0.679987\\n","2010-01-02  0.604608  0.707200\\n","2010-01-03 -0.608692 -0.579467\\n","2010-01-04 -0.515733 -0.522700\\n","2010-01-05  0.020037  0.017379"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tide_df = daily_pivot_table(\'six_min_tide\', np.mean, \'td_av\')\\n","tide_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["##  Tide when rain is at max"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r15-1_td-17</th>\\n","      <th>r15-1_td-18</th>\\n","      <th>r15-2_td-17</th>\\n","      <th>r15-2_td-18</th>\\n","      <th>r15-7_td-17</th>\\n","      <th>r15-7_td-18</th>\\n","      <th>r15-11_td-17</th>\\n","      <th>r15-11_td-18</th>\\n","      <th>r15-12_td-17</th>\\n","      <th>r15-12_td-18</th>\\n","      <th>r15-13_td-17</th>\\n","      <th>r15-13_td-18</th>\\n","      <th>r15-14_td-17</th>\\n","      <th>r15-14_td-18</th>\\n","      <th>r15-15_td-17</th>\\n","      <th>r15-15_td-18</th>\\n","      <th>r15-16_td-17</th>\\n","      <th>r15-16_td-18</th>\\n","      <th>r15-21_td-17</th>\\n","      <th>r15-21_td-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.814333</td>\\n","      <td>2.148</td>\\n","      <td>-0.246</td>\\n","      <td>-0.092</td>\\n","      <td>1.8375</td>\\n","      <td>2.0505</td>\\n","      <td>-0.567500</td>\\n","      <td>-0.503500</td>\\n","      <td>-0.2460</td>\\n","      <td>-0.092</td>\\n","      <td>-0.049333</td>\\n","      <td>-0.431</td>\\n","      <td>-0.5675</td>\\n","      <td>-0.5035</td>\\n","      <td>1.836333</td>\\n","      <td>1.962000</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.912</td>\\n","      <td>1.273</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.869333</td>\\n","      <td>-1.160333</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.729333</td>\\n","      <td>0.919</td>\\n","      <td>0.901</td>\\n","      <td>1.135</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.968000</td>\\n","      <td>1.240500</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.6005</td>\\n","      <td>0.530</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.772000</td>\\n","      <td>0.740333</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            r15-1_td-17  r15-1_td-18  r15-2_td-17  r15-2_td-18  r15-7_td-17  \\\\\\n","Datetime                                                                      \\n","2010-01-01          NaN          NaN          NaN          NaN     1.814333   \\n","2010-01-02          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-03          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-04          NaN          NaN          NaN          NaN     0.729333   \\n","2010-01-05          NaN          NaN          NaN          NaN          NaN   \\n","\\n","            r15-7_td-18  r15-11_td-17  r15-11_td-18  r15-12_td-17  \\\\\\n","Datetime                                                            \\n","2010-01-01        2.148        -0.246        -0.092        1.8375   \\n","2010-01-02          NaN         0.912         1.273           NaN   \\n","2010-01-03          NaN           NaN           NaN           NaN   \\n","2010-01-04        0.919         0.901         1.135           NaN   \\n","2010-01-05          NaN           NaN           NaN           NaN   \\n","\\n","            r15-12_td-18  r15-13_td-17  r15-13_td-18  r15-14_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01        2.0505     -0.567500     -0.503500       -0.2460   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN     -0.869333     -1.160333           NaN   \\n","2010-01-04           NaN      0.968000      1.240500           NaN   \\n","2010-01-05           NaN           NaN           NaN        0.6005   \\n","\\n","            r15-14_td-18  r15-15_td-17  r15-15_td-18  r15-16_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01        -0.092     -0.049333        -0.431       -0.5675   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN           NaN           NaN           NaN   \\n","2010-01-04           NaN           NaN           NaN           NaN   \\n","2010-01-05         0.530           NaN           NaN           NaN   \\n","\\n","            r15-16_td-18  r15-21_td-17  r15-21_td-18  \\n","Datetime                                              \\n","2010-01-01       -0.5035      1.836333      1.962000  \\n","2010-01-02           NaN           NaN           NaN  \\n","2010-01-03           NaN           NaN           NaN  \\n","2010-01-04           NaN           NaN           NaN  \\n","2010-01-05           NaN      0.772000      0.740333  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["td_r15mx = tide_when_rain_max(r15_timemx)\\n","td_r15mx.head()"]},{"cell_type":"code","execution_count":23,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rhr-1_td-17</th>\\n","      <th>rhr-1_td-18</th>\\n","      <th>rhr-2_td-17</th>\\n","      <th>rhr-2_td-18</th>\\n","      <th>rhr-7_td-17</th>\\n","      <th>rhr-7_td-18</th>\\n","      <th>rhr-11_td-17</th>\\n","      <th>rhr-11_td-18</th>\\n","      <th>rhr-12_td-17</th>\\n","      <th>rhr-12_td-18</th>\\n","      <th>rhr-13_td-17</th>\\n","      <th>rhr-13_td-18</th>\\n","      <th>rhr-14_td-17</th>\\n","      <th>rhr-14_td-18</th>\\n","      <th>rhr-15_td-17</th>\\n","      <th>rhr-15_td-18</th>\\n","      <th>rhr-16_td-17</th>\\n","      <th>rhr-16_td-18</th>\\n","      <th>rhr-21_td-17</th>\\n","      <th>rhr-21_td-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.837500</td>\\n","      <td>2.0505</td>\\n","      <td>-0.246</td>\\n","      <td>-0.092</td>\\n","      <td>1.836333</td>\\n","      <td>1.962</td>\\n","      <td>-0.567500</td>\\n","      <td>-0.503500</td>\\n","      <td>-0.2460</td>\\n","      <td>-0.092</td>\\n","      <td>-0.049333</td>\\n","      <td>-0.431</td>\\n","      <td>-0.5675</td>\\n","      <td>-0.5035</td>\\n","      <td>1.836333</td>\\n","      <td>1.962000</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.912</td>\\n","      <td>1.273</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.869333</td>\\n","      <td>-1.160333</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.729333</td>\\n","      <td>0.9190</td>\\n","      <td>0.901</td>\\n","      <td>1.135</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.968000</td>\\n","      <td>1.240500</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.6005</td>\\n","      <td>0.530</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.772000</td>\\n","      <td>0.740333</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            rhr-1_td-17  rhr-1_td-18  rhr-2_td-17  rhr-2_td-18  rhr-7_td-17  \\\\\\n","Datetime                                                                      \\n","2010-01-01          NaN          NaN          NaN          NaN     1.837500   \\n","2010-01-02          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-03          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-04          NaN          NaN          NaN          NaN     0.729333   \\n","2010-01-05          NaN          NaN          NaN          NaN          NaN   \\n","\\n","            rhr-7_td-18  rhr-11_td-17  rhr-11_td-18  rhr-12_td-17  \\\\\\n","Datetime                                                            \\n","2010-01-01       2.0505        -0.246        -0.092      1.836333   \\n","2010-01-02          NaN         0.912         1.273           NaN   \\n","2010-01-03          NaN           NaN           NaN           NaN   \\n","2010-01-04       0.9190         0.901         1.135           NaN   \\n","2010-01-05          NaN           NaN           NaN           NaN   \\n","\\n","            rhr-12_td-18  rhr-13_td-17  rhr-13_td-18  rhr-14_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01         1.962     -0.567500     -0.503500       -0.2460   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN     -0.869333     -1.160333           NaN   \\n","2010-01-04           NaN      0.968000      1.240500           NaN   \\n","2010-01-05           NaN           NaN           NaN        0.6005   \\n","\\n","            rhr-14_td-18  rhr-15_td-17  rhr-15_td-18  rhr-16_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01        -0.092     -0.049333        -0.431       -0.5675   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN           NaN           NaN           NaN   \\n","2010-01-04           NaN           NaN           NaN           NaN   \\n","2010-01-05         0.530           NaN           NaN           NaN   \\n","\\n","            rhr-16_td-18  rhr-21_td-17  rhr-21_td-18  \\n","Datetime                                              \\n","2010-01-01       -0.5035      1.836333      1.962000  \\n","2010-01-02           NaN           NaN           NaN  \\n","2010-01-03           NaN           NaN           NaN  \\n","2010-01-04           NaN           NaN           NaN  \\n","2010-01-05           NaN      0.772000      0.740333  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["td_rhrmx = tide_when_rain_max(rhr_timemx)\\n","td_rhrmx.head()"]},{"cell_type":"markdown","metadata":{},"source":["## HI/LOs"]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true},"outputs":[],"source":["hilos = []\\n","for v in [\'high_tide\', \'high_high_tide\', \'low_tide\', \'low_low_tide\']:\\n","    hilos.append(daily_pivot_table(v, np.mean, \\"\\".join(w[0] for w in v.split(\'_\'))))"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>ht-17</th>\\n","      <th>ht-18</th>\\n","      <th>hht-17</th>\\n","      <th>hht-18</th>\\n","      <th>lt-17</th>\\n","      <th>lt-18</th>\\n","      <th>llt-17</th>\\n","      <th>llt-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>1.952</td>\\n","      <td>2.241</td>\\n","      <td>2.493</td>\\n","      <td>2.7490</td>\\n","      <td>-0.797</td>\\n","      <td>-1.043</td>\\n","      <td>-1.198</td>\\n","      <td>-1.430</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.939</td>\\n","      <td>2.2395</td>\\n","      <td>-0.604</td>\\n","      <td>-0.840</td>\\n","      <td>-1.056</td>\\n","      <td>-1.132</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>0.830</td>\\n","      <td>1.096</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.841</td>\\n","      <td>-2.024</td>\\n","      <td>-2.516</td>\\n","      <td>-2.694</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.102</td>\\n","      <td>1.3190</td>\\n","      <td>-1.693</td>\\n","      <td>-1.949</td>\\n","      <td>-2.349</td>\\n","      <td>-2.566</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>1.355</td>\\n","      <td>1.654</td>\\n","      <td>1.480</td>\\n","      <td>1.7680</td>\\n","      <td>-1.253</td>\\n","      <td>-1.453</td>\\n","      <td>-1.306</td>\\n","      <td>-1.522</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            ht-17  ht-18  hht-17  hht-18  lt-17  lt-18  llt-17  llt-18\\n","Datetime                                                              \\n","2010-01-01  1.952  2.241   2.493  2.7490 -0.797 -1.043  -1.198  -1.430\\n","2010-01-02    NaN    NaN   1.939  2.2395 -0.604 -0.840  -1.056  -1.132\\n","2010-01-03  0.830  1.096     NaN     NaN -1.841 -2.024  -2.516  -2.694\\n","2010-01-04    NaN    NaN   1.102  1.3190 -1.693 -1.949  -2.349  -2.566\\n","2010-01-05  1.355  1.654   1.480  1.7680 -1.253 -1.453  -1.306  -1.522"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["hilo_df = pd.concat(hilos, axis=1)\\n","hilo_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#  Wind"]},{"cell_type":"code","execution_count":26,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>WDF2-19</th>\\n","      <th>WDF2-20</th>\\n","      <th>WSF2-19</th>\\n","      <th>WSF2-20</th>\\n","      <th>AWDR-19</th>\\n","      <th>AWND-19</th>\\n","      <th>AWND-20</th>\\n","      <th>WGF6-18</th>\\n","      <th>AWND-18</th>\\n","      <th>AWDR-18</th>\\n","      <th>AWND-3</th>\\n","      <th>AWDR-3</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>360.0</td>\\n","      <td>340.0</td>\\n","      <td>23.0</td>\\n","      <td>23.9</td>\\n","      <td>353.0</td>\\n","      <td>6.3</td>\\n","      <td>7.2</td>\\n","      <td>6.798833</td>\\n","      <td>4.384917</td>\\n","      <td>201.898458</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>340.0</td>\\n","      <td>310.0</td>\\n","      <td>23.9</td>\\n","      <td>30.0</td>\\n","      <td>321.0</td>\\n","      <td>13.9</td>\\n","      <td>19.9</td>\\n","      <td>18.064142</td>\\n","      <td>11.356569</td>\\n","      <td>337.813724</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>290.0</td>\\n","      <td>290.0</td>\\n","      <td>17.9</td>\\n","      <td>28.0</td>\\n","      <td>295.0</td>\\n","      <td>11.2</td>\\n","      <td>16.6</td>\\n","      <td>16.935208</td>\\n","      <td>10.734083</td>\\n","      <td>325.094250</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>330.0</td>\\n","      <td>310.0</td>\\n","      <td>16.1</td>\\n","      <td>21.0</td>\\n","      <td>306.0</td>\\n","      <td>7.2</td>\\n","      <td>9.8</td>\\n","      <td>9.317000</td>\\n","      <td>6.280500</td>\\n","      <td>324.969875</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>310.0</td>\\n","      <td>300.0</td>\\n","      <td>15.0</td>\\n","      <td>17.0</td>\\n","      <td>292.0</td>\\n","      <td>6.0</td>\\n","      <td>8.5</td>\\n","      <td>8.925750</td>\\n","      <td>6.063000</td>\\n","      <td>317.637125</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            WDF2-19  WDF2-20  WSF2-19  WSF2-20  AWDR-19  AWND-19  AWND-20  \\\\\\n","Datetime                                                                    \\n","2010-01-01    360.0    340.0     23.0     23.9    353.0      6.3      7.2   \\n","2010-01-02    340.0    310.0     23.9     30.0    321.0     13.9     19.9   \\n","2010-01-03    290.0    290.0     17.9     28.0    295.0     11.2     16.6   \\n","2010-01-04    330.0    310.0     16.1     21.0    306.0      7.2      9.8   \\n","2010-01-05    310.0    300.0     15.0     17.0    292.0      6.0      8.5   \\n","\\n","              WGF6-18    AWND-18     AWDR-18  AWND-3  AWDR-3  \\n","Datetime                                                      \\n","2010-01-01   6.798833   4.384917  201.898458     NaN     NaN  \\n","2010-01-02  18.064142  11.356569  337.813724     NaN     NaN  \\n","2010-01-03  16.935208  10.734083  325.094250     NaN     NaN  \\n","2010-01-04   9.317000   6.280500  324.969875     NaN     NaN  \\n","2010-01-05   8.925750   6.063000  317.637125     NaN     NaN  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["wind_dfs = []\\n","for v in [\'WDF2\', \'WSF2\', \'AWDR\', \'AWND\', \'WGF6\', \'WSF6\', \'WDF6\', \'WS2min\', \'WD2min\']:\\n","    if v == \'WSF6\':\\n","        abbr = \'AWND\'\\n","    elif v == \'WDF6\':\\n","        abbr = \'AWDR\'\\n","    elif v == \'WS2min\':\\n","        abbr = \'AWND\'\\n","    elif v == \'WD2min\':\\n","        abbr = \'AWDR\'\\n","    else:\\n","        abbr = v\\n","    wind_dfs.append(daily_pivot_table(v, np.mean, abbr))\\n","all_wind = pd.concat(wind_dfs, axis=1)\\n","all_wind.head()"]},{"cell_type":"code","execution_count":27,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>WDF2-19</th>\\n","      <th>WDF2-20</th>\\n","      <th>WSF2-19</th>\\n","      <th>WSF2-20</th>\\n","      <th>AWDR-19</th>\\n","      <th>AWND-19</th>\\n","      <th>AWND-20</th>\\n","      <th>WGF6-18</th>\\n","      <th>AWND-18</th>\\n","      <th>AWDR-18</th>\\n","      <th>...</th>\\n","      <th>r3d-1</th>\\n","      <th>r3d-2</th>\\n","      <th>r3d-7</th>\\n","      <th>r3d-11</th>\\n","      <th>r3d-12</th>\\n","      <th>r3d-13</th>\\n","      <th>r3d-14</th>\\n","      <th>r3d-15</th>\\n","      <th>r3d-16</th>\\n","      <th>r3d-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-09-15</th>\\n","      <td>140.0</td>\\n","      <td>110.0</td>\\n","      <td>13.0</td>\\n","      <td>15.0</td>\\n","      <td>119.0</td>\\n","      <td>5.1</td>\\n","      <td>5.6</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>2.200000e-01</td>\\n","      <td>2.400000e-01</td>\\n","      <td>2.600000e-01</td>\\n","      <td>2.200000e-01</td>\\n","      <td>3.100000e-01</td>\\n","      <td>2.400000e-01</td>\\n","      <td>3.600000e-01</td>\\n","      <td>2.400000e-01</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-16</th>\\n","      <td>220.0</td>\\n","      <td>200.0</td>\\n","      <td>25.9</td>\\n","      <td>19.9</td>\\n","      <td>210.0</td>\\n","      <td>15.2</td>\\n","      <td>9.6</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.000000e-02</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-17</th>\\n","      <td>220.0</td>\\n","      <td>200.0</td>\\n","      <td>21.0</td>\\n","      <td>16.1</td>\\n","      <td>41.0</td>\\n","      <td>11.0</td>\\n","      <td>9.4</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.351350e-15</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-18</th>\\n","      <td>30.0</td>\\n","      <td>30.0</td>\\n","      <td>16.1</td>\\n","      <td>18.1</td>\\n","      <td>37.0</td>\\n","      <td>8.5</td>\\n","      <td>9.4</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.351350e-15</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-19</th>\\n","      <td>40.0</td>\\n","      <td>10.0</td>\\n","      <td>10.1</td>\\n","      <td>12.1</td>\\n","      <td>58.0</td>\\n","      <td>4.3</td>\\n","      <td>4.7</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.351350e-15</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","<p>5 rows  113 columns</p>\\n","</div>"],"text/plain":["            WDF2-19  WDF2-20  WSF2-19  WSF2-20  AWDR-19  AWND-19  AWND-20  \\\\\\n","Datetime                                                                    \\n","2010-09-15    140.0    110.0     13.0     15.0    119.0      5.1      5.6   \\n","2010-09-16    220.0    200.0     25.9     19.9    210.0     15.2      9.6   \\n","2010-09-17    220.0    200.0     21.0     16.1     41.0     11.0      9.4   \\n","2010-09-18     30.0     30.0     16.1     18.1     37.0      8.5      9.4   \\n","2010-09-19     40.0     10.0     10.1     12.1     58.0      4.3      4.7   \\n","\\n","            WGF6-18  AWND-18  AWDR-18      ...       r3d-1  r3d-2  \\\\\\n","Datetime                                   ...                      \\n","2010-09-15      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-16      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-17      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-18      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-19      NaN      NaN      NaN      ...         NaN    NaN   \\n","\\n","                   r3d-7        r3d-11        r3d-12        r3d-13  \\\\\\n","Datetime                                                             \\n","2010-09-15  2.200000e-01  2.400000e-01  2.600000e-01  2.200000e-01   \\n","2010-09-16  1.000000e-02 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","2010-09-17 -1.351350e-15 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","2010-09-18 -1.351350e-15 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","2010-09-19 -1.351350e-15 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","\\n","                  r3d-14        r3d-15        r3d-16        r3d-21  \\n","Datetime                                                            \\n","2010-09-15  3.100000e-01  2.400000e-01  3.600000e-01  2.400000e-01  \\n","2010-09-16  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","2010-09-17  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","2010-09-18  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","2010-09-19  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","\\n","[5 rows x 113 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["feature_df = pd.concat([all_wind, hilo_df, td_r15mx, td_rhrmx, tide_df, gw_df, r15_mx, rhr_mx, rain_daily_comb_named, rain_prev_3_days], axis=1)\\n","feature_df = feature_df.loc[\'2010-09-15\':\'2016-10-15\']\\n","feature_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["\\n","### Save Daily Observations to DB"]},{"cell_type":"code","execution_count":28,"metadata":{"collapsed":false},"outputs":[],"source":["con = sqlite3.connect(db_filename)\\n","feature_df.to_sql(con=con, name=\\"nor_daily_observations\\", if_exists=\\"replace\\")"]},{"cell_type":"markdown","metadata":{},"source":["### Make av. table"]},{"cell_type":"code","execution_count":29,"metadata":{"collapsed":false},"outputs":[{"data":{"text/plain":["array([\'WDF2\', \'WSF2\', \'AWDR\', \'AWND\', \'WGF6\', \'ht\', \'hht\', \'lt\', \'llt\',\\n","       \'r15_td\', \'rhr_td\', \'td_av\', \'gw_av\', \'r15mx\', \'rhrmx\', \'rd\', \'r3d\'], dtype=object)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["cols = pd.Series(feature_df.columns)\\n","cols_splt = cols.str.split(\'-\', expand=True)\\n","# do this to make sure the tide when the hourly and 15-min max rains have unique col names\\n","for a in cols_splt.iterrows():\\n","    if a[1].str.contains(\'\\\\d_td\').sum() == 1:\\n","        cols_splt.loc[a[0], 0] += \\"_td\\"\\n","col_vars = cols_splt[0].unique()\\n","col_vars"]},{"cell_type":"code","execution_count":30,"metadata":{"collapsed":false},"outputs":[],"source":["avdf = pd.DataFrame()\\n","for v in col_vars:\\n","    if v not in [\'r15_td\', \'rhr_td\']:\\n","        avdf[v] = feature_df[[a for a in feature_df.columns if a.startswith(v)]].mean(axis=1)\\n","    else:\\n","        avdf[v] = feature_df[cols[cols.str.contains(r\'{}-\\\\d+_td-\\\\d+\'.format(v.split(\'_\')[0]))]].mean(axis=1)"]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":false},"outputs":[],"source":["avdf.to_sql(con=con, name=\'nor_daily_observations_ave\', if_exists=\'replace\')"]},{"cell_type":"code","execution_count":32,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>WDF2</th>\\n","      <th>WSF2</th>\\n","      <th>AWDR</th>\\n","      <th>AWND</th>\\n","      <th>WGF6</th>\\n","      <th>ht</th>\\n","      <th>hht</th>\\n","      <th>lt</th>\\n","      <th>llt</th>\\n","      <th>r15_td</th>\\n","      <th>rhr_td</th>\\n","      <th>td_av</th>\\n","      <th>gw_av</th>\\n","      <th>r15mx</th>\\n","      <th>rhrmx</th>\\n","      <th>rd</th>\\n","      <th>r3d</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-09-15</th>\\n","      <td>125.0</td>\\n","      <td>14.00</td>\\n","      <td>119.0</td>\\n","      <td>5.35</td>\\n","      <td>NaN</td>\\n","      <td>1.5470</td>\\n","      <td>1.91250</td>\\n","      <td>-0.58400</td>\\n","      <td>-0.60400</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.630327</td>\\n","      <td>1.439483</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>2.570000e-01</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-16</th>\\n","      <td>210.0</td>\\n","      <td>22.90</td>\\n","      <td>210.0</td>\\n","      <td>12.40</td>\\n","      <td>NaN</td>\\n","      <td>1.2205</td>\\n","      <td>1.45200</td>\\n","      <td>-0.86250</td>\\n","      <td>-1.16800</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.317994</td>\\n","      <td>1.424287</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>1.000000e-03</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-17</th>\\n","      <td>210.0</td>\\n","      <td>18.55</td>\\n","      <td>41.0</td>\\n","      <td>10.20</td>\\n","      <td>NaN</td>\\n","      <td>0.8865</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.17150</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.033356</td>\\n","      <td>1.405075</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-18</th>\\n","      <td>30.0</td>\\n","      <td>17.10</td>\\n","      <td>37.0</td>\\n","      <td>8.95</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.63575</td>\\n","      <td>-0.83650</td>\\n","      <td>-0.67900</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.517577</td>\\n","      <td>1.373122</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-19</th>\\n","      <td>25.0</td>\\n","      <td>11.10</td>\\n","      <td>58.0</td>\\n","      <td>4.50</td>\\n","      <td>NaN</td>\\n","      <td>1.7275</td>\\n","      <td>2.01750</td>\\n","      <td>-0.51350</td>\\n","      <td>-0.45100</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.729448</td>\\n","      <td>1.365681</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-20</th>\\n","      <td>15.0</td>\\n","      <td>22.45</td>\\n","      <td>29.0</td>\\n","      <td>10.20</td>\\n","      <td>NaN</td>\\n","      <td>1.8965</td>\\n","      <td>2.35750</td>\\n","      <td>-0.22625</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.034590</td>\\n","      <td>1.354308</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-21</th>\\n","      <td>135.0</td>\\n","      <td>14.10</td>\\n","      <td>79.0</td>\\n","      <td>7.05</td>\\n","      <td>NaN</td>\\n","      <td>2.0685</td>\\n","      <td>1.97500</td>\\n","      <td>-0.52650</td>\\n","      <td>-0.22800</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.843558</td>\\n","      <td>1.314162</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-22</th>\\n","      <td>220.0</td>\\n","      <td>18.00</td>\\n","      <td>209.0</td>\\n","      <td>9.95</td>\\n","      <td>NaN</td>\\n","      <td>1.4095</td>\\n","      <td>1.43500</td>\\n","      <td>-0.83500</td>\\n","      <td>-0.78750</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.290825</td>\\n","      <td>1.293849</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-23</th>\\n","      <td>155.0</td>\\n","      <td>15.00</td>\\n","      <td>205.0</td>\\n","      <td>6.80</td>\\n","      <td>NaN</td>\\n","      <td>1.3130</td>\\n","      <td>NaN</td>\\n","      <td>-1.29600</td>\\n","      <td>-1.53200</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.065860</td>\\n","      <td>1.272830</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-24</th>\\n","      <td>200.0</td>\\n","      <td>18.45</td>\\n","      <td>221.0</td>\\n","      <td>10.75</td>\\n","      <td>NaN</td>\\n","      <td>1.2815</td>\\n","      <td>1.76700</td>\\n","      <td>-0.94350</td>\\n","      <td>-1.39250</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.213317</td>\\n","      <td>1.263802</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-25</th>\\n","      <td>215.0</td>\\n","      <td>18.55</td>\\n","      <td>217.0</td>\\n","      <td>11.40</td>\\n","      <td>NaN</td>\\n","      <td>1.0825</td>\\n","      <td>1.41750</td>\\n","      <td>-1.12200</td>\\n","      <td>-1.50100</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.052823</td>\\n","      <td>1.267731</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-26</th>\\n","      <td>40.0</td>\\n","      <td>18.00</td>\\n","      <td>42.0</td>\\n","      <td>8.80</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.98000</td>\\n","      <td>-0.63800</td>\\n","      <td>-1.27600</td>\\n","      <td>-0.361573</td>\\n","      <td>-0.253688</td>\\n","      <td>0.378873</td>\\n","      <td>1.260087</td>\\n","      <td>0.06750</td>\\n","      <td>1.600000e-01</td>\\n","      <td>0.302</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-27</th>\\n","      <td>165.0</td>\\n","      <td>15.10</td>\\n","      <td>190.0</td>\\n","      <td>5.60</td>\\n","      <td>NaN</td>\\n","      <td>1.7650</td>\\n","      <td>2.03900</td>\\n","      <td>-0.29550</td>\\n","      <td>-0.70050</td>\\n","      <td>1.634417</td>\\n","      <td>0.803500</td>\\n","      <td>0.696519</td>\\n","      <td>1.640508</td>\\n","      <td>0.27750</td>\\n","      <td>6.050000e-01</td>\\n","      <td>2.107</td>\\n","      <td>3.020000e-01</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-28</th>\\n","      <td>210.0</td>\\n","      <td>19.00</td>\\n","      <td>192.0</td>\\n","      <td>7.95</td>\\n","      <td>NaN</td>\\n","      <td>1.9180</td>\\n","      <td>2.09650</td>\\n","      <td>NaN</td>\\n","      <td>-0.35425</td>\\n","      <td>1.526219</td>\\n","      <td>1.638354</td>\\n","      <td>0.734892</td>\\n","      <td>2.067030</td>\\n","      <td>0.17750</td>\\n","      <td>2.750000e-01</td>\\n","      <td>0.438</td>\\n","      <td>2.409000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-29</th>\\n","      <td>120.0</td>\\n","      <td>21.90</td>\\n","      <td>84.0</td>\\n","      <td>7.80</td>\\n","      <td>NaN</td>\\n","      <td>1.4910</td>\\n","      <td>2.09300</td>\\n","      <td>-0.25075</td>\\n","      <td>NaN</td>\\n","      <td>0.699688</td>\\n","      <td>0.928375</td>\\n","      <td>0.753175</td>\\n","      <td>2.163813</td>\\n","      <td>0.22750</td>\\n","      <td>4.837500e-01</td>\\n","      <td>0.973</td>\\n","      <td>2.847000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-30</th>\\n","      <td>175.0</td>\\n","      <td>35.00</td>\\n","      <td>180.0</td>\\n","      <td>13.20</td>\\n","      <td>NaN</td>\\n","      <td>1.8240</td>\\n","      <td>1.87000</td>\\n","      <td>NaN</td>\\n","      <td>-0.02450</td>\\n","      <td>1.156938</td>\\n","      <td>0.991833</td>\\n","      <td>0.932358</td>\\n","      <td>4.159302</td>\\n","      <td>0.60500</td>\\n","      <td>1.321250e+00</td>\\n","      <td>8.350</td>\\n","      <td>3.518000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-01</th>\\n","      <td>170.0</td>\\n","      <td>19.45</td>\\n","      <td>348.0</td>\\n","      <td>10.60</td>\\n","      <td>NaN</td>\\n","      <td>2.2195</td>\\n","      <td>2.63150</td>\\n","      <td>0.22475</td>\\n","      <td>NaN</td>\\n","      <td>1.201875</td>\\n","      <td>1.286562</td>\\n","      <td>1.323240</td>\\n","      <td>4.636991</td>\\n","      <td>0.30500</td>\\n","      <td>9.050000e-01</td>\\n","      <td>0.609</td>\\n","      <td>9.761000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-02</th>\\n","      <td>35.0</td>\\n","      <td>19.55</td>\\n","      <td>42.0</td>\\n","      <td>10.60</td>\\n","      <td>NaN</td>\\n","      <td>2.0505</td>\\n","      <td>2.30850</td>\\n","      <td>NaN</td>\\n","      <td>-0.11975</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.140260</td>\\n","      <td>4.170616</td>\\n","      <td>0.00000</td>\\n","      <td>-6.088879e-16</td>\\n","      <td>0.000</td>\\n","      <td>9.932000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-03</th>\\n","      <td>20.0</td>\\n","      <td>28.00</td>\\n","      <td>38.0</td>\\n","      <td>17.20</td>\\n","      <td>NaN</td>\\n","      <td>2.3230</td>\\n","      <td>3.26800</td>\\n","      <td>0.31800</td>\\n","      <td>NaN</td>\\n","      <td>0.607354</td>\\n","      <td>0.555792</td>\\n","      <td>1.703937</td>\\n","      <td>4.088179</td>\\n","      <td>0.08875</td>\\n","      <td>1.750000e-01</td>\\n","      <td>0.596</td>\\n","      <td>8.959000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-04</th>\\n","      <td>20.0</td>\\n","      <td>23.45</td>\\n","      <td>347.0</td>\\n","      <td>12.50</td>\\n","      <td>NaN</td>\\n","      <td>3.2105</td>\\n","      <td>3.61750</td>\\n","      <td>1.18600</td>\\n","      <td>0.53300</td>\\n","      <td>2.713385</td>\\n","      <td>2.945146</td>\\n","      <td>2.103325</td>\\n","      <td>4.225803</td>\\n","      <td>0.04000</td>\\n","      <td>1.200000e-01</td>\\n","      <td>0.320</td>\\n","      <td>1.205000e+00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["             WDF2   WSF2   AWDR   AWND  WGF6      ht      hht       lt  \\\\\\n","Datetime                                                                 \\n","2010-09-15  125.0  14.00  119.0   5.35   NaN  1.5470  1.91250 -0.58400   \\n","2010-09-16  210.0  22.90  210.0  12.40   NaN  1.2205  1.45200 -0.86250   \\n","2010-09-17  210.0  18.55   41.0  10.20   NaN  0.8865      NaN      NaN   \\n","2010-09-18   30.0  17.10   37.0   8.95   NaN     NaN  1.63575 -0.83650   \\n","2010-09-19   25.0  11.10   58.0   4.50   NaN  1.7275  2.01750 -0.51350   \\n","2010-09-20   15.0  22.45   29.0  10.20   NaN  1.8965  2.35750 -0.22625   \\n","2010-09-21  135.0  14.10   79.0   7.05   NaN  2.0685  1.97500 -0.52650   \\n","2010-09-22  220.0  18.00  209.0   9.95   NaN  1.4095  1.43500 -0.83500   \\n","2010-09-23  155.0  15.00  205.0   6.80   NaN  1.3130      NaN -1.29600   \\n","2010-09-24  200.0  18.45  221.0  10.75   NaN  1.2815  1.76700 -0.94350   \\n","2010-09-25  215.0  18.55  217.0  11.40   NaN  1.0825  1.41750 -1.12200   \\n","2010-09-26   40.0  18.00   42.0   8.80   NaN     NaN  1.98000 -0.63800   \\n","2010-09-27  165.0  15.10  190.0   5.60   NaN  1.7650  2.03900 -0.29550   \\n","2010-09-28  210.0  19.00  192.0   7.95   NaN  1.9180  2.09650      NaN   \\n","2010-09-29  120.0  21.90   84.0   7.80   NaN  1.4910  2.09300 -0.25075   \\n","2010-09-30  175.0  35.00  180.0  13.20   NaN  1.8240  1.87000      NaN   \\n","2010-10-01  170.0  19.45  348.0  10.60   NaN  2.2195  2.63150  0.22475   \\n","2010-10-02   35.0  19.55   42.0  10.60   NaN  2.0505  2.30850      NaN   \\n","2010-10-03   20.0  28.00   38.0  17.20   NaN  2.3230  3.26800  0.31800   \\n","2010-10-04   20.0  23.45  347.0  12.50   NaN  3.2105  3.61750  1.18600   \\n","\\n","                llt    r15_td    rhr_td     td_av     gw_av    r15mx  \\\\\\n","Datetime                                                               \\n","2010-09-15 -0.60400       NaN       NaN  0.630327  1.439483  0.00000   \\n","2010-09-16 -1.16800       NaN       NaN  0.317994  1.424287  0.00000   \\n","2010-09-17 -1.17150       NaN       NaN -0.033356  1.405075  0.00000   \\n","2010-09-18 -0.67900       NaN       NaN  0.517577  1.373122  0.00000   \\n","2010-09-19 -0.45100       NaN       NaN  0.729448  1.365681  0.00000   \\n","2010-09-20      NaN       NaN       NaN  1.034590  1.354308  0.00000   \\n","2010-09-21 -0.22800       NaN       NaN  0.843558  1.314162  0.00000   \\n","2010-09-22 -0.78750       NaN       NaN  0.290825  1.293849  0.00000   \\n","2010-09-23 -1.53200       NaN       NaN -0.065860  1.272830  0.00000   \\n","2010-09-24 -1.39250       NaN       NaN  0.213317  1.263802  0.00000   \\n","2010-09-25 -1.50100       NaN       NaN -0.052823  1.267731  0.00000   \\n","2010-09-26 -1.27600 -0.361573 -0.253688  0.378873  1.260087  0.06750   \\n","2010-09-27 -0.70050  1.634417  0.803500  0.696519  1.640508  0.27750   \\n","2010-09-28 -0.35425  1.526219  1.638354  0.734892  2.067030  0.17750   \\n","2010-09-29      NaN  0.699688  0.928375  0.753175  2.163813  0.22750   \\n","2010-09-30 -0.02450  1.156938  0.991833  0.932358  4.159302  0.60500   \\n","2010-10-01      NaN  1.201875  1.286562  1.323240  4.636991  0.30500   \\n","2010-10-02 -0.11975       NaN       NaN  1.140260  4.170616  0.00000   \\n","2010-10-03      NaN  0.607354  0.555792  1.703937  4.088179  0.08875   \\n","2010-10-04  0.53300  2.713385  2.945146  2.103325  4.225803  0.04000   \\n","\\n","                   rhrmx     rd           r3d  \\n","Datetime                                       \\n","2010-09-15 -5.418842e-16  0.000  2.570000e-01  \\n","2010-09-16 -5.418842e-16  0.000  1.000000e-03  \\n","2010-09-17 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-18 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-19 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-20 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-21 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-22 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-23 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-24 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-25 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-26  1.600000e-01  0.302 -4.654263e-16  \\n","2010-09-27  6.050000e-01  2.107  3.020000e-01  \\n","2010-09-28  2.750000e-01  0.438  2.409000e+00  \\n","2010-09-29  4.837500e-01  0.973  2.847000e+00  \\n","2010-09-30  1.321250e+00  8.350  3.518000e+00  \\n","2010-10-01  9.050000e-01  0.609  9.761000e+00  \\n","2010-10-02 -6.088879e-16  0.000  9.932000e+00  \\n","2010-10-03  1.750000e-01  0.596  8.959000e+00  \\n","2010-10-04  1.200000e-01  0.320  1.205000e+00  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["avdf.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-6ruameaohfn7.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 202 (char 201)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"code","executio...\n', 'kps1gf', 'Done'),
	('48kskz8kt4h', 'e6kct2xn7hmmtxu7ww5m', '2019-02-25 15:19:52', '2019-02-25 15:19:59', 'j9pxl1-NS3eu;b6deul-dpAHi;4hf60x-4VBv2;t0cqqj-azF9B;', '54gs9wq42m9g;vcmv8kviazm1;eqqk1insvd0o;6ruameaohfn7;', 'kps1gf;', 'Done'),
	('b1pclsh12t2x', 'b6deul', '2019-02-25 16:02:40', '2019-02-25 16:02:41', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-b1pclsh12t2x.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 608 (char 607)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('yhcyj3hz1mgt', 'b6deul', '2019-02-25 16:06:39', '2019-02-25 16:06:40', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-yhcyj3hz1mgt.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting \',\' delimiter: line 1 column 608 (char 607)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('uehlx68hq7lj', 'b6deul', '2019-02-25 16:08:11', '2019-02-25 16:08:12', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-uehlx68hq7lj.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('a723acsh4qet', 'b6deul', '2019-02-25 16:10:15', '2019-02-25 16:10:15', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('rt04xpt7rck3', 'b6deul', '2019-02-25 16:12:16', '2019-02-25 16:12:17', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-rt04xpt7rck3.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('7f9u8qm4vbbf', 'b6deul', '2019-02-25 16:13:55', '2019-02-25 16:13:55', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', 'bash: -c: line 0: syntax error near unexpected token `(\'\n', 'kps1gf', 'Done'),
	('x7xu5ciexbr1', 'b6deul', '2019-02-25 16:14:36', '2019-02-25 16:14:37', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-x7xu5ciexbr1.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Invalid \\escape: line 1 column 878 (char 877)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('zj14gueium6g', 'b6deul', '2019-02-25 16:15:35', '2019-02-25 16:15:36', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-zj14gueium6g.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Invalid \\escape: line 1 column 607 (char 606)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('7mfuvcecbzhn', 'b6deul', '2019-02-25 16:16:55', '2019-02-25 16:16:56', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-7mfuvcecbzhn.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Invalid \\escape: line 1 column 878 (char 877)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'{"cells":[{"cell_type":"markdown","meta...\n', 'kps1gf', 'Done'),
	('mda7bv784eki', 'b6deul', '2019-02-25 16:38:22', '2019-02-25 16:38:23', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-mda7bv784eki.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('8ba3dt8qqjq8', 'b6deul', '2019-02-25 16:48:31', '2019-02-25 16:48:32', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-8ba3dt8qqjq8.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('6fsayzi7vmf', '071wew', '2019-02-25 16:48:58', '2019-02-25 16:48:58', NULL, NULL, 'cvpgu6', 'Done'),
	('12maoumbx3b', 'e6kct2xn7hmmtxu7ww5m', '2019-02-26 09:30:22', '2019-02-26 09:32:23', 'j9pxl1-NS3eu;b6deul-dpAHi;4hf60x-4VBv2;t0cqqj-azF9B;', 'null;null;null;null;', 'kps1gf;', 'Done'),
	('hz0npdehs3j', '7sb7xj', '2019-03-25 12:51:26', '2019-03-25 12:51:26', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', NULL, 'kps1gf', 'Done'),
	('zqfg611b0ae', 'vke2yf47hyot7ae7np7h', '2019-03-25 12:51:23', '2019-03-25 12:51:27', 'nhi96d-QjAOf;umv6tx-4GR5R;rh1u8q-4GbwM;rpnhlg-J05ve;wsxeps-6vYXt;qp820f-NCTrl;ew8pku-GsoF6;spz3b5-czpKT;omop8l-CNs0W;m6bbrf-KIAHv;7sb7xj-jyToc;', 'null;null;null;null;null;null;null;null;null;null;hz0npdehs3j;', 'kps1gf;', 'Done'),
	('ycn8c2hjv665', 'w5z0p8', '2019-04-09 17:27:56', '2019-04-09 17:27:56', NULL, './geoweaver-testpython.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('4lu30m065pbg', 'f0qvfi', '2019-04-09 17:29:33', '2019-04-09 17:29:37', '# Write first python in Geoweaver\nprint("test2")', '[NbConvertApp] Converting notebook jupyter-4lu30m065pbg.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 14, in parse_json\n    nb_dict = json.loads(s, **kwargs)\n  File "/usr/lib/python3.6/json/__init__.py", line 354, in loads\n    return _default_decoder.decode(s)\n  File "/usr/lib/python3.6/json/decoder.py", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File "/usr/lib/python3.6/json/decoder.py", line 357, in raw_decode\n    raise JSONDecodeError("Expecting value", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 141, in read\n    return reads(fp.read(), as_version, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/__init__.py", line 74, in reads\n    nb = reader.reads(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 58, in reads\n    nb_dict = parse_json(s, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/nbformat/reader.py", line 17, in parse_json\n    raise NotJSONError(("Notebook does not appear to be JSON: %r" % s)[:77] + "...")\nnbformat.reader.NotJSONError: Notebook does not appear to be JSON: \'# Write first python in Geoweaver\\\\npri...\n', 'kps1gf', 'Done'),
	('kpc76du6o9eg', 'f0qvfi', '2019-04-09 17:36:38', '2019-04-09 17:36:38', '# Write first python in Geoweaver\nprint("test2")', 'bash: ./python-kpc76du6o9eg.py: Permission denied\n', 'kps1gf', 'Done'),
	('zwtd0zjk36eu', 'f0qvfi', '2019-04-09 17:38:27', '2019-04-09 17:38:27', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('qzx8heab6yo3', 'f0qvfi', '2019-04-09 17:56:59', '2019-04-09 17:56:59', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('w7xk66trm57l', 'f0qvfi', '2019-04-09 17:57:17', '2019-04-09 17:57:17', '# Write first python in Geoweaver\nprint("test2")', './python-w7xk66trm57l.py: line 2: syntax error near unexpected token `test2\'\n./python-w7xk66trm57l.py: line 2: `print(test2)\'\n', 'kps1gf', 'Done'),
	('311f9xajjxry', 'f0qvfi', '2019-04-09 17:58:07', '2019-04-09 17:58:07', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('bqj4pjwnzp61', 'f0qvfi', '2019-04-09 17:59:10', '2019-04-09 17:59:10', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('09c6h05ktlo3', 'f0qvfi', '2019-04-09 17:59:38', '2019-04-09 17:59:38', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('g7ef6ldoe8sp', 'f0qvfi', '2019-04-09 18:03:12', '2019-04-09 18:03:12', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('t0u78q1nk7t9', 'f0qvfi', '2019-04-09 18:05:43', '2019-04-09 18:05:43', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('j1x1o6t9hkud', 'f0qvfi', '2019-04-09 18:07:00', '2019-04-09 18:07:00', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('kpxto7zan57g', 'f0qvfi', '2019-04-09 18:07:23', '2019-04-09 18:07:23', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('wvog0ekj0v24', 'f0qvfi', '2019-04-09 18:07:54', '2019-04-09 18:07:54', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('14j0x9wt7i7r', 'f0qvfi', '2019-04-09 18:09:40', '2019-04-09 18:09:40', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('qy9u4el5k0m5', 'f0qvfi', '2019-04-09 18:14:18', '2019-04-09 18:14:18', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('zcyjjxwhj6k9', 'f0qvfi', '2019-04-09 18:15:23', '2019-04-09 18:15:23', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('f4ajidq0hj2t', 'f0qvfi', '2019-04-09 18:15:44', '2019-04-09 18:15:44', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('7gv0j12sccab', 'f0qvfi', '2019-04-09 18:18:30', '2019-04-09 18:18:30', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('srio74q6qnxz', 'f0qvfi', '2019-04-09 18:18:51', '2019-04-09 18:18:51', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('fzedm0skhjnt', 'f0qvfi', '2019-04-09 18:19:20', '2019-04-09 18:19:20', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('znjbuerxwvjn', 'f0qvfi', '2019-04-09 18:20:47', '2019-04-09 18:20:47', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('sdong0fqg1yn', 'f0qvfi', '2019-04-09 18:21:07', '2019-04-09 18:21:07', '# Write first python in Geoweaver\nprint("test2")', '', 'kps1gf', 'Done'),
	('z9hsbo0h8e25', 'f0qvfi', '2019-04-09 18:24:06', '2019-04-09 18:24:06', '# Write first python in Geoweaver\nprint("test2")', './python-z9hsbo0h8e25.py: line 2: syntax error near unexpected token `"test2"\'\n./python-z9hsbo0h8e25.py: line 2: `print("test2")\'\n', 'kps1gf', 'Done'),
	('0h72nw6iwbpv', 'f0qvfi', '2019-04-09 18:28:54', '2019-04-09 18:28:54', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('m5ulyfxb1tsr', 'f0qvfi', '2019-04-10 12:10:33', '2019-04-10 12:10:33', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('dyw2u71z8npq', 'f0qvfi', '2019-04-10 12:24:31', '2019-04-10 12:24:31', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('lyhzegy3gaxw', '4ng18f', '2019-04-10 12:27:10', '2019-04-10 12:27:11', '#!/bin/bash\n#write your bash script\nbasedir=/home/zsun/data/\ngdalwarp -overwrite -t_srs EPSG:32614 -of GTiff D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38.tif D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif\ngdaltindex -tileindex location D:/workspace/ec-deep/data/cdl/tileindex/2015213/LC80310272015213LGN00.shp D:\\workspace\\ec-deep\\data\\cdl\\tileindex\\2015213/LC80310272015213LGN00_sr_band1.tif\ngdalwarp -q -cutline D:/workspace/ec-deep/data/cdl/tileindex/20110907/LT05_L1TP_031027_20110907_20160830_01_T1/LT05_L1TP_031027_20110907_20160830_01_T1.shp -crop_to_cutline -tr 30.0 30.0 -of GTiff D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_20110907.tif\n', 'ERROR 4: D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38.tif: No such file or directory\nCreating new index file...\nERROR 4: D:workspaceec-deepdatacdltileindex2015213/LC80310272015213LGN00_sr_band1.tif: No such file or directory\nERROR 1: Failed to create file D:/workspace/ec-deep/data/cdl/tileindex/2015213/LC80310272015213LGN00.shp: No such file or directory\nUnable to open/create shapefile `D:/workspace/ec-deep/data/cdl/tileindex/2015213/LC80310272015213LGN00.shp\'.\nERROR 4: D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif: No such file or directory\n', 'kps1gf', 'Done'),
	('il6g73mre2we', 'f0qvfi', '2019-04-10 12:27:39', '2019-04-10 12:27:39', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('5f9qe0zo1qio', 'f0qvfi', '2019-04-10 12:28:56', '2019-04-10 12:28:56', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('ntyiva7knxld', 'f0qvfi', '2019-04-11 18:24:43', '2019-04-11 18:24:43', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('ve8yhcjc4cgc', 'f0qvfi', '2019-04-11 18:29:08', '2019-04-11 18:29:08', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('xooli9vxlv63', 'f0qvfi', '2019-04-13 00:21:48', '2019-04-13 00:21:48', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('rbaxodbho7ou', 'f0qvfi', '2019-04-13 00:22:52', '2019-04-13 00:22:52', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('mvj087tugsls', 'f0qvfi', '2019-04-13 00:23:44', '2019-04-13 00:23:44', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('ime1s7vhi9kb', 'f0qvfi', '2019-04-13 01:02:40', '2019-04-13 01:02:41', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('3rps9fgo0ezg', 'f0qvfi', '2019-04-13 01:04:24', '2019-04-13 01:04:24', '# Write first python in Geoweaver\nprint("test2")', 'bash: activate: No such file or directory\ntest2\n', 'kps1gf', 'Done'),
	('bqfu56g0ebb6', 'f0qvfi', '2019-04-13 01:26:51', '2019-04-13 01:26:51', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('aroc3d4lmvab', 'f0qvfi', '2019-04-13 01:27:50', '2019-04-13 01:27:50', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('bpinqvrg9978', 'f0qvfi', '2019-04-13 01:29:10', '2019-04-13 01:29:10', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('poxpetnqi40u', 'f0qvfi', '2019-04-13 01:30:05', '2019-04-13 01:30:05', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('gne4oycbxzod', 'f0qvfi', '2019-04-13 01:31:26', '2019-04-13 01:31:26', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('da9vengdvf8o', 'f0qvfi', '2019-04-13 01:33:38', '2019-04-13 01:33:38', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('tbzeynlkzehy', 'f0qvfi', '2019-04-13 01:35:14', '2019-04-13 01:35:14', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('ikvqmx9swaur', 'f0qvfi', '2019-04-13 01:35:42', '2019-04-13 01:35:42', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('197pv0s0a3zy', 'f0qvfi', '2019-04-13 01:36:15', '2019-04-13 01:36:15', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('8gyvu3hkdcb9', 'f0qvfi', '2019-04-13 01:39:48', '2019-04-13 01:39:48', '# Write first python in Geoweaver\nprint("test2")', 'test2\n', 'kps1gf', 'Done'),
	('o2yo7b49qy40', 'f0qvfi', '2019-04-13 01:40:49', '2019-04-13 01:40:49', '# Write first python in Geoweaver\nprint("test2")', 'bash: activate: No such file or directory\ntest2\n', 'kps1gf', 'Done'),
	('w2oxen9lyy4z', '0giu1h', '2019-04-14 20:57:37', '2019-04-14 20:57:38', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.gz\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	if [ year -lt 2008 ]\n		\n		echo "there is no CDL fro this year, skipping"\n		continue;\n\n	fi\n\n	echo "unzip "$entry\n	tar -zxvf $entry -C $landsat_unzip_folder\n	\n	echo "create tile boundary using tileindex"\n	shpfile=$tileindex_folder$filename".shp"\n	band1file=$landsat_unzip_folder$filename"*band1.tif"\n	gdalindex -tileindex location $shpfile $band1file\n\n	echo "cut and resample CDL to fit the landsat scene"\n	cutcdlfile=$cut_cdl_folder$filename\n	gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', '  File "python-w2oxen9lyy4z.py", line 3\n    echo "start to prepare landsat into training dataset"\n                                                        ^\nSyntaxError: invalid syntax\n', 'kps1gf', 'Done'),
	('e7mzyym92jjp', '0giu1h', '2019-04-14 20:59:38', '2019-04-14 20:59:38', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.gz\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	if [ year -lt 2008 ]\n		\n		echo "there is no CDL fro this year, skipping"\n		continue;\n\n	fi\n\n	echo "unzip "$entry\n	tar -zxvf $entry -C $landsat_unzip_folder\n	\n	echo "create tile boundary using tileindex"\n	shpfile=$tileindex_folder$filename".shp"\n	band1file=$landsat_unzip_folder$filename"*band1.tif"\n	gdalindex -tileindex location $shpfile $band1file\n\n	echo "cut and resample CDL to fit the landsat scene"\n	cutcdlfile=$cut_cdl_folder$filename\n	gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', '  File "python-e7mzyym92jjp.py", line 3\n    echo "start to prepare landsat into training dataset"\n                                                        ^\nSyntaxError: invalid syntax\n', 'kps1gf', 'Done'),
	('raac35qcz5sh', '0giu1h', '2019-04-14 23:08:30', '2019-04-14 23:08:30', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.gz\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	if [ year -lt 2008 ]\n		\n		echo "there is no CDL fro this year, skipping"\n		continue;\n\n	fi\n\n	echo "unzip "$entry\n	tar -zxvf $entry -C $landsat_unzip_folder\n	\n	echo "create tile boundary using tileindex"\n	shpfile=$tileindex_folder$filename".shp"\n	band1file=$landsat_unzip_folder$filename"*band1.tif"\n	gdalindex -tileindex location $shpfile $band1file\n\n	echo "cut and resample CDL to fit the landsat scene"\n	cutcdlfile=$cut_cdl_folder$filename\n	gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', '  File "python-raac35qcz5sh.py", line 3\n    echo "start to prepare landsat into training dataset"\n                                                        ^\nSyntaxError: invalid syntax\n', 'kps1gf', 'Done'),
	('j92ldmlzs9tk', '0giu1h', '2019-04-14 23:19:40', '2019-04-14 23:19:41', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n./geoweaver-6y69jvtr4u5j.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-6y69jvtr4u5j.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('x2ozgz7yz87x', '0giu1h', '2019-04-14 23:21:09', '2019-04-14 23:21:10', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n./geoweaver-i5wwmusa0uyx.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-i5wwmusa0uyx.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('22gjx924ow3u', '0giu1h', '2019-04-15 10:09:05', '2019-04-15 10:09:06', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n./geoweaver-gwwrqznjv89i.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-gwwrqznjv89i.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('1v279ck3lfxi', '0giu1h', '2019-04-15 10:12:59', '2019-04-15 10:12:59', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n./geoweaver-heqszwobhy5o.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-heqszwobhy5o.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('7846lza4ac56', '0giu1h', '2019-04-15 10:20:17', '2019-04-15 10:20:18', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n./geoweaver-qc11lqb1e7jq.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-qc11lqb1e7jq.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('kkcn3kmhg6ep', '0giu1h', '2019-04-15 10:30:05', '2019-04-15 10:30:06', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('8tcuz8m4wuy4', '0giu1h', '2019-04-15 10:30:54', '2019-04-15 10:30:54', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n./geoweaver-22umfgdcwtry.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-22umfgdcwtry.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('17huaix5irbh', '0giu1h', '2019-04-15 10:44:17', '2019-04-15 10:44:17', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory ../data/cdl-projected/: No such file or directory\n../data/cdl-raw//*cdls.img\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff ../data/cdl-raw//*cdls.img ../data/cdl-projected/*cdls.img_32614.tif\nERROR 4: ../data/cdl-raw//*cdls.img: No such file or directory\nmkdir: cannot create directory ../data/landsat-unzip/: No such file or directory\nmkdir: cannot create directory ../data/tileindex/: No such file or directory\nmkdir: cannot create directory ../data/cdl-cut/: No such file or directory\n./geoweaver-wyebvj5druvh.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-wyebvj5druvh.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('dhfympbxfcez', 'f0qvfi', '2019-04-15 14:58:32', '2019-04-15 14:58:32', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', '0.0153570175171\n', 'kps1gf', 'Done'),
	('eer11zoco6y4', '0giu1h', '2019-04-15 16:37:08', '2019-04-15 16:37:08', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    if [ year -lt 2008 ]\n        \n        echo "there is no CDL fro this year, skipping"\n        continue;\n\n    fi\n\n    echo "unzip "$entry\n    tar -zxvf $entry -C $landsat_unzip_folder\n    \n    echo "create tile boundary using tileindex"\n    shpfile=$tileindex_folder$filename".shp"\n    band1file=$landsat_unzip_folder$filename"*band1.tif"\n    gdalindex -tileindex location $shpfile $band1file\n\n    echo "cut and resample CDL to fit the landsat scene"\n    cutcdlfile=$cut_cdl_folder$filename\n    gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder"CDL_"$year"_38_32614.tif" $cutcdlfile\n\ndone\n\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory ../data/cdl-projected/: No such file or directory\n../data/cdl-raw//*cdls.img\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff ../data/cdl-raw//*cdls.img ../data/cdl-projected/*cdls.img_32614.tif\nERROR 4: ../data/cdl-raw//*cdls.img: No such file or directory\nmkdir: cannot create directory ../data/landsat-unzip/: No such file or directory\nmkdir: cannot create directory ../data/tileindex/: No such file or directory\nmkdir: cannot create directory ../data/cdl-cut/: No such file or directory\n./geoweaver-o1k0sxmwk6fd.sh: line 59: syntax error near unexpected token `fi\'\n./geoweaver-o1k0sxmwk6fd.sh: line 59: `    fi\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('w8dwev4pcmux', '0giu1h', '2019-04-15 16:39:17', '2019-04-15 16:39:17', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncd /home/zsun/dl-cdl/bin/\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    unzipped=0\n\n    for band1 in "$landsat_unzip_folder"/*"$date"*band1*\n    do \n        echo "found band1 image: "$band1\n        unzipped=1\n    done\n\n    if [ $unzipped == 1 ] \n    then\n        echo "already unzipped"\n    else\n\n        echo "unzip "$entry\n            tar -zxvf $entry -C $landsat_unzip_folder\n    fi\ndone\n\nfor en in "$landsat_unzip_folder"/*band1*\ndo\n    echo "$en"\n    filename=${en##*/}\n    echo "get band name: "$filename\n    # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n    date=${filename:17:8}\n        echo "current date is: "$date\n        year=${date:0:4}\n        monthday=${date:4:4}\n\n    uncut=1\n\n        for band1 in "$cut_cdl_folder"/*"$date"*band1*\n        do\n                echo "found band1 image: "$band1\n                uncut=0\n        done\n\n    if [ $year -lt 2008 ] || [ $uncut == 0  ]\n        then\n                echo "there is no CDL fro this year or the scene has already been cutted, skipping"\n        else\n\n                echo "create tile boundary using tileindex"\n                shpfile=$tileindex_folder$filename".shp"\n                band1file=$en\n                gdaltindex -tileindex location $shpfile $band1file\n\n                echo "cut and resample CDL to fit the landsat scene"\n                cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n                gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder""$year"_30m_cdls.img_32614.tif" $cutcdlfile\n\n        fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\n./geoweaver-w3i2cg9s91h4.sh: line 5: cd: /home/zsun/dl-cdl/bin/: No such file or directory\nmkdir: cannot create directory ../data/cdl-projected/: No such file or directory\n../data/cdl-raw//*cdls.img\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff ../data/cdl-raw//*cdls.img ../data/cdl-projected/*cdls.img_32614.tif\nERROR 4: ../data/cdl-raw//*cdls.img: No such file or directory\nmkdir: cannot create directory ../data/landsat-unzip/: No such file or directory\nmkdir: cannot create directory ../data/tileindex/: No such file or directory\nmkdir: cannot create directory ../data/cdl-cut/: No such file or directory\n../data/landsat//*\nget file name: *\ncurrent date is: \nfound band1 image: ../data/landsat-unzip//**band1*\nalready unzipped\n../data/landsat-unzip//*band1*\nget band name: *band1*\ncurrent date is: \nfound band1 image: ../data/cdl-cut//**band1*\n./geoweaver-w3i2cg9s91h4.sh: line 93: [: -lt: unary operator expected\nthere is no CDL fro this year or the scene has already been cutted, skipping\nend the data preparation\n', 'kps1gf', 'Done'),
	('vrjjmfd6ohna', 'f0qvfi', '2019-05-13 13:25:28', '2019-05-13 13:25:28', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', '0.0157108306885\n', 'kps1gf', 'Done'),
	('3ga7pb5x519l', '4hf60x', '2019-05-13 14:45:53', '2019-05-13 14:45:57', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\\n","from suds.client import Client\\n","from pandas import Series\\n","import matplotlib.pyplot as plt\\n","import matplotlib.dates as mdates"]},{"cell_type":"markdown","metadata":{},"source":["#### Connect to website "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["now = datetime.datetime.now() # Use now function to get current time. \\n","now1 = now.strftime(\\"%Y-%m-%d %H:%M:%S\\")\\n","\\n","wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09315000\' # Can change to different site if desired.  Format: \'NWISUV:########\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = now1  # Can change to less recent date if desired. "]},{"cell_type":"markdown","metadata":{},"source":["#### Create a new object named NWIS for calling the web service "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["#### Call the GetValuesObject method to return the datavalues"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["#### Get the site name from the response "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName\\n","values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["#### Load called objects into a pandas series. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create blank lists in which to put the values and dates\\n","a = []  \\n","b = []\\n","\\n","# Loop through the values and load into the blank lists using append\\n","for v in values:\\n","    a.append(float(v.value))\\n","    b.append(v._dateTime)\\n","    \\n","# Set the index of the series object to the dates\\n","ts = Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["#### Resample data on daily interval with mean/min/max functions <br>\\n","#### create hourly max, min, and avg series "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create hourly max, min, and avg series \\n","hourlyTotDisAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","hourlyTotDisMax = ts.resample(rule=\'1D\', base=0).max()\\n","hourlyTotDisMin = ts.resample(rule=\'1D\', base=0).min()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot stuff\\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a figure object and add a subplot\\n","fig = plt.figure(figsize=(12,8))\\n","ax = fig.add_subplot(1, 1, 1)  # arguments for add_subplot - add_subplot(nrows, ncols, plot_number)\\n","\\n","# Call the plot() methods on the series object to plot the data\\n","ts.plot(color=\'grey\', linestyle=\'solid\', label=\'15-minute streamflow values\', alpha=0.5, linewidth=0.5)\\n","hourlyTotDisAvg.plot(color=\'green\', linestyle=\'solid\', label=\'Daily avg flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMax.plot(color=\'red\', linestyle=\'solid\', label=\'Daily max flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMin.plot(color=\'blue\', linestyle=\'solid\', label=\'Daily min flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","# Set some properties of the subplot to make it look nice\\n","ax.set_ylabel(\'Discharge, cubic feet per second\')\\n","ax.set_xlabel(\'Date (YYYY-MM-DD)\')\\n","ax.grid(True)\\n","ax.set_title(\'Daily Max, Min, & Avg Flows for: \' + siteName + \', \' + siteCode)\\n","ax.set_xlim(beginDate, endDate) #set limits with date variables\\n","# Add a legend with some customizations\\n","legend = ax.legend(loc=\'upper left\', shadow=True)\\n","fig.autofmt_xdate()  # use auto-formatter to enable accurate date representation with mouse\\n","ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # set ticks interval for every 15 days.\\n","\\n","# Create a frame around the legend.\\n","frame = legend.get_frame()\\n","frame.set_facecolor(\'0.95\')\\n","\\n","# Set the font size in the legend\\n","for label in legend.get_texts():\\n","    label.set_fontsize(\'large\')\\n","\\n","for label in legend.get_lines():\\n","    label.set_linewidth(1.5)  # the legend line width"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\'done!\')"]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-3ga7pb5x519l.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('kfq8bgsws99s', 'ac4724', '2019-05-13 14:46:35', '2019-05-13 14:46:50', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('7h73i8nwjnk', '5k56d9vcx4ip3tr5pj26', '2019-05-13 15:32:00', '2019-05-13 15:32:07', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'null;null;null;', 'kps1gf;', 'Done'),
	('pifijdrh3usj', '0giu1h', '2019-05-13 16:50:33', '2019-05-13 16:50:38', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncd /home/zsun/dl-cdl/bin/\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    unzipped=0\n\n    for band1 in "$landsat_unzip_folder"/*"$date"*band1*\n    do \n        echo "found band1 image: "$band1\n        unzipped=1\n    done\n\n    if [ $unzipped == 1 ] \n    then\n        echo "already unzipped"\n    else\n\n        echo "unzip "$entry\n            tar -zxvf $entry -C $landsat_unzip_folder\n    fi\ndone\n\nfor en in "$landsat_unzip_folder"/*band1*\ndo\n    echo "$en"\n    filename=${en##*/}\n    echo "get band name: "$filename\n    # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n    date=${filename:17:8}\n        echo "current date is: "$date\n        year=${date:0:4}\n        monthday=${date:4:4}\n\n    uncut=1\n\n        for band1 in "$cut_cdl_folder"/*"$date"*band1*\n        do\n                echo "found band1 image: "$band1\n                uncut=0\n        done\n\n    if [ $year -lt 2008 ] || [ $uncut == 0  ]\n        then\n                echo "there is no CDL fro this year or the scene has already been cutted, skipping"\n        else\n\n                echo "create tile boundary using tileindex"\n                shpfile=$tileindex_folder$filename".shp"\n                band1file=$en\n                gdaltindex -tileindex location $shpfile $band1file\n\n                echo "cut and resample CDL to fit the landsat scene"\n                cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n                gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder""$year"_30m_cdls.img_32614.tif" $cutcdlfile\n\n        fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\n./geoweaver-4bsnfszo7ue6.sh: line 5: cd: /home/zsun/dl-cdl/bin/: No such file or directory\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget band name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4bsnfszo7ue6.sh: line 93: [: -lt: unary operator expected\n./geoweaver-4bsnfszo7ue6.sh: line 93: [: ==: unary operator expected\ncreate tile boundary using tileindex\n\nUsage: gdaltindex [-f format] [-tileindex field_name] [-write_absolute_path] \n                  [-skip_different_projection] [-t_srs target_srs]\n                  [-src_srs_name field_name] [-src_srs_format [AUTO|WKT|EPSG|PROJ]\n                  [-lyr_name name] index_file [gdal_file]*\n\ne.g.\n  % gdaltindex doq_index.shp doq/*.tif\n\nNOTES:\n  o The shapefile (index_file) will be created if it doesn\'t already exist.\n  o The default tile index field is \'location\'.\n  o Raster filenames will be put in the file exactly as they are specified\n    on the commandline unless the option -write_absolute_path is used.\n  o If -skip_different_projection is specified, only files with same projection ref\n    as files already inserted in the tileindex will be inserted (unless t_srs is specified).\n  o If -t_srs is specified, geometries of input files will be transformed to the desired\n    target coordinate reference system.\n    Note that using this option generates files that are NOT compatible with MapServer < 6.4.\n  o Simple rectangular polygons are generated in the same coordinate reference system\n    as the rasters, or in target reference system if the -t_srs option is used.\n\nFAILURE: No index filename specified.\ncut and resample CDL to fit the landsat scene\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nend the data preparation\n', 'kps1gf', 'Done'),
	('l8e71k7ijnn9', '0giu1h', '2019-05-13 16:51:59', '2019-05-13 16:52:03', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncd /home/zsun/dl-cdl/bin/\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    unzipped=0\n\n    for band1 in "$landsat_unzip_folder"/*"$date"*band1*\n    do \n        echo "found band1 image: "$band1\n        unzipped=1\n    done\n\n    if [ $unzipped == 1 ] \n    then\n        echo "already unzipped"\n    else\n\n        echo "unzip "$entry\n            tar -zxvf $entry -C $landsat_unzip_folder\n    fi\ndone\n\nfor en in "$landsat_unzip_folder"/*band1*\ndo\n    echo "$en"\n    filename=${en##*/}\n    echo "get band name: "$filename\n    # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n    date=${filename:17:8}\n        echo "current date is: "$date\n        year=${date:0:4}\n        monthday=${date:4:4}\n\n    uncut=1\n\n        for band1 in "$cut_cdl_folder"/*"$date"*band1*\n        do\n                echo "found band1 image: "$band1\n                uncut=0\n        done\n\n    if [ $year -lt 2008 ] || [ $uncut == 0  ]\n        then\n                echo "there is no CDL fro this year or the scene has already been cutted, skipping"\n        else\n\n                echo "create tile boundary using tileindex"\n                shpfile=$tileindex_folder$filename".shp"\n                band1file=$en\n                gdaltindex -tileindex location $shpfile $band1file\n\n                echo "cut and resample CDL to fit the landsat scene"\n                cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n                gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder""$year"_30m_cdls.img_32614.tif" $cutcdlfile\n\n        fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\n./geoweaver-bitf7nmyt6ii.sh: line 5: cd: /home/zsun/dl-cdl/bin/: No such file or directory\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget band name: \ncurrent date is: \nfound band1 image: \n./geoweaver-bitf7nmyt6ii.sh: line 93: [: -lt: unary operator expected\n./geoweaver-bitf7nmyt6ii.sh: line 93: [: ==: unary operator expected\ncreate tile boundary using tileindex\n\nUsage: gdaltindex [-f format] [-tileindex field_name] [-write_absolute_path] \n                  [-skip_different_projection] [-t_srs target_srs]\n                  [-src_srs_name field_name] [-src_srs_format [AUTO|WKT|EPSG|PROJ]\n                  [-lyr_name name] index_file [gdal_file]*\n\ne.g.\n  % gdaltindex doq_index.shp doq/*.tif\n\nNOTES:\n  o The shapefile (index_file) will be created if it doesn\'t already exist.\n  o The default tile index field is \'location\'.\n  o Raster filenames will be put in the file exactly as they are specified\n    on the commandline unless the option -write_absolute_path is used.\n  o If -skip_different_projection is specified, only files with same projection ref\n    as files already inserted in the tileindex will be inserted (unless t_srs is specified).\n  o If -t_srs is specified, geometries of input files will be transformed to the desired\n    target coordinate reference system.\n    Note that using this option generates files that are NOT compatible with MapServer < 6.4.\n  o Simple rectangular polygons are generated in the same coordinate reference system\n    as the rasters, or in target reference system if the -t_srs option is used.\n\nFAILURE: No index filename specified.\ncut and resample CDL to fit the landsat scene\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nend the data preparation\n', 'kps1gf', 'Done'),
	('f3ln3znv5uph', '0giu1h', '2019-05-13 16:52:55', '2019-05-13 16:52:59', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncd /home/zsun/dl-cdl/bin/\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    unzipped=0\n\n    for band1 in "$landsat_unzip_folder"/*"$date"*band1*\n    do \n        echo "found band1 image: "$band1\n        unzipped=1\n    done\n\n    if [ $unzipped == 1 ] \n    then\n        echo "already unzipped"\n    else\n\n        echo "unzip "$entry\n            tar -zxvf $entry -C $landsat_unzip_folder\n    fi\ndone\n\nfor en in "$landsat_unzip_folder"/*band1*\ndo\n    echo "$en"\n    filename=${en##*/}\n    echo "get band name: "$filename\n    # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n    date=${filename:17:8}\n        echo "current date is: "$date\n        year=${date:0:4}\n        monthday=${date:4:4}\n\n    uncut=1\n\n        for band1 in "$cut_cdl_folder"/*"$date"*band1*\n        do\n                echo "found band1 image: "$band1\n                uncut=0\n        done\n\n    if [ $year -lt 2008 ] || [ $uncut == 0  ]\n        then\n                echo "there is no CDL fro this year or the scene has already been cutted, skipping"\n        else\n\n                echo "create tile boundary using tileindex"\n                shpfile=$tileindex_folder$filename".shp"\n                band1file=$en\n                gdaltindex -tileindex location $shpfile $band1file\n\n                echo "cut and resample CDL to fit the landsat scene"\n                cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n                gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder""$year"_30m_cdls.img_32614.tif" $cutcdlfile\n\n        fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\n./geoweaver-2smm1zszguhp.sh: line 5: cd: /home/zsun/dl-cdl/bin/: No such file or directory\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget band name: \ncurrent date is: \nfound band1 image: \n./geoweaver-2smm1zszguhp.sh: line 93: [: -lt: unary operator expected\n./geoweaver-2smm1zszguhp.sh: line 93: [: ==: unary operator expected\ncreate tile boundary using tileindex\n\nUsage: gdaltindex [-f format] [-tileindex field_name] [-write_absolute_path] \n                  [-skip_different_projection] [-t_srs target_srs]\n                  [-src_srs_name field_name] [-src_srs_format [AUTO|WKT|EPSG|PROJ]\n                  [-lyr_name name] index_file [gdal_file]*\n\ne.g.\n  % gdaltindex doq_index.shp doq/*.tif\n\nNOTES:\n  o The shapefile (index_file) will be created if it doesn\'t already exist.\n  o The default tile index field is \'location\'.\n  o Raster filenames will be put in the file exactly as they are specified\n    on the commandline unless the option -write_absolute_path is used.\n  o If -skip_different_projection is specified, only files with same projection ref\n    as files already inserted in the tileindex will be inserted (unless t_srs is specified).\n  o If -t_srs is specified, geometries of input files will be transformed to the desired\n    target coordinate reference system.\n    Note that using this option generates files that are NOT compatible with MapServer < 6.4.\n  o Simple rectangular polygons are generated in the same coordinate reference system\n    as the rasters, or in target reference system if the -t_srs option is used.\n\nFAILURE: No index filename specified.\ncut and resample CDL to fit the landsat scene\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nend the data preparation\n', 'kps1gf', 'Done'),
	('1omcod6tozc2', 'zdh3ll', '2019-05-14 15:13:56', '2019-05-14 15:13:56', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('68b3khpzncao', 'zdh3ll', '2019-05-14 15:14:49', '2019-05-14 15:14:54', '#!/bin/bash\necho "coordinate transformation"\nsleep 5s', 'coordinate transformation\n', 'kps1gf', 'Done'),
	('og16hat4susu', 'wsxeps', '2019-05-14 15:19:51', '2019-05-14 15:19:51', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('44mb3xh7vb6q', 'dufwvd', '2019-05-14 20:32:59', '2019-05-14 20:33:00', '#!/bin/bash\n\necho "Test2 + 3 + 4 + 5"\n\necho "{\\"cells\\":[{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"# Connecting to an existing IPython kernel using the Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## The Frontend/Kernel Model\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\\\n\\",\\"\\\\n\\",\\"While this traditional application still exists, the modern Jupyter consists of two processes:\\\\n\\",\\"\\\\n\\",\\"* Kernel: this is the process that runs the users code.\\\\n\\",\\"* Frontend: this is the process that provides the user interface where the user types code and sees results.\\\\n\\",\\"\\\\n\\",\\"Jupyter currently has 3 frontends:\\\\n\\",\\"\\\\n\\",\\"* Terminal Console (`jupyter console`)\\\\n\\",\\"* Qt Console (`jupyter qtconsole`)\\\\n\\",\\"* Notebook (`jupyter notebook`)\\\\n\\",\\"\\\\n\\",\\"The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\\\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\\\'s Kernel and use it as a help\\\\n\\",\\"browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\\\n\\",\\"one in the notebook).  \\\\n\\",\\"\\\\n\\",\\"This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\\\n\\",\\"The commands currently given here are specific to the IPython kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Manual connection\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%connect_info\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can see that this magic displays everything you need to connect to this Notebook\\\'s Kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Automatic connection using a new Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\\\n\\",\\"information and start the Qt Console for you automatically.\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"a = 10\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%qtconsole\\"]}],\\"metadata\\":{\\"nbsphinx\\":{\\"execute\\":\\"never\\"},\\"kernelspec\\":{\\"display_name\\":\\"Python 3\\",\\"language\\":\\"python\\",\\"name\\":\\"python3\\"},\\"language_info\\":{\\"codemirror_mode\\":{\\"name\\":\\"ipython\\",\\"version\\":3},\\"file_extension\\":\\".py\\",\\"mimetype\\":\\"text/x-python\\",\\"name\\":\\"python\\",\\"nbconvert_exporter\\":\\"python\\",\\"pygments_lexer\\":\\"ipython3\\",\\"version\\":\\"3.5.2\\"}},\\"nbformat\\":4,\\"nbformat_minor\\":1}\\r\\n" > testjupyter.ipynb;\n\necho "==== Geoweaver Bash Output Finished ====";\n\n\n\n\n\n', 'bash: -c: line 4: syntax error near unexpected token `(\'\nbash: -c: line 4: `echo \\"{\\\\"cells\\\\":[{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"# Connecting to an existing IPython kernel using the Qt Console\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"## The Frontend/Kernel Model\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"While this traditional application still exists, the modern Jupyter consists of two processes:\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"* Kernel: this is the process that runs the users code.\\\\n\\\\",\\\\"* Frontend: this is the process that provides the user interface where the user types code and sees results.\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"Jupyter currently has 3 frontends:\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"* Terminal Console (`jupyter console`)\\\\n\\\\",\\\\"* Qt Console (`jupyter qtconsole`)\\\\n\\\\",\\\\"* Notebook (`jupyter notebook`)\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\\\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\\\'s Kernel and use it as a help\\\\n\\\\",\\\\"browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\\\n\\\\",\\\\"one in the notebook).  \\\\n\\\\",\\\\"\\\\n\\\\",\\\\"This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\\\n\\\\",\\\\"The commands currently given here are specific to the IPython kernel.\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"## Manual connection\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:\\\\"]},{\\\\"cell_type\\\\":\\\\"code\\\\",\\\\"execution_count\\\\":null,\\\\"metadata\\\\":{},\\\\"outputs\\\\":[],\\\\"source\\\\":[\\\\"%connect_info\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"You can see that this magic displays everything you need to connect to this Notebook\\\'s Kernel.\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"## Automatic connection using a new Qt Console\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\\\n\\\\",\\\\"information and start the Qt Console for you automatically.\\\\"]},{\\\\"cell_type\\\\":\\\\"code\\\\",\\\\"execution_count\\\\":null,\\\\"metadata\\\\":{},\\\\"outputs\\\\":[],\\\\"source\\\\":[\\\\"a = 10\\\\"]},{\\\\"cell_type\\\\":\\\\"code\\\\",\\\\"execution_count\\\\":null,\\\\"metadata\\\\":{},\\\\"outputs\\\\":[],\\\\"source\\\\":[\\\\"%qtconsole\\\\"]}],\\\\"metadata\\\\":{\\\\"nbsphinx\\\\":{\\\\"execute\\\\":\\\\"never\\\\"},\\\\"kernelspec\\\\":{\\\\"display_name\\\\":\\\\"Python 3\\\\",\\\\"language\\\\":\\\\"python\\\\",\\\\"name\\\\":\\\\"python3\\\\"},\\\\"language_info\\\\":{\\\\"codemirror_mode\\\\":{\\\\"name\\\\":\\\\"ipython\\\\",\\\\"version\\\\":3},\\\\"file_extension\\\\":\\\\".py\\\\",\\\\"mimetype\\\\":\\\\"text/x-python\\\\",\\\\"name\\\\":\\\\"python\\\\",\\\\"nbconvert_exporter\\\\":\\\\"python\\\\",\\\\"pygments_lexer\\\\":\\\\"ipython3\\\\",\\\\"version\\\\":\\\\"3.5.2\\\\"}},\\\\"nbformat\\\\":4,\\\\"nbformat_minor\\\\":1}\\r\\n\\" > testjupyter.ipynb;\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('btr73aveswcj', 't9g0ta', '2019-05-14 20:35:27', '2019-05-14 20:35:27', '#!/bin/bash\n\necho "Test2 + 3 + 4 + 5"\n\necho "{\\"cells\\":[{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"# Connecting to an existing IPython kernel using the Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## The Frontend/Kernel Model\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\\\n\\",\\"\\\\n\\",\\"While this traditional application still exists, the modern Jupyter consists of two processes:\\\\n\\",\\"\\\\n\\",\\"* Kernel: this is the process that runs the users code.\\\\n\\",\\"* Frontend: this is the process that provides the user interface where the user types code and sees results.\\\\n\\",\\"\\\\n\\",\\"Jupyter currently has 3 frontends:\\\\n\\",\\"\\\\n\\",\\"* Terminal Console (`jupyter console`)\\\\n\\",\\"* Qt Console (`jupyter qtconsole`)\\\\n\\",\\"* Notebook (`jupyter notebook`)\\\\n\\",\\"\\\\n\\",\\"The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\\\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\\\'s Kernel and use it as a help\\\\n\\",\\"browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\\\n\\",\\"one in the notebook).  \\\\n\\",\\"\\\\n\\",\\"This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\\\n\\",\\"The commands currently given here are specific to the IPython kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Manual connection\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%connect_info\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can see that this magic displays everything you need to connect to this Notebook\\\'s Kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Automatic connection using a new Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\\\n\\",\\"information and start the Qt Console for you automatically.\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"a = 10\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%qtconsole\\"]}],\\"metadata\\":{\\"nbsphinx\\":{\\"execute\\":\\"never\\"},\\"kernelspec\\":{\\"display_name\\":\\"Python 3\\",\\"language\\":\\"python\\",\\"name\\":\\"python3\\"},\\"language_info\\":{\\"codemirror_mode\\":{\\"name\\":\\"ipython\\",\\"version\\":3},\\"file_extension\\":\\".py\\",\\"mimetype\\":\\"text/x-python\\",\\"name\\":\\"python\\",\\"nbconvert_exporter\\":\\"python\\",\\"pygments_lexer\\":\\"ipython3\\",\\"version\\":\\"3.5.2\\"}},\\"nbformat\\":4,\\"nbformat_minor\\":1}\\r\\n" > testjupyter.ipynb;\n\necho "==== Geoweaver Bash Output Finished ====";\n\n\n\n\n\n', 'bash: -c: line 4: syntax error near unexpected token `(\'\nbash: -c: line 4: `echo \\"{\\\\"cells\\\\":[{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"# Connecting to an existing IPython kernel using the Qt Console\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"## The Frontend/Kernel Model\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"While this traditional application still exists, the modern Jupyter consists of two processes:\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"* Kernel: this is the process that runs the users code.\\\\n\\\\",\\\\"* Frontend: this is the process that provides the user interface where the user types code and sees results.\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"Jupyter currently has 3 frontends:\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"* Terminal Console (`jupyter console`)\\\\n\\\\",\\\\"* Qt Console (`jupyter qtconsole`)\\\\n\\\\",\\\\"* Notebook (`jupyter notebook`)\\\\n\\\\",\\\\"\\\\n\\\\",\\\\"The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\\\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\\\'s Kernel and use it as a help\\\\n\\\\",\\\\"browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\\\n\\\\",\\\\"one in the notebook).  \\\\n\\\\",\\\\"\\\\n\\\\",\\\\"This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\\\n\\\\",\\\\"The commands currently given here are specific to the IPython kernel.\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"## Manual connection\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:\\\\"]},{\\\\"cell_type\\\\":\\\\"code\\\\",\\\\"execution_count\\\\":null,\\\\"metadata\\\\":{},\\\\"outputs\\\\":[],\\\\"source\\\\":[\\\\"%connect_info\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"You can see that this magic displays everything you need to connect to this Notebook\\\'s Kernel.\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"## Automatic connection using a new Qt Console\\\\"]},{\\\\"cell_type\\\\":\\\\"markdown\\\\",\\\\"metadata\\\\":{},\\\\"source\\\\":[\\\\"You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\\\n\\\\",\\\\"information and start the Qt Console for you automatically.\\\\"]},{\\\\"cell_type\\\\":\\\\"code\\\\",\\\\"execution_count\\\\":null,\\\\"metadata\\\\":{},\\\\"outputs\\\\":[],\\\\"source\\\\":[\\\\"a = 10\\\\"]},{\\\\"cell_type\\\\":\\\\"code\\\\",\\\\"execution_count\\\\":null,\\\\"metadata\\\\":{},\\\\"outputs\\\\":[],\\\\"source\\\\":[\\\\"%qtconsole\\\\"]}],\\\\"metadata\\\\":{\\\\"nbsphinx\\\\":{\\\\"execute\\\\":\\\\"never\\\\"},\\\\"kernelspec\\\\":{\\\\"display_name\\\\":\\\\"Python 3\\\\",\\\\"language\\\\":\\\\"python\\\\",\\\\"name\\\\":\\\\"python3\\\\"},\\\\"language_info\\\\":{\\\\"codemirror_mode\\\\":{\\\\"name\\\\":\\\\"ipython\\\\",\\\\"version\\\\":3},\\\\"file_extension\\\\":\\\\".py\\\\",\\\\"mimetype\\\\":\\\\"text/x-python\\\\",\\\\"name\\\\":\\\\"python\\\\",\\\\"nbconvert_exporter\\\\":\\\\"python\\\\",\\\\"pygments_lexer\\\\":\\\\"ipython3\\\\",\\\\"version\\\\":\\\\"3.5.2\\\\"}},\\\\"nbformat\\\\":4,\\\\"nbformat_minor\\\\":1}\\r\\n\\" > testjupyter.ipynb;\'\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('8m1d4r9bcest', '4hf60x', '2019-05-14 22:30:13', '2019-05-14 22:30:14', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\\n","from suds.client import Client\\n","from pandas import Series\\n","import matplotlib.pyplot as plt\\n","import matplotlib.dates as mdates"]},{"cell_type":"markdown","metadata":{},"source":["#### Connect to website "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["now = datetime.datetime.now() # Use now function to get current time. \\n","now1 = now.strftime(\\"%Y-%m-%d %H:%M:%S\\")\\n","\\n","wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09315000\' # Can change to different site if desired.  Format: \'NWISUV:########\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = now1  # Can change to less recent date if desired. "]},{"cell_type":"markdown","metadata":{},"source":["#### Create a new object named NWIS for calling the web service "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["#### Call the GetValuesObject method to return the datavalues"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["#### Get the site name from the response "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName\\n","values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["#### Load called objects into a pandas series. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create blank lists in which to put the values and dates\\n","a = []  \\n","b = []\\n","\\n","# Loop through the values and load into the blank lists using append\\n","for v in values:\\n","    a.append(float(v.value))\\n","    b.append(v._dateTime)\\n","    \\n","# Set the index of the series object to the dates\\n","ts = Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["#### Resample data on daily interval with mean/min/max functions <br>\\n","#### create hourly max, min, and avg series "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create hourly max, min, and avg series \\n","hourlyTotDisAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","hourlyTotDisMax = ts.resample(rule=\'1D\', base=0).max()\\n","hourlyTotDisMin = ts.resample(rule=\'1D\', base=0).min()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot stuff\\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a figure object and add a subplot\\n","fig = plt.figure(figsize=(12,8))\\n","ax = fig.add_subplot(1, 1, 1)  # arguments for add_subplot - add_subplot(nrows, ncols, plot_number)\\n","\\n","# Call the plot() methods on the series object to plot the data\\n","ts.plot(color=\'grey\', linestyle=\'solid\', label=\'15-minute streamflow values\', alpha=0.5, linewidth=0.5)\\n","hourlyTotDisAvg.plot(color=\'green\', linestyle=\'solid\', label=\'Daily avg flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMax.plot(color=\'red\', linestyle=\'solid\', label=\'Daily max flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMin.plot(color=\'blue\', linestyle=\'solid\', label=\'Daily min flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","# Set some properties of the subplot to make it look nice\\n","ax.set_ylabel(\'Discharge, cubic feet per second\')\\n","ax.set_xlabel(\'Date (YYYY-MM-DD)\')\\n","ax.grid(True)\\n","ax.set_title(\'Daily Max, Min, & Avg Flows for: \' + siteName + \', \' + siteCode)\\n","ax.set_xlim(beginDate, endDate) #set limits with date variables\\n","# Add a legend with some customizations\\n","legend = ax.legend(loc=\'upper left\', shadow=True)\\n","fig.autofmt_xdate()  # use auto-formatter to enable accurate date representation with mouse\\n","ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # set ticks interval for every 15 days.\\n","\\n","# Create a frame around the legend.\\n","frame = legend.get_frame()\\n","frame.set_facecolor(\'0.95\')\\n","\\n","# Set the font size in the legend\\n","for label in legend.get_texts():\\n","    label.set_fontsize(\'large\')\\n","\\n","for label in legend.get_lines():\\n","    label.set_linewidth(1.5)  # the legend line width"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\'done!\')"]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-8m1d4r9bcest.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('4j35nldwgsyk', 'hmwl0u', '2019-05-15 01:04:42', '2019-05-15 01:04:43', '#!/bin/bash\necho "Test"\necho "Test 2"\necho "Test for multiple lines"\ngdalinfo -version\npython -v\necho "End of test"\n', 'Test\nTest 2\nTest for multiple lines\nERROR 6: Unknown option name \'-version\'\nUsage: gdalinfo [--help-general] [-json] [-mm] [-stats] [-hist] [-nogcp] [-nomd]\n                [-norat] [-noct] [-nofl] [-checksum] [-proj4]\n                [-listmdd] [-mdd domain|`all`]*\n                [-sd subdataset] [-oo NAME=VALUE]* datasetname\n# installing zipimport hook\nimport zipimport # builtin\n# installed zipimport hook\n# /usr/lib/python2.7/site.pyc matches /usr/lib/python2.7/site.py\nimport site # precompiled from /usr/lib/python2.7/site.pyc\n# /usr/lib/python2.7/os.pyc matches /usr/lib/python2.7/os.py\nimport os # precompiled from /usr/lib/python2.7/os.pyc\nimport errno # builtin\nimport posix # builtin\n# /usr/lib/python2.7/posixpath.pyc matches /usr/lib/python2.7/posixpath.py\nimport posixpath # precompiled from /usr/lib/python2.7/posixpath.pyc\n# /usr/lib/python2.7/stat.pyc matches /usr/lib/python2.7/stat.py\nimport stat # precompiled from /usr/lib/python2.7/stat.pyc\n# /usr/lib/python2.7/genericpath.pyc matches /usr/lib/python2.7/genericpath.py\nimport genericpath # precompiled from /usr/lib/python2.7/genericpath.pyc\n# /usr/lib/python2.7/warnings.pyc matches /usr/lib/python2.7/warnings.py\nimport warnings # precompiled from /usr/lib/python2.7/warnings.pyc\n# /usr/lib/python2.7/linecache.pyc matches /usr/lib/python2.7/linecache.py\nimport linecache # precompiled from /usr/lib/python2.7/linecache.pyc\n# /usr/lib/python2.7/types.pyc matches /usr/lib/python2.7/types.py\nimport types # precompiled from /usr/lib/python2.7/types.pyc\n# /usr/lib/python2.7/UserDict.pyc matches /usr/lib/python2.7/UserDict.py\nimport UserDict # precompiled from /usr/lib/python2.7/UserDict.pyc\n# /usr/lib/python2.7/_abcoll.pyc matches /usr/lib/python2.7/_abcoll.py\nimport _abcoll # precompiled from /usr/lib/python2.7/_abcoll.pyc\n# /usr/lib/python2.7/abc.pyc matches /usr/lib/python2.7/abc.py\nimport abc # precompiled from /usr/lib/python2.7/abc.pyc\n# /usr/lib/python2.7/_weakrefset.pyc matches /usr/lib/python2.7/_weakrefset.py\nimport _weakrefset # precompiled from /usr/lib/python2.7/_weakrefset.pyc\nimport _weakref # builtin\n# /usr/lib/python2.7/copy_reg.pyc matches /usr/lib/python2.7/copy_reg.py\nimport copy_reg # precompiled from /usr/lib/python2.7/copy_reg.pyc\n# /usr/lib/python2.7/traceback.pyc matches /usr/lib/python2.7/traceback.py\nimport traceback # precompiled from /usr/lib/python2.7/traceback.pyc\n# /usr/lib/python2.7/sysconfig.pyc matches /usr/lib/python2.7/sysconfig.py\nimport sysconfig # precompiled from /usr/lib/python2.7/sysconfig.pyc\n# /usr/lib/python2.7/re.pyc matches /usr/lib/python2.7/re.py\nimport re # precompiled from /usr/lib/python2.7/re.pyc\n# /usr/lib/python2.7/sre_compile.pyc matches /usr/lib/python2.7/sre_compile.py\nimport sre_compile # precompiled from /usr/lib/python2.7/sre_compile.pyc\nimport _sre # builtin\n# /usr/lib/python2.7/sre_parse.pyc matches /usr/lib/python2.7/sre_parse.py\nimport sre_parse # precompiled from /usr/lib/python2.7/sre_parse.pyc\n# /usr/lib/python2.7/sre_constants.pyc matches /usr/lib/python2.7/sre_constants.py\nimport sre_constants # precompiled from /usr/lib/python2.7/sre_constants.pyc\nimport _locale # builtin\n# /usr/lib/python2.7/_sysconfigdata.pyc matches /usr/lib/python2.7/_sysconfigdata.py\nimport _sysconfigdata # precompiled from /usr/lib/python2.7/_sysconfigdata.pyc\n# /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.pyc matches /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.py\nimport _sysconfigdata_nd # precompiled from /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.pyc\n# /usr/lib/python2.7/sitecustomize.pyc matches /usr/lib/python2.7/sitecustomize.py\nimport sitecustomize # precompiled from /usr/lib/python2.7/sitecustomize.pyc\nimport encodings # directory /usr/lib/python2.7/encodings\n# /usr/lib/python2.7/encodings/__init__.pyc matches /usr/lib/python2.7/encodings/__init__.py\nimport encodings # precompiled from /usr/lib/python2.7/encodings/__init__.pyc\n# /usr/lib/python2.7/codecs.pyc matches /usr/lib/python2.7/codecs.py\nimport codecs # precompiled from /usr/lib/python2.7/codecs.pyc\nimport _codecs # builtin\n# /usr/lib/python2.7/encodings/aliases.pyc matches /usr/lib/python2.7/encodings/aliases.py\nimport encodings.aliases # precompiled from /usr/lib/python2.7/encodings/aliases.pyc\n# /usr/lib/python2.7/encodings/utf_8.pyc matches /usr/lib/python2.7/encodings/utf_8.py\nimport encodings.utf_8 # precompiled from /usr/lib/python2.7/encodings/utf_8.pyc\nPython 2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n[GCC 7.3.0] on linux2\nType "help", "copyright", "credits" or "license" for more information.\ndlopen("/usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so", 2);\nimport readline # dynamically loaded from /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n', 'kps1gf', 'Done'),
	('0f0x8bqa66is', 'hmwl0u', '2019-05-15 01:06:00', '2019-05-15 01:06:00', '#!/bin/bash\necho "Test"\necho "Test 2"\necho "Test for multiple lines"\ngdalinfo -version\npython -version\necho "End of test"\n', 'Test\nTest 2\nTest for multiple lines\nERROR 6: Unknown option name \'-version\'\nUsage: gdalinfo [--help-general] [-json] [-mm] [-stats] [-hist] [-nogcp] [-nomd]\n                [-norat] [-noct] [-nofl] [-checksum] [-proj4]\n                [-listmdd] [-mdd domain|`all`]*\n                [-sd subdataset] [-oo NAME=VALUE]* datasetname\nUnknown option: -e\nusage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\nTry `python -h\' for more information.\nEnd of test\n', 'kps1gf', 'Done'),
	('lxv6krnp9o0p', 'hmwl0u', '2019-05-15 01:06:40', '2019-05-15 01:06:40', '#!/bin/bash\necho "Test"\necho "Test 2"\necho "Test for multiple lines"\ngdalinfo -version\npython -h\necho "End of test"\n', 'Test\nTest 2\nTest for multiple lines\nERROR 6: Unknown option name \'-version\'\nUsage: gdalinfo [--help-general] [-json] [-mm] [-stats] [-hist] [-nogcp] [-nomd]\n                [-norat] [-noct] [-nofl] [-checksum] [-proj4]\n                [-listmdd] [-mdd domain|`all`]*\n                [-sd subdataset] [-oo NAME=VALUE]* datasetname\nusage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\nOptions and arguments (and corresponding environment variables):\n-b     : issue warnings about comparing bytearray with unicode\n         (-bb: issue errors)\n-B     : don\'t write .py[co] files on import; also PYTHONDONTWRITEBYTECODE=x\n-c cmd : program passed in as string (terminates option list)\n-d     : debug output from parser; also PYTHONDEBUG=x\n-E     : ignore PYTHON* environment variables (such as PYTHONPATH)\n-h     : print this help message and exit (also --help)\n-i     : inspect interactively after running script; forces a prompt even\n         if stdin does not appear to be a terminal; also PYTHONINSPECT=x\n-m mod : run library module as a script (terminates option list)\n-O     : optimize generated bytecode slightly; also PYTHONOPTIMIZE=x\n-OO    : remove doc-strings in addition to the -O optimizations\n-R     : use a pseudo-random salt to make hash() values of various types be\n         unpredictable between separate invocations of the interpreter, as\n         a defense against denial-of-service attacks\n-Q arg : division options: -Qold (default), -Qwarn, -Qwarnall, -Qnew\n-s     : don\'t add user site directory to sys.path; also PYTHONNOUSERSITE\n-S     : don\'t imply \'import site\' on initialization\n-t     : issue warnings about inconsistent tab usage (-tt: issue errors)\n-u     : unbuffered binary stdout and stderr; also PYTHONUNBUFFERED=x\n         see man page for details on internal buffering relating to \'-u\'\n-v     : verbose (trace import statements); also PYTHONVERBOSE=x\n         can be supplied multiple times to increase verbosity\n-V     : print the Python version number and exit (also --version)\n-W arg : warning control; arg is action:message:category:module:lineno\n         also PYTHONWARNINGS=arg\n-x     : skip first line of source, allowing use of non-Unix forms of #!cmd\n-3     : warn about Python 3.x incompatibilities that 2to3 cannot trivially fix\nfile   : program read from script file\n-      : program read from stdin (default; interactive mode if a tty)\narg ...: arguments passed to program in sys.argv[1:]\n\nOther environment variables:\nPYTHONSTARTUP: file executed on interactive startup (no default)\nPYTHONPATH   : \':\'-separated list of directories prefixed to the\n               default module search path.  The result is sys.path.\nPYTHONHOME   : alternate <prefix> directory (or <prefix>:<exec_prefix>).\n               The default module search path uses <prefix>/pythonX.X.\nPYTHONCASEOK : ignore case in \'import\' statements (Windows).\nPYTHONIOENCODING: Encoding[:errors] used for stdin/stdout/stderr.\nPYTHONHASHSEED: if this variable is set to \'random\', the effect is the same\n   as specifying the -R option: a random value is used to seed the hashes of\n   str, bytes and datetime objects.  It can also be set to an integer\n   in the range [0,4294967295] to get hash values with a predictable seed.\nEnd of test\n', 'kps1gf', 'Done'),
	('nh3ie47epsvp', 'f0qvfi', '2019-05-20 15:44:19', '2019-05-20 15:44:19', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', 'bash: python-nh3ie47epsvp.py: Permission denied\nchmod: cannot access \'python-nh3ie47epsvp.py\': No such file or directory\npython: can\'t open file \'python-nh3ie47epsvp.py\': [Errno 2] No such file or directory\n', 'kps1gf', 'Done'),
	('4agkfj9eknvf', 'f0qvfi', '2019-05-20 15:51:34', '2019-05-20 15:51:34', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', 'bash: python-4agkfj9eknvf.py: Permission denied\nchmod: cannot access \'python-4agkfj9eknvf.py\': No such file or directory\nbash: activate: No such file or directory\npython3: can\'t open file \'python-4agkfj9eknvf.py\': [Errno 2] No such file or directory\n', 'kps1gf', 'Done'),
	('8ekivc7f9wzl', 'f0qvfi', '2019-05-20 15:52:06', '2019-05-20 15:52:06', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', 'bash: python-8ekivc7f9wzl.py: Permission denied\nchmod: cannot access \'python-8ekivc7f9wzl.py\': No such file or directory\nbash: activate: No such file or directory\npython3: can\'t open file \'python-8ekivc7f9wzl.py\': [Errno 2] No such file or directory\n', 'kps1gf', 'Done'),
	('fn1smz3pb1vr', 'f0qvfi', '2019-05-20 15:52:44', '2019-05-20 15:52:44', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', 'bash: activate: No such file or directory\n0.014511585235595703\n', 'kps1gf', 'Done'),
	('ubsvfcwg7k44', 'f0qvfi', '2019-05-20 16:01:27', '2019-05-20 16:01:27', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', 'bash: activate: No such file or directory\n0.013810157775878906\n', 'kps1gf', 'Done'),
	('lmzhu9s2zn6t', 'b6deul', '2019-05-20 16:04:47', '2019-05-20 16:04:52', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', 'bash: activate: No such file or directory\n[NbConvertApp] Converting notebook jupyter-lmzhu9s2zn6t.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('alhgtrcjevb6', '199vsg', '2019-06-24 16:56:02', '2019-06-24 16:56:02', NULL, './geoweaver-1ep68lng86sx.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('wifsd9c6nbdw', 'ac4724', '2019-06-24 16:56:03', '2019-06-24 16:56:18', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('fj1eveoxv73u', '199vsg', '2019-06-24 16:56:19', '2019-06-24 16:56:19', NULL, './geoweaver-1ep68lng86sx.sh: line 1: null: command not found\n', 'kps1gf', 'Done'),
	('9z1ro7bf7cb', '5k56d9vcx4ip3tr5pj26', '2019-06-24 16:56:00', '2019-06-24 16:56:19', '199vsg-oAq2d;ac4724-jL0Ep;199vsg-Xr6FZ;', 'alhgtrcjevb6;wifsd9c6nbdw;fj1eveoxv73u;', 'kps1gf;', 'Done'),
	('i4mr353sdig7', '0giu1h', '2019-06-24 17:33:04', '2019-06-24 17:33:08', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncd /home/zsun/dl-cdl/bin/\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    unzipped=0\n\n    for band1 in "$landsat_unzip_folder"/*"$date"*band1*\n    do \n        echo "found band1 image: "$band1\n        unzipped=1\n    done\n\n    if [ $unzipped == 1 ] \n    then\n        echo "already unzipped"\n    else\n\n        echo "unzip "$entry\n            tar -zxvf $entry -C $landsat_unzip_folder\n    fi\ndone\n\nfor en in "$landsat_unzip_folder"/*band1*\ndo\n    echo "$en"\n    filename=${en##*/}\n    echo "get band name: "$filename\n    # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n    date=${filename:17:8}\n        echo "current date is: "$date\n        year=${date:0:4}\n        monthday=${date:4:4}\n\n    uncut=1\n\n        for band1 in "$cut_cdl_folder"/*"$date"*band1*\n        do\n                echo "found band1 image: "$band1\n                uncut=0\n        done\n\n    if [ $year -lt 2008 ] || [ $uncut == 0  ]\n        then\n                echo "there is no CDL fro this year or the scene has already been cutted, skipping"\n        else\n\n                echo "create tile boundary using tileindex"\n                shpfile=$tileindex_folder$filename".shp"\n                band1file=$en\n                gdaltindex -tileindex location $shpfile $band1file\n\n                echo "cut and resample CDL to fit the landsat scene"\n                cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n                gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder""$year"_30m_cdls.img_32614.tif" $cutcdlfile\n\n        fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\n./geoweaver-4me51m4cyy2j.sh: line 5: cd: /home/zsun/dl-cdl/bin/: No such file or directory\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\n gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff  _32614.tif\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 64: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget band name: \ncurrent date is: \nfound band1 image: \n./geoweaver-4me51m4cyy2j.sh: line 93: [: -lt: unary operator expected\n./geoweaver-4me51m4cyy2j.sh: line 93: [: ==: unary operator expected\ncreate tile boundary using tileindex\n\nUsage: gdaltindex [-f format] [-tileindex field_name] [-write_absolute_path] \n                  [-skip_different_projection] [-t_srs target_srs]\n                  [-src_srs_name field_name] [-src_srs_format [AUTO|WKT|EPSG|PROJ]\n                  [-lyr_name name] index_file [gdal_file]*\n\ne.g.\n  % gdaltindex doq_index.shp doq/*.tif\n\nNOTES:\n  o The shapefile (index_file) will be created if it doesn\'t already exist.\n  o The default tile index field is \'location\'.\n  o Raster filenames will be put in the file exactly as they are specified\n    on the commandline unless the option -write_absolute_path is used.\n  o If -skip_different_projection is specified, only files with same projection ref\n    as files already inserted in the tileindex will be inserted (unless t_srs is specified).\n  o If -t_srs is specified, geometries of input files will be transformed to the desired\n    target coordinate reference system.\n    Note that using this option generates files that are NOT compatible with MapServer < 6.4.\n  o Simple rectangular polygons are generated in the same coordinate reference system\n    as the rasters, or in target reference system if the -t_srs option is used.\n\nFAILURE: No index filename specified.\ncut and resample CDL to fit the landsat scene\nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nend the data preparation\n', 'kps1gf', 'Done'),
	('gueeyczcz2u8', 's8fh2z', '2019-06-24 17:36:54', '2019-06-24 17:36:54', '#!/bin/bash\n#write your bash script\ncd /home/zsun/\ngdalinfo', 'Usage: gdalinfo [--help-general] [-json] [-mm] [-stats] [-hist] [-nogcp] [-nomd]\n                [-norat] [-noct] [-nofl] [-checksum] [-proj4]\n                [-listmdd] [-mdd domain|`all`]*\n                [-sd subdataset] [-oo NAME=VALUE]* datasetname\n\nFAILURE: No datasource specified.\n', 'kps1gf', 'Done'),
	('6nizzd3sb296', '4hf60x', '2019-06-24 17:38:51', '2019-06-24 17:38:56', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\\n","from suds.client import Client\\n","from pandas import Series\\n","import matplotlib.pyplot as plt\\n","import matplotlib.dates as mdates"]},{"cell_type":"markdown","metadata":{},"source":["#### Connect to website "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["now = datetime.datetime.now() # Use now function to get current time. \\n","now1 = now.strftime(\\"%Y-%m-%d %H:%M:%S\\")\\n","\\n","wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09315000\' # Can change to different site if desired.  Format: \'NWISUV:########\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = now1  # Can change to less recent date if desired. "]},{"cell_type":"markdown","metadata":{},"source":["#### Create a new object named NWIS for calling the web service "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["#### Call the GetValuesObject method to return the datavalues"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["#### Get the site name from the response "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName\\n","values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["#### Load called objects into a pandas series. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create blank lists in which to put the values and dates\\n","a = []  \\n","b = []\\n","\\n","# Loop through the values and load into the blank lists using append\\n","for v in values:\\n","    a.append(float(v.value))\\n","    b.append(v._dateTime)\\n","    \\n","# Set the index of the series object to the dates\\n","ts = Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["#### Resample data on daily interval with mean/min/max functions <br>\\n","#### create hourly max, min, and avg series "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create hourly max, min, and avg series \\n","hourlyTotDisAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","hourlyTotDisMax = ts.resample(rule=\'1D\', base=0).max()\\n","hourlyTotDisMin = ts.resample(rule=\'1D\', base=0).min()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot stuff\\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a figure object and add a subplot\\n","fig = plt.figure(figsize=(12,8))\\n","ax = fig.add_subplot(1, 1, 1)  # arguments for add_subplot - add_subplot(nrows, ncols, plot_number)\\n","\\n","# Call the plot() methods on the series object to plot the data\\n","ts.plot(color=\'grey\', linestyle=\'solid\', label=\'15-minute streamflow values\', alpha=0.5, linewidth=0.5)\\n","hourlyTotDisAvg.plot(color=\'green\', linestyle=\'solid\', label=\'Daily avg flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMax.plot(color=\'red\', linestyle=\'solid\', label=\'Daily max flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMin.plot(color=\'blue\', linestyle=\'solid\', label=\'Daily min flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","# Set some properties of the subplot to make it look nice\\n","ax.set_ylabel(\'Discharge, cubic feet per second\')\\n","ax.set_xlabel(\'Date (YYYY-MM-DD)\')\\n","ax.grid(True)\\n","ax.set_title(\'Daily Max, Min, & Avg Flows for: \' + siteName + \', \' + siteCode)\\n","ax.set_xlim(beginDate, endDate) #set limits with date variables\\n","# Add a legend with some customizations\\n","legend = ax.legend(loc=\'upper left\', shadow=True)\\n","fig.autofmt_xdate()  # use auto-formatter to enable accurate date representation with mouse\\n","ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # set ticks interval for every 15 days.\\n","\\n","# Create a frame around the legend.\\n","frame = legend.get_frame()\\n","frame.set_facecolor(\'0.95\')\\n","\\n","# Set the font size in the legend\\n","for label in legend.get_texts():\\n","    label.set_fontsize(\'large\')\\n","\\n","for label in legend.get_lines():\\n","    label.set_linewidth(1.5)  # the legend line width"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\'done!\')"]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-6nizzd3sb296.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('oq6s6itt7if', '7sb7xj', '2019-06-24 17:39:43', '2019-06-24 17:39:44', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'demo1.png', 'kps1gf', 'Done'),
	('y5i046rg6atr', 'f0qvfi', '2019-06-24 17:39:57', '2019-06-24 17:39:57', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', '0.0142910480499\n', 'kps1gf', 'Done'),
	('djz3zh5svmek', 'b6deul', '2019-06-24 17:46:23', '2019-06-24 17:46:24', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', '[NbConvertApp] Converting notebook jupyter-djz3zh5svmek.ipynb to notebook\nTraceback (most recent call last):\n  File "/usr/local/bin/jupyter-nbconvert", line 10, in <module>\n    sys.exit(main())\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 266, in launch_instance\n    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 658, in launch_instance\n    app.start()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 337, in start\n    self.convert_notebooks()\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 507, in convert_notebooks\n    self.convert_single_notebook(notebook_filename)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 478, in convert_single_notebook\n    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/nbconvertapp.py", line 407, in export_single_notebook\n    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 178, in from_filename\n    return self.from_file(f, resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 196, in from_file\n    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node\n    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 138, in from_notebook_node\n    nb_copy, resources = self._preprocess(nb_copy, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/exporters/exporter.py", line 315, in _preprocess\n    nbc, resc = preprocessor(nbc, resc)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/base.py", line 47, in __call__\n    return self.preprocess(nb, resources)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 352, in preprocess\n    with self.setup_preprocessor(nb, resources, km=km):\n  File "/usr/lib/python3.6/contextlib.py", line 81, in __enter__\n    return next(self.gen)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 297, in setup_preprocessor\n    self.km, self.kc = self.start_new_kernel(cwd=path)\n  File "/usr/local/lib/python3.6/dist-packages/nbconvert/preprocessors/execute.py", line 246, in start_new_kernel\n    km.start_kernel(extra_arguments=self.extra_arguments, **kwargs)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 246, in start_kernel\n    kernel_cmd = self.format_kernel_cmd(extra_arguments=extra_arguments)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 170, in format_kernel_cmd\n    cmd = self.kernel_spec.argv + extra_arguments\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 82, in kernel_spec\n    self._kernel_spec = self.kernel_spec_manager.get_kernel_spec(self.kernel_name)\n  File "/usr/local/lib/python3.6/dist-packages/jupyter_client/kernelspec.py", line 236, in get_kernel_spec\n    raise NoSuchKernel(kernel_name)\njupyter_client.kernelspec.NoSuchKernel: No such kernel named python2\n', 'kps1gf', 'Done'),
	('wpj9m1j1amh0', 'h2xbof', '2019-06-24 17:47:23', '2019-06-24 17:47:25', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["<!--BOOK_INFORMATION-->\\n","<img align=\\"left\\" style=\\"padding-right:10px;\\" src=\\"figures/PDSH-cover-small.png\\">\\n","\\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\\n","\\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]},{"cell_type":"markdown","metadata":{},"source":["# IPython: Beyond Normal Python"]},{"cell_type":"markdown","metadata":{},"source":["There are many options for development environments for Python, and I\'m often asked which one I use in my own work.\\n","My answer sometimes surprises people: my preferred environment is [IPython](http://ipython.org/) plus a text editor (in my case, Emacs or Atom depending on my mood).\\n","IPython (short for *Interactive Python*) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez\'s words, \\"Tools for the entire life cycle of research computing.\\"\\n","If Python is the engine of our data science task, you might think of IPython as the interactive control panel.\\n","\\n","As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we\'ll cover the most useful of these additions here.\\n","In addition, IPython is closely tied with the [Jupyter project](http://jupyter.org), which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.\\n","The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.\\n","As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.\\n","\\n","IPython is about using Python effectively for interactive scientific and data-intensive computing.\\n","This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.\\n","Next, we will go into a bit more depth on some of the more useful \\"magic commands\\" that can speed-up common tasks in creating and using data science code.\\n","Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results."]},{"cell_type":"markdown","metadata":{},"source":["## Shell or Notebook?\\n","\\n","There are two primary means of using IPython that we\'ll discuss in this chapter: the IPython shell and the IPython notebook.\\n","The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.\\n","In the few sections that are relevant to just one or the other, we will explicitly state that fact.\\n","Before we start, some words on how to launch the IPython shell and IPython notebook."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the IPython Shell\\n","\\n","This chapter, like most of this book, is not designed to be absorbed passively.\\n","I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.\\n","Start by launching the IPython interpreter by typing **``ipython``** on the command-line; alternatively, if you\'ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we\'ll discuss this more fully in [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\\n","\\n","Once you do this, you should see a prompt like the following:\\n","```\\n","IPython 4.0.1 -- An enhanced Interactive Python.\\n","?         -> Introduction and overview of IPython\'s features.\\n","%quickref -> Quick reference.\\n","help      -> Python\'s own help system.\\n","object?   -> Details about \'object\', use \'object??\' for extra details.\\n","In [1]:\\n","```\\n","With that, you\'re ready to follow along."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the Jupyter Notebook\\n","\\n","The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.\\n","As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.\\n","Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.\\n","\\n","Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.\\n","This process (known as a \\"kernel\\") can be started by running the following command in your system shell:\\n","\\n","```\\n","$ jupyter notebook\\n","```\\n","\\n","This command will launch a local web server that will be visible to your browser.\\n","It immediately spits out a log showing what it is doing; that log will look something like this:\\n","\\n","```\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","```\\n","\\n","Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;\\n","the exact address will depend on your system.\\n","If the browser does not open automatically, you can open a window and manually open this address (*http://localhost:8888/* in this example)."]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"}},"nbformat":4,"nbformat_minor":0}', 'bash: n,IPython: command not found\nbash: n,$: command not found\nbash: command substitution: line 0: syntax error near unexpected token `(\'\nbash: command substitution: line 0: `\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","\'\n[NbConvertApp] Converting notebook jupyter-wpj9m1j1amh0.ipynb to notebook\n[NbConvertApp] Executing notebook with kernel: python3\n[NbConvertApp] Writing 7749 bytes to jupyter-wpj9m1j1amh0.nbconvert.ipynb\n', 'kps1gf', 'Done'),
	('qxn3pr9clozu', 'nhi96d', '2019-06-24 17:51:45', '2019-06-24 17:52:06', '#!/bin/bash\n# download landsat data from geobrain\n\nwget https://landsat-pds.s3.amazonaws.com/c1/L8/139/045/LC08_L1TP_139045_20170304_20170316_01_T1/LC08_L1TP_139045_20170304_20170316_01_T1_B8.TIF -O /tmp/LC08_L1TP_139045_20170304_20170316_01_T1_B8.TIF\n\necho "download complete"', '--2019-06-24 21:51:45--  https://landsat-pds.s3.amazonaws.com/c1/L8/139/045/LC08_L1TP_139045_20170304_20170316_01_T1/LC08_L1TP_139045_20170304_20170316_01_T1_B8.TIF\nResolving landsat-pds.s3.amazonaws.com (landsat-pds.s3.amazonaws.com)... 52.218.232.122\nConnecting to landsat-pds.s3.amazonaws.com (landsat-pds.s3.amazonaws.com)|52.218.232.122|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 229147981 (219M) [image/tiff]\nSaving to: /tmp/LC08_L1TP_139045_20170304_20170316_01_T1_B8.TIF\n\n\n          /tmp/LC08   0%[                    ]       0  --.-KB/s               \n         /tmp/LC08_   0%[                    ] 109.60K   414KB/s               \n        /tmp/LC08_L   0%[                    ] 245.60K   463KB/s               \n       /tmp/LC08_L1   0%[                    ] 381.60K   480KB/s               \n      /tmp/LC08_L1T   0%[                    ] 517.60K   488KB/s               \n     /tmp/LC08_L1TP   0%[                    ] 670.60K   506KB/s               \n    /tmp/LC08_L1TP_   0%[                    ] 823.60K   518KB/s               \n   /tmp/LC08_L1TP_1   0%[                    ] 993.60K   535KB/s               \n  /tmp/LC08_L1TP_13   0%[                    ]   1.15M   557KB/s               \n /tmp/LC08_L1TP_139   0%[                    ]   1.33M   573KB/s               \n/tmp/LC08_L1TP_1390   0%[                    ]   1.53M   593KB/s               \ntmp/LC08_L1TP_13904   0%[                    ]   1.75M   615KB/s               \nmp/LC08_L1TP_139045   0%[                    ]   1.97M   633KB/s    eta 5m 50s \np/LC08_L1TP_139045_   1%[                    ]   2.20M   653KB/s    eta 5m 50s \n/LC08_L1TP_139045_2   1%[                    ]   2.45M   675KB/s    eta 5m 50s \nLC08_L1TP_139045_20   1%[                    ]   2.70M   695KB/s    eta 5m 50s \nC08_L1TP_139045_201   1%[                    ]   2.96M   747KB/s    eta 5m 7s  \n08_L1TP_139045_2017   1%[                    ]   3.18M   778KB/s    eta 5m 7s  \n8_L1TP_139045_20170   1%[                    ]   3.46M   813KB/s    eta 5m 7s  \n_L1TP_139045_201703   1%[                    ]   3.69M   861KB/s    eta 5m 7s  \nL1TP_139045_2017030   1%[                    ]   3.92M   892KB/s    eta 5m 7s  \n1TP_139045_20170304   1%[                    ]   4.22M   932KB/s    eta 4m 31s \nTP_139045_20170304_   2%[                    ]   4.47M   983KB/s    eta 4m 31s \nP_139045_20170304_2   2%[                    ]   4.74M  1007KB/s    eta 4m 31s \n_139045_20170304_20   2%[                    ]   5.05M  1.02MB/s    eta 4m 31s \n139045_20170304_201   2%[                    ]   5.34M  1.07MB/s    eta 4m 31s \n39045_20170304_2017   2%[                    ]   5.62M  1.10MB/s    eta 4m 4s  \n9045_20170304_20170   2%[                    ]   5.95M  1.13MB/s    eta 4m 4s  \n045_20170304_201703   2%[                    ]   6.23M  1.18MB/s    eta 4m 4s  \n45_20170304_2017031   2%[                    ]   6.53M  1.21MB/s    eta 4m 4s  \n5_20170304_20170316   3%[                    ]   6.83M  1.24MB/s    eta 4m 4s  \n_20170304_20170316_   3%[                    ]   7.16M  1.28MB/s    eta 3m 41s \n20170304_20170316_0   3%[                    ]   7.49M  1.32MB/s    eta 3m 41s \n0170304_20170316_01   3%[                    ]   7.86M  1.34MB/s    eta 3m 41s \n170304_20170316_01_   3%[                    ]   8.22M  1.38MB/s    eta 3m 41s \n70304_20170316_01_T   3%[                    ]   8.61M  1.43MB/s    eta 3m 41s \n0304_20170316_01_T1   4%[                    ]   9.07M  1.48MB/s    eta 3m 19s \n304_20170316_01_T1_   4%[                    ]   9.55M  1.55MB/s    eta 3m 19s \n04_20170316_01_T1_B   4%[                    ]  10.05M  1.63MB/s    eta 3m 19s \n4_20170316_01_T1_B8   4%[                    ]  10.62M  1.71MB/s    eta 3m 19s \n_20170316_01_T1_B8.   5%[>                   ]  11.18M  1.78MB/s    eta 3m 19s \n20170316_01_T1_B8.T   5%[>                   ]  11.82M  1.88MB/s    eta 2m 49s \n0170316_01_T1_B8.TI   5%[>                   ]  12.52M  2.02MB/s    eta 2m 49s \n170316_01_T1_B8.TIF   6%[>                   ]  13.28M  2.15MB/s    eta 2m 49s \n70316_01_T1_B8.TIF    6%[>                   ]  14.02M  2.28MB/s    eta 2m 49s \n0316_01_T1_B8.TIF     6%[>                   ]  14.86M  2.42MB/s    eta 2m 49s \n316_01_T1_B8.TIF      7%[>                   ]  15.72M  2.61MB/s    eta 2m 18s \n16_01_T1_B8.TIF       7%[>                   ]  16.71M  2.80MB/s    eta 2m 18s \n6_01_T1_B8.TIF        8%[>                   ]  17.61M  2.95MB/s    eta 2m 18s \n_01_T1_B8.TIF         8%[>                   ]  18.74M  3.18MB/s    eta 2m 18s \n01_T1_B8.TIF          9%[>                   ]  19.90M  3.49MB/s    eta 2m 18s \n1_T1_B8.TIF           9%[>                   ]  21.21M  3.75MB/s    eta 1m 49s \n_T1_B8.TIF           10%[=>                  ]  22.50M  3.99MB/s    eta 1m 49s \nT1_B8.TIF            10%[=>                  ]  23.88M  4.24MB/s    eta 1m 49s \n1_B8.TIF             11%[=>                  ]  25.34M  4.61MB/s    eta 1m 49s \n_B8.TIF              12%[=>                  ]  26.97M  4.95MB/s    eta 1m 49s \nB8.TIF               13%[=>                  ]  28.62M  5.18MB/s    eta 85s    \n8.TIF                13%[=>                  ]  30.37M  5.51MB/s    eta 85s    \n.TIF                 14%[=>                  ]  32.28M  5.99MB/s    eta 85s    \nTIF                  15%[==>                 ]  34.31M  6.34MB/s    eta 85s    \nIF                   16%[==>                 ]  36.47M  6.76MB/s    eta 85s    \nF                    17%[==>                 ]  38.76M  7.15MB/s    eta 64s    \n                     18%[==>                 ]  41.11M  7.70MB/s    eta 64s    \n                  /  19%[==>                 ]  43.55M  8.16MB/s    eta 64s    \n                 /t  21%[===>                ]  46.09M  8.56MB/s    eta 64s    \n                /tm  22%[===>                ]  48.87M  9.09MB/s    eta 64s    \n               /tmp  23%[===>                ]  51.73M  9.67MB/s    eta 48s    \n              /tmp/  25%[====>               ]  54.72M  10.1MB/s    eta 48s    \n             /tmp/L  26%[====>               ]  57.91M  10.7MB/s    eta 48s    \n            /tmp/LC  28%[====>               ]  61.20M  11.1MB/s    eta 48s    \n           /tmp/LC0  29%[====>               ]  64.69M  11.8MB/s    eta 48s    \n          /tmp/LC08  31%[=====>              ]  68.25M  12.6MB/s    eta 35s    \n         /tmp/LC08_  32%[=====>              ]  72.05M  13.1MB/s    eta 35s    \n        /tmp/LC08_L  34%[=====>              ]  76.03M  13.8MB/s    eta 35s    \n       /tmp/LC08_L1  36%[======>             ]  80.14M  14.3MB/s    eta 35s    \n      /tmp/LC08_L1T  38%[======>             ]  84.48M  15.3MB/s    eta 35s    \n     /tmp/LC08_L1TP  40%[=======>            ]  89.08M  16.1MB/s    eta 24s    \n    /tmp/LC08_L1TP_  42%[=======>            ]  93.76M  16.7MB/s    eta 24s    \n   /tmp/LC08_L1TP_1  45%[========>           ]  98.64M  17.7MB/s    eta 24s    \n  /tmp/LC08_L1TP_13  47%[========>           ] 103.70M  18.6MB/s    eta 24s    \n /tmp/LC08_L1TP_139  49%[========>           ] 109.01M  19.2MB/s    eta 24s    \n/tmp/LC08_L1TP_1390  52%[=========>          ] 114.51M  20.3MB/s    eta 16s    \ntmp/LC08_L1TP_13904  55%[==========>         ] 120.25M  21.3MB/s    eta 16s    \nmp/LC08_L1TP_139045  57%[==========>         ] 126.18M  22.0MB/s    eta 16s    \np/LC08_L1TP_139045_  60%[===========>        ] 132.33M  23.0MB/s    eta 16s    \n/LC08_L1TP_139045_2  63%[===========>        ] 138.81M  24.3MB/s    eta 16s    \nLC08_L1TP_139045_20  66%[============>       ] 145.50M  25.2MB/s    eta 9s     \nC08_L1TP_139045_201  69%[============>       ] 152.20M  26.1MB/s    eta 9s     \n08_L1TP_139045_2017  72%[=============>      ] 159.36M  27.4MB/s    eta 9s     \n8_L1TP_139045_20170  76%[==============>     ] 166.85M  28.5MB/s    eta 9s     \n_L1TP_139045_201703  79%[==============>     ] 174.58M  29.4MB/s    eta 9s     \nL1TP_139045_2017030  83%[===============>    ] 182.59M  31.0MB/s    eta 4s     \n1TP_139045_20170304  87%[================>   ] 190.76M  31.9MB/s    eta 4s     \nTP_139045_20170304_  91%[=================>  ] 199.37M  33.0MB/s    eta 4s     \nP_139045_20170304_2  95%[==================> ] 208.23M  34.2MB/s    eta 4s     \n_139045_20170304_20  99%[==================> ] 217.22M  35.6MB/s    eta 4s     \n/tmp/LC08_L1TP_1390 100%[===================>] 218.53M  35.6MB/s    in 21s     \n\n2019-06-24 21:52:07 (10.6 MB/s) - /tmp/LC08_L1TP_139045_20170304_20170316_01_T1_B8.TIF saved [229147981/229147981]\n\ndownload complete\n', 'kps1gf', 'Done'),
	('mmyd4efmk3xa', 'nhi96d', '2019-07-01 12:16:05', '2019-07-01 12:16:05', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop/\n\nmkdir /home/zsun/crop/landsat/\n\ncd /home/zsun/crop/landsat/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101906111420 -d .\n\necho "download complete"', './geoweaver-x4lbjbzz45ms.sh: line 10: download_espa_order.py: command not found\ndownload complete\n', 'kps1gf', 'Done'),
	('dx2o3vx2rxab', 'nhi96d', '2019-07-01 12:17:32', '2019-07-01 12:17:33', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop/\n\nmkdir /home/zsun/crop/landsat/\n\ncd /home/zsun/crop/landsat/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101906111420 -d .\n\necho "download complete"', 'mkdir: cannot create directory /home/zsun/crop/: File exists\nmkdir: cannot create directory /home/zsun/crop/landsat/: File exists\n2019-07-01 16:17:34,706| No scenes in "completed" state for order espa-szhwhu@gmail.com-0101906111420\ndownload complete\n', 'kps1gf', 'Done'),
	('usd1my4k4hbx', 'nhi96d', '2019-07-01 14:27:38', '2019-07-01 15:58:24', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop/\n\nmkdir /home/zsun/crop/landsat/\n\ncd /home/zsun/crop/landsat/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101907010724 -d .\n\necho "download complete"', 'mkdir: cannot create directory /home/zsun/crop/: File exists\nmkdir: cannot create directory /home/zsun/crop/landsat/: File exists\n2019-07-01 18:27:40,802| File 1 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:28:50,486| File 2 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:30:48,214| File 3 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:32:39,392| File 4 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:33:30,301| File 5 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:35:20,520| File 6 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:37:04,197| File 7 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:39:11,525| File 8 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:41:02,603| File 9 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:43:10,443| File 10 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:45:37,797| File 11 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:47:18,174| File 12 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:49:08,702| File 13 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:51:05,583| File 14 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:53:08,238| File 15 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:55:08,249| File 16 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:56:33,758| File 17 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 18:58:20,783| File 18 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:00:10,050| File 19 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:02:17,211| File 20 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:04:24,012| File 21 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:06:31,710| File 22 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:08:07,761| File 23 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:09:39,585| File 24 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:11:20,364| File 25 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:12:20,967| File 26 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:14:03,610| File 27 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:15:37,679| File 28 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:16:25,423| File 29 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:16:58,858| File 30 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:17:10,240| File 31 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:17:36,636| File 32 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:18:43,026| File 33 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:20:08,992| File 34 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:20:50,957| File 35 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:22:48,047| File 36 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:24:54,906| File 37 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:27:12,372| File 38 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:29:07,798| File 39 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:30:47,230| File 40 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:32:39,483| File 41 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:35:08,490| File 42 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:36:11,379| File 43 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:38:16,262| File 44 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:40:16,113| File 45 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:42:26,992| File 46 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:44:27,353| File 47 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:46:40,982| File 48 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:48:28,226| File 49 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:50:16,516| File 50 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:51:49,227| File 51 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:53:18,887| File 52 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:54:45,695| File 53 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-01 19:56:22,518| File 54 of 54 for order: espa-szhwhu@gmail.com-0101907010724\ndownload complete\n', 'kps1gf', 'Done'),
	('mc21oy41vk2v', 'ac4724', '2019-07-01 16:54:49', '2019-07-01 16:55:04', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('0yya90jfsstn', 'ac4724', '2019-07-01 16:55:37', '2019-07-01 16:55:52', '#!/bin/bash\necho "test run bash function"\necho "sleep for 15 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 15 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('kbu7nhmqkrdk', 'ac4724', '2019-07-01 17:01:16', '2019-07-01 17:01:31', '#!/bin/bash\necho "test run bash function"\necho "sleep for 50 seconds"\nsleep 15s\necho "great now end"', 'test run bash function\nsleep for 50 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('80l04ec9l721', 'ac4724', '2019-07-01 17:02:28', '2019-07-01 17:04:58', '#!/bin/bash\necho "test run bash function"\necho "sleep for 50 seconds"\nsleep 150s\necho "great now end"', 'test run bash function\nsleep for 50 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('oz261hokxa89', 'ac4724', '2019-07-01 17:33:20', '2019-07-01 17:35:50', '#!/bin/bash\necho "test run bash function"\necho "sleep for 50 seconds"\nsleep 150s\necho "great now end"', 'test run bash function\nsleep for 50 seconds\ngreat now end\n', 'kps1gf', 'Done');
INSERT INTO `history` (`id`, `process`, `begin_time`, `end_time`, `input`, `output`, `host`, `indicator`) VALUES
	('6lm0ytplvnkr', 'c7ot8y', '2019-07-02 09:50:12', '2019-07-02 09:50:20', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/crop-oh/cdl-raw/\n\ncdl_projected_folder=/home/zsun/crop-oh/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        	tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n        date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'logfile', 'kps1gf', 'Done'),
	('ga4qkgqxlheu', 'nhi96d', '2019-07-02 09:53:13', '2019-07-02 10:04:44', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop/\n\nmkdir /home/zsun/crop/landsat/\n\ncd /home/zsun/crop/landsat/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101907010724 -d .\n\necho "download complete"', '2019-07-02 13:53:17,163| File 1 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:53:50,749| File 2 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:55:14,175| File 3 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:55:59,742| File 4 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:57:06,952| File 5 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:57:54,514| File 6 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:58:54,604| File 7 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 13:59:22,061| File 8 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:00:23,344| File 9 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:00:51,776| File 10 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:01:55,640| File 11 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:03:08,393| File 12 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:04:27,281| File 13 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:04:38,596| File 14 of 54 for order: espa-szhwhu@gmail.com-0101907010724\nnull\n', 'kps1gf', 'Failed'),
	('urwj2ez6hkyu', 'c7ot8y', '2019-07-02 10:00:43', '2019-07-02 10:00:43', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/crop-oh/cdl-raw/\n\ncdl_projected_folder=/home/zsun/crop-oh/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-4wnno620ujwf.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n5070 is already there\nget band name: \n./geoweaver-4wnno620ujwf.sh: line 127: [: : integer expression expected\ngdaltindex -tileindex location -t_srs EPSG:5070  \n\nUsage: gdaltindex [-f format] [-tileindex field_name] [-write_absolute_path] \n                  [-skip_different_projection] [-t_srs target_srs]\n                  [-src_srs_name field_name] [-src_srs_format [AUTO|WKT|EPSG|PROJ]\n                  [-lyr_name name] index_file [gdal_file]*\n\ne.g.\n  % gdaltindex doq_index.shp doq/*.tif\n\nNOTES:\n  o The shapefile (index_file) will be created if it doesn\'t already exist.\n  o The default tile index field is \'location\'.\n  o Raster filenames will be put in the file exactly as they are specified\n    on the commandline unless the option -write_absolute_path is used.\n  o If -skip_different_projection is specified, only files with same projection ref\n    as files already inserted in the tileindex will be inserted (unless t_srs is specified).\n  o If -t_srs is specified, geometries of input files will be transformed to the desired\n    target coordinate reference system.\n    Note that using this option generates files that are NOT compatible with MapServer < 6.4.\n  o Simple rectangular polygons are generated in the same coordinate reference system\n    as the rasters, or in target reference system if the -t_srs option is used.\n\nFAILURE: No index filename specified.\ngdalwarp -q -overwrite -t_srs EPSG:5070 -cutline  -crop_to_cutline -tr 30.0 30.0 -of GTiff _30m_cdls.img \nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nend the data preparation\n', 'kps1gf', 'Done'),
	('sl22pa70ydky', 'c7ot8y', '2019-07-02 10:05:17', '2019-07-02 10:05:17', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/crop-oh/cdl-raw/\n\ncdl_projected_folder=/home/zsun/crop-oh/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\nmkdir: missing operand\nTry \'mkdir --help\' for more information.\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n\nget file name: \ncurrent date is: \n++++++++++++++++found band1 image: \n./geoweaver-6xvowj2018zx.sh: line 71: [: ==: unary operator expected\nunzip \ntar (child): -C: Cannot open: No such file or directory\ntar (child): Error is not recoverable: exiting now\ntar: Child returned status 2\ntar: Error is not recoverable: exiting now\n5070 is already there\nget band name: \n./geoweaver-6xvowj2018zx.sh: line 127: [: : integer expression expected\ngdaltindex -tileindex location -t_srs EPSG:5070  \n\nUsage: gdaltindex [-f format] [-tileindex field_name] [-write_absolute_path] \n                  [-skip_different_projection] [-t_srs target_srs]\n                  [-src_srs_name field_name] [-src_srs_format [AUTO|WKT|EPSG|PROJ]\n                  [-lyr_name name] index_file [gdal_file]*\n\ne.g.\n  % gdaltindex doq_index.shp doq/*.tif\n\nNOTES:\n  o The shapefile (index_file) will be created if it doesn\'t already exist.\n  o The default tile index field is \'location\'.\n  o Raster filenames will be put in the file exactly as they are specified\n    on the commandline unless the option -write_absolute_path is used.\n  o If -skip_different_projection is specified, only files with same projection ref\n    as files already inserted in the tileindex will be inserted (unless t_srs is specified).\n  o If -t_srs is specified, geometries of input files will be transformed to the desired\n    target coordinate reference system.\n    Note that using this option generates files that are NOT compatible with MapServer < 6.4.\n  o Simple rectangular polygons are generated in the same coordinate reference system\n    as the rasters, or in target reference system if the -t_srs option is used.\n\nFAILURE: No index filename specified.\ngdalwarp -q -overwrite -t_srs EPSG:5070 -cutline  -crop_to_cutline -tr 30.0 30.0 -of GTiff _30m_cdls.img \nUsage: gdalwarp [--help-general] [--formats]\n    [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"] [-novshiftgrid]\n    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n    [-refine_gcps tolerance [minimum_gcps]]\n    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n    [-ovr level|AUTO|AUTO-n|NONE] [-wo "NAME=VALUE"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n    [-srcnodata "value [value...]"] [-dstnodata "value [value...]"] -dstalpha\n    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n    [-cutline datasource] [-cl layer] [-cwhere expression]\n    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n    [-of format] [-co "NAME=VALUE"]* [-overwrite]\n    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n    [-doo NAME=VALUE]*\n    srcfile* dstfile\n\nAvailable resampling methods:\n    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n\nFAILURE: No target filename specified.\nend the data preparation\n', 'kps1gf', 'Done'),
	('9tpmijr3fgco', 'c7ot8y', '2019-07-02 10:10:18', NULL, '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/crop-oh/cdl-raw/\n\ncdl_projected_folder=/home/zsun/crop-oh/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'started', 'kps1gf', 'Running'),
	('79h9n4ptqyk4', 'c7ot8y', '2019-07-02 10:20:14', NULL, '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/crop-oh/cdl-raw/\n\ncdl_projected_folder=/home/zsun/crop-oh/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'started', 'kps1gf', 'Running'),
	('p0tefmpg8u13', 'c7ot8y', '2019-07-02 10:21:52', NULL, '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/crop-oh/cdl-raw/\n\ncdl_projected_folder=/home/zsun/crop-oh/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'started', 'kps1gf', 'Running'),
	('gvmckm8xowzw', 'c7ot8y', '2019-07-02 10:31:16', '2019-07-02 14:55:11', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\n/home/zsun/cdl-raw//2008_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff /home/zsun/cdl-raw//2008_30m_cdls.img /home/zsun/cdl-projected/2008_30m_cdls.img_3857.tif\nCopying color table from /home/zsun/cdl-raw//2008_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2008_30m_cdls.img.\nUsing internal nodata values (e.g. 0) for image /home/zsun/cdl-raw//2008_30m_cdls.img.\nCopying nodata values from source /home/zsun/cdl-raw//2008_30m_cdls.img to destination /home/zsun/cdl-projected/2008_30m_cdls.img_3857.tif.\n0...10...20...30...40...50...60...70...80...90...100 - done.\n/home/zsun/cdl-raw//2009_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff /home/zsun/cdl-raw//2009_30m_cdls.img /home/zsun/cdl-projected/2009_30m_cdls.img_3857.tif\nCopying color table from /home/zsun/cdl-raw//2009_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2009_30m_cdls.img.\nUsing internal nodata values (e.g. 0) for image /home/zsun/cdl-raw//2009_30m_cdls.img.\nCopying nodata values from source /home/zsun/cdl-raw//2009_30m_cdls.img to destination /home/zsun/cdl-projected/2009_30m_cdls.img_3857.tif.\n0...10...20...30...40...50...60...70...80...90...100 - done.\n/home/zsun/cdl-raw//2010_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff /home/zsun/cdl-raw//2010_30m_cdls.img /home/zsun/cdl-projected/2010_30m_cdls.img_3857.tif\nCopying color table from /home/zsun/cdl-raw//2010_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2010_30m_cdls.img.\n0...10...20...30...40...50...60...70...80...90...100 - done.\n/home/zsun/cdl-raw//2011_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff /home/zsun/cdl-raw//2011_30m_cdls.img /home/zsun/cdl-projected/2011_30m_cdls.img_3857.tif\nCopying color table from /home/zsun/cdl-raw//2011_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2011_30m_cdls.img.\n0...10...20...30...40...50...60...70...80...90...100 - done.\n/home/zsun/cdl-raw//2012_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff /home/zsun/cdl-raw//2012_30m_cdls.img /home/zsun/cdl-projected/2012_30m_cdls.img_3857.tif\nCopying color table from /home/zsun/cdl-raw//2012_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2012_30m_cdls.img.\n0...10...20...30...40...50...60...70...80...90...100 - done.\n/home/zsun/cdl-raw//2013_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff /home/zsun/cdl-raw//2013_30m_cdls.img /home/zsun/cdl-projected/2013_30m_cdls.img_3857.tif\nCopying color table from /home/zsun/cdl-raw//2013_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2013_30m_cdls.img.\nUsing internal nodata values (e.g. 0) for image /home/zsun/cdl-raw//2013_30m_cdls.img.\nCopying nodata values from source /home/zsun/cdl-raw//2013_30m_cdls.img to destination /home/zsun/cdl-projected/2013_30m_cdls.img_3857.tif.\n', 'kps1gf', 'Failed'),
	('lrcfnkctgtbt', 'ac4724', '2019-07-02 10:35:46', '2019-07-02 10:38:16', '#!/bin/bash\necho "test run bash function"\necho "sleep for 50 seconds"\nsleep 150s\necho "great now end"', 'test run bash function\nsleep for 50 seconds\ngreat now end\n', 'kps1gf', 'Done'),
	('r8n7skkpbcyv', 'nhi96d', '2019-07-02 10:49:17', '2019-07-02 11:59:07', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop-oh/\n\nmkdir /home/zsun/crop-oh/landsat-2/\n\ncd /home/zsun/crop-oh/landsat-2/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101907010724 -d .\n\necho "download complete"', 'mkdir: cannot create directory /home/zsun/crop-oh/: File exists\n2019-07-02 14:49:20,381| File 1 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:50:08,917| File 2 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:51:05,450| File 3 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:52:10,565| File 4 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:53:18,721| File 5 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:54:27,506| File 6 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:54:55,530| File 7 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:56:23,235| File 8 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:57:00,511| File 9 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:58:00,973| File 10 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 14:59:07,287| File 11 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:00:06,001| File 12 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:01:18,982| File 13 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:02:30,744| File 14 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:03:18,053| File 15 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:04:10,024| File 16 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:05:15,392| File 17 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:06:31,032| File 18 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:07:19,390| File 19 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:08:27,272| File 20 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:10:19,111| File 21 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:11:41,866| File 22 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:12:44,198| File 23 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:13:45,103| File 24 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:14:46,688| File 25 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:15:32,807| File 26 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:16:26,313| File 27 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:17:06,752| File 28 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:18:10,526| File 29 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:19:00,417| File 30 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:19:55,633| File 31 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:21:14,687| File 32 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:22:36,603| File 33 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:24:24,464| File 34 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:26:05,130| File 35 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:27:48,333| File 36 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:29:19,066| File 37 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:31:00,837| File 38 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:31:53,808| File 39 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:33:05,004| File 40 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:34:21,493| File 41 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:36:25,608| File 42 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:38:32,250| File 43 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:39:28,049| File 44 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:41:44,517| File 45 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:43:41,173| File 46 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:45:34,239| File 47 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:47:24,548| File 48 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:49:14,173| File 49 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:51:06,166| File 50 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:52:24,772| File 51 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:54:27,952| File 52 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:56:19,982| File 53 of 54 for order: espa-szhwhu@gmail.com-0101907010724\n2019-07-02 15:58:24,570| File 54 of 54 for order: espa-szhwhu@gmail.com-0101907010724\ndownload complete\n', 'kps1gf', 'Done'),
	('wri6bvlgkncx', 'c7ot8y', '2019-07-02 13:09:57', NULL, '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:5070 -of GTiff "$entry" "$cdl_projected_folder$filename"_3857.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_3857.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'started', 'kps1gf', 'Running'),
	('trylopto4zf2', 'c7ot8y', '2019-07-02 13:12:09', NULL, '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'started', 'kps1gf', 'Running'),
	('jrj30sbx0zxs', 'c7ot8y', '2019-07-02 13:14:28', '2019-07-02 14:54:52', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n	echo "$entry"\n	filename=${entry##*/}\n	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n\n		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n	\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n	fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\n/home/zsun/cdl-raw//2008_30m_cdls.img\n/home/zsun/cdl-raw//2009_30m_cdls.img\n/home/zsun/cdl-raw//2010_30m_cdls.img\n/home/zsun/cdl-raw//2011_30m_cdls.img\n/home/zsun/cdl-raw//2012_30m_cdls.img\n/home/zsun/cdl-raw//2013_30m_cdls.img\n gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff /home/zsun/cdl-raw//2013_30m_cdls.img /home/zsun/cdl-projected/2013_30m_cdls.img_5070.tif\nCopying color table from /home/zsun/cdl-raw//2013_30m_cdls.img to new file.\nCreating output file that is 153811P x 96523L.\nProcessing input file /home/zsun/cdl-raw//2013_30m_cdls.img.\nUsing internal nodata values (e.g. 0) for image /home/zsun/cdl-raw//2013_30m_cdls.img.\nCopying nodata values from source /home/zsun/cdl-raw//2013_30m_cdls.img to destination /home/zsun/cdl-projected/2013_30m_cdls.img_5070.tif.\n', 'kps1gf', 'Failed'),
	('poj9yvnkescn', 'c7ot8y', '2019-07-02 14:45:29', NULL, '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'started', 'kps1gf', 'Running'),
	('5083rdn98e1n', 'c7ot8y', '2019-07-02 14:55:36', '2019-07-02 14:55:36', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo "5070 is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-unzip/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/tileindex/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/cdl-cut/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-5070/: File exists\n/home/zsun/crop-oh/landsat//LC080220322018082601T1-SC20190701115245.tar.gz\nget file name: LC080220322018082601T1-SC20190701115245.tar.gz\ncurrent date is: 20180826\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018072501T1-SC20190701114045.tar.gz\nget file name: LC080220332018072501T1-SC20190701114045.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018050601T1-SC20190701114123.tar.gz\nget file name: LC080220342018050601T1-SC20190701114123.tar.gz\ncurrent date is: 20180506\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018080101T1-SC20190701114321.tar.gz\nget file name: LC080230332018080101T1-SC20190701114321.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018050401T1-SC20190701114043.tar.gz\nget file name: LC080240302018050401T1-SC20190701114043.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018072301T1-SC20190701114131.tar.gz\nget file name: LC080240302018072301T1-SC20190701114131.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018050401T1-SC20190701114107.tar.gz\nget file name: LC080240312018050401T1-SC20190701114107.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018072301T1-SC20190701114044.tar.gz\nget file name: LC080240312018072301T1-SC20190701114044.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018072301T1-SC20190701114053.tar.gz\nget file name: LC080240322018072301T1-SC20190701114053.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018062801T1-SC20190701114039.tar.gz\nget file name: LC080250312018062801T1-SC20190701114039.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018052701T1-SC20190701114040.tar.gz\nget file name: LC080250322018052701T1-SC20190701114040.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018062801T1-SC20190701114107.tar.gz\nget file name: LC080250322018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018062801T1-SC20190701114119.tar.gz\nget file name: LC080250332018062801T1-SC20190701114119.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n5070 is already there\n./geoweaver-zfpndle1stf0.sh: line 152: unexpected EOF while looking for matching `"\'\n./geoweaver-zfpndle1stf0.sh: line 153: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('j6hkcwdf93rh', 'c7ot8y', '2019-07-02 14:59:47', '2019-07-02 14:59:47', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder""$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder""$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-unzip/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/tileindex/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/cdl-cut/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-5070/: File exists\n/home/zsun/crop-oh/landsat//LC080220322018082601T1-SC20190701115245.tar.gz\nget file name: LC080220322018082601T1-SC20190701115245.tar.gz\ncurrent date is: 20180826\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018072501T1-SC20190701114045.tar.gz\nget file name: LC080220332018072501T1-SC20190701114045.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018050601T1-SC20190701114123.tar.gz\nget file name: LC080220342018050601T1-SC20190701114123.tar.gz\ncurrent date is: 20180506\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018080101T1-SC20190701114321.tar.gz\nget file name: LC080230332018080101T1-SC20190701114321.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018050401T1-SC20190701114043.tar.gz\nget file name: LC080240302018050401T1-SC20190701114043.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018072301T1-SC20190701114131.tar.gz\nget file name: LC080240302018072301T1-SC20190701114131.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018050401T1-SC20190701114107.tar.gz\nget file name: LC080240312018050401T1-SC20190701114107.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018072301T1-SC20190701114044.tar.gz\nget file name: LC080240312018072301T1-SC20190701114044.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018072301T1-SC20190701114053.tar.gz\nget file name: LC080240322018072301T1-SC20190701114053.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018062801T1-SC20190701114039.tar.gz\nget file name: LC080250312018062801T1-SC20190701114039.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018052701T1-SC20190701114040.tar.gz\nget file name: LC080250322018052701T1-SC20190701114040.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018062801T1-SC20190701114107.tar.gz\nget file name: LC080250322018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018062801T1-SC20190701114119.tar.gz\nget file name: LC080250332018062801T1-SC20190701114119.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\nLC08_L1TP_022032_20180826_20180830_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band7.tif is already there\n./geoweaver-8tv9d86e5one.sh: line 152: unexpected EOF while looking for matching `"\'\n./geoweaver-8tv9d86e5one.sh: line 153: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('l8zuj5s4f0nr', 'c7ot8y', '2019-07-02 15:02:45', '2019-07-02 15:02:45', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n\n        # echo ">>>>>>>>>> found band1 image: "$ba\n        #if [ $date == 20160326 ]; then\n        #        echo "-------)))))))))))))))))))))(((((((((((((((((((-----------------"\n        #	echo $ba\n        #fi\n\n        uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ] \n    then\n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-unzip/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/tileindex/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/cdl-cut/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-5070/: File exists\n/home/zsun/crop-oh/landsat//LC080220322018082601T1-SC20190701115245.tar.gz\nget file name: LC080220322018082601T1-SC20190701115245.tar.gz\ncurrent date is: 20180826\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018072501T1-SC20190701114045.tar.gz\nget file name: LC080220332018072501T1-SC20190701114045.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018050601T1-SC20190701114123.tar.gz\nget file name: LC080220342018050601T1-SC20190701114123.tar.gz\ncurrent date is: 20180506\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018080101T1-SC20190701114321.tar.gz\nget file name: LC080230332018080101T1-SC20190701114321.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018050401T1-SC20190701114043.tar.gz\nget file name: LC080240302018050401T1-SC20190701114043.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018072301T1-SC20190701114131.tar.gz\nget file name: LC080240302018072301T1-SC20190701114131.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018050401T1-SC20190701114107.tar.gz\nget file name: LC080240312018050401T1-SC20190701114107.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018072301T1-SC20190701114044.tar.gz\nget file name: LC080240312018072301T1-SC20190701114044.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018072301T1-SC20190701114053.tar.gz\nget file name: LC080240322018072301T1-SC20190701114053.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018062801T1-SC20190701114039.tar.gz\nget file name: LC080250312018062801T1-SC20190701114039.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018052701T1-SC20190701114040.tar.gz\nget file name: LC080250322018052701T1-SC20190701114040.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018062801T1-SC20190701114107.tar.gz\nget file name: LC080250322018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018062801T1-SC20190701114119.tar.gz\nget file name: LC080250332018062801T1-SC20190701114119.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\nLC08_L1TP_022032_20180826_20180830_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band7.tif is already there\n./geoweaver-h4zhfr23ryrt.sh: line 152: unexpected EOF while looking for matching `"\'\n./geoweaver-h4zhfr23ryrt.sh: line 153: syntax error: unexpected end of file\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('cunes12y3928', 'c7ot8y', '2019-07-02 15:12:49', '2019-07-02 15:31:09', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n          uncut=0\n        fi\n    done\n\n#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]; then\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ]; then \n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        #find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'logfile', 'kps1gf', 'Done'),
	('sxv9yfq0dy81', 'c7ot8y', '2019-07-02 16:06:54', '2019-07-02 16:11:55', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n          uncut=0\n        fi\n    done\n\n	#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]; then\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ]; then \n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'logfile', 'kps1gf', 'Done'),
	('vm15ipi8kda9', 'c7ot8y', '2019-07-02 16:26:05', '2019-07-02 16:26:05', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n          uncut=0\n        fi\n    done\n\n	#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]; then\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ]; then \n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-unzip/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/tileindex/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/cdl-cut/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-5070/: File exists\n/home/zsun/crop-oh/landsat//LC080210342018051501T1-SC20190701114122.tar.gz\nget file name: LC080210342018051501T1-SC20190701114122.tar.gz\ncurrent date is: 20180515\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220312018060701T1-SC20190701114037.tar.gz\nget file name: LC080220312018060701T1-SC20190701114037.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220312018070901T1-SC20190701115347.tar.gz\nget file name: LC080220312018070901T1-SC20190701115347.tar.gz\ncurrent date is: 20180709\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220312018072501T1-SC20190701114339.tar.gz\nget file name: LC080220312018072501T1-SC20190701114339.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018060701T1-SC20190701114032.tar.gz\nget file name: LC080220322018060701T1-SC20190701114032.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018070901T1-SC20190701114117.tar.gz\nget file name: LC080220322018070901T1-SC20190701114117.tar.gz\ncurrent date is: 20180709\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018072501T1-SC20190701114330.tar.gz\nget file name: LC080220322018072501T1-SC20190701114330.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018082601T1-SC20190701115245.tar.gz\nget file name: LC080220322018082601T1-SC20190701115245.tar.gz\ncurrent date is: 20180826\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018060701T1-SC20190701115212.tar.gz\nget file name: LC080220332018060701T1-SC20190701115212.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018070901T1-SC20190701114106.tar.gz\nget file name: LC080220332018070901T1-SC20190701114106.tar.gz\ncurrent date is: 20180709\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018072501T1-SC20190701114045.tar.gz\nget file name: LC080220332018072501T1-SC20190701114045.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018050601T1-SC20190701114123.tar.gz\nget file name: LC080220342018050601T1-SC20190701114123.tar.gz\ncurrent date is: 20180506\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018060701T1-SC20190701114117.tar.gz\nget file name: LC080220342018060701T1-SC20190701114117.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018072501T1-SC20190701114113.tar.gz\nget file name: LC080220342018072501T1-SC20190701114113.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230312018063001T1-SC20190701114034.tar.gz\nget file name: LC080230312018063001T1-SC20190701114034.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230312018080101T1-SC20190701114100.tar.gz\nget file name: LC080230312018080101T1-SC20190701114100.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230322018063001T1-SC20190701114056.tar.gz\nget file name: LC080230322018063001T1-SC20190701114056.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230322018071601T1-SC20190701114107.tar.gz\nget file name: LC080230322018071601T1-SC20190701114107.tar.gz\ncurrent date is: 20180716\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230322018080101T1-SC20190701114403.tar.gz\nget file name: LC080230322018080101T1-SC20190701114403.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018061401T1-SC20190701114102.tar.gz\nget file name: LC080230332018061401T1-SC20190701114102.tar.gz\ncurrent date is: 20180614\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018063001T1-SC20190701115409.tar.gz\nget file name: LC080230332018063001T1-SC20190701115409.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018071601T1-SC20190701114040.tar.gz\nget file name: LC080230332018071601T1-SC20190701114040.tar.gz\ncurrent date is: 20180716\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018080101T1-SC20190701114321.tar.gz\nget file name: LC080230332018080101T1-SC20190701114321.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018061401T1-SC20190701114117.tar.gz\nget file name: LC080230342018061401T1-SC20190701114117.tar.gz\ncurrent date is: 20180614\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018063001T1-SC20190701114123.tar.gz\nget file name: LC080230342018063001T1-SC20190701114123.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018071601T1-SC20190701114056.tar.gz\nget file name: LC080230342018071601T1-SC20190701114056.tar.gz\ncurrent date is: 20180716\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018080101T1-SC20190701114313.tar.gz\nget file name: LC080230342018080101T1-SC20190701114313.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018050401T1-SC20190701114043.tar.gz\nget file name: LC080240302018050401T1-SC20190701114043.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018060501T1-SC20190701114045.tar.gz\nget file name: LC080240302018060501T1-SC20190701114045.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018070701T1-SC20190701114044.tar.gz\nget file name: LC080240302018070701T1-SC20190701114044.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018072301T1-SC20190701114131.tar.gz\nget file name: LC080240302018072301T1-SC20190701114131.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018080801T1-SC20190701114117.tar.gz\nget file name: LC080240302018080801T1-SC20190701114117.tar.gz\ncurrent date is: 20180808\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018050401T1-SC20190701114107.tar.gz\nget file name: LC080240312018050401T1-SC20190701114107.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018060501T1-SC20190701114128.tar.gz\nget file name: LC080240312018060501T1-SC20190701114128.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018070701T1-SC20190701114102.tar.gz\nget file name: LC080240312018070701T1-SC20190701114102.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018072301T1-SC20190701114044.tar.gz\nget file name: LC080240312018072301T1-SC20190701114044.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018060501T1-SC20190701114102.tar.gz\nget file name: LC080240322018060501T1-SC20190701114102.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018070701T1-SC20190701114117.tar.gz\nget file name: LC080240322018070701T1-SC20190701114117.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018072301T1-SC20190701114053.tar.gz\nget file name: LC080240322018072301T1-SC20190701114053.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240332018060501T1-SC20190701114115.tar.gz\nget file name: LC080240332018060501T1-SC20190701114115.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240332018070701T1-SC20190701114101.tar.gz\nget file name: LC080240332018070701T1-SC20190701114101.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240332018072301T1-SC20190701114119.tar.gz\nget file name: LC080240332018072301T1-SC20190701114119.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240342018060501T1-SC20190701114055.tar.gz\nget file name: LC080240342018060501T1-SC20190701114055.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240342018070701T1-SC20190701114107.tar.gz\nget file name: LC080240342018070701T1-SC20190701114107.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240342018072301T1-SC20190701114055.tar.gz\nget file name: LC080240342018072301T1-SC20190701114055.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250302018052701T1-SC20190701114051.tar.gz\nget file name: LC080250302018052701T1-SC20190701114051.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250302018062801T1-SC20190701114107.tar.gz\nget file name: LC080250302018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250302018073001T1-SC20190701114313.tar.gz\nget file name: LC080250302018073001T1-SC20190701114313.tar.gz\ncurrent date is: 20180730\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018052701T1-SC20190701114031.tar.gz\nget file name: LC080250312018052701T1-SC20190701114031.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018062801T1-SC20190701114039.tar.gz\nget file name: LC080250312018062801T1-SC20190701114039.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018052701T1-SC20190701114040.tar.gz\nget file name: LC080250322018052701T1-SC20190701114040.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018062801T1-SC20190701114107.tar.gz\nget file name: LC080250322018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018052701T1-SC20190701115150.tar.gz\nget file name: LC080250332018052701T1-SC20190701115150.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018062801T1-SC20190701114119.tar.gz\nget file name: LC080250332018062801T1-SC20190701114119.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\nLC08_L1TP_021034_20180515_20180604_01_T1_pixel_qa.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_radsat_qa.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band2.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band3.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band4.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band5.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band6.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band7.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band2.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band3.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band4.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band5.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band6.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band7.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band7.tif is already there\nget band name: LC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nskipping\nend the data preparation\n', 'kps1gf', 'Done'),
	('s06tm0wrc6g0', 'aikfaz', '2019-07-02 17:44:31', '2019-07-02 17:44:31', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\nimport Segnet, LSTMRNN\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Traceback (most recent call last):\n  File "python-s06tm0wrc6g0.py", line 5, in <module>\n    from PIL import Image\nImportError: No module named PIL\n', 'kps1gf', 'Done'),
	('fbbz1cict794', 'c0cs3l', '2019-07-03 11:00:14', '2019-07-03 11:00:15', '# Write first python in Geoweaver\nprint("testsdfdsfsd")', 'bash: python-fbbz1cict794.py: Permission denied\nchmod: cannot access \'python-fbbz1cict794.py\': No such file or directory\npython3: can\'t open file \'python-fbbz1cict794.py\': [Errno 2] No such file or directory\n', 'kps1gf', 'Done'),
	('1r98qpz9kfzl', 'aikfaz', '2019-07-03 11:01:38', '2019-07-03 11:01:39', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\nimport Segnet, LSTMRNN\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Traceback (most recent call last):\n  File "python-1r98qpz9kfzl.py", line 5, in <module>\n    from PIL import Image\nModuleNotFoundError: No module named \'PIL\'\n', 'kps1gf', 'Done'),
	('wrnigsazcdxc', 'aikfaz', '2019-07-03 11:03:27', '2019-07-03 11:03:28', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\nimport Segnet, LSTMRNN\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Traceback (most recent call last):\n  File "python-wrnigsazcdxc.py", line 6, in <module>\n    import numpy as np\nModuleNotFoundError: No module named \'numpy\'\n', 'kps1gf', 'Done'),
	('5ve782pfkkq2', 'aikfaz', '2019-07-03 11:04:57', '2019-07-03 11:04:57', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\nimport Segnet, LSTMRNN\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Traceback (most recent call last):\n  File "python-5ve782pfkkq2.py", line 9, in <module>\n    import my_keras_common as cm\nModuleNotFoundError: No module named \'my_keras_common\'\n', 'kps1gf', 'Done'),
	('m5li3sytnrnb', 'aikfaz', '2019-07-03 11:15:28', '2019-07-03 11:15:29', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Traceback (most recent call last):\n  File "python-m5li3sytnrnb.py", line 9, in <module>\n    import my_keras_common as cm\n  File "/home/zsun/my_keras_common.py", line 6, in <module>\n    import keras\nModuleNotFoundError: No module named \'keras\'\n', 'kps1gf', 'Done'),
	('tszupg9bky09', 'aikfaz', '2019-07-03 11:50:35', '2019-07-03 11:50:38', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nTraceback (most recent call last):\n  File "python-tszupg9bky09.py", line 9, in <module>\n    import my_keras_common as cm\n  File "/home/zsun/my_keras_common.py", line 15, in <module>\n    import SegNet, LSTMRNN, UNet\nModuleNotFoundError: No module named \'LSTMRNN\'\n', 'kps1gf', 'Done'),
	('73bujacq7jgt', 'aikfaz', '2019-07-03 11:56:24', '2019-07-03 11:56:40', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nthis is change from christina\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\nWARNING:tensorflow:From /home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n2019-07-03 15:56:28.239911: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n2019-07-03 15:56:28.276732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz\n2019-07-03 15:56:28.282465: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55e70cc027d0 executing computations on platform Host. Devices:\n2019-07-03 15:56:28.282546: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n2019-07-03 15:56:39.801883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:3d:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2019-07-03 15:56:40.009809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 1 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:3e:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2019-07-03 15:56:40.212519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 2 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:da:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2019-07-03 15:56:40.417866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 3 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:db:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2019-07-03 15:56:40.419762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1, 2, 3\nTraceback (most recent call last):\n  File "python-73bujacq7jgt.py", line 30, in <module>\n    model = cm.getModel()\n  File "/home/zsun/my_keras_common.py", line 135, in getModel\n    model = SegNet.segnet(n_classes, input_height=img_height, input_width=img_width, channels=img_channels)\n  File "/home/zsun/SegNet.py", line 41, in segnet\n    model.add(BatchNormalization())\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/engine/sequential.py", line 181, in add\n    output_tensor = layer(self.outputs[0])\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/engine/base_layer.py", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/layers/normalization.py", line 185, in call\n    epsilon=self.epsilon)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 1858, in normalize_batch_in_training\n    if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 292, in _has_nchw_support\n    gpus_available = len(_get_available_gpus()) > 0\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 278, in _get_available_gpus\n    _LOCAL_DEVICES = get_session().list_devices()\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 186, in get_session\n    _SESSION = tf.Session(config=config)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1551, in __init__\n    super(Session, self).__init__(target, graph, config=config)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 676, in __init__\n    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)\ntensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version\n', 'kps1gf', 'Done'),
	('fm8pge55028n', 'aikfaz', '2019-07-03 12:10:13', '2019-07-03 12:10:27', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\n# landsat_folder=cm.folder + "/data/cdl/"\n\ncdl_folder="/home/zsun/dl-cdl/data/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using Theano backend.\nthis is change from christina\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\noutput shape:  (None, 64, 64, 255)\nTraceback (most recent call last):\n  File "python-fm8pge55028n.py", line 41, in <module>\n    for f in listdir(cm.landsat_folder):\nFileNotFoundError: [Errno 2] No such file or directory: \'/home/zsun/dl-cdl/data/landsat-5070/\'\n', 'kps1gf', 'Done'),
	('6fec85wdy6y0', 'aikfaz', '2019-07-03 12:12:03', '2019-07-03 12:12:10', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\nlandsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using Theano backend.\nthis is change from christina\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\noutput shape:  (None, 64, 64, 255)\nTraceback (most recent call last):\n  File "python-6fec85wdy6y0.py", line 41, in <module>\n    for f in listdir(cm.landsat_folder):\nFileNotFoundError: [Errno 2] No such file or directory: \'/home/zsun/dl-cdl/data/landsat-5070/\'\n', 'kps1gf', 'Done'),
	('d9ro04f83l52', 'aikfaz', '2019-07-03 12:13:18', '2019-07-03 12:13:25', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using Theano backend.\nthis is change from christina\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\noutput shape:  (None, 64, 64, 255)\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\n^^^^^^^^^^^^^^^^^/n Epoch : 0\n=========> Processing  LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nTraceback (most recent call last):\n  File "python-d9ro04f83l52.py", line 55, in <module>\n    exist = isfile(cdl_folder + f)\nNameError: name \'cdl_folder\' is not defined\n', 'kps1gf', 'Done'),
	('lwq1tx0sd0sv', 'aikfaz', '2019-07-03 12:14:14', '2019-07-03 12:34:35', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using Theano backend.\nthis is change from christina\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\noutput shape:  (None, 64, 64, 255)\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\n^^^^^^^^^^^^^^^^^/n Epoch : 0\n=========> Processing  LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\ndate:  20180725  tile:  022033  year: 2018\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 24s 437ms/step - loss: 5.6408 - acc: 0.0047 - val_loss: 10.6596 - val_acc: 0.0024\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 23s 416ms/step - loss: 5.1452 - acc: 0.2202 - val_loss: 13.5218 - val_acc: 0.0385\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 23s 404ms/step - loss: 4.6104 - acc: 0.2706 - val_loss: 11.6100 - val_acc: 0.0740\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 400ms/step - loss: 4.2961 - acc: 0.3595 - val_loss: 11.5081 - val_acc: 0.0173\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 376ms/step - loss: 4.1535 - acc: 0.3963 - val_loss: 9.0667 - val_acc: 0.4351\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 385ms/step - loss: 4.1419 - acc: 0.3592 - val_loss: 9.9948 - val_acc: 0.0739\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 20s 362ms/step - loss: 3.7956 - acc: 0.4207 - val_loss: 7.3039 - val_acc: 0.0552\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 393ms/step - loss: 3.6158 - acc: 0.4395 - val_loss: 11.1121 - val_acc: 0.0087\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 394ms/step - loss: 3.6989 - acc: 0.4454 - val_loss: 9.1389 - val_acc: 0.4295\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 392ms/step - loss: 3.4147 - acc: 0.4974 - val_loss: 7.3992 - val_acc: 0.2210\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 23s 408ms/step - loss: 3.1120 - acc: 0.5566 - val_loss: 4.7846 - val_acc: 0.1488\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 393ms/step - loss: 3.1401 - acc: 0.5399 - val_loss: 5.4102 - val_acc: 0.0857\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 385ms/step - loss: 2.9432 - acc: 0.5800 - val_loss: 6.6063 - val_acc: 0.1469\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 378ms/step - loss: 2.8654 - acc: 0.5611 - val_loss: 4.5914 - val_acc: 0.3696\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 378ms/step - loss: 2.7971 - acc: 0.5791 - val_loss: 7.7848 - val_acc: 0.0256\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 380ms/step - loss: 2.8240 - acc: 0.5862 - val_loss: 9.1496 - val_acc: 0.3580\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 390ms/step - loss: 3.0312 - acc: 0.5313 - val_loss: 12.3707 - val_acc: 0.0173\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 390ms/step - loss: 2.9188 - acc: 0.5423 - val_loss: 7.4749 - val_acc: 0.2406\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 373ms/step - loss: 2.5337 - acc: 0.6063 - val_loss: 5.7414 - val_acc: 0.2360\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 400ms/step - loss: 2.3809 - acc: 0.6365 - val_loss: 5.4711 - val_acc: 0.3075\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 395ms/step - loss: 2.4052 - acc: 0.6279 - val_loss: 4.5056 - val_acc: 0.2665\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 23s 403ms/step - loss: 2.3077 - acc: 0.6412 - val_loss: 3.9059 - val_acc: 0.3747\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 377ms/step - loss: 2.3911 - acc: 0.6218 - val_loss: 4.7852 - val_acc: 0.3226\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 385ms/step - loss: 2.3140 - acc: 0.6286 - val_loss: 6.2885 - val_acc: 0.2560\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 376ms/step - loss: 2.1762 - acc: 0.6555 - val_loss: 4.2900 - val_acc: 0.4424\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 390ms/step - loss: 2.1726 - acc: 0.6612 - val_loss: 4.8072 - val_acc: 0.2290\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 393ms/step - loss: 2.3153 - acc: 0.6128 - val_loss: 4.6112 - val_acc: 0.3424\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 383ms/step - loss: 2.3336 - acc: 0.6263 - val_loss: 4.5092 - val_acc: 0.2985\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 23s 403ms/step - loss: 2.3870 - acc: 0.6103 - val_loss: 10.8081 - val_acc: 0.2729\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 397ms/step - loss: 2.2167 - acc: 0.6534 - val_loss: 4.4219 - val_acc: 0.2865\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 393ms/step - loss: 2.3197 - acc: 0.6085 - val_loss: 5.1164 - val_acc: 0.3640\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 397ms/step - loss: 2.1767 - acc: 0.6248 - val_loss: 5.0716 - val_acc: 0.1941\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 380ms/step - loss: 2.2044 - acc: 0.6092 - val_loss: 4.6886 - val_acc: 0.2429\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 394ms/step - loss: 2.0870 - acc: 0.6505 - val_loss: 4.9870 - val_acc: 0.2098\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 379ms/step - loss: 2.0755 - acc: 0.6582 - val_loss: 5.4400 - val_acc: 0.2990\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 383ms/step - loss: 2.0719 - acc: 0.6401 - val_loss: 4.7482 - val_acc: 0.2493\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 388ms/step - loss: 2.0644 - acc: 0.6437 - val_loss: 4.2374 - val_acc: 0.3381\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 387ms/step - loss: 1.9272 - acc: 0.6815 - val_loss: 4.4688 - val_acc: 0.2915\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 381ms/step - loss: 1.9921 - acc: 0.6673 - val_loss: 4.4856 - val_acc: 0.3462\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 382ms/step - loss: 2.0737 - acc: 0.6496 - val_loss: 7.0138 - val_acc: 0.2807\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 389ms/step - loss: 1.9924 - acc: 0.6565 - val_loss: 5.3565 - val_acc: 0.2581\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 382ms/step - loss: 1.8398 - acc: 0.6894 - val_loss: 4.2672 - val_acc: 0.2886\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 376ms/step - loss: 1.9554 - acc: 0.6471 - val_loss: 4.0098 - val_acc: 0.3872\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 22s 387ms/step - loss: 1.8933 - acc: 0.6580 - val_loss: 3.9067 - val_acc: 0.1430\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 20s 350ms/step - loss: 1.8472 - acc: 0.6608 - val_loss: 5.4183 - val_acc: 0.2054\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 21s 376ms/step - loss: 1.8656 - acc: 0.6823 - val_loss: 5.0820 - val_acc: 0.0151\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n', 'kps1gf', 'Done'),
	('jtdeh0poonnl', 'aikfaz', '2019-07-03 12:42:06', '2019-07-03 12:42:07', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nTraceback (most recent call last):\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper\n    _mod = imp.load_module(\'_pywrap_tensorflow_internal\', fp, pathname, description)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 342, in load_dynamic\n    return _load(spec)\nImportError: libnvidia-fatbinaryloader.so.418.67: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "python-jtdeh0poonnl.py", line 9, in <module>\n    import my_keras_common as cm\n  File "/home/zsun/my_keras_common.py", line 6, in <module>\n    import keras\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/__init__.py", line 3, in <module>\n    from . import utils\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/utils/__init__.py", line 6, in <module>\n    from . import conv_utils\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/utils/conv_utils.py", line 9, in <module>\n    from .. import backend as K\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/__init__.py", line 89, in <module>\n    from .tensorflow_backend import *\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 5, in <module>\n    import tensorflow as tf\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/__init__.py", line 24, in <module>\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/__init__.py", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 74, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper\n    _mod = imp.load_module(\'_pywrap_tensorflow_internal\', fp, pathname, description)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 342, in load_dynamic\n    return _load(spec)\nImportError: libnvidia-fatbinaryloader.so.418.67: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.\n', 'kps1gf', 'Done'),
	('8sxv2gxw9lr5', 'aikfaz', '2019-07-03 12:46:16', '2019-07-03 12:46:17', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nos.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152\nos.environ["CUDA_VISIBLE_DEVICES"] = ""\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nTraceback (most recent call last):\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper\n    _mod = imp.load_module(\'_pywrap_tensorflow_internal\', fp, pathname, description)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 342, in load_dynamic\n    return _load(spec)\nImportError: libnvidia-fatbinaryloader.so.418.67: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "python-8sxv2gxw9lr5.py", line 9, in <module>\n    import my_keras_common as cm\n  File "/home/zsun/my_keras_common.py", line 6, in <module>\n    import keras\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/__init__.py", line 3, in <module>\n    from . import utils\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/utils/__init__.py", line 6, in <module>\n    from . import conv_utils\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/utils/conv_utils.py", line 9, in <module>\n    from .. import backend as K\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/__init__.py", line 89, in <module>\n    from .tensorflow_backend import *\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 5, in <module>\n    import tensorflow as tf\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/__init__.py", line 24, in <module>\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/__init__.py", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 74, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper\n    _mod = imp.load_module(\'_pywrap_tensorflow_internal\', fp, pathname, description)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/imp.py", line 342, in load_dynamic\n    return _load(spec)\nImportError: libnvidia-fatbinaryloader.so.418.67: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.\n', 'kps1gf', 'Done'),
	('z3kthg7zymf5', 'aikfaz', '2019-07-03 15:25:03', '2019-07-03 15:31:26', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nos.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152\nos.environ["CUDA_VISIBLE_DEVICES"] = ""\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nthis is change from christina\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\nWARNING:tensorflow:From /home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n2019-07-03 19:25:19.424999: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n2019-07-03 19:25:19.619253: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz\n2019-07-03 19:25:19.626030: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562b9716ffb0 executing computations on platform Host. Devices:\n2019-07-03 19:25:19.626099: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n2019-07-03 19:25:31.421990: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2019-07-03 19:25:31.422059: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: r740-2\n2019-07-03 19:25:31.422084: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: r740-2\n2019-07-03 19:25:31.422326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 430.26.0\n2019-07-03 19:25:31.422359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 430.26.0\n2019-07-03 19:25:31.422369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 430.26.0\noutput shape:  (None, 64, 64, 255)\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\n^^^^^^^^^^^^^^^^^/n Epoch : 0\n=========> Processing  LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\ndate:  20180725  tile:  022033  year: 2018\nWARNING:tensorflow:From /home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 8s 139ms/step - loss: 5.6411 - acc: 0.0035 - val_loss: 7.4737 - val_acc: 0.0746\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 102ms/step - loss: 4.9423 - acc: 0.2871 - val_loss: 10.8218 - val_acc: 0.2410\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 4.3228 - acc: 0.3924 - val_loss: 7.9497 - val_acc: 0.0439\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 4.0504 - acc: 0.4501 - val_loss: 5.8484 - val_acc: 0.4034\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 3.7263 - acc: 0.5123 - val_loss: 4.3211 - val_acc: 0.3753\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 3.5062 - acc: 0.5483 - val_loss: 3.5197 - val_acc: 0.5115\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 3.7008 - acc: 0.4917 - val_loss: 3.6936 - val_acc: 0.5060\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 3.3654 - acc: 0.5658 - val_loss: 3.3956 - val_acc: 0.5151\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 100ms/step - loss: 3.2902 - acc: 0.5648 - val_loss: 3.5156 - val_acc: 0.5071\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 3.1946 - acc: 0.5641 - val_loss: 3.4495 - val_acc: 0.5186\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.9198 - acc: 0.6024 - val_loss: 2.8505 - val_acc: 0.5910\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 101ms/step - loss: 2.9417 - acc: 0.5797 - val_loss: 3.4814 - val_acc: 0.4534\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 96ms/step - loss: 2.8588 - acc: 0.5901 - val_loss: 4.2216 - val_acc: 0.3801\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 3.0037 - acc: 0.5565 - val_loss: 4.0164 - val_acc: 0.3903\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 100ms/step - loss: 2.9821 - acc: 0.5688 - val_loss: 11.8974 - val_acc: 0.1869\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 96ms/step - loss: 3.0364 - acc: 0.5376 - val_loss: 3.6910 - val_acc: 0.4486\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 2.7827 - acc: 0.5918 - val_loss: 3.0703 - val_acc: 0.4703\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.5639 - acc: 0.6153 - val_loss: 3.4086 - val_acc: 0.4802\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.3864 - acc: 0.6498 - val_loss: 2.1179 - val_acc: 0.6782\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 98ms/step - loss: 2.3687 - acc: 0.6387 - val_loss: 2.6526 - val_acc: 0.5607\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.4580 - acc: 0.6322 - val_loss: 3.1701 - val_acc: 0.4514\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.4656 - acc: 0.6171 - val_loss: 4.0292 - val_acc: 0.3641\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.2639 - acc: 0.6537 - val_loss: 3.2052 - val_acc: 0.4906\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 100ms/step - loss: 2.4005 - acc: 0.6516 - val_loss: 3.8668 - val_acc: 0.3645\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 98ms/step - loss: 2.3996 - acc: 0.6259 - val_loss: 2.7021 - val_acc: 0.5753\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.1532 - acc: 0.6661 - val_loss: 2.6343 - val_acc: 0.5433\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 98ms/step - loss: 2.2329 - acc: 0.6427 - val_loss: 2.6048 - val_acc: 0.5815\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 2.3462 - acc: 0.6231 - val_loss: 3.5722 - val_acc: 0.4136\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 96ms/step - loss: 2.2187 - acc: 0.6314 - val_loss: 2.1186 - val_acc: 0.6219\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 2.4645 - acc: 0.5899 - val_loss: 2.3594 - val_acc: 0.6069\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 96ms/step - loss: 2.3144 - acc: 0.6126 - val_loss: 2.8157 - val_acc: 0.4998\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.1308 - acc: 0.6504 - val_loss: 3.0139 - val_acc: 0.4911\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.3394 - acc: 0.6059 - val_loss: 4.4067 - val_acc: 0.2995\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 96ms/step - loss: 2.2766 - acc: 0.6171 - val_loss: 2.9340 - val_acc: 0.4600\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 2.1556 - acc: 0.6356 - val_loss: 2.4457 - val_acc: 0.5183\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 1.7975 - acc: 0.7041 - val_loss: 3.2152 - val_acc: 0.4906\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 98ms/step - loss: 2.1132 - acc: 0.6392 - val_loss: 4.3188 - val_acc: 0.2722\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.2165 - acc: 0.6310 - val_loss: 5.0554 - val_acc: 0.2843\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 2.1206 - acc: 0.6376 - val_loss: 3.6446 - val_acc: 0.3727\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 100ms/step - loss: 2.0087 - acc: 0.6666 - val_loss: 3.2203 - val_acc: 0.4563\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 1.9716 - acc: 0.6528 - val_loss: 2.6636 - val_acc: 0.5175\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 1.7987 - acc: 0.6919 - val_loss: 4.2126 - val_acc: 0.3552\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 100ms/step - loss: 2.0679 - acc: 0.6391 - val_loss: 3.4357 - val_acc: 0.3741\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 2.0477 - acc: 0.6437 - val_loss: 6.1757 - val_acc: 0.1336\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 99ms/step - loss: 1.9038 - acc: 0.6632 - val_loss: 3.4789 - val_acc: 0.3815\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 6s 100ms/step - loss: 2.0113 - acc: 0.6454 - val_loss: 2.7400 - val_acc: 0.6260\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 1.8751 - acc: 0.6788 - val_loss: 4.5395 - val_acc: 0.2825\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 97ms/step - loss: 1.9649 - acc: 0.6509 - val_loss: 2.7211 - val_acc: 0.4970\nTrain on 56 samples, validate on 8 samples\nEpoch 1/1\n\n56/56 [==============================] - 5s 98ms/step - loss: 1.8732 - acc: 0.6600 - val_loss: 1.9220 - val_acc: 0.6494\nTraceback (most recent call last):\n  File "python-z3kthg7zymf5.py", line 232, in <module>\n    cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\nAttributeError: \'str\' object has no attribute \'save\'\n', 'kps1gf', 'Done'),
	('r7xnxvepxv53', 'ejc7yo', '2019-07-03 15:57:27', '2019-07-03 15:57:29', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\nfrom colormap import *\n# from keras import backend as K\nfrom pathlib import Path\nimport Segnet\nimport cv2\n\nfrom os import listdir,environ\nfrom os.path import isfile, join\n\nenviron["CUDA_VISIBLE_DEVICES"] = "2"\n\n# datearray = ["2016104", "2016120"]\n\n# cm.modelpath = cm.folder + "/model/keras_cdl_SegNet_standard.net";\n\n\nbatch = 32\n\ncm.NN="SegNet"\n\ncm.reuse=True\n\ncm.modelpath = "/home/zsun/ag-net/keras_cdl_" + cm.NN +"_standard_multiple_oh.net";#032027\n\ninput_folder="/home/zsun/crop-oh/ag-net-input/"\n\ntarget_folder="/home/zsun/crop-oh/ag-net-target/"\n\nmodel = cm.getModel()\n\n#for f in listdir(input_folder):\n#    if "band1.tif" in f:\n#        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(input_folder):\n\n        if "band1.tif" in f:\n            \n            # print("=========> Processing ",f)\n            exist1 = isfile(input_folder + f)\n            exist2 = isfile(input_folder + f.replace("band1", "band2"))\n            exist3 = isfile(input_folder + f.replace("band1", "band3"))\n            exist4 = isfile(input_folder + f.replace("band1", "band4"))\n            exist5 = isfile(input_folder + f.replace("band1", "band5"))\n            exist6 = isfile(input_folder + f.replace("band1", "band6"))\n            exist7 = isfile(input_folder + f.replace("band1", "band7"))\n            # 031026_20160718_57_76_band1.tif\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            #sate=f[0:4]\n            date=f[7:15]\n            month=date[4:6]\n            tile=f[0:6]\n            year=date[0:4]\n            # print("date: ", date, " tile: ", tile, " year:", year)\n            \n            # if not exist or date != "20160314":\n            \n            if not exist1 or not exist2 or not exist3 or not exist4 or not exist5 or not exist6 or not exist7 or int(year) < 2013 or int(month) < 5 or int(month) > 8 :\n                \n                continue;\n\n            im1 = Image.open(input_folder + f)\n            im2 = Image.open(input_folder + f.replace("band1", "band2"))\n            im3 = Image.open(input_folder + f.replace("band1", "band3"))\n            im4 = Image.open(input_folder + f.replace("band1", "band4"))\n            im5 = Image.open(input_folder + f.replace("band1", "band5"))\n            im6 = Image.open(input_folder + f.replace("band1", "band6"))\n            im7 = Image.open(input_folder + f.replace("band1", "band7"))\n            cdl_im = Image.open(target_folder + f.replace("band1", "cdl"))\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            cdlarray = numpy.array(cdl_im)\n            predict_cdl = numpy.zeros((imarray1.shape[0], imarray1.shape[1], 3))\n\n            # show a small tile of 360*360\n            x_tile_num = imarray1.shape[0] / cm.img_width\n            y_tile_num = imarray1.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            i_array = numpy.zeros(batch)\n\n            j_array = numpy.zeros(batch)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n            \n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                current_tile1 = np.expand_dims(current_tile1, axis=2)\n                current_tile2 = np.expand_dims(current_tile2, axis=2)\n                current_tile3 = np.expand_dims(current_tile3, axis=2)\n                current_tile4 = np.expand_dims(current_tile4, axis=2)\n                current_tile5 = np.expand_dims(current_tile5, axis=2)\n                current_tile6 = np.expand_dims(current_tile6, axis=2)\n                current_tile7 = np.expand_dims(current_tile7, axis=2)\n                current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                combine_tensor = np.expand_dims(combine_tensor, axis=0)  # (1, height, width, channels), add a dimension because the\n                \n                if (cm.NN == "ConvLSTM"):\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor;\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                    cdl_array = keras.utils.to_categorical(current_cdl, num_classes=cm.n_classes)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # add time dimensions: (time, height, width, channels)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                    if (len(cm.cdl_tensor) == 0):\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0);  # the new image will be a new batch\n                \n                elif (cm.NN == "SegNet" or cm.NN == "U-Net"):\n                    \n                    cdl_array = np.ravel(current_cdl, \'c\')\n                    \n                    cdl_array = keras.utils.to_categorical(cdl_array, num_classes=cm.n_classes)\n                    \n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                if cm.cdl_tensor.shape[0] < batch:\n\n                    continue;\n\n                model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch, epochs=1, callbacks=[])\n                    \n                cm.input_tensor = [];\n\n                cm.cdl_tensor = [];\n\n                model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n    model.save(cm.modelpath + "_checkpoint_" + str(n) + ".net") # prevent model failure\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nThe color of class 5 is:  (38, 112, 0)\nTraceback (most recent call last):\n  File "python-r7xnxvepxv53.py", line 20, in <module>\n    import Segnet\nModuleNotFoundError: No module named \'Segnet\'\n', 'kps1gf', 'Done'),
	('i9oxs9a0r9za', 'ejc7yo', '2019-07-03 15:57:56', '2019-07-03 15:57:58', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\nfrom colormap import *\n# from keras import backend as K\nfrom pathlib import Path\nimport SegNet\nimport cv2\n\nfrom os import listdir,environ\nfrom os.path import isfile, join\n\nenviron["CUDA_VISIBLE_DEVICES"] = "2"\n\n# datearray = ["2016104", "2016120"]\n\n# cm.modelpath = cm.folder + "/model/keras_cdl_SegNet_standard.net";\n\n\nbatch = 32\n\ncm.NN="SegNet"\n\ncm.reuse=True\n\ncm.modelpath = "/home/zsun/ag-net/keras_cdl_" + cm.NN +"_standard_multiple_oh.net";#032027\n\ninput_folder="/home/zsun/crop-oh/ag-net-input/"\n\ntarget_folder="/home/zsun/crop-oh/ag-net-target/"\n\nmodel = cm.getModel()\n\n#for f in listdir(input_folder):\n#    if "band1.tif" in f:\n#        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(input_folder):\n\n        if "band1.tif" in f:\n            \n            # print("=========> Processing ",f)\n            exist1 = isfile(input_folder + f)\n            exist2 = isfile(input_folder + f.replace("band1", "band2"))\n            exist3 = isfile(input_folder + f.replace("band1", "band3"))\n            exist4 = isfile(input_folder + f.replace("band1", "band4"))\n            exist5 = isfile(input_folder + f.replace("band1", "band5"))\n            exist6 = isfile(input_folder + f.replace("band1", "band6"))\n            exist7 = isfile(input_folder + f.replace("band1", "band7"))\n            # 031026_20160718_57_76_band1.tif\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            #sate=f[0:4]\n            date=f[7:15]\n            month=date[4:6]\n            tile=f[0:6]\n            year=date[0:4]\n            # print("date: ", date, " tile: ", tile, " year:", year)\n            \n            # if not exist or date != "20160314":\n            \n            if not exist1 or not exist2 or not exist3 or not exist4 or not exist5 or not exist6 or not exist7 or int(year) < 2013 or int(month) < 5 or int(month) > 8 :\n                \n                continue;\n\n            im1 = Image.open(input_folder + f)\n            im2 = Image.open(input_folder + f.replace("band1", "band2"))\n            im3 = Image.open(input_folder + f.replace("band1", "band3"))\n            im4 = Image.open(input_folder + f.replace("band1", "band4"))\n            im5 = Image.open(input_folder + f.replace("band1", "band5"))\n            im6 = Image.open(input_folder + f.replace("band1", "band6"))\n            im7 = Image.open(input_folder + f.replace("band1", "band7"))\n            cdl_im = Image.open(target_folder + f.replace("band1", "cdl"))\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            cdlarray = numpy.array(cdl_im)\n            predict_cdl = numpy.zeros((imarray1.shape[0], imarray1.shape[1], 3))\n\n            # show a small tile of 360*360\n            x_tile_num = imarray1.shape[0] / cm.img_width\n            y_tile_num = imarray1.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            i_array = numpy.zeros(batch)\n\n            j_array = numpy.zeros(batch)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n            \n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                current_tile1 = np.expand_dims(current_tile1, axis=2)\n                current_tile2 = np.expand_dims(current_tile2, axis=2)\n                current_tile3 = np.expand_dims(current_tile3, axis=2)\n                current_tile4 = np.expand_dims(current_tile4, axis=2)\n                current_tile5 = np.expand_dims(current_tile5, axis=2)\n                current_tile6 = np.expand_dims(current_tile6, axis=2)\n                current_tile7 = np.expand_dims(current_tile7, axis=2)\n                current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                combine_tensor = np.expand_dims(combine_tensor, axis=0)  # (1, height, width, channels), add a dimension because the\n                \n                if (cm.NN == "ConvLSTM"):\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor;\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                    cdl_array = keras.utils.to_categorical(current_cdl, num_classes=cm.n_classes)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # add time dimensions: (time, height, width, channels)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                    if (len(cm.cdl_tensor) == 0):\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0);  # the new image will be a new batch\n                \n                elif (cm.NN == "SegNet" or cm.NN == "U-Net"):\n                    \n                    cdl_array = np.ravel(current_cdl, \'c\')\n                    \n                    cdl_array = keras.utils.to_categorical(cdl_array, num_classes=cm.n_classes)\n                    \n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                if cm.cdl_tensor.shape[0] < batch:\n\n                    continue;\n\n                model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch, epochs=1, callbacks=[])\n                    \n                cm.input_tensor = [];\n\n                cm.cdl_tensor = [];\n\n                model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n    model.save(cm.modelpath + "_checkpoint_" + str(n) + ".net") # prevent model failure\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nThe color of class 5 is:  (38, 112, 0)\nTraceback (most recent call last):\n  File "python-i9oxs9a0r9za.py", line 21, in <module>\n    import cv2\nModuleNotFoundError: No module named \'cv2\'\n', 'kps1gf', 'Done'),
	('fc449ot8wnxz', 'ejc7yo', '2019-07-03 15:58:34', '2019-07-03 15:58:55', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\nfrom colormap import *\n# from keras import backend as K\nfrom pathlib import Path\nimport SegNet\n\nfrom os import listdir,environ\nfrom os.path import isfile, join\n\nenviron["CUDA_VISIBLE_DEVICES"] = "2"\n\n# datearray = ["2016104", "2016120"]\n\n# cm.modelpath = cm.folder + "/model/keras_cdl_SegNet_standard.net";\n\n\nbatch = 32\n\ncm.NN="SegNet"\n\ncm.reuse=True\n\ncm.modelpath = "/home/zsun/ag-net/keras_cdl_" + cm.NN +"_standard_multiple_oh.net";#032027\n\ninput_folder="/home/zsun/crop-oh/ag-net-input/"\n\ntarget_folder="/home/zsun/crop-oh/ag-net-target/"\n\nmodel = cm.getModel()\n\n#for f in listdir(input_folder):\n#    if "band1.tif" in f:\n#        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(input_folder):\n\n        if "band1.tif" in f:\n            \n            # print("=========> Processing ",f)\n            exist1 = isfile(input_folder + f)\n            exist2 = isfile(input_folder + f.replace("band1", "band2"))\n            exist3 = isfile(input_folder + f.replace("band1", "band3"))\n            exist4 = isfile(input_folder + f.replace("band1", "band4"))\n            exist5 = isfile(input_folder + f.replace("band1", "band5"))\n            exist6 = isfile(input_folder + f.replace("band1", "band6"))\n            exist7 = isfile(input_folder + f.replace("band1", "band7"))\n            # 031026_20160718_57_76_band1.tif\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            #sate=f[0:4]\n            date=f[7:15]\n            month=date[4:6]\n            tile=f[0:6]\n            year=date[0:4]\n            # print("date: ", date, " tile: ", tile, " year:", year)\n            \n            # if not exist or date != "20160314":\n            \n            if not exist1 or not exist2 or not exist3 or not exist4 or not exist5 or not exist6 or not exist7 or int(year) < 2013 or int(month) < 5 or int(month) > 8 :\n                \n                continue;\n\n            im1 = Image.open(input_folder + f)\n            im2 = Image.open(input_folder + f.replace("band1", "band2"))\n            im3 = Image.open(input_folder + f.replace("band1", "band3"))\n            im4 = Image.open(input_folder + f.replace("band1", "band4"))\n            im5 = Image.open(input_folder + f.replace("band1", "band5"))\n            im6 = Image.open(input_folder + f.replace("band1", "band6"))\n            im7 = Image.open(input_folder + f.replace("band1", "band7"))\n            cdl_im = Image.open(target_folder + f.replace("band1", "cdl"))\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            cdlarray = numpy.array(cdl_im)\n            predict_cdl = numpy.zeros((imarray1.shape[0], imarray1.shape[1], 3))\n\n            # show a small tile of 360*360\n            x_tile_num = imarray1.shape[0] / cm.img_width\n            y_tile_num = imarray1.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            i_array = numpy.zeros(batch)\n\n            j_array = numpy.zeros(batch)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n            \n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                current_tile1 = np.expand_dims(current_tile1, axis=2)\n                current_tile2 = np.expand_dims(current_tile2, axis=2)\n                current_tile3 = np.expand_dims(current_tile3, axis=2)\n                current_tile4 = np.expand_dims(current_tile4, axis=2)\n                current_tile5 = np.expand_dims(current_tile5, axis=2)\n                current_tile6 = np.expand_dims(current_tile6, axis=2)\n                current_tile7 = np.expand_dims(current_tile7, axis=2)\n                current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                combine_tensor = np.expand_dims(combine_tensor, axis=0)  # (1, height, width, channels), add a dimension because the\n                \n                if (cm.NN == "ConvLSTM"):\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor;\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                    cdl_array = keras.utils.to_categorical(current_cdl, num_classes=cm.n_classes)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # add time dimensions: (time, height, width, channels)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                    if (len(cm.cdl_tensor) == 0):\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0);  # the new image will be a new batch\n                \n                elif (cm.NN == "SegNet" or cm.NN == "U-Net"):\n                    \n                    cdl_array = np.ravel(current_cdl, \'c\')\n                    \n                    cdl_array = keras.utils.to_categorical(cdl_array, num_classes=cm.n_classes)\n                    \n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                if cm.cdl_tensor.shape[0] < batch:\n\n                    continue;\n\n                model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch, epochs=1, callbacks=[])\n                    \n                cm.input_tensor = [];\n\n                cm.cdl_tensor = [];\n\n                model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n    model.save(cm.modelpath + "_checkpoint_" + str(n) + ".net") # prevent model failure\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\nThe color of class 5 is:  (38, 112, 0)\nUsing Model: SegNet\nCreate a new neural network model..\nchannel:  7\nWARNING:tensorflow:From /home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n2019-07-03 19:58:37.268995: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n2019-07-03 19:58:37.307193: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz\n2019-07-03 19:58:37.313194: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559cde0e99c0 executing computations on platform Host. Devices:\n2019-07-03 19:58:37.313270: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n2019-07-03 19:58:48.493869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:da:00.0\ntotalMemory: 11.17GiB freeMemory: 11.11GiB\n2019-07-03 19:58:48.493970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n2019-07-03 19:58:48.506045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n2019-07-03 19:58:48.506096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n2019-07-03 19:58:48.506116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n2019-07-03 19:58:48.506359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:da:00.0, compute capability: 3.7)\n2019-07-03 19:58:48.530523: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559cdc84b670 executing computations on platform CUDA. Devices:\n2019-07-03 19:58:48.530561: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\noutput shape:  (None, 64, 64, 255)\n^^^^^^^^^^^^^^^^^/n Epoch : 0\nTraceback (most recent call last):\n  File "python-fc449ot8wnxz.py", line 56, in <module>\n    for f in listdir(input_folder):\nFileNotFoundError: [Errno 2] No such file or directory: \'/home/zsun/crop-oh/ag-net-input/\'\n', 'kps1gf', 'Done'),
	('ukk8gfz72oec', 'ikfk1x', '2019-07-03 16:04:19', '2019-07-03 16:04:31', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nimport sys\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n# from keras import backend as K\nfrom pathlib import Path\nimport cv2\nimport imageio\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n# datearray = ["2016104", "2016120"]\n\n# model = cm.getModel()\n\nbatch_size = 64\n\n# landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.folder="/home/zsun/"\n\nlandsat_folder=cm.folder + "/crop-oh/landsat-5070/"\n\ncdl_folder = cm.folder + "/crop-oh/cdl-cut/"\n\ninput_folder = cm.folder + "/crop-oh/ag-net-input/"\n\ntarget_folder = cm.folder + "/crop-oh/ag-net-target/"\n\ndef checkComplete(f):\n#for f in listdir(landsat_folder):\n    complete=True\n    if "band1.tif" in f:\n        im1 = isfile(landsat_folder + f)\n        im2 = isfile(landsat_folder + f.replace("band1", "band2"))\n        im3 = isfile(landsat_folder + f.replace("band1", "band3"))\n        im4 = isfile(landsat_folder + f.replace("band1", "band4"))\n        im5 = isfile(landsat_folder + f.replace("band1", "band5"))\n        im6 = isfile(landsat_folder + f.replace("band1", "band6"))\n        im7 = isfile(landsat_folder + f.replace("band1", "band7"))\n        cfmask = isfile(landsat_folder + f.replace("sr_band1", "pixel_qa"))\n        cdl = isfile(cdl_folder + f)\n        if(not im1 or not im2 or not im3 or not im4 or not im5 or not im6 or not im7 or not cdl):\n            print("found incomplete tile: ", f)\n            complete=False\n    return complete\n\n# sys.exit()\n\nstart_time = time.time()\n\ndef isprocessed(date):\n    isp=False\n    for f in listdir(input_folder):\n        if date in f:\n            isp=True\n            print("this scene has already processed")\n            break;\n    return isp\n\n\nfor f in listdir(landsat_folder):\n\n    if "band1.tif" in f:\n        print("=========> Processing ", f)\n        exist = isfile(cdl_folder + f)\n                # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n        sate = f[0:4]\n        date = f[17:25]\n        month = date[4:6]\n        tile = f[10:16]\n        year = date[0:4]\n        # processed=isprocessed(date)\n        print("cdl exist: ", exist," date: ", date, " tile: ", tile, " year:", year, " month", month)\n        # if not exist or date != "20160314":\n        if not exist or int(year) < 2013 or int(month) < 6 or int(month) > 8:\n            print("skip, cdl doesn\'t exist or the date is out of windows")\n            continue;\n\n        complete=checkComplete(f)\n\n        if not complete:\n            continue;\n        \n        print("slicing.....")\n\n        # if date != "20110705":\n        #    continue;\n\n        im1 = Image.open(landsat_folder + f)\n        im2 = Image.open(landsat_folder + f.replace("band1", "band2"))\n        im3 = Image.open(landsat_folder + f.replace("band1", "band3"))\n        im4 = Image.open(landsat_folder + f.replace("band1", "band4"))\n        im5 = Image.open(landsat_folder + f.replace("band1", "band5"))\n        im6 = Image.open(landsat_folder + f.replace("band1", "band6"))\n        im7 = Image.open(landsat_folder + f.replace("band1", "band7"))\n        cfmask = Image.open(landsat_folder + f.replace("sr_band1", "pixel_qa"))\n        cdl_im = Image.open(cdl_folder + f)\n\n        imarray1 = numpy.array(im1)\n        imarray2 = numpy.array(im2)\n        imarray3 = numpy.array(im3)\n        imarray4 = numpy.array(im4)\n        imarray5 = numpy.array(im5)\n        imarray6 = numpy.array(im6)\n        imarray7 = numpy.array(im7)\n        # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n        imarraymask = numpy.array(cfmask)\n        cdlarray = numpy.array(cdl_im)\n        # print(imarraymask.shape)\n        # print(cdlarray.shape)\n        predict_cdl = numpy.zeros((imarraymask.shape[0], imarraymask.shape[1], 3))\n\n        # show a small tile of 360*360\n        x_tile_num = imarraymask.shape[0] / cm.img_width\n        y_tile_num = imarraymask.shape[1] / cm.img_height\n\n        total_num = int(x_tile_num * y_tile_num)\n\n        i_array = numpy.zeros(int(batch_size))\n\n        j_array = numpy.zeros(int(batch_size))\n\n        for k in range(0, total_num):\n\n            i = random.randint(0, int(x_tile_num) - 1)\n            j = random.randint(0, int(y_tile_num) - 1)\n\n            # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n            # print("imgarray3 shape: ", imarray3.shape)\n\n            # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n            # print("imgarray3 shape: ", imarray3.shape)\n\n            current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_width:(j + 1) * cm.img_height];\n            current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n            #                j * cm.img_height:(j + 1) * cm.img_height];\n            current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                           j * cm.img_height:(j + 1) * cm.img_height];\n            current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width,\n                          j * cm.img_height:(j + 1) * cm.img_height];\n\n            # print(current_tile1.shape);\n            # bqa - High confidence cloud ? 480,992\n            # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n            # if the CDL contains 0, skip\n            if (992 in current_mask or 834 in current_mask\n                    or 1 in current_mask or 480 in current_mask or 898 in current_mask\n                    or 928 in current_mask or 96 in current_mask or 112 in current_mask\n                    or 160 in current_mask or 176 in current_mask or 224 in current_mask\n                    or 0 in current_mask or 0 in current_cdl):\n                # if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                # print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                continue;\n            elif (cm.checkOutSeasonCrops(current_cdl, month)):\n                # print("tile ", i, " ", j, " is skipped because it is out of season")\n                continue;\n            else:\n                # print(current_tile1)\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band1.tif", current_tile1);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band2.tif", current_tile2);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band3.tif", current_tile3);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band4.tif", current_tile4);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band5.tif", current_tile5);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band6.tif", current_tile6);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band7.tif", current_tile7);\n                imageio.imwrite(target_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_cdl.tif", current_cdl);\n                # print("tile ", i, " ", j, " is valid")\n                # current_tile1 = np.expand_dims(current_tile1, axis=2)\n                # current_tile2 = np.expand_dims(current_tile2, axis=2)\n                # current_tile3 = np.expand_dims(current_tile3, axis=2)\n                # current_tile4 = np.expand_dims(current_tile4, axis=2)\n                # current_tile5 = np.expand_dims(current_tile5, axis=2)\n                # current_tile6 = np.expand_dims(current_tile6, axis=2)\n                # current_tile7 = np.expand_dims(current_tile7, axis=2)\n                # # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                # current_cdl = np.expand_dims(current_cdl, axis=2)\n                #\n                # combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                #                                  current_tile5, current_tile6, current_tile7), axis=2)\n                # combine_tensor = np.expand_dims(combine_tensor,\n                #                                 axis=0)  # (1, height, width, channels), add a dimension because the\n                # # model expects this shape: (batch_size, height, width, channels)\n                # #                                   axis=0)  # (1, 1, height, width, channels), add a dimension because\n                # # the model expects this shape: (batch_size, time, height, width, channels)\n                # if (cm.NN == "ConvLSTM"):\n                #\n                #     if (len(cm.input_tensor) == 0):\n                #\n                #         cm.input_tensor = combine_tensor;\n                #\n                #     else:\n                #\n                #         cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                #                                          axis=0);  # use batch to combine multiple images. Each batch only\n                #         # has one step, which is the sequence to sequence mode.\n                #\n                #     # cdl_array = np.ravel(cdl_array, \'c\')\n                #\n                #     cdl_array = keras.utils.to_categorical(current_cdl, num_classes=256)\n                #\n                #     cdl_array = np.expand_dims(cdl_array,\n                #                                axis=0)  # add time dimensions: (time, height, width, channels)\n                #\n                #     cdl_array = np.expand_dims(cdl_array, axis=0)\n                #\n                #     if (len(cm.cdl_tensor) == 0):\n                #\n                #         cm.cdl_tensor = cdl_array\n                #\n                #     else:\n                #\n                #         cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                #                                        axis=0);  # the new image will be a new batch\n                #\n                # #    i_array[cm.cdl_tensor.shape[0]] = i\n                #\n                # #    j_array[cm.cdl_tensor.shape[0]] = j\n                #\n                # elif (cm.NN == "SegNet"):\n                #\n                #     # combine_tensor = np.expand_dims(combine_tensor,\n                #     #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                #     #  the model expects this shape: (batch_size, time, height, width, channels)\n                #\n                #     # else:\n                #     #\n                #     #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n                #\n                #     # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n                #\n                #     cdl_array = np.ravel(current_cdl, \'c\')\n                #     cdl_array = keras.utils.to_categorical(cdl_array, num_classes=256)\n                #     cdl_array = np.expand_dims(cdl_array,\n                #                                axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n                #\n                #     if (len(cm.input_tensor) == 0):\n                #\n                #         cm.input_tensor = combine_tensor\n                #\n                #         cm.cdl_tensor = cdl_array\n                #\n                #     else:\n                #\n                #         cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n                #\n                #         cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                # if cm.cdl_tensor.shape[0] != batch_size:\n                #     continue;\n\n                # i_array[cm.cdl_tensor.shape[0]-1] = i\n                #\n                # j_array[cm.cdl_tensor.shape[0]-1] = j\n                #\n                # model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1,\n                #           callbacks=[])\n                #\n                # predict_output = model.predict(cm.input_tensor, batch_size=batch_size, verbose=0)\n                # print("Predict Output Shape: ", predict_output.shape)\n\n                # y_pred = np.argmax(predict_output, axis=1)\n\n                # for x in range(batch_size):\n                #\n                #     predict_output_single = cm.reshapePredictOutput(predict_output[x])\n                #\n                #     seg_img = np.zeros((cm.img_height, cm.img_width, 3))\n                #     # colors = [  ( np.random.randint(0,255),\n                #     #               np.random.randint(0,255),\n                #     #               np.random.randint(0,255)   ) for _ in range(n_classes)  ]\n                #     for c in range(cm.n_classes):\n                #         seg_img[:, :, 0] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[0])).astype(\'uint8\')\n                #         seg_img[:, :, 1] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[1])).astype(\'uint8\')\n                #         seg_img[:, :, 2] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[2])).astype(\'uint8\')\n                #\n                #     # save the predicted results to file\n                #     # seg_img = cv2.resize(seg_img, (360, 360))\n                #     # print(seg_img.shape)\n                #     # saveimg = seg_img[..., ::-1]\n                #     # cv2.imwrite(cm.saveimgpath, saveimg)\n                #\n                #     # predict_cdl[i * 360:(i + 1) * 360, j * 360:(j + 1) * 360] = predict_output;\n                #     predict_cdl[int(i_array[x]) * cm.img_width:(int(i_array[x]) + 1) * cm.img_width,\n                #     int(j_array[x]) * cm.img_height:(int(j_array[x]) + 1) * cm.img_height, :] = seg_img;\n\n                # cm.input_tensor = [];\n                #\n                # cm.cdl_tensor = [];\n\n        # savemodel = model.get_layer(\'sequential_1\')\n\n        # predict_cdl = cv2.resize(predict_cdl, imarraymask.shape)\n        #\n        # predict_cdl = predict_cdl[..., ::-1]\n        #\n        # saveimgpath = cm.folder + "/data/cdl/" + cm.NN + "_output_" + tile + "_" + str(date) + "_epoch_" + str(n) + ".jpg";\n        #\n        # print("save predicted picture", saveimgpath)\n        #\n        # cv2.imwrite(saveimgpath, predict_cdl)\n        #\n        # cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n        #\n        # model.save(cm.modelpath + "_parallel.net")\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\n=========> Processing  LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180725  tile:  022033  year: 2018  month 07\nslicing.....\nTraceback (most recent call last):\n  File "python-ukk8gfz72oec.py", line 187, in <module>\n    imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band1.tif", current_tile1);\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/imageio/core/functions.py", line 259, in imwrite\n    writer = get_writer(uri, format, "i", **kwargs)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/imageio/core/functions.py", line 187, in get_writer\n    return format.get_writer(request)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/imageio/core/format.py", line 178, in get_writer\n    return self.Writer(self, request)\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/imageio/core/format.py", line 214, in __init__\n    self._open(**self.request.kwargs.copy())\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/imageio/plugins/tifffile.py", line 289, in _open\n    self.request.get_file(), bigtiff, byteorder, software=software\n  File "/home/zsun/anaconda3/envs/ag/lib/python3.7/site-packages/imageio/core/request.py", line 349, in get_file\n    self._file = open(self.filename, "wb")\nPermissionError: [Errno 13] Permission denied: \'/home/zsun/crop-oh/ag-net-input/022033_20180725_65_25_band1.tif\'\n', 'kps1gf', 'Done'),
	('8zox419ne3d8', 'ikfk1x', '2019-07-03 16:05:28', '2019-07-03 16:30:59', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nimport sys\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n# from keras import backend as K\nfrom pathlib import Path\nimport cv2\nimport imageio\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n# datearray = ["2016104", "2016120"]\n\n# model = cm.getModel()\n\nbatch_size = 64\n\n# landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.folder="/home/zsun/"\n\nlandsat_folder=cm.folder + "/crop-oh/landsat-5070/"\n\ncdl_folder = cm.folder + "/crop-oh/cdl-cut/"\n\ninput_folder = cm.folder + "/crop-oh/ag-net-input/"\n\ntarget_folder = cm.folder + "/crop-oh/ag-net-target/"\n\ndef checkComplete(f):\n#for f in listdir(landsat_folder):\n    complete=True\n    if "band1.tif" in f:\n        im1 = isfile(landsat_folder + f)\n        im2 = isfile(landsat_folder + f.replace("band1", "band2"))\n        im3 = isfile(landsat_folder + f.replace("band1", "band3"))\n        im4 = isfile(landsat_folder + f.replace("band1", "band4"))\n        im5 = isfile(landsat_folder + f.replace("band1", "band5"))\n        im6 = isfile(landsat_folder + f.replace("band1", "band6"))\n        im7 = isfile(landsat_folder + f.replace("band1", "band7"))\n        cfmask = isfile(landsat_folder + f.replace("sr_band1", "pixel_qa"))\n        cdl = isfile(cdl_folder + f)\n        if(not im1 or not im2 or not im3 or not im4 or not im5 or not im6 or not im7 or not cdl):\n            print("found incomplete tile: ", f)\n            complete=False\n    return complete\n\n# sys.exit()\n\nstart_time = time.time()\n\ndef isprocessed(date):\n    isp=False\n    for f in listdir(input_folder):\n        if date in f:\n            isp=True\n            print("this scene has already processed")\n            break;\n    return isp\n\n\nfor f in listdir(landsat_folder):\n\n    if "band1.tif" in f:\n        print("=========> Processing ", f)\n        exist = isfile(cdl_folder + f)\n                # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n        sate = f[0:4]\n        date = f[17:25]\n        month = date[4:6]\n        tile = f[10:16]\n        year = date[0:4]\n        # processed=isprocessed(date)\n        print("cdl exist: ", exist," date: ", date, " tile: ", tile, " year:", year, " month", month)\n        # if not exist or date != "20160314":\n        if not exist or int(year) < 2013 or int(month) < 6 or int(month) > 8:\n            print("skip, cdl doesn\'t exist or the date is out of windows")\n            continue;\n\n        complete=checkComplete(f)\n\n        if not complete:\n            continue;\n        \n        print("slicing.....")\n\n        # if date != "20110705":\n        #    continue;\n\n        im1 = Image.open(landsat_folder + f)\n        im2 = Image.open(landsat_folder + f.replace("band1", "band2"))\n        im3 = Image.open(landsat_folder + f.replace("band1", "band3"))\n        im4 = Image.open(landsat_folder + f.replace("band1", "band4"))\n        im5 = Image.open(landsat_folder + f.replace("band1", "band5"))\n        im6 = Image.open(landsat_folder + f.replace("band1", "band6"))\n        im7 = Image.open(landsat_folder + f.replace("band1", "band7"))\n        cfmask = Image.open(landsat_folder + f.replace("sr_band1", "pixel_qa"))\n        cdl_im = Image.open(cdl_folder + f)\n\n        imarray1 = numpy.array(im1)\n        imarray2 = numpy.array(im2)\n        imarray3 = numpy.array(im3)\n        imarray4 = numpy.array(im4)\n        imarray5 = numpy.array(im5)\n        imarray6 = numpy.array(im6)\n        imarray7 = numpy.array(im7)\n        # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n        imarraymask = numpy.array(cfmask)\n        cdlarray = numpy.array(cdl_im)\n        # print(imarraymask.shape)\n        # print(cdlarray.shape)\n        predict_cdl = numpy.zeros((imarraymask.shape[0], imarraymask.shape[1], 3))\n\n        # show a small tile of 360*360\n        x_tile_num = imarraymask.shape[0] / cm.img_width\n        y_tile_num = imarraymask.shape[1] / cm.img_height\n\n        total_num = int(x_tile_num * y_tile_num)\n\n        i_array = numpy.zeros(int(batch_size))\n\n        j_array = numpy.zeros(int(batch_size))\n\n        for k in range(0, total_num):\n\n            i = random.randint(0, int(x_tile_num) - 1)\n            j = random.randint(0, int(y_tile_num) - 1)\n\n            # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n            # print("imgarray3 shape: ", imarray3.shape)\n\n            # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n            # print("imgarray3 shape: ", imarray3.shape)\n\n            current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_width:(j + 1) * cm.img_height];\n            current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n            #                j * cm.img_height:(j + 1) * cm.img_height];\n            current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                           j * cm.img_height:(j + 1) * cm.img_height];\n            current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width,\n                          j * cm.img_height:(j + 1) * cm.img_height];\n\n            # print(current_tile1.shape);\n            # bqa - High confidence cloud ? 480,992\n            # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n            # if the CDL contains 0, skip\n            if (992 in current_mask or 834 in current_mask\n                    or 1 in current_mask or 480 in current_mask or 898 in current_mask\n                    or 928 in current_mask or 96 in current_mask or 112 in current_mask\n                    or 160 in current_mask or 176 in current_mask or 224 in current_mask\n                    or 0 in current_mask or 0 in current_cdl):\n                # if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                # print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                continue;\n            elif (cm.checkOutSeasonCrops(current_cdl, month)):\n                # print("tile ", i, " ", j, " is skipped because it is out of season")\n                continue;\n            else:\n                # print(current_tile1)\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band1.tif", current_tile1);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band2.tif", current_tile2);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band3.tif", current_tile3);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band4.tif", current_tile4);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band5.tif", current_tile5);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band6.tif", current_tile6);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band7.tif", current_tile7);\n                imageio.imwrite(target_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_cdl.tif", current_cdl);\n                # print("tile ", i, " ", j, " is valid")\n                # current_tile1 = np.expand_dims(current_tile1, axis=2)\n                # current_tile2 = np.expand_dims(current_tile2, axis=2)\n                # current_tile3 = np.expand_dims(current_tile3, axis=2)\n                # current_tile4 = np.expand_dims(current_tile4, axis=2)\n                # current_tile5 = np.expand_dims(current_tile5, axis=2)\n                # current_tile6 = np.expand_dims(current_tile6, axis=2)\n                # current_tile7 = np.expand_dims(current_tile7, axis=2)\n                # # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                # current_cdl = np.expand_dims(current_cdl, axis=2)\n                #\n                # combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                #                                  current_tile5, current_tile6, current_tile7), axis=2)\n                # combine_tensor = np.expand_dims(combine_tensor,\n                #                                 axis=0)  # (1, height, width, channels), add a dimension because the\n                # # model expects this shape: (batch_size, height, width, channels)\n                # #                                   axis=0)  # (1, 1, height, width, channels), add a dimension because\n                # # the model expects this shape: (batch_size, time, height, width, channels)\n                # if (cm.NN == "ConvLSTM"):\n                #\n                #     if (len(cm.input_tensor) == 0):\n                #\n                #         cm.input_tensor = combine_tensor;\n                #\n                #     else:\n                #\n                #         cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                #                                          axis=0);  # use batch to combine multiple images. Each batch only\n                #         # has one step, which is the sequence to sequence mode.\n                #\n                #     # cdl_array = np.ravel(cdl_array, \'c\')\n                #\n                #     cdl_array = keras.utils.to_categorical(current_cdl, num_classes=256)\n                #\n                #     cdl_array = np.expand_dims(cdl_array,\n                #                                axis=0)  # add time dimensions: (time, height, width, channels)\n                #\n                #     cdl_array = np.expand_dims(cdl_array, axis=0)\n                #\n                #     if (len(cm.cdl_tensor) == 0):\n                #\n                #         cm.cdl_tensor = cdl_array\n                #\n                #     else:\n                #\n                #         cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                #                                        axis=0);  # the new image will be a new batch\n                #\n                # #    i_array[cm.cdl_tensor.shape[0]] = i\n                #\n                # #    j_array[cm.cdl_tensor.shape[0]] = j\n                #\n                # elif (cm.NN == "SegNet"):\n                #\n                #     # combine_tensor = np.expand_dims(combine_tensor,\n                #     #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                #     #  the model expects this shape: (batch_size, time, height, width, channels)\n                #\n                #     # else:\n                #     #\n                #     #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n                #\n                #     # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n                #\n                #     cdl_array = np.ravel(current_cdl, \'c\')\n                #     cdl_array = keras.utils.to_categorical(cdl_array, num_classes=256)\n                #     cdl_array = np.expand_dims(cdl_array,\n                #                                axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n                #\n                #     if (len(cm.input_tensor) == 0):\n                #\n                #         cm.input_tensor = combine_tensor\n                #\n                #         cm.cdl_tensor = cdl_array\n                #\n                #     else:\n                #\n                #         cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n                #\n                #         cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                # if cm.cdl_tensor.shape[0] != batch_size:\n                #     continue;\n\n                # i_array[cm.cdl_tensor.shape[0]-1] = i\n                #\n                # j_array[cm.cdl_tensor.shape[0]-1] = j\n                #\n                # model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1,\n                #           callbacks=[])\n                #\n                # predict_output = model.predict(cm.input_tensor, batch_size=batch_size, verbose=0)\n                # print("Predict Output Shape: ", predict_output.shape)\n\n                # y_pred = np.argmax(predict_output, axis=1)\n\n                # for x in range(batch_size):\n                #\n                #     predict_output_single = cm.reshapePredictOutput(predict_output[x])\n                #\n                #     seg_img = np.zeros((cm.img_height, cm.img_width, 3))\n                #     # colors = [  ( np.random.randint(0,255),\n                #     #               np.random.randint(0,255),\n                #     #               np.random.randint(0,255)   ) for _ in range(n_classes)  ]\n                #     for c in range(cm.n_classes):\n                #         seg_img[:, :, 0] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[0])).astype(\'uint8\')\n                #         seg_img[:, :, 1] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[1])).astype(\'uint8\')\n                #         seg_img[:, :, 2] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[2])).astype(\'uint8\')\n                #\n                #     # save the predicted results to file\n                #     # seg_img = cv2.resize(seg_img, (360, 360))\n                #     # print(seg_img.shape)\n                #     # saveimg = seg_img[..., ::-1]\n                #     # cv2.imwrite(cm.saveimgpath, saveimg)\n                #\n                #     # predict_cdl[i * 360:(i + 1) * 360, j * 360:(j + 1) * 360] = predict_output;\n                #     predict_cdl[int(i_array[x]) * cm.img_width:(int(i_array[x]) + 1) * cm.img_width,\n                #     int(j_array[x]) * cm.img_height:(int(j_array[x]) + 1) * cm.img_height, :] = seg_img;\n\n                # cm.input_tensor = [];\n                #\n                # cm.cdl_tensor = [];\n\n        # savemodel = model.get_layer(\'sequential_1\')\n\n        # predict_cdl = cv2.resize(predict_cdl, imarraymask.shape)\n        #\n        # predict_cdl = predict_cdl[..., ::-1]\n        #\n        # saveimgpath = cm.folder + "/data/cdl/" + cm.NN + "_output_" + tile + "_" + str(date) + "_epoch_" + str(n) + ".jpg";\n        #\n        # print("save predicted picture", saveimgpath)\n        #\n        # cv2.imwrite(saveimgpath, predict_cdl)\n        #\n        # cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n        #\n        # model.save(cm.modelpath + "_parallel.net")\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'Using TensorFlow backend.\n=========> Processing  LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180725  tile:  022033  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180527  tile:  025031  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180709  tile:  022031  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180730  tile:  025030  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180725  tile:  022034  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180709  tile:  022033  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180723  tile:  024030  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180725  tile:  022032  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180723  tile:  024034  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180607  tile:  022034  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180628  tile:  025031  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180605  tile:  024030  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180504  tile:  024031  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180630  tile:  023034  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180605  tile:  024032  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180504  tile:  024030  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180605  tile:  024031  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180628  tile:  025030  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180630  tile:  023031  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180801  tile:  023034  year: 2018  month 08\nslicing.....\n=========> Processing  LC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180707  tile:  024033  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180707  tile:  024032  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180614  tile:  023034  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180808  tile:  024030  year: 2018  month 08\nslicing.....\n=========> Processing  LC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180605  tile:  024033  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180801  tile:  023032  year: 2018  month 08\nslicing.....\n=========> Processing  LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180826  tile:  022032  year: 2018  month 08\nslicing.....\n=========> Processing  LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180628  tile:  025032  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180709  tile:  022032  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180607  tile:  022031  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180527  tile:  025030  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180506  tile:  022034  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180515  tile:  021034  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180707  tile:  024030  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180725  tile:  022031  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180801  tile:  023031  year: 2018  month 08\nslicing.....\n=========> Processing  LC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180707  tile:  024034  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180723  tile:  024033  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180614  tile:  023033  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180607  tile:  022032  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180527  tile:  025033  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180607  tile:  022033  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180723  tile:  024032  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180527  tile:  025032  year: 2018  month 05\nskip, cdl doesn\'t exist or the date is out of windows\n=========> Processing  LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180628  tile:  025033  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180630  tile:  023033  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180723  tile:  024031  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180707  tile:  024031  year: 2018  month 07\nslicing.....\n=========> Processing  LC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180605  tile:  024034  year: 2018  month 06\nslicing.....\n=========> Processing  LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180801  tile:  023033  year: 2018  month 08\nslicing.....\n=========> Processing  LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\ncdl exist:  True  date:  20180630  tile:  023032  year: 2018  month 06\nslicing.....\ntotal time cost:  1527.3811638355255\n', 'kps1gf', 'Done'),
	('nxboa4xqcz9t', 'aikfaz', '2019-07-03 16:13:51', '2019-07-03 17:18:24', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nos.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152\nos.environ["CUDA_VISIBLE_DEVICES"] = ""\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'logfile', 'kps1gf', 'Failed'),
	('usc9155codbu', 'ejc7yo', '2019-07-03 16:17:01', '2019-07-03 17:18:24', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\nfrom colormap import *\n# from keras import backend as K\nfrom pathlib import Path\nimport SegNet\n\nfrom os import listdir,environ\nfrom os.path import isfile, join\n\nenviron["CUDA_VISIBLE_DEVICES"] = "2"\n\n# datearray = ["2016104", "2016120"]\n\n# cm.modelpath = cm.folder + "/model/keras_cdl_SegNet_standard.net";\n\n\nbatch = 32\n\ncm.NN="SegNet"\n\ncm.reuse=True\n\ncm.modelpath = "/home/zsun/ag-net/keras_cdl_" + cm.NN +"_standard_multiple_oh_ready.net";#032027\n\ninput_folder="/home/zsun/crop-oh/ag-net-input/"\n\ntarget_folder="/home/zsun/crop-oh/ag-net-target/"\n\nmodel = cm.getModel()\n\n#for f in listdir(input_folder):\n#    if "band1.tif" in f:\n#        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(input_folder):\n\n        if "band1.tif" in f:\n            \n            # print("=========> Processing ",f)\n            exist1 = isfile(input_folder + f)\n            exist2 = isfile(input_folder + f.replace("band1", "band2"))\n            exist3 = isfile(input_folder + f.replace("band1", "band3"))\n            exist4 = isfile(input_folder + f.replace("band1", "band4"))\n            exist5 = isfile(input_folder + f.replace("band1", "band5"))\n            exist6 = isfile(input_folder + f.replace("band1", "band6"))\n            exist7 = isfile(input_folder + f.replace("band1", "band7"))\n            # 031026_20160718_57_76_band1.tif\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            #sate=f[0:4]\n            date=f[7:15]\n            month=date[4:6]\n            tile=f[0:6]\n            year=date[0:4]\n            # print("date: ", date, " tile: ", tile, " year:", year)\n            \n            # if not exist or date != "20160314":\n            \n            if not exist1 or not exist2 or not exist3 or not exist4 or not exist5 or not exist6 or not exist7 or int(year) < 2013 or int(month) < 5 or int(month) > 8 :\n                \n                continue;\n\n            im1 = Image.open(input_folder + f)\n            im2 = Image.open(input_folder + f.replace("band1", "band2"))\n            im3 = Image.open(input_folder + f.replace("band1", "band3"))\n            im4 = Image.open(input_folder + f.replace("band1", "band4"))\n            im5 = Image.open(input_folder + f.replace("band1", "band5"))\n            im6 = Image.open(input_folder + f.replace("band1", "band6"))\n            im7 = Image.open(input_folder + f.replace("band1", "band7"))\n            cdl_im = Image.open(target_folder + f.replace("band1", "cdl"))\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            cdlarray = numpy.array(cdl_im)\n            predict_cdl = numpy.zeros((imarray1.shape[0], imarray1.shape[1], 3))\n\n            # show a small tile of 360*360\n            x_tile_num = imarray1.shape[0] / cm.img_width\n            y_tile_num = imarray1.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            i_array = numpy.zeros(batch)\n\n            j_array = numpy.zeros(batch)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n            \n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                current_tile1 = np.expand_dims(current_tile1, axis=2)\n                current_tile2 = np.expand_dims(current_tile2, axis=2)\n                current_tile3 = np.expand_dims(current_tile3, axis=2)\n                current_tile4 = np.expand_dims(current_tile4, axis=2)\n                current_tile5 = np.expand_dims(current_tile5, axis=2)\n                current_tile6 = np.expand_dims(current_tile6, axis=2)\n                current_tile7 = np.expand_dims(current_tile7, axis=2)\n                current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                combine_tensor = np.expand_dims(combine_tensor, axis=0)  # (1, height, width, channels), add a dimension because the\n                \n                if (cm.NN == "ConvLSTM"):\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor;\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                    cdl_array = keras.utils.to_categorical(current_cdl, num_classes=cm.n_classes)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # add time dimensions: (time, height, width, channels)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                    if (len(cm.cdl_tensor) == 0):\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0);  # the new image will be a new batch\n                \n                elif (cm.NN == "SegNet" or cm.NN == "U-Net"):\n                    \n                    cdl_array = np.ravel(current_cdl, \'c\')\n                    \n                    cdl_array = keras.utils.to_categorical(cdl_array, num_classes=cm.n_classes)\n                    \n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                if cm.cdl_tensor.shape[0] < batch:\n\n                    continue;\n\n                model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch, epochs=1, callbacks=[])\n                    \n                cm.input_tensor = [];\n\n                cm.cdl_tensor = [];\n\n                model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n    model.save(cm.modelpath + "_checkpoint_" + str(n) + ".net") # prevent model failure\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'logfile', 'kps1gf', 'Failed'),
	('jv7hge4qq3r2', 'ejc7yo', '2019-07-08 15:52:02', '2019-07-09 01:55:20', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\nfrom colormap import *\n# from keras import backend as K\nfrom pathlib import Path\nimport SegNet\n\nfrom os import listdir,environ\nfrom os.path import isfile, join\n\nenviron["CUDA_VISIBLE_DEVICES"] = "2"\n\n# datearray = ["2016104", "2016120"]\n\n# cm.modelpath = cm.folder + "/model/keras_cdl_SegNet_standard.net";\n\n\nbatch = 32\n\ncm.NN="SegNet"\n\ncm.reuse=True\n\ncm.modelpath = "/home/zsun/ag-net/keras_cdl_" + cm.NN +"_standard_multiple_oh_ready.net";#032027\n\ninput_folder="/home/zsun/crop-oh/ag-net-input/"\n\ntarget_folder="/home/zsun/crop-oh/ag-net-target/"\n\nmodel = cm.getModel()\n\n#for f in listdir(input_folder):\n#    if "band1.tif" in f:\n#        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(input_folder):\n\n        if "band1.tif" in f:\n            \n            # print("=========> Processing ",f)\n            exist1 = isfile(input_folder + f)\n            exist2 = isfile(input_folder + f.replace("band1", "band2"))\n            exist3 = isfile(input_folder + f.replace("band1", "band3"))\n            exist4 = isfile(input_folder + f.replace("band1", "band4"))\n            exist5 = isfile(input_folder + f.replace("band1", "band5"))\n            exist6 = isfile(input_folder + f.replace("band1", "band6"))\n            exist7 = isfile(input_folder + f.replace("band1", "band7"))\n            # 031026_20160718_57_76_band1.tif\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            #sate=f[0:4]\n            date=f[7:15]\n            month=date[4:6]\n            tile=f[0:6]\n            year=date[0:4]\n            # print("date: ", date, " tile: ", tile, " year:", year)\n            \n            # if not exist or date != "20160314":\n            \n            if not exist1 or not exist2 or not exist3 or not exist4 or not exist5 or not exist6 or not exist7 or int(year) < 2013 or int(month) < 5 or int(month) > 8 :\n                \n                continue;\n\n            im1 = Image.open(input_folder + f)\n            im2 = Image.open(input_folder + f.replace("band1", "band2"))\n            im3 = Image.open(input_folder + f.replace("band1", "band3"))\n            im4 = Image.open(input_folder + f.replace("band1", "band4"))\n            im5 = Image.open(input_folder + f.replace("band1", "band5"))\n            im6 = Image.open(input_folder + f.replace("band1", "band6"))\n            im7 = Image.open(input_folder + f.replace("band1", "band7"))\n            cdl_im = Image.open(target_folder + f.replace("band1", "cdl"))\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            cdlarray = numpy.array(cdl_im)\n            predict_cdl = numpy.zeros((imarray1.shape[0], imarray1.shape[1], 3))\n\n            # show a small tile of 360*360\n            x_tile_num = imarray1.shape[0] / cm.img_width\n            y_tile_num = imarray1.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            i_array = numpy.zeros(batch)\n\n            j_array = numpy.zeros(batch)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n            \n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                current_tile1 = np.expand_dims(current_tile1, axis=2)\n                current_tile2 = np.expand_dims(current_tile2, axis=2)\n                current_tile3 = np.expand_dims(current_tile3, axis=2)\n                current_tile4 = np.expand_dims(current_tile4, axis=2)\n                current_tile5 = np.expand_dims(current_tile5, axis=2)\n                current_tile6 = np.expand_dims(current_tile6, axis=2)\n                current_tile7 = np.expand_dims(current_tile7, axis=2)\n                current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                combine_tensor = np.expand_dims(combine_tensor, axis=0)  # (1, height, width, channels), add a dimension because the\n                \n                if (cm.NN == "ConvLSTM"):\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor;\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                    cdl_array = keras.utils.to_categorical(current_cdl, num_classes=cm.n_classes)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # add time dimensions: (time, height, width, channels)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                    if (len(cm.cdl_tensor) == 0):\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0);  # the new image will be a new batch\n                \n                elif (cm.NN == "SegNet" or cm.NN == "U-Net"):\n                    \n                    cdl_array = np.ravel(current_cdl, \'c\')\n                    \n                    cdl_array = keras.utils.to_categorical(cdl_array, num_classes=cm.n_classes)\n                    \n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                if cm.cdl_tensor.shape[0] < batch:\n\n                    continue;\n\n                model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch, epochs=1, callbacks=[])\n                    \n                cm.input_tensor = [];\n\n                cm.cdl_tensor = [];\n\n                model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n    model.save(cm.modelpath + "_checkpoint_" + str(n) + ".net") # prevent model failure\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'logfile', 'kps1gf', 'Done'),
	('hoij3vhzcjo8', 'c7ot8y', '2019-07-13 08:03:37', '2019-07-13 08:03:37', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n          uncut=0\n        fi\n    done\n\n	#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]; then\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ]; then \n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'start to prepare landsat into training dataset\nmkdir: cannot create directory /home/zsun/cdl-projected/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-unzip/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/tileindex/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/cdl-cut/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-5070/: File exists\n/home/zsun/crop-oh/landsat//LC080210342018051501T1-SC20190701114122.tar.gz\nget file name: LC080210342018051501T1-SC20190701114122.tar.gz\ncurrent date is: 20180515\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220312018060701T1-SC20190701114037.tar.gz\nget file name: LC080220312018060701T1-SC20190701114037.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220312018070901T1-SC20190701115347.tar.gz\nget file name: LC080220312018070901T1-SC20190701115347.tar.gz\ncurrent date is: 20180709\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220312018072501T1-SC20190701114339.tar.gz\nget file name: LC080220312018072501T1-SC20190701114339.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018060701T1-SC20190701114032.tar.gz\nget file name: LC080220322018060701T1-SC20190701114032.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018070901T1-SC20190701114117.tar.gz\nget file name: LC080220322018070901T1-SC20190701114117.tar.gz\ncurrent date is: 20180709\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018072501T1-SC20190701114330.tar.gz\nget file name: LC080220322018072501T1-SC20190701114330.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220322018082601T1-SC20190701115245.tar.gz\nget file name: LC080220322018082601T1-SC20190701115245.tar.gz\ncurrent date is: 20180826\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018060701T1-SC20190701115212.tar.gz\nget file name: LC080220332018060701T1-SC20190701115212.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018070901T1-SC20190701114106.tar.gz\nget file name: LC080220332018070901T1-SC20190701114106.tar.gz\ncurrent date is: 20180709\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220332018072501T1-SC20190701114045.tar.gz\nget file name: LC080220332018072501T1-SC20190701114045.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018050601T1-SC20190701114123.tar.gz\nget file name: LC080220342018050601T1-SC20190701114123.tar.gz\ncurrent date is: 20180506\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018060701T1-SC20190701114117.tar.gz\nget file name: LC080220342018060701T1-SC20190701114117.tar.gz\ncurrent date is: 20180607\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080220342018072501T1-SC20190701114113.tar.gz\nget file name: LC080220342018072501T1-SC20190701114113.tar.gz\ncurrent date is: 20180725\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230312018063001T1-SC20190701114034.tar.gz\nget file name: LC080230312018063001T1-SC20190701114034.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230312018080101T1-SC20190701114100.tar.gz\nget file name: LC080230312018080101T1-SC20190701114100.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230322018063001T1-SC20190701114056.tar.gz\nget file name: LC080230322018063001T1-SC20190701114056.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230322018071601T1-SC20190701114107.tar.gz\nget file name: LC080230322018071601T1-SC20190701114107.tar.gz\ncurrent date is: 20180716\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230322018080101T1-SC20190701114403.tar.gz\nget file name: LC080230322018080101T1-SC20190701114403.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018061401T1-SC20190701114102.tar.gz\nget file name: LC080230332018061401T1-SC20190701114102.tar.gz\ncurrent date is: 20180614\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018063001T1-SC20190701115409.tar.gz\nget file name: LC080230332018063001T1-SC20190701115409.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018071601T1-SC20190701114040.tar.gz\nget file name: LC080230332018071601T1-SC20190701114040.tar.gz\ncurrent date is: 20180716\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230332018080101T1-SC20190701114321.tar.gz\nget file name: LC080230332018080101T1-SC20190701114321.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018061401T1-SC20190701114117.tar.gz\nget file name: LC080230342018061401T1-SC20190701114117.tar.gz\ncurrent date is: 20180614\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018063001T1-SC20190701114123.tar.gz\nget file name: LC080230342018063001T1-SC20190701114123.tar.gz\ncurrent date is: 20180630\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018071601T1-SC20190701114056.tar.gz\nget file name: LC080230342018071601T1-SC20190701114056.tar.gz\ncurrent date is: 20180716\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080230342018080101T1-SC20190701114313.tar.gz\nget file name: LC080230342018080101T1-SC20190701114313.tar.gz\ncurrent date is: 20180801\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018050401T1-SC20190701114043.tar.gz\nget file name: LC080240302018050401T1-SC20190701114043.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018060501T1-SC20190701114045.tar.gz\nget file name: LC080240302018060501T1-SC20190701114045.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018070701T1-SC20190701114044.tar.gz\nget file name: LC080240302018070701T1-SC20190701114044.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018072301T1-SC20190701114131.tar.gz\nget file name: LC080240302018072301T1-SC20190701114131.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240302018080801T1-SC20190701114117.tar.gz\nget file name: LC080240302018080801T1-SC20190701114117.tar.gz\ncurrent date is: 20180808\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018050401T1-SC20190701114107.tar.gz\nget file name: LC080240312018050401T1-SC20190701114107.tar.gz\ncurrent date is: 20180504\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018060501T1-SC20190701114128.tar.gz\nget file name: LC080240312018060501T1-SC20190701114128.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018070701T1-SC20190701114102.tar.gz\nget file name: LC080240312018070701T1-SC20190701114102.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240312018072301T1-SC20190701114044.tar.gz\nget file name: LC080240312018072301T1-SC20190701114044.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018060501T1-SC20190701114102.tar.gz\nget file name: LC080240322018060501T1-SC20190701114102.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018070701T1-SC20190701114117.tar.gz\nget file name: LC080240322018070701T1-SC20190701114117.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240322018072301T1-SC20190701114053.tar.gz\nget file name: LC080240322018072301T1-SC20190701114053.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240332018060501T1-SC20190701114115.tar.gz\nget file name: LC080240332018060501T1-SC20190701114115.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240332018070701T1-SC20190701114101.tar.gz\nget file name: LC080240332018070701T1-SC20190701114101.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240332018072301T1-SC20190701114119.tar.gz\nget file name: LC080240332018072301T1-SC20190701114119.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240342018060501T1-SC20190701114055.tar.gz\nget file name: LC080240342018060501T1-SC20190701114055.tar.gz\ncurrent date is: 20180605\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240342018070701T1-SC20190701114107.tar.gz\nget file name: LC080240342018070701T1-SC20190701114107.tar.gz\ncurrent date is: 20180707\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080240342018072301T1-SC20190701114055.tar.gz\nget file name: LC080240342018072301T1-SC20190701114055.tar.gz\ncurrent date is: 20180723\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250302018052701T1-SC20190701114051.tar.gz\nget file name: LC080250302018052701T1-SC20190701114051.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250302018062801T1-SC20190701114107.tar.gz\nget file name: LC080250302018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250302018073001T1-SC20190701114313.tar.gz\nget file name: LC080250302018073001T1-SC20190701114313.tar.gz\ncurrent date is: 20180730\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018052701T1-SC20190701114031.tar.gz\nget file name: LC080250312018052701T1-SC20190701114031.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250312018062801T1-SC20190701114039.tar.gz\nget file name: LC080250312018062801T1-SC20190701114039.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018052701T1-SC20190701114040.tar.gz\nget file name: LC080250322018052701T1-SC20190701114040.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250322018062801T1-SC20190701114107.tar.gz\nget file name: LC080250322018062801T1-SC20190701114107.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018052701T1-SC20190701115150.tar.gz\nget file name: LC080250332018052701T1-SC20190701115150.tar.gz\ncurrent date is: 20180527\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nalready unzipped\n/home/zsun/crop-oh/landsat//LC080250332018062801T1-SC20190701114119.tar.gz\nget file name: LC080250332018062801T1-SC20190701114119.tar.gz\ncurrent date is: 20180628\n++++++++++++++++found band1 image: /home/zsun/crop-oh/landsat-unzip//LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nalready unzipped\nLC08_L1TP_021034_20180515_20180604_01_T1_pixel_qa.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_radsat_qa.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band2.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band3.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band4.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band5.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band6.tif is already there\nLC08_L1TP_021034_20180515_20180604_01_T1_sr_band7.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022031_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_022031_20180709_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022031_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180709_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band2.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band3.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band4.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band5.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band6.tif is already there\nLC08_L1TP_022032_20180826_20180830_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180709_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022033_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180506_20180517_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180607_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_022034_20180725_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023031_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023031_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023032_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023032_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180614_20180703_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023033_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band2.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band3.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band4.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band5.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band6.tif is already there\nLC08_L1TP_023034_20180614_20180703_01_T1_sr_band7.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band2.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band3.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band4.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band5.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band6.tif is already there\nLC08_L1TP_023034_20180630_20180716_01_T1_sr_band7.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_023034_20180801_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band2.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band3.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band4.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band5.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band6.tif is already there\nLC08_L1TP_024030_20180808_20180815_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180504_20180516_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024031_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024032_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024033_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024033_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024033_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band2.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band3.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band4.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band5.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band6.tif is already there\nLC08_L1TP_024034_20180605_20180615_01_T1_sr_band7.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band2.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band3.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band4.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band5.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band6.tif is already there\nLC08_L1TP_024034_20180707_20180717_01_T1_sr_band7.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_pixel_qa.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_radsat_qa.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band2.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band3.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band4.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band5.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band6.tif is already there\nLC08_L1TP_024034_20180723_20180731_01_T1_sr_band7.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025030_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025030_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band2.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band3.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band4.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band5.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band6.tif is already there\nLC08_L1TP_025030_20180730_20180814_01_T1_sr_band7.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025031_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025031_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025032_20180628_20180704_01_T1_sr_band7.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band2.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band3.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band4.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band5.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band6.tif is already there\nLC08_L1TP_025033_20180527_20180605_01_T1_sr_band7.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_pixel_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_radsat_qa.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_aerosol.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band2.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band3.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band4.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band5.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band6.tif is already there\nLC08_L1TP_025033_20180628_20180704_01_T1_sr_band7.tif is already there\nget band name: LC08_L1TP_021034_20180515_20180604_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022031_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022031_20180709_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022031_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180709_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022032_20180826_20180830_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022033_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022033_20180709_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022033_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022034_20180506_20180517_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022034_20180607_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_022034_20180725_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023031_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023031_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023032_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023032_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023033_20180614_20180703_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023033_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023033_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023034_20180614_20180703_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023034_20180630_20180716_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_023034_20180801_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180504_20180516_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024030_20180808_20180815_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180504_20180516_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024031_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024032_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024032_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024032_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024033_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024033_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024033_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024034_20180605_20180615_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024034_20180707_20180717_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_024034_20180723_20180731_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025030_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025030_20180628_20180704_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025030_20180730_20180814_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025031_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025031_20180628_20180704_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025032_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025032_20180628_20180704_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025033_20180527_20180605_01_T1_sr_band1.tif\nskipping\nget band name: LC08_L1TP_025033_20180628_20180704_01_T1_sr_band1.tif\nskipping\nend the data preparation\n', 'kps1gf', 'Done'),
	('xm1ymrs9nq54', 'nhi96d', '2019-07-16 14:28:24', '2019-07-16 14:28:27', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop-oh/\n\nmkdir /home/zsun/crop-oh/landsat-2/\n\ncd /home/zsun/crop-oh/landsat-2/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101907010724 -d .\n\necho "download complete"', 'mkdir: cannot create directory /home/zsun/crop-oh/: File exists\nmkdir: cannot create directory /home/zsun/crop-oh/landsat-2/: File exists\n2019-07-16 20:28:25,485| No scenes in "completed" state for order espa-szhwhu@gmail.com-0101907010724\ndownload complete\n', 'kps1gf', 'Done'),
	('bv59fte14s21', 'qp820f', '2019-07-16 14:28:29', '2019-07-16 14:28:29', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('kw9kn8dzx50q', 'rh1u8q', '2019-07-16 14:28:30', '2019-07-16 14:28:30', '#!/bin/bash\necho "filter cloud"', 'filter cloud\n', 'kps1gf', 'Done'),
	('fpqb0j99w25v', 'rpnhlg', '2019-07-16 14:28:32', '2019-07-16 14:28:32', '#!/bin/bash\necho "remove shadow pixels"', 'remove shadow pixels\n', 'kps1gf', 'Done'),
	('keiu2m929158', 'wsxeps', '2019-07-16 14:28:34', '2019-07-16 14:28:34', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'download cdl\n', 'kps1gf', 'Done'),
	('lx9q8cpftqsy', 'spz3b5', '2019-07-16 14:28:36', '2019-07-16 14:28:36', '#!/bin/bash', '', 'kps1gf', 'Done'),
	('dx6w9qxxujb3', 'omop8l', '2019-07-16 14:28:38', '2019-07-16 14:28:48', '#!/bin/bash\nsleep 10s', '', 'kps1gf', 'Done'),
	('n0ft92cb38b', 'kuxiy1ax12m858vuoeps', '2019-07-16 14:28:22', '2019-07-16 14:28:48', 'nhi96d-hht7r;qp820f-ICD7t;rh1u8q-Xh2j8;rpnhlg-bVSvc;wsxeps-N8Rwj;spz3b5-xn1QB;omop8l-EAFYQ;', 'xm1ymrs9nq54;bv59fte14s21;kw9kn8dzx50q;fpqb0j99w25v;keiu2m929158;lx9q8cpftqsy;dx6w9qxxujb3;', 'kps1gf;', NULL),
	('28baqsz1f8ek', 'aikfaz', '2019-07-16 16:41:23', '2019-07-17 10:13:37', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nos.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152\nos.environ["CUDA_VISIBLE_DEVICES"] = ""\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'logfile', 'kps1gf', 'Failed'),
	('a05db0jr25ms', 'a652kg', '2019-07-17 18:05:14', '2019-07-17 18:05:16', '# Write first python in Geoweaver\necho "this is test for year 2019"', '  File "python-a05db0jr25ms.py", line 2\n    echo "this is test for year 2019"\n                                    ^\nSyntaxError: invalid syntax\n', 'spvy8u', 'Done'),
	('oa7yg7rzcl4w', 'a652kg', '2019-07-17 18:06:35', '2019-07-17 18:06:36', '# Write first python in Geoweaver\nprint("this is test for year 2019")', 'this is test for year 2019\n', 'spvy8u', 'Done'),
	('5zgzxuydxtkl', 'wcyu4q', '2019-07-17 18:36:46', '2019-07-17 18:36:48', '# Write first python in Geoweaver\nprint("oceanography example script")', 'oceanography example script\n', 'ngn7gx', 'Done'),
	('z38gnvmb0g2d', 'fz04z1', '2019-07-17 19:22:23', '2019-07-17 20:09:09', '#!/bin/bash\n#write your bash script\nscp zsun@192.168.1.1:/home/zsun/data-to-move/* /home/newserver/folder/\n', 'The authenticity of host \'192.168.1.1 (192.168.1.1)\' can\'t be established.\nECDSA key fingerprint is SHA256:t0fqn4EizvZ1DB8hf1bMw/vD9FAHoiTA6Km+q8TSm28.\n', 'ngn7gx', 'Failed');
/*!40000 ALTER TABLE `history` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.hosts
DROP TABLE IF EXISTS `hosts`;
CREATE TABLE IF NOT EXISTS `hosts` (
  `id` varchar(50) NOT NULL,
  `name` varchar(50) NOT NULL,
  `ip` varchar(50) NOT NULL,
  `port` smallint(6) NOT NULL,
  `user` varchar(50) NOT NULL,
  `owner` varchar(50) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='Host managed by CyberConnector';

-- Dumping data for table cyberconnector.hosts: ~7 rows (approximately)
DELETE FROM `hosts`;
/*!40000 ALTER TABLE `hosts` DISABLE KEYS */;
INSERT INTO `hosts` (`id`, `name`, `ip`, `port`, `user`, `owner`) VALUES
	('kps1gf', 'GeoBrain', '129.174.131.229', 22, 'zsun', 'null'),
	('v1xysy', 'LocalHost', '127.0.0.1', 22, 'zsun', 'null'),
	('43rbn7', 'Google Earth Engine', '123.23.12.0', 22, 'zsun', 'null'),
	('rl15z2', 'Amazon EC2 VM', '112.33.1.1', 22, 'zsun', 'null'),
	('8zlfux', 'Pangeo-Jupyter-Server1', '2.2.2.2', 22, 'zsun', 'null'),
	('spvy8u', 'TestESIP', '129.174.131.229', 22, 'zsun', 'null'),
	('ngn7gx', 'TestESIP2', '129.174.131.229', 22, 'zsun', 'null');
/*!40000 ALTER TABLE `hosts` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.orders
DROP TABLE IF EXISTS `orders`;
CREATE TABLE IF NOT EXISTS `orders` (
  `orderid` varchar(50) NOT NULL,
  `product` varchar(50) NOT NULL,
  `ordertime` datetime NOT NULL,
  `updatetime` datetime NOT NULL,
  `project` varchar(50) DEFAULT NULL,
  `userid` int(10) DEFAULT NULL,
  `east` double(20,6) DEFAULT NULL,
  `south` double(20,6) DEFAULT NULL,
  `west` double(20,6) DEFAULT NULL,
  `north` double(20,6) DEFAULT NULL,
  `email` tinytext NOT NULL,
  `begintime` datetime DEFAULT NULL,
  `endtime` datetime DEFAULT NULL,
  `status` enum('Running','Ready','Done','Failed') NOT NULL,
  `message` text NOT NULL,
  `parametermap` text,
  UNIQUE KEY `orderid` (`orderid`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='This table stores the user orders.';

-- Dumping data for table cyberconnector.orders: ~120 rows (approximately)
DELETE FROM `orders`;
/*!40000 ALTER TABLE `orders` DISABLE KEYS */;
INSERT INTO `orders` (`orderid`, `product`, `ordertime`, `updatetime`, `project`, `userid`, `east`, `south`, `west`, `north`, `email`, `begintime`, `endtime`, `status`, `message`, `parametermap`) VALUES
	('07k39gqypmwy0q581k', 'temperature and salinity condition data', '2015-11-18 14:46:35', '2015-11-18 14:47:03', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2010;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,14;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,013;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('0fslvm55zmz7totu1c', 'wind forcing condition data', '2015-10-18 00:56:16', '2015-10-18 00:59:17', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,09;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,09;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,09;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('0gu7z9c28u2alkbdfj', 'temperature and salinity condition data', '2015-11-18 14:50:05', '2015-11-18 14:50:33', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2010;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,14;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,013;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('0j0qpcn0x05dhij77t', 'temperature and salinity condition data', '2015-11-10 10:02:24', '2015-11-10 10:02:29', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,01;email,zsun@gmu.edu;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,094;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('0mclrxbuks2yg7anep', 'river boundary condition data', '2015-10-16 23:52:00', '2015-10-16 23:55:12', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2012;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2013'),
	('0mimulzekne27bz5so', 'wind forcing condition data', '2015-10-26 17:07:20', '2015-10-26 17:07:21', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,28;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('0sywlo7n9aumkidgtv', '16 days 250m global customizable VCI', '2015-09-01 10:26:10', '2015-09-01 10:26:18', 'WGS84', 1, -77.432156, 37.944198, -77.607937, 38.074041, 'szhwhu@gmail.com', '2015-08-05 00:00:00', '2015-08-20 00:00:00', 'Done', 'The order is finished. ', NULL),
	('0w7bor0twk6qawudrg', '16 days 250m global customizable VCI', '2015-08-31 11:28:06', '2015-08-31 11:28:12', 'WGS84', 1, -77.259979, 36.173357, -79.281464, 38.203655, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('103ikkllawyvuqz4lg', 'river boundary condition data', '2015-10-16 03:27:04', '2015-10-16 03:27:04', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('1pa6km1ctqyc2cl07x', '16 days 250m global customizable VCI', '2015-09-01 18:11:47', '2015-09-01 18:12:14', 'WGS84', 1, -77.435760, 37.579413, -78.402557, 39.300299, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('1tlffbqi4hkooc6h21', 'river boundary condition data', '2015-10-17 11:37:11', '2015-10-17 11:37:11', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Ready', 'A new order is placed.', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('1xemyptnghl6x41pw0', 'river boundary condition data', '2015-10-16 04:09:05', '2015-10-16 04:09:05', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('21jd1o0sqa164uavpg', '16 days 250m global customizable VCI', '2015-08-31 11:18:54', '2015-08-31 11:19:09', 'WGS84', 1, -76.293182, 37.230328, -78.402557, 38.479395, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('2cd57tqvvm0lawv3i2', 'river boundary condition data', '2015-10-16 03:19:47', '2015-10-16 03:19:47', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', 'productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2009;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662-0/year,2010'),
	('2j7cx5hevdxdg54542', '16 days 250m global customizable VCI', '2015-09-10 14:53:19', '2015-09-10 14:57:49', 'EPSG:4326', NULL, -78.563747, 38.548165, -79.069118, 38.933776, 'szhwhu@gmail.com', '2014-09-01 00:00:00', '2014-09-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('2rxwpvtzm9pifq139b', '16 days 250m global customizable VCI', '2015-08-31 11:25:16', '2015-08-31 11:25:21', 'WGS84', 1, -76.996307, 37.090240, -79.633026, 38.341656, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('350t83zbi6h9nnh04l', 'river boundary condition data', '2015-10-16 18:06:18', '2015-10-16 18:08:16', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('3crzthky6c1n9k9nv0', 'river boundary condition data', '2015-10-17 11:50:33', '2015-10-17 11:52:42', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('3qgsibngjsba8lcgqf', 'river boundary condition data', '2015-10-16 03:17:43', '2015-10-16 03:17:43', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', 'productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2009;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662-0/year,2010'),
	('3yn6xoruv86g6zlet4', 'wind forcing condition data', '2015-11-20 18:24:09', '2015-11-20 20:28:18', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2015-11-20 18:24:09', '2015-11-20 20:28:18', 'Done', 'The order is finished. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,28;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2011;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2011;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('41uk1h7izxbvevb595', 'river boundary condition data', '2015-10-16 17:59:02', '2015-10-16 17:59:03', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('41y9dcan33tn6y1mpa', '16 days 250m global customizable VCI', '2015-08-14 17:53:03', '2015-08-14 17:53:05', 'WGS84', 1, -77.163849, 37.020098, -78.482208, 37.996163, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-13 00:00:00', 'Failed', 'Fail to instantiate the abstract model into an executable workflow.\nSorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:com.lpm.LPMException:LPMException: faultCode=CONFIGURATION_ERROR ', NULL),
	('4268wq88wmhnx8kzpx', 'DownloadECMWFDatasets', '2017-03-27 15:02:22', '2017-03-27 15:08:18', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-27 15:02:22', '2017-03-27 15:08:18', 'Done', 'The order is finished. ', 'termination,;cron,    ;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-01;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('48btmmwxx72y38qne5', 'temperature and salinity condition data', '2015-11-17 09:57:54', '2015-11-17 19:42:47', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,03;email,szhwhu@gmail.com;productid,iqm44atsu71ximwas0dv3w88ua4pcf;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,096'),
	('52t5jn8mju1eodpf9r', 'wind forcing condition data', '2015-10-18 00:21:01', '2015-10-18 00:21:05', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,05;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2015;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,10;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2015;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,10;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('5fcejsqo6zzkly0cdi', 'CRM_array_averaged_analysis_model', '2017-03-29 15:43:12', '2017-03-29 15:46:30', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-29 15:43:12', '2017-03-29 15:46:30', 'Done', 'The order is finished. ', 'termination,2 3;cron,* * * * *;email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;userid,3;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/nsa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('5n4z0wr02hxtwbtbts', '16 days 250m global customizable VCI', '2015-09-01 11:04:57', '2015-09-01 11:05:04', 'WGS84', 1, -77.352118, 38.916682, -77.418036, 38.953001, 'szhwhu@gmail.com', '2015-08-05 00:00:00', '2015-08-20 00:00:00', 'Done', 'The order is finished. ', NULL),
	('62jipkihha5kiky7lb', 'temperature and salinity condition data', '2015-10-17 21:40:24', '2015-10-17 21:40:25', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Running', 'The order starts to be processed. ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,19;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('6aah8p1dm8k2x34zhd', '16 days 250m global customizable VCI', '2015-08-31 11:44:10', '2015-08-31 11:47:23', 'WGS84', 1, -77.301865, 37.090240, -79.015732, 37.892196, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('6cakh78puenzqok6ze', 'river boundary condition data', '2015-10-16 16:38:36', '2015-10-16 16:38:36', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('6jam49l73gpcpx8vk9', 'wind forcing condition data', '2015-10-27 17:56:38', '2015-10-27 17:56:39', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,01;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,03;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('6lz1px9hdjxqkmtbuu', 'temperature and salinity condition data', '2015-11-18 11:50:31', '2015-11-18 11:50:59', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2010;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,14;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,013;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('6yo15fl0p1ipcsuh7c', 'temperature and salinity condition data', '2015-10-17 21:42:22', '2015-10-17 21:43:29', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,03;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,093;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('72p3gosliad5g3dvsc', '16 days 250m global customizable VCI', '2015-09-01 11:09:57', '2015-09-01 11:16:45', 'WGS84', 1, -77.787323, 37.370157, -78.842010, 38.479395, 'szhwhu@gmail.com', '2014-09-01 00:00:00', '2014-09-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('731k5watc9zmidljpz', 'wind forcing condition data', '2015-10-26 17:01:49', '2015-10-26 17:01:51', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,28;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('7ac94c44me7j2j0on5', 'DownloadECMWFDatasets', '2017-03-27 16:16:49', '2017-03-27 16:24:38', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-27 16:16:49', '2017-03-27 16:24:38', 'Done', 'The order is finished. ', 'termination,2 1;cron,* * * * *;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-01;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('7hbxqek3pnp13gpq2l', 'river boundary condition data', '2015-10-25 18:11:34', '2015-10-25 18:13:18', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2011;email,szhwhu@gmail.com;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2012'),
	('7v95ans2siyjcfnag3', 'CRM_array_averaged_analysis_model', '2017-03-29 15:55:20', '2017-03-29 15:57:30', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-29 15:55:20', '2017-03-29 15:57:30', 'Done', 'The order is finished. ', 'termination,2 4;cron,* * * * *;email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;userid,3;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/nsa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('7we2r67kt0yn0wc53h', 'DownloadECMWFDatasets', '2017-02-22 17:30:49', '2017-02-22 17:31:18', NULL, 1, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-02-22 17:30:49', '2017-02-22 17:31:18', 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-01;userid,1;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('82sklh42diydsb9u85', 'temperature and salinity condition data', '2015-10-17 21:45:28', '2015-10-17 21:45:29', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Running', 'The order starts to be processed. ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,21;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('8c3hzml1l6q5m96oo3', 'CRM_array_averaged_analysis_model', '2017-02-21 09:47:41', '2017-02-21 09:48:13', NULL, 1, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-02-21 09:47:41', '2017-02-21 09:48:13', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;userid,1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/nsa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('90dk3e1feoif8hv5ye', 'river boundary condition data', '2017-02-20 17:44:18', '2017-02-20 17:44:34', NULL, 0, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2017-02-20 17:44:18', '2017-02-20 17:44:34', 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010;userid,0'),
	('9mheq94xr5a3dsvp7b', 'wind forcing condition data', '2015-10-18 00:39:16', '2015-10-18 00:42:16', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,09;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,09;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,09;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('9u6c2o59wym0xx0r9y', 'river boundary condition data', '2015-10-16 23:56:16', '2015-10-16 23:57:35', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2013;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2014'),
	('9uggjfyr5by4t9rmbs', '16 days 250m global customizable VCI', '2015-08-14 17:44:49', '2015-08-14 17:44:50', 'WGS84', 1, -77.251740, 36.527295, -79.449005, 37.996163, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-13 00:00:00', 'Failed', 'Fail to instantiate the abstract model into an executable workflow.\nSorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:com.lpm.LPMException:LPMException: faultCode=CONFIGURATION_ERROR ', NULL),
	('9v1n3iix9lyq11bkwv', 'river boundary condition data', '2015-10-16 18:03:49', '2015-10-16 18:05:32', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2011;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2012'),
	('a0t84ud5r9jxvtxwxv', 'wind forcing condition data', '2015-10-25 18:11:16', '2015-10-25 18:11:16', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Running', 'The order starts to be processed. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,28;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('a2295pmktt2nvpjolv', '16 days 250m global customizable VCI', '2015-09-02 03:08:13', '2015-09-02 03:08:52', 'WGS84', 1, -77.563992, 38.873929, -77.739773, 39.027719, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('a3hm34kyglkcxzltsg', '16 days 250m global customizable VCI', '2015-08-17 17:12:28', '2015-08-17 17:12:31', 'WGS84', 1, -77.875489, 36.738884, -80.160645, 38.479395, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-10 00:00:00', 'Failed', 'Fail to instantiate the abstract model into an executable workflow.\nSorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:com.lpm.LPMException:LPMException: faultCode=CONFIGURATION_ERROR ', NULL),
	('ae1p8yc4i8wpvgysas', '16 days 250m global customizable VCI', '2015-08-21 11:18:56', '2015-08-21 11:19:05', 'WGS84', 1, -77.699432, 36.738884, -79.457245, 38.616870, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-12 00:00:00', 'Failed', 'Fail to instantiate the abstract model into an executable workflow.\nSorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:com.lpm.LPMException:LPMException: faultCode=CONFIGURATION_ERROR ', NULL),
	('b3iuio4ks6h7r6ryg5', 'temperature and salinity condition data', '2016-06-28 14:47:16', '2016-06-28 14:47:41', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-28 14:47:16', '2016-06-28 14:47:41', 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.RuntimeException:Fail to read logic process from the xml string.javax.xml.bind.UnmarshalException:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,19;email,zsun@gmu.edu;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('bks9mn8yya09bpe33h', '16 days 250m global customizable VCI', '2015-09-02 15:07:46', '2015-09-02 15:09:01', 'EPSG:4326', 1, -77.509060, 38.916682, -77.871609, 39.172659, 'szhwhu@gmail.com', '2015-08-03 00:00:00', '2015-08-18 00:00:00', 'Done', 'The order is finished. ', NULL),
	('c5ych188ooj7wyh34g', 'wind forcing condition data', '2015-10-27 17:50:15', '2015-10-27 17:50:17', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,01;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,03;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('cq61kzwl45shvj8wd0', 'DownloadECMWFDatasets', '2017-03-20 11:27:25', '2017-03-20 11:29:40', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-20 11:27:25', '2017-03-20 11:29:40', 'Done', 'The order is finished. ', '/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-30;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('cykf4p6iqjz7ihkuri', 'ImageObjectPreprocessing', '2016-07-04 17:22:34', '2016-07-04 17:22:57', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-07-04 17:22:34', '2016-07-04 17:22:57', 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/ImageObjectPreprocessingRequest/RequestRaster_RGB2SingleValueService_3d6787e0-24e5-1034-908b-3155c0a80006_0/imgURL,http://129.174.131.8:9006/GeoprocessingWS/temp/da15b49d-bf57-41cc-afa7-d873c6d94fd7/cfpp_clipped.fusion.tif;email,zsun@gmu.edu;productid,9cb0aa3nms58torire0dbk87t2mkry;/ImageObjectPreprocessingRequest/RequestRaster_RGB2SingleValueService_3d6787e0-24e5-1034-908b-3155c0a80006_0/returnformat,GeoTiff;/ImageObjectPreprocessingRequest/RequestRaster_R2VService_40a8a920-24e5-1034-93a1-ec35c0a80006_1/returnformat,ESRI Shapefile'),
	('dj8rllxkl7hvfx3yrz', 'YearsDailyNDVIModel', '2017-04-03 16:50:26', '2017-04-03 16:51:03', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-04-03 16:50:26', '2017-04-03 16:51:03', 'Done', 'The order is finished. ', 'termination,;/YearsDailyNDVIModelRequest/RequestNDVICalWorkflow_87a05ab0-af49-1033-9974-546381aea662_0/bbox,2.0949554443358807,32.626942456513845,2.1924591064452557,32.66307841506968;cron,    ;email,szhwhu@gmail.com;productid,iwvsnr3oxhxfg8p0yzzeflmk7pedr5;/YearsDailyNDVIModelRequest/RequestNDVICalWorkflow_87a05ab0-af49-1033-9974-546381aea662_0/day,1;userid,3;/YearsDailyNDVIModelRequest/RequestNDVICalWorkflow_87a05ab0-af49-1033-9974-546381aea662_0/years,2015'),
	('ekdnz5zey4h9hikqfy', 'temperature and salinity condition data', '2016-06-28 14:47:46', '2016-06-28 14:47:48', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-28 14:47:46', '2016-06-28 14:47:48', 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.RuntimeException:Fail to read logic process from the xml string.javax.xml.bind.UnmarshalException:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,19;email,zsun@gmu.edu;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('ewgxm7bb1yfj8xpogp', 'temperature and salinity condition data', '2016-06-28 15:11:14', '2016-06-28 15:32:14', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-28 15:11:14', '2016-06-28 15:32:14', 'Failed', 'com.sun.xml.internal.messaging.saaj.SOAPExceptionImplcom.sun.xml.internal.messaging.saaj.SOAPExceptionImpl: Bad response: (503Service Temporarily Unavailable ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,19;email,zsun@gmu.edu;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('ewnoeqqgip14lbwazq', 'wind forcing condition data', '2015-10-18 00:24:51', '2015-10-18 00:24:52', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Running', 'The order starts to be processed. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,10;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,05;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2015;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,10;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2015;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,10;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('fe9wwpch4x9v8wywku', 'wind forcing condition data', '2015-10-27 17:55:39', '2015-10-27 17:55:41', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,01;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,03;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('fjdec3vs8qytfb7j0p', '16 days 250m global customizable VCI', '2015-09-01 10:18:26', '2015-09-01 10:18:36', 'WGS84', 1, -77.355251, 37.474858, -77.618923, 37.657732, 'szhwhu@gmail.com', '2015-08-30 00:00:00', '2015-09-14 00:00:00', 'Done', 'The order is finished. ', NULL),
	('fovhrj35enx9ublmx8', 'wind forcing condition data', '2015-10-27 18:16:10', '2015-10-27 18:21:13', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Cannt send messages to http://www3.csiss.gmu.edu/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 502 for URL: http://www3.csiss.gmu.edu/WorkflowCore/IQuery ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,06;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,06;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('gltwfq7fzxi2goyiep', '16 days 250m global customizable VCI', '2015-09-01 21:38:22', '2015-09-01 21:38:23', 'WGS84', 1, -77.717800, 38.771216, -77.926540, 38.916682, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Running', 'The order starts to be processed. ', NULL),
	('h2zwrdpa9c54y5da0k', 'river boundary condition data', '2015-10-16 23:39:45', '2015-10-16 23:41:48', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('h5airxvbodiuhhg3ug', 'temperature and salinity condition data', '2015-11-16 17:15:50', '2015-11-17 10:10:53', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,20;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('hl0yqildqp55jrhomj', 'DownloadECMWFDatasets', '2017-03-27 15:51:24', '2017-03-27 15:59:38', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-27 15:51:24', '2017-03-27 15:59:38', 'Done', 'The order is finished. ', 'termination,2 3;cron,* * * * *;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-01;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('hmwe9s7maqqhm5g1ym', 'river boundary condition data', '2015-10-16 03:24:05', '2015-10-16 03:24:05', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662-0/year,2010'),
	('hs8gma5646mzp46yjw', 'CRM_array_averaged_analysis_model', '2017-02-21 15:35:48', '2017-02-21 15:36:20', NULL, 1, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-02-21 15:35:48', '2017-02-21 15:36:20', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;userid,1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/nsa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('hxnpre6038jb0v3f02', 'river boundary condition data', '2016-06-30 11:42:58', '2016-06-30 11:43:13', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-30 11:42:58', '2016-06-30 11:43:13', 'Failed', 'Cannt send messages to http://localhost:8080/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 500 for URL: http://localhost:8080/WorkflowCore/IQuery ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('i2ue99xzul2ylm3dor', '16 days 250m global customizable VCI', '2015-08-31 11:31:43', '2015-08-31 11:32:03', 'WGS84', 1, -77.084198, 36.949892, -80.160370, 38.479395, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('i3j5kip661pzugpd19', 'river boundary condition data', '2016-06-28 16:03:47', '2016-06-28 16:05:19', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-28 16:03:47', '2016-06-28 16:05:19', 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('jf1dzsfwpdsqcb8mmk', 'wind forcing condition data', '2015-10-23 21:41:30', '2015-10-23 21:45:48', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,09;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,09;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,09;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('jfy324eyaahew3x591', 'CRM_array_averaged_analysis_model', '2015-11-23 16:25:57', '2015-11-23 16:26:02', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2015-11-23 16:25:57', '2015-11-23 16:26:02', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/ssa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('ji5ccra6zmjx6soqxo', 'river boundary condition data', '2015-10-18 01:19:37', '2015-10-18 01:21:36', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,szhwhu@gmail.com;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('jo0p90h0cote4io9sz', 'temperature and salinity condition data', '2015-10-17 17:34:29', '2015-10-17 17:35:37', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,19;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('kbehm804ov72wuk6lo', 'river boundary condition data', '2015-10-16 14:50:49', '2015-10-16 14:50:49', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('kkw9vsh7dani6e7cl5', '16 days 250m global customizable VCI', '2015-09-02 15:44:53', '2015-09-02 15:46:13', 'EPSG:4326', NULL, -77.717800, 39.257778, -77.904568, 39.385264, 'szhwhu@gmail.com', '2015-08-06 00:00:00', '2015-08-21 00:00:00', 'Done', 'The order is finished. ', NULL),
	('kpj6b4u09spdv52zcz', 'wind forcing condition data', '2015-10-26 16:27:37', '2015-10-26 16:27:38', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,szhwhu@gmail.com;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,28;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('l2f5p00kek56x1y7dq', 'wind forcing condition data', '2015-10-28 10:04:13', '2015-10-28 10:09:15', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Cannt send messages to http://www3.csiss.gmu.edu/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 502 for URL: http://www3.csiss.gmu.edu/WorkflowCore/IQuery ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,06;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,8;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('lunipd71l92ekz8279', 'river boundary condition data', '2016-06-30 11:46:29', '2016-06-30 11:46:43', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-30 11:46:29', '2016-06-30 11:46:43', 'Failed', 'Cannt send messages to http://localhost:8080/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 500 for URL: http://localhost:8080/WorkflowCore/IQuery ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('m4et3sasp0y0o8ei7u', '16 days 250m global customizable VCI', '2015-09-01 21:37:25', '2015-09-01 21:37:25', 'WGS84', 1, -77.435760, 38.065392, -78.050995, 38.685510, 'szhwhu@gmail.com', '2015-07-01 00:00:00', '2015-07-16 00:00:00', 'Running', 'The order starts to be processed. ', NULL),
	('ma8g7hwm9hamuxxlpg', 'river boundary condition data', '2015-10-16 12:17:58', '2015-10-16 12:17:58', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('mv81w6fnqj3i3tjsds', 'wind forcing condition data', '2015-10-27 18:06:04', '2015-10-27 18:11:08', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Cannt send messages to http://www3.csiss.gmu.edu/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 502 for URL: http://www3.csiss.gmu.edu/WorkflowCore/IQuery ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,01;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,03;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('ncsliqnlf6jai6l8rd', 'wind forcing condition data', '2015-10-28 09:55:27', '2015-10-28 10:00:30', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Cannt send messages to http://www3.csiss.gmu.edu/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 502 for URL: http://www3.csiss.gmu.edu/WorkflowCore/IQuery ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,06;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,10;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('newh8wdqxxf6z7jvj4', 'river boundary condition data', '2015-10-16 16:00:54', '2015-10-16 16:00:54', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('nrhropgf8k9cirb35s', 'river boundary condition data', '2015-10-19 14:27:46', '2015-10-19 14:28:56', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2013;email,szhwhu@gmail.com;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2014'),
	('o5h1cxnov2j92obuov', '16 days 250m global customizable VCI', '2015-09-01 10:22:09', '2015-09-01 10:22:16', 'WGS84', 1, -77.904568, 37.256566, -78.102322, 37.396346, 'szhwhu@gmail.com', '2015-07-01 00:00:00', '2015-07-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('o5nsh4qxgsjq9b9pl6', 'wind forcing condition data', '2015-10-27 16:46:15', '2015-10-27 16:46:17', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,02;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,13;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,02;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('ptrbvbehicnidf35g4', 'river boundary condition data', '2015-10-18 00:42:32', '2015-10-18 00:44:37', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,szhwhu@gmail.com;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('q29ld5e6ogzxa0epwa', '16 days 250m global customizable VCI', '2015-09-01 11:24:02', '2015-09-01 11:25:00', 'WGS84', 1, -77.662868, 38.719805, -77.904568, 38.950865, 'szhwhu@gmail.com', '2014-09-01 00:00:00', '2014-09-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('q8c6tw24yhzm4fov44', 'river boundary condition data', '2016-06-30 11:20:37', '2016-06-30 11:20:50', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-30 11:20:37', '2016-06-30 11:20:50', 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('qttrg5nggkbofmoqf2', '16 days 250m global customizable VCI', '2015-08-31 11:30:39', '2015-08-31 11:31:01', 'WGS84', 1, -76.820526, 36.315125, -79.808807, 37.926868, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('r6vea4s63q3tf5wmka', 'river boundary condition data', '2016-06-30 14:28:04', '2016-06-30 14:28:16', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-30 14:28:04', '2016-06-30 14:28:16', 'Failed', 'Cannt send messages to http://localhost:8080/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 500 for URL: http://localhost:8080/WorkflowCore/IQuery ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('rhlcuom7ycy02nw5oa', 'DownloadECMWFDatasets', '2017-03-27 15:17:22', '2017-03-27 15:24:38', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-27 15:17:22', '2017-03-27 15:24:38', 'Done', 'The order is finished. ', 'termination,2 2;cron,* * * * *;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-01;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('rhx6f3tws1eo5hz33v', 'wind forcing condition data', '2015-10-28 15:00:49', '2015-10-28 15:13:24', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,11;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,01;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,15;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('svqq1vjkqukww7aciv', 'temperature and salinity condition data', '2015-11-18 14:39:11', '2015-11-18 14:39:44', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2010;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,14;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,013;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('t1j28pq3c5u28zxqp1', 'river boundary condition data', '2015-10-16 04:19:31', '2015-10-16 04:19:31', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('tbz5y5uidjrge9iivd', 'wind forcing condition data', '2015-10-28 15:15:11', '2015-10-29 15:23:54', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'ERR.java.lang.RuntimeException:Fail to read document from string:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,11;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,03;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,31;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2014;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,03;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,true'),
	('tigc9xlhh2zf4knlh8', 'DownloadECMWFDatasets', '2017-02-23 17:35:22', '2017-02-23 17:48:20', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2017-02-23 17:35:22', '2017-02-23 17:48:20', 'Done', 'The order is finished. ', '/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,zsun@gmu.edu;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-30;userid,1;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('tnq4fykea19t5tt4ol', 'null', '2015-11-23 15:58:12', '2015-11-23 15:58:14', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2015-11-23 15:58:12', '2015-11-23 15:58:14', 'Failed', 'No such an abstract model with the inputted identifier. ', 'email,szhwhu@gmail.com;productid,urn:uuid:beb9d320-7531-1033-ac74-df4e81aea662;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/ssa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('uowi5541e2nz1mktu1', 'DownloadECMWFDatasets', '2017-03-29 11:57:43', '2017-03-29 12:01:26', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-29 11:57:43', '2017-03-29 12:01:26', 'Done', 'The order is finished. ', 'termination,1 2017-03-29 12:00:02;cron,* * * * *;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-31;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('uw0pdn9nhu44i1967v', 'river boundary condition data', '2015-10-16 03:14:59', '2015-10-16 03:14:59', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', 'productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2009;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662-0/year,2010'),
	('uyg9enz4rmep1z6ulm', 'CRM_array_averaged_analysis_model', '2015-11-23 16:22:10', '2015-11-23 16:22:15', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2015-11-23 16:22:10', '2015-11-23 16:22:15', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/ssa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('v48250u94ngitbxy4p', 'temperature and salinity condition data', '2016-06-28 11:14:38', '2016-06-28 11:14:51', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-28 11:14:38', '2016-06-28 11:14:51', 'Failed', 'Cannt send messages to http://localhost:8080/VDP/InstantiationServlet. Reason: http://localhost:8080/VDP/InstantiationServlet ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2009;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,19;email,zsun@gmu.edu;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,091;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('v51nwktk1nenpydo9c', 'river boundary condition data', '2015-10-16 17:09:42', '2015-10-16 17:09:42', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('v7qrw3ebqlh9uxn36g', 'river boundary condition data', '2016-07-01 12:10:55', '2016-07-01 12:15:31', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-07-01 12:10:55', '2016-07-01 12:15:31', 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('vd6stcw6akoxvhfdp9', '16 days 250m global customizable VCI', '2015-09-01 21:45:13', '2015-09-01 21:46:35', 'WGS84', 1, -77.432156, 39.027719, -77.585964, 39.164141, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('vi6ddmccks6ijarya4', 'river boundary condition data', '2015-10-17 00:16:31', '2015-10-17 00:18:36', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Done', 'The order is finished. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2011;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2012'),
	('vt609vt4p46ic0ekzf', 'wind forcing condition data', '2015-10-27 17:58:30', '2015-10-27 17:58:31', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Failed', 'Fail to instantiate the abstract model into an executable workflow.Sorry, exception happens. java.lang.RuntimeException:Fail to instantiate the logic process and message type into a BPEL workflow. Reason:java.lang.NullPointerException:null ', '/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_0aa8cfa0-5865-1033-8e09-20acc0a80002_2/month_end,01;email,zsun@gmu.edu;productid,823q83eltkardidwgbn3c6cvfmsg07;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/day_end,03;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_end,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_start,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/year_start,2013;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/month_end,01;/wind_forcing_fvcom_inputRequest/RequestFVCOMService_03e23120-5865-1033-a7b1-002bc0a80002_0/full_month,false'),
	('ww4v9ii91zjdu2db2r', 'DownloadECMWFDatasets', '2017-03-27 15:39:23', '2017-03-27 15:46:38', NULL, 3, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-03-27 15:39:23', '2017-03-27 15:46:38', 'Done', 'The order is finished. ', 'termination,2 2;cron,* * * * *;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,201.128/202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-01;userid,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3/6/9/12;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,00:00:00/12:00:00'),
	('x3mn93crskyvyt44od', 'river boundary condition data', '2016-06-30 14:32:32', '2016-06-30 14:32:35', NULL, 1, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', '2016-06-30 14:32:32', '2016-06-30 14:32:35', 'Failed', 'Cannt send messages to http://localhost:8080/WorkflowCore/IQuery. Reason: Server returned HTTP response code: 500 for URL: http://localhost:8080/WorkflowCore/IQuery ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('x4m95jtk658dntudvb', 'null', '2015-11-23 15:56:15', '2015-11-23 15:56:16', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2015-11-23 15:56:15', '2015-11-23 15:56:16', 'Failed', 'No such an abstract model with the inputted identifier. ', 'email,szhwhu@gmail.com;productid,urn:uuid:beb9d320-7531-1033-ac74-df4e81aea662;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/ssa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('x6wl3lsqi4eubjs0t2', 'DownloadECMWFDatasets', '2017-02-22 19:04:08', '2017-02-22 19:07:00', NULL, 1, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-02-22 19:04:08', '2017-02-22 19:07:00', 'Done', 'The order is finished. ', '/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/end_date,2016-12-31;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/parameters,202.128;email,szhwhu@gmail.com;productid,hl6tgckiv5k09lvsb4xf2gd79aa7kc;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/start_date,2016-12-30;userid,1;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/dataset,interim;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/step,3;/DownloadECMWFDatasetsRequest/RequestECMWFService_357414a0-dc6d-1034-b252-502c81aea649_0/time,12:00:00'),
	('x8wck7e4mrkyrh951u', 'CRM_array_averaged_analysis_model', '2015-11-23 16:01:32', '2015-11-23 16:01:46', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2015-11-23 16:01:32', '2015-11-23 16:01:46', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/ssa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('xec3onjiw4gwmr54n6', 'CRM_array_averaged_analysis_model', '2017-02-21 11:06:13', '2017-02-21 11:06:45', NULL, 1, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-02-21 11:06:13', '2017-02-21 11:06:45', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;userid,1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/nsa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('xnspb12kf4aavw1260', 'river boundary condition data', '2015-10-17 11:38:15', '2015-10-17 11:38:15', NULL, NULL, NULL, NULL, NULL, NULL, 'zsun@gmu.edu', NULL, NULL, 'Ready', 'A new order is placed.', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2010;email,zsun@gmu.edu;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2011'),
	('xr58nrkwnlipxfzo9m', 'CRM_array_averaged_analysis_model', '2017-02-21 12:10:57', '2017-02-21 12:11:30', NULL, 1, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', '2017-02-21 12:10:57', '2017-02-21 12:11:30', 'Done', 'The order is finished. ', 'email,szhwhu@gmail.com;productid,330j1mtkt6elfkud7anu2cnx9rrqrq;userid,1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/fieldDataURL,http://www3.csiss.gmu.edu/data/fields.lsan_v1;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_4a96a4b0-7530-1033-8d2c-713581aea662_2/fluxDataURL,http://www3.csiss.gmu.edu/data/nsa.dfluxes;/CRM_array_averaged_analysis_modelRequest/RequestCRMService_47106420-7530-1033-95db-c4cf81aea662_0/Q1Q2DataURL,http://www3.csiss.gmu.edu/data/q1q2.lsan_v1'),
	('ybgatxsy1x23qi5xnp', '16 days 250m global customizable VCI', '2015-08-13 19:03:48', '2015-08-13 19:03:51', 'WGS84', 1, -76.724396, 36.456636, -78.570099, 37.926868, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-12 00:00:00', 'Failed', 'Fail to instantiate the abstract model into an executable workflow. ', NULL),
	('ybnny8adv85fvua7ed', 'river boundary condition data', '2015-10-16 17:14:45', '2015-10-16 17:14:45', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2011;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2012'),
	('ydyybo2wm9ht3m0ndn', 'river boundary condition data', '2015-10-16 16:57:13', '2015-10-16 16:57:13', NULL, NULL, NULL, NULL, NULL, NULL, 'null', NULL, NULL, 'Running', 'The order starts to be processed. ', '/FVCOM_River_inputRequest/RequestFVCOMService_6da55650-56a8-1033-b499-2f0c81aea662_0/year,2009;productid,9t1o2kjwpkrgcvchxueutiiz1ftkvj;/FVCOM_River_inputRequest/RequestFVCOMService_6f027550-56a8-1033-8166-87a181aea662_0/year,2010'),
	('yn3v8tont303fduny7', '16 days 250m global customizable VCI', '2015-09-01 23:06:38', '2015-09-01 23:07:10', 'WGS84', 1, -76.996307, 37.996163, -78.314667, 38.959409, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('yrdsysp7h0gt8a2v8f', '16 days 250m global customizable VCI', '2015-09-01 21:39:42', '2015-09-01 21:42:53', 'WGS84', 1, -77.772732, 38.899583, -77.926540, 39.061849, 'szhwhu@gmail.com', '2015-08-01 00:00:00', '2015-08-16 00:00:00', 'Done', 'The order is finished. ', NULL),
	('zg6reii1f7vi6efwry', 'temperature and salinity condition data', '2015-11-18 14:56:03', '2015-11-19 00:40:56', NULL, NULL, NULL, NULL, NULL, NULL, 'szhwhu@gmail.com', NULL, NULL, 'Done', 'The order is finished. ', '/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/year,2010;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/hour,14;email,szhwhu@gmail.com;/T_S_condition_fvcom_inputRequest/RequestFVCOMService_af2b3850-581b-1033-80f8-4d06c0a80002_0/day,013;productid,iqm44atsu71ximwas0dv3w88ua4pcf'),
	('zis9by2dutk748wmw5', '16 days 250m global customizable VCI', '2015-09-01 15:16:16', '2015-09-01 15:17:36', 'WGS84', 1, -77.437391, 38.138877, -77.613173, 38.259750, 'szhwhu@gmail.com', '2014-09-03 00:00:00', '2014-09-18 00:00:00', 'Done', 'The order is finished. ', NULL);
/*!40000 ALTER TABLE `orders` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.process_type
DROP TABLE IF EXISTS `process_type`;
CREATE TABLE IF NOT EXISTS `process_type` (
  `id` varchar(50) NOT NULL,
  `name` varchar(50) NOT NULL,
  `code` longtext NOT NULL,
  `description` text,
  `inputs` text,
  `inputs_datatypes` varchar(200) DEFAULT NULL,
  `output` text,
  `output_datatype` varchar(100) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='This table stores all the usable logic process for modeling.';

-- Dumping data for table cyberconnector.process_type: ~121 rows (approximately)
DELETE FROM `process_type`;
/*!40000 ALTER TABLE `process_type` DISABLE KEYS */;
INSERT INTO `process_type` (`id`, `name`, `code`, `description`, `inputs`, `inputs_datatypes`, `output`, `output_datatype`) VALUES
	('0giu1h', 'ag_net_preparation', '#!/bin/bash\n\necho "start to prepare landsat into training dataset"\n\ncd /home/zsun/dl-cdl/bin/\n\ncdl_folder=../data/cdl-raw/\n\ncdl_projected_folder=../data/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\nfor entry in "$cdl_folder"/*cdls.img\ndo\n    echo "$entry"\n    filename=${entry##*/}\n    if [ ! -f  $cdl_projected_folder$filename"_32614.tif" ]; then\n\n        echo " gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff "$entry" "$cdl_projected_folder$filename"_32614.tif"\n    \n        gdalwarp -overwrite -t_srs EPSG:32614 -of GTiff $entry $cdl_projected_folder$filename"_32614.tif"\n    fi\ndone\n\n# unzip landsat\nlandsat_zip_folder=../data/landsat/\n\nlandsat_unzip_folder=../data/landsat-unzip/\n\ntileindex_folder=../data/tileindex/\n\ncut_cdl_folder=../data/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo      \n    echo "$entry"    \n    # get file name\n    filename=${entry##*/}\n    echo "get file name: "$filename\n\n    # get date\n\n    # LT050310272005080501T1-SC20180823155307.tar.gz\n    date=${filename:10:8}\n    echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n    unzipped=0\n\n    for band1 in "$landsat_unzip_folder"/*"$date"*band1*\n    do \n        echo "found band1 image: "$band1\n        unzipped=1\n    done\n\n    if [ $unzipped == 1 ] \n    then\n        echo "already unzipped"\n    else\n\n        echo "unzip "$entry\n            tar -zxvf $entry -C $landsat_unzip_folder\n    fi\ndone\n\nfor en in "$landsat_unzip_folder"/*band1*\ndo\n    echo "$en"\n    filename=${en##*/}\n    echo "get band name: "$filename\n    # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n    date=${filename:17:8}\n        echo "current date is: "$date\n        year=${date:0:4}\n        monthday=${date:4:4}\n\n    uncut=1\n\n        for band1 in "$cut_cdl_folder"/*"$date"*band1*\n        do\n                echo "found band1 image: "$band1\n                uncut=0\n        done\n\n    if [ $year -lt 2008 ] || [ $uncut == 0  ]\n        then\n                echo "there is no CDL fro this year or the scene has already been cutted, skipping"\n        else\n\n                echo "create tile boundary using tileindex"\n                shpfile=$tileindex_folder$filename".shp"\n                band1file=$en\n                gdaltindex -tileindex location $shpfile $band1file\n\n                echo "cut and resample CDL to fit the landsat scene"\n                cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n                gdalwarp -q -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_projected_folder""$year"_30m_cdls.img_32614.tif" $cutcdlfile\n\n        fi\ndone\n\necho "end the data preparation"\n', 'shell', NULL, NULL, NULL, NULL),
	('108', 'merge', 'merge_id', 'null', 'sourceURL;classlist', NULL, 'returnURL;returnFormat', NULL),
	('219', 'r2v', 'r2v_id', 'null', 'imgURL;returnformat', NULL, 'returnURL', NULL),
	('220', 'eliminate_smallpolygons', 'eliminate_smallpolygons_id', 'null', 'imgURL;returnformat', NULL, 'returnURL', NULL),
	('222', 'classify', 'classify_id', 'null', 'vectorURL;rasterURL;segURL;classhierarchy;featurespace;k;unclassfied;threshold', NULL, 'returnVURL', NULL),
	('223', 'rgb2singlevalue', 'rgb2singlevalue_id', 'null', 'imgURL;returnformat', NULL, 'returnURL', NULL),
	('224', 'segment', 'segment_id', 'null', 'imgURL;sigmaS;sigmaR;minRegion;speedUpLevel;speedUpThreshold;checkWeightMap;gradientWindow;blendVar;threshold;returnFormat;sigmaS2', NULL, 'filter_imgURL;fusion_imgURL;seg_imgURL;boundary_imgURL', NULL),
	('225', 'classify', 'classify_id', 'null', 'vectorURL;rasterURL;segURL;classhierarchy;featurespace;k;unclassfied;threshold', NULL, 'returnVURL', NULL),
	('229', 'Generate_River_USGS_links', 'Generate_River_USGS_links_id', 'null', 'year;stationid;parameterlist', NULL, 'river_originial_file_url', NULL),
	('230', 'interpolate_HYCOM_combine_to_FVCOM_grid', 'interpolate_HYCOM_combine_to_FVCOM_grid_id', 'null', 'hycom_combine_InputURL', NULL, 'inter_temperature_InputURL;inter_salinity_InputURL;inter_U_velocity_InputURL;inter_V_velocity_InputURL', NULL),
	('231', 'Generate_HYCOM_links', 'Generate_HYCOM_links_id', 'null', 'year;day;hour', NULL, 'hycom_combination_file_url', NULL),
	('232', 'Generate_Wind_FVCOM_Input', 'Generate_Wind_FVCOM_Input_id', 'null', 'interp_wind_vector_list;year_start;year_end;month_start;month_end;day_start;day_end', NULL, 'wind_wnd_fvcom_input_url;wind_hfx_fvcom_input_url', NULL),
	('233', 'Interpolate_NARR_Wind_Vector', 'Interpolate_NARR_Wind_Vector_id', 'null', 'nomads_txt_list;year_start;year_end;month_start;month_end;day_start;day_end', NULL, 'interpl_uv_file_list', NULL),
	('234', 'Pick_NARR_Wind_Vector', 'Pick_NARR_Wind_Vector_id', 'null', 'narr_txt_list;year_start;year_end;month_start;month_end;day_start;day_end;lat1;lon1;lat2;lon2', NULL, 'nomads_data_subset_list', NULL),
	('235', 'Downlad_NARR_TO_ASCII', 'Downlad_NARR_TO_ASCII_id', 'null', 'year_start;year_end;month_start;month_end;full_month;day_start;day_end', NULL, 'narr_grb_url_list;narr_txt_url_list', NULL),
	('236', 'Write_River_FVCOM_Input', 'Write_River_FVCOM_Input_id', 'null', 'Caern_file_URL;Atcha_file_URL;Missi_file_URL;Wax_file_URL', NULL, 'River_FVCOM_Input_URL', NULL),
	('237', 'GMT_Check', 'GMT_Check_id', 'null', 'GMT_file_URL;last_year_GMT_file_URL;rivername;year', NULL, 'GMT_DAT_URL;Report_DAT_URL;Check_DAT_URL;No_NAN_DAT_URL', NULL),
	('238', 'CDT_and_CST_to_GMT', 'CDT_and_CST_to_GMT_id', 'null', 'original_file_URL;rivername', NULL, 'returnURL', NULL),
	('239', 'interpolate_HYCOM_to_FVCOM_grid', 'interpolate_HYCOM_to_FVCOM_grid_id', 'null', 'temperature_InputURL;salinity_InputURL;U_velocity_InputURL;V_velocity_InputURL', NULL, 'inter_temperature_InputURL;inter_salinity_InputURL;inter_U_velocity_InputURL;inter_V_velocity_InputURL', NULL),
	('240', 'rewrite_to_FVCOM_input_format', 'rewrite_to_FVCOM_input_format_id', 'null', 'inter_temperature_InputURL;inter_salinity_InputURL;inter_U_velocity_InputURL;inter_V_velocity_InputURL', NULL, 'returnURL', NULL),
	('245', 'dynamo_reform1', 'dynamo_reform1_id', 'null', 'fieldDataURL;Q1Q2DataURL', NULL, 'dynamoForcingDataURL;dynamoQ1Q2DataURL', NULL),
	('246', 'dynamo_reform2', 'dynamo_reform2_id', 'null', 'fieldDataURL', NULL, 'surfaceDataURL;soundingDataURL', NULL),
	('247', 'get_sst_sflux_6hourly', 'get_sst_sflux_6hourly_id', 'null', 'fluxDataURL', NULL, 'surfaceFlux6HrsURI', NULL),
	('248', 'get_crm_input_dynamo', 'get_crm_input_dynamo_id', 'null', 'soundingDataURL;forcingDataURL;SSTLSHDataURL;surfaceDataURL', NULL, 'forcingProfilesDataURL;initalSoundingDataURL;thetaAndQVProfilesURL;timeseriesOfThetaAndQVDataURL;velocityProfileDataURL', NULL),
	('249', 'zip_crm_input', 'zip_crm_input_id', 'null', 'forcingProfilesDataURL;initalSoundingDataURL;thetaAndQVProfilesURL;timeseriesOfThetaAndQVDataURL;velocityProfileDataURL', NULL, 'crmInputPackage', NULL),
	('251', 'DrawDroughtTimeSeries', 'DrawDroughtTimeSeries_id', 'null', 'Op;fips_str;in_year;cropType', NULL, 'return', NULL),
	('252', 'DrawBarChart', 'DrawBarChart_id', 'null', 'Op;fips_str;in_year;in_day;cropType', NULL, 'return', NULL),
	('253', 'DrawTimeSeries', 'DrawTimeSeries_id', 'null', 'Op;fips_str;in_year;cropType', NULL, 'return', NULL),
	('4hf60x', 'call_nwis', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\\n","from suds.client import Client\\n","from pandas import Series\\n","import matplotlib.pyplot as plt\\n","import matplotlib.dates as mdates"]},{"cell_type":"markdown","metadata":{},"source":["#### Connect to website "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["now = datetime.datetime.now() # Use now function to get current time. \\n","now1 = now.strftime(\\"%Y-%m-%d %H:%M:%S\\")\\n","\\n","wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09315000\' # Can change to different site if desired.  Format: \'NWISUV:########\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = now1  # Can change to less recent date if desired. "]},{"cell_type":"markdown","metadata":{},"source":["#### Create a new object named NWIS for calling the web service "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["#### Call the GetValuesObject method to return the datavalues"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["#### Get the site name from the response "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName\\n","values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["#### Load called objects into a pandas series. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create blank lists in which to put the values and dates\\n","a = []  \\n","b = []\\n","\\n","# Loop through the values and load into the blank lists using append\\n","for v in values:\\n","    a.append(float(v.value))\\n","    b.append(v._dateTime)\\n","    \\n","# Set the index of the series object to the dates\\n","ts = Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["#### Resample data on daily interval with mean/min/max functions <br>\\n","#### create hourly max, min, and avg series "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create hourly max, min, and avg series \\n","hourlyTotDisAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","hourlyTotDisMax = ts.resample(rule=\'1D\', base=0).max()\\n","hourlyTotDisMin = ts.resample(rule=\'1D\', base=0).min()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot stuff\\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a figure object and add a subplot\\n","fig = plt.figure(figsize=(12,8))\\n","ax = fig.add_subplot(1, 1, 1)  # arguments for add_subplot - add_subplot(nrows, ncols, plot_number)\\n","\\n","# Call the plot() methods on the series object to plot the data\\n","ts.plot(color=\'grey\', linestyle=\'solid\', label=\'15-minute streamflow values\', alpha=0.5, linewidth=0.5)\\n","hourlyTotDisAvg.plot(color=\'green\', linestyle=\'solid\', label=\'Daily avg flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMax.plot(color=\'red\', linestyle=\'solid\', label=\'Daily max flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","hourlyTotDisMin.plot(color=\'blue\', linestyle=\'solid\', label=\'Daily min flows\',\\n","                     marker = \'o\', ms=2, linewidth =0.75)\\n","# Set some properties of the subplot to make it look nice\\n","ax.set_ylabel(\'Discharge, cubic feet per second\')\\n","ax.set_xlabel(\'Date (YYYY-MM-DD)\')\\n","ax.grid(True)\\n","ax.set_title(\'Daily Max, Min, & Avg Flows for: \' + siteName + \', \' + siteCode)\\n","ax.set_xlim(beginDate, endDate) #set limits with date variables\\n","# Add a legend with some customizations\\n","legend = ax.legend(loc=\'upper left\', shadow=True)\\n","fig.autofmt_xdate()  # use auto-formatter to enable accurate date representation with mouse\\n","ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # set ticks interval for every 15 days.\\n","\\n","# Create a frame around the legend.\\n","frame = legend.get_frame()\\n","frame.set_facecolor(\'0.95\')\\n","\\n","# Set the font size in the legend\\n","for label in legend.get_texts():\\n","    label.set_fontsize(\'large\')\\n","\\n","for label in legend.get_lines():\\n","    label.set_linewidth(1.5)  # the legend line width"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\'done!\')"]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', 'jupyter', NULL, NULL, NULL, NULL),
	('4ng18f', 'cdl-preprocessing', '#!/bin/bash\n#write your bash script\nbasedir=/home/zsun/data/\ngdalwarp -overwrite -t_srs EPSG:32614 -of GTiff D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38.tif D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif\ngdaltindex -tileindex location D:/workspace/ec-deep/data/cdl/tileindex/2015213/LC80310272015213LGN00.shp D:\\workspace\\ec-deep\\data\\cdl\\tileindex\\2015213/LC80310272015213LGN00_sr_band1.tif\ngdalwarp -q -cutline D:/workspace/ec-deep/data/cdl/tileindex/20110907/LT05_L1TP_031027_20110907_20160830_01_T1/LT05_L1TP_031027_20110907_20160830_01_T1.shp -crop_to_cutline -tr 30.0 30.0 -of GTiff D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_38_32614.tif D:/workspace/ec-deep/data/cdl/CDL_2011_38/CDL_2011_20110907.tif\n', 'shell', NULL, NULL, NULL, NULL),
	('666', 'tiledWeeklyNDVI2VCICalc', 'tiledWeeklyNDVI2VCICalc_id', 'null', 'Daily_NDVI_URL;Weekly_Max_Min_URL;start_year;start_day;end_year;end_day', NULL, 'return', NULL),
	('667', 'clipROIHDF', 'clipROIHDF_id', 'null', 'bbox;year;day', NULL, 'return', NULL),
	('668', 'ROIYearsDailyNDVICalc', 'ROIYearsDailyNDVICalc_id', 'null', 'years_b1b2QA_URL;years;in_day', NULL, 'return', NULL),
	('669', 'tiledWeeklyNDVIMaxMinCalc', 'tiledWeeklyNDVIMaxMinCalc_id', 'null', 'Daily_NDVI_URL;start_year;start_day;end_year;end_day', NULL, 'return', NULL),
	('670', 'tiledDailyNDVICalcSimple', 'tiledDailyNDVICalcSimple_id', 'null', 'in_year;in_day', NULL, 'return', NULL),
	('671', 'clipROIHDFYears', 'clipROIHDFYears_id', 'null', 'bbox;years;day', NULL, 'return', NULL),
	('672', 'getQATilesWeekly', 'getQATilesWeekly_id', 'null', 'tile_no;in_year;in_day', NULL, 'return', NULL),
	('673', 'ROIDailyNDVICalc', 'ROIDailyNDVICalc_id', 'null', 'b1b2QA_URL;in_year;in_day', NULL, 'return', NULL),
	('674', 'clipROIHDFYearsDays', 'clipROIHDFYearsDays_id', 'null', 'bbox;years;in_day;daynum', NULL, 'return', NULL),
	('675', 'readHDFSubset', 'readHDFSubset_id', 'null', 'in_hdf;subset_no', NULL, 'return', NULL),
	('676', 'clipROIHDFDays', 'clipROIHDFDays_id', 'null', 'bbox;in_year;in_day;daynum', NULL, 'return', NULL),
	('677', 'tiled7DayNDVICalc', 'tiled7DayNDVICalc_id', 'null', 'MOD09GQK_URL;MOD09GST_URL;in_year;in_day', NULL, 'return', NULL),
	('678', 'getb1b2TilesYearsWeekly', 'getb1b2TilesYearsWeekly_id', 'null', 'tile_no;year_list;in_day', NULL, 'return', NULL),
	('679', 'getQATiles', 'getQATiles_id', 'null', 'tile_list;year;day', NULL, 'return', NULL),
	('680', 'VCI16bitsTO8bitsCalc', 'VCI16bitsTO8bitsCalc_id', 'null', 'Tiff_URL', NULL, 'return', NULL),
	('681', 'ROIDaysNDVICompositeCalc', 'ROIDaysNDVICompositeCalc_id', 'null', 'Daily_NDVI_URL;in_year;in_day;daynum', NULL, 'return', NULL),
	('682', 'ROIYearsDaysNDVICalc', 'ROIYearsDaysNDVICalc_id', 'null', 'years_b1b2QA_URL;years;in_day;daynum', NULL, 'return', NULL),
	('683', 'getb1b2TilesWeekly', 'getb1b2TilesWeekly_id', 'null', 'tile_no;in_year;in_day', NULL, 'return', NULL),
	('684', 'getQATilesYears', 'getQATilesYears_id', 'null', 'tile_no;year_list;day', NULL, 'return', NULL),
	('685', 'ROIDaysDailyNDVICalc', 'ROIDaysDailyNDVICalc_id', 'null', 'days_b1b2QA_URL;in_year;in_day;daynum', NULL, 'return', NULL),
	('686', 'ROIYearsDailyNDVIMaxMinCalc', 'ROIYearsDailyNDVIMaxMinCalc_id', 'null', 'Daily_NDVI_URL;years;in_day', NULL, 'return', NULL),
	('687', 'ROIDailyNDVI2VCICalc', 'ROIDailyNDVI2VCICalc_id', 'null', 'Daily_NDVI_URL;Max_Min_NDVI_URL;in_year;in_day', NULL, 'return', NULL),
	('688', 'ROIMaskVCIByCropLayer', 'ROIMaskVCIByCropLayer_id', 'null', 'vciurl;in_year;in_day', NULL, 'return', NULL),
	('689', 'tiledDailyNDVIMaxMinCalc', 'tiledDailyNDVIMaxMinCalc_id', 'null', 'Daily_NDVI_URL;in_year;in_day', NULL, 'return', NULL),
	('68oat6', 'SegNet', 'from keras.models import Sequential\nfrom keras.layers import Input, Embedding, LSTM,Dense, Dropout, Flatten\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Reshape\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape, Permute\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\nfrom keras.layers.convolutional import Convolution1D, MaxPooling1D\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam , SGD\nfrom keras.layers.embeddings import Embedding\nfrom keras.utils import np_utils\n# from keras.utils import multi_gpu_model\n# from keras.regularizers import ActivityRegularizer\n# from keras import backend as K\n\n\ndef segnet(nClasses, optimizer=None, input_height=360, input_width=360, channels=3):\n    kernel = 3\n    # channels = 3\n    filter_size = 64\n    pad = 1\n    pool_size = 2\n\n    print("channel: ", channels)\n\n    model = Sequential()\n    model.add(Layer(input_shape=(input_height,input_width, channels)))\n\n    # encoder\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(filter_size, (kernel, kernel), activation=\'relu\', name="conv_1"))\n    model.add(BatchNormalization())\n    model.add(Activation(\'relu\'))\n    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(128, (kernel, kernel), activation=\'relu\', name="conv_2"))\n    model.add(BatchNormalization())\n    model.add(Activation(\'relu\'))\n    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(256, (kernel, kernel), activation=\'relu\', name="conv_3"))\n    model.add(BatchNormalization())\n    model.add(Activation(\'relu\'))\n    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(512, (kernel, kernel), activation=\'relu\', name="conv_4"))\n    model.add(BatchNormalization())\n    model.add(Activation(\'relu\'))\n\n    # decoder\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(512, (kernel, kernel), activation=\'relu\', name="conv_5"))\n    model.add(BatchNormalization())\n\n    model.add(UpSampling2D(size=(pool_size, pool_size)))\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(256, (kernel, kernel), activation=\'relu\', name="conv_6"))\n    model.add(BatchNormalization())\n\n    model.add(UpSampling2D(size=(pool_size, pool_size)))\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(128, (kernel, kernel), activation=\'relu\', name="conv_7"))\n    model.add(BatchNormalization())\n\n    model.add(UpSampling2D(size=(pool_size, pool_size)))\n    model.add(ZeroPadding2D(padding=(pad, pad)))\n    model.add(Conv2D(filter_size, (kernel, kernel), padding=\'valid\', name="conv_8"))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(nClasses, (1, 1), activation=\'relu\', name="conv_9"))\n\n    model.outputHeight = model.output_shape[-3]\n    model.outputWidth = model.output_shape[-2]\n\n    print("output shape: ", model.output_shape);\n\n    model.add(Reshape((model.output_shape[-3] * model.output_shape[-2], nClasses)))\n\n    # model.add(Permute((2, 1)))\n    model.add(Activation(\'softmax\'))\n\n    #model = multi_gpu_model(model, gpus=4)\n\n    #model.compile(loss=\'categorical_crossentropy\',\n\n    #              optimizer=\'adadelta\',\n\n    #              metrics=[\'accuracy\'])\n\n    # if not optimizer is None:\n    #     model.compile(loss="categorical_crossentropy", optimizer=optimizer, metrics=[\'accuracy\'])\n\n    return model\n', 'python', NULL, NULL, NULL, NULL),
	('690', 'getQATilesYearsWeekly', 'getQATilesYearsWeekly_id', 'null', 'tile_no;year_list;in_day', NULL, 'return', NULL),
	('691', 'tiledYearsDailyNDVICalc', 'tiledYearsDailyNDVICalc_id', 'null', 'MOD09GQK_URL;MOD09GST_URL;in_year;in_day', NULL, 'return', NULL),
	('692', 'ROIYearsDaysNDVICompositeCalc', 'ROIYearsDaysNDVICompositeCalc_id', 'null', 'Daily_NDVI_URL;years;in_day;daynum', NULL, 'return', NULL),
	('693', 'getHDFTiles', 'getHDFTiles_id', 'null', 'LongitudeLo;LatitudeHi;LongitudeHi;LatitudeLo', NULL, 'return', NULL),
	('694', 'tiledYears7DaysNDVICalc', 'tiledYears7DaysNDVICalc_id', 'null', 'MOD09GQK_URL;MOD09GST_URL;in_year;in_day', NULL, 'return', NULL),
	('695', 'tiled1YearWeeklyNDVIComposite', 'tiled1YearWeeklyNDVIComposite_id', 'null', 'Daily_NDVI_URL;start_year;start_day;end_year;end_day', NULL, 'return', NULL),
	('696', 'tiledDailyNDVICalc', 'tiledDailyNDVICalc_id', 'null', 'MOD09GQK_URL;MOD09GST_URL;in_year;in_day', NULL, 'return', NULL),
	('697', 'getVCIstats', 'getVCIstats_id', 'null', 'Tiff_URL', NULL, 'return', NULL),
	('698', 'getb1b2TilesYears', 'getb1b2TilesYears_id', 'null', 'tile_no;year_list;day', NULL, 'return', NULL),
	('699', 'tiledDailyNDVI2VCICalc', 'tiledDailyNDVI2VCICalc_id', 'null', 'Daily_NDVI_URL;Max_Min_NDVI_URL;in_year;in_day', NULL, 'return', NULL),
	('700', 'getb1b2Tiles', 'getb1b2Tiles_id', 'null', 'tile_list;year;day', NULL, 'return', NULL),
	('705', 'remove', 'remove_id', 'null', 'sourceURL;min_area', NULL, 'returnURL;returnFormat', NULL),
	('706', 'get_projection', 'get_projection_id', 'null', 'inputURL', NULL, 'returnURL;returnFormat', NULL),
	('708', 'download', 'download_id', 'null', 'dataset;start_date;end_date;parameters;step;time', NULL, 'netcdf_urls', NULL),
	('710', 'param_scale', 'param_scale_id', 'null', 'sourceURL;s_tol;c_tol;size;param;exp;zscale;central_window;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('711', 'gml2shp', 'gml2shp_id', 'null', 'sourceURL', NULL, 'returnURL;returnFormat', NULL),
	('712', 'patch', 'patch_id', 'null', 'sourceURLArray', NULL, 'returnURL;returnFormat', NULL),
	('713', 'rgb_composite', 'rgb_composite_id', 'null', 'redImageURL;greenImageURL;blueImageURL;dither;closestcolor;levels;lev_red;lev_green;lev_blue;rgbDisplayMode;outputFormatType', NULL, 'returnURL;returnFormat', NULL),
	('714', 'patch_singleband', 'patch_singleband_id', 'null', 'sourceURLArray;outputFormatType;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('715', 'map_calculation', 'map_calculation_id', 'null', 'sourceURLArray;formula;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('716', 'openness', 'openness_id', 'null', 'sourceURL;scale;zunit;outputGeoTiffType', NULL, 'phiReturnURL;phiReturnFormat;psiReturnURL;psiReturnFormat', NULL),
	('717', 'surf_contour', 'surf_contour_id', 'null', 'sourceURL;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('718', 'supervised', 'supervised_id', 'null', 'sourceURLArray;trainingImageURL;classificationMethod;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('719', 'rgb2HIS', 'rgb2HIS_id', 'null', 'redImageURL;greenImageURL;blueImageURL;outputGeoTiffType', NULL, 'hueReturnURL;intensityReturnURL;saturationReturnURL;hueReturnFormat;intensityReturnFormat;saturationReturnFormat', NULL),
	('71u4k0', 'normalize', '#!/bin/bash\necho "test update"\nsleep 15s', 'shell', NULL, NULL, NULL, NULL),
	('720', 'defined_interval', 'defined_interval_id', 'null', 'sourceURL;interval_size', NULL, 'reportURL;pieGraphURL;barGraphURL;reportFormat;pieGraphFormat;barGraphFormat', NULL),
	('721', 'shortest_path', 'shortest_path_id', 'null', 'sourceURL;flags;startPoint_x;startPoint_y;endPoint_x;endPoint_y', NULL, 'returnURL;returnFormat', NULL),
	('722', 'edge_detection', 'edge_detection_id', 'null', 'sourceURL;width;threshold;orientations;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('723', 'tangential_curvature', 'tangential_curvature_id', 'null', 'sourceURL;zfactor;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('724', 'covariance', 'covariance_id', 'null', 'sourceURLArray;matrixType', NULL, 'returnURL;returnFormat', NULL),
	('725', 'unsupervised', 'unsupervised_id', 'null', 'sourceURLArray;classes;iterations;convergence;separation;outputGeoTiffType', NULL, 'returnURL;returnFormat;reportURL;reportFormat', NULL),
	('726', 'fft', 'fft_id', 'null', 'sourceURL;outputGeoTiffType', NULL, 'realReturnURL;realReturnFormat;imaginaryReturnURL;imaginaryReturnFormat', NULL),
	('727', 'classification_statistics', 'classification_statistics_id', 'null', 'sourceURL', NULL, 'returnURL;returnFormat', NULL),
	('728', 'buffer', 'buffer_id', 'null', 'sourceURL;distances;units;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('729', 'buffer', 'buffer_id', 'null', 'sourceURL;buffer', NULL, 'returnURL;returnFormat', NULL),
	('730', 'aspect', 'aspect_id', 'null', 'sourceURL;prec;zfactor;min_slope_allowed;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('731', 'mosaic', 'mosaic_id', 'null', 'sourceURLArray;outputFormatType', NULL, 'returnURL;returnFormat', NULL),
	('732', 'shaded_relief', 'shaded_relief_id', 'null', 'sourceURL;altitude;azimuth;zmult;scale;units;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('733', 'contour', 'contour_id', 'null', 'sourceURL;step;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('734', 'latlon_bbox_clip', 'latlon_bbox_clip_id', 'null', 'sourceURL;northern;southern;eastern;western;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('735', 'drainage_basin', 'drainage_basin_id', 'null', 'sourceURL;threshold;outputGeoTiffType', NULL, 'drainageReturnURL;basinReturnURL;drainageReturnFormat;basinReturnFormat', NULL),
	('736', 'rast_to_vect', 'rast_to_vect_id', 'null', 'sourceURL;flags;feature;outputFormatType', NULL, 'returnURL;returnFormat', NULL),
	('737', 'manual_interval', 'manual_interval_id', 'null', 'sourceURL;manual_interval', NULL, 'reportURL;pieGraphURL;barGraphURL;reportFormat;pieGraphFormat;barGraphFormat', NULL),
	('738', 'vect_column', 'vect_column_id', 'null', 'sourceURL', NULL, 'returnURL;returnFormat', NULL),
	('739', 'flowdirection', 'flowdirection_id', 'null', 'sourceURL;flowModel;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('740', 'matrix_filter', 'matrix_filter_id', 'null', 'sourceURL;filterURL;zero;repeat;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('741', 'his2RGB', 'his2RGB_id', 'null', 'hueImageURL;intensityImageURL;saturationImageURL;outputGeoTiffType', NULL, 'redReturnURL;greenReturnURL;blueReturnURL;redReturnFormat;greenReturnFormat;blueReturnFormat', NULL),
	('742', 'area_stats', 'area_stats_id', 'null', 'rastInputURL;vectInputURL', NULL, 'reportURL;reportFormat;barGraphURL;barGraphFormat', NULL),
	('743', 'grey_scale', 'grey_scale_id', 'null', 'redImageURL;greenImageURL;blueImageURL;red_weights;green_weights;blue_weights;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('744', 'vect_info', 'vect_info_id', 'null', 'sourceURL', NULL, 'returnURL;returnFormat', NULL),
	('745', 'oif', 'oif_id', 'null', 'band1URL;band2URL;band3URL;band4URL;band5URL;band7URL', NULL, 'returnURL;returnFormat', NULL),
	('746', 'select_feature', 'select_feature_id', 'null', 'ainputURL;binputURL;flags;atype;alayer;btype;blayer', NULL, 'returnURL;returnFormat', NULL),
	('747', 'surf_interpolation', 'surf_interpolation_id', 'null', 'sourceURL;interpolationMethod;npoints;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('748', 'userdefinedRules', 'userdefinedRules_id', 'null', 'sourceURL;userdefinedRulesURL;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('749', 'ndvi', 'ndvi_id', 'null', 'nirImageURL;redImageURL;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('750', 'patch_multiband', 'patch_multiband_id', 'null', 'firstRedImageURL;firstGreenImageURL;firstBlueImageURL;secondRedImageURL;secondGreenImageURL;secondBlueImageURL;outputFormatType', NULL, 'returnURL;returnFormat', NULL),
	('751', 'profile', 'profile_id', 'null', 'sourceURL;profile;res;null', NULL, 'returnURL;returnFormat', NULL),
	('752', 'clean_topology', 'clean_topology_id', 'null', 'sourceURL;tool', NULL, 'returnURL;returnFormat', NULL),
	('753', 'bbox_clip', 'bbox_clip_id', 'null', 'sourceURL;northern;southern;eastern;western;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('754', 'extract_values', 'extract_values_id', 'null', 'rasterInputURL;vectorInputURL', NULL, 'returnURL;returnFormat', NULL),
	('755', 'fusion_brovey', 'fusion_brovey_id', 'null', 'sensor;ms1ImageURL;ms2ImageURL;ms3ImageURL;panImageURL;outputFormatType', NULL, 'returnURL;returnFormat', NULL),
	('756', 'vect_to_rast', 'vect_to_rast_id', 'null', 'rastInputURL;vectInputURL;use;type;layer;column;value;rows;rgbcolumn;labelcolumn;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('757', 'flow_accumulation', 'flow_accumulation_id', 'null', 'sourceURL;model;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('758', 'slope', 'slope_id', 'null', 'sourceURL;format;prec;zfactor;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('759', 'polygon_clip', 'polygon_clip_id', 'null', 'sourceURL;polygonURL;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('760', 'build_polylines', 'build_polylines_id', 'null', 'sourceURL', NULL, 'returnURL;returnFormat', NULL),
	('761', 'ifft', 'ifft_id', 'null', 'realImageURL;imaginaryImageURL;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('762', 'equal_interval', 'equal_interval_id', 'null', 'sourceURL;classes', NULL, 'reportURL;pieGraphURL;barGraphURL;reportFormat;pieGraphFormat;barGraphFormat', NULL),
	('763', 'curvatureBasedMethod', 'curvatureBasedMethod_id', 'null', 'sourceURL;tcurv_threshold;flowaccum_threshold;outputFormatType;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('764', 'flowDirectionBasedMethod_GRASS', 'flowDirectionBasedMethod_GRASS_id', 'null', 'sourceURL;flowaccum_threshold;outputFormatType;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('765', 'simplifiedCurvatureMethod', 'simplifiedCurvatureMethod_id', 'null', 'sourceURL;tcurv_threshold;flowaccum_threshold;outputFormatType;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('766', 'topidx', 'topidx_id', 'null', 'sourceURL;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('767', 'tasscap', 'tasscap_id', 'null', 'sensor;band1URL;band2URL;band3URL;band4URL;band5URL;band7URL;outputGeoTiffType', NULL, 'brightnessReturnURL;brightnessReturnFormat;greennessReturnURL;greennessReturnFormat;wetnessReturnURL;wetnessReturnFormat;hazeReturnURL;hazeReturnFormat', NULL),
	('768', 'overlay', 'overlay_id', 'null', 'ainputURL;binputURL;operator', NULL, 'returnURL;returnFormat', NULL),
	('769', 'build_topology', 'build_topology_id', 'null', 'sourceURL', NULL, 'returnURL;returnFormat', NULL),
	('770', 'extract_feature', 'extract_feature_id', 'null', 'sourceURL;flags;type;layer;new;list;where', NULL, 'returnURL;returnFormat', NULL),
	('771', 'shp2gml', 'shp2gml_id', 'null', 'shapefileDataStoreURL', NULL, 'returnURL;returnFormat', NULL),
	('772', 'pca', 'pca_id', 'null', 'sourceURLArray;outputGeoTiffType', NULL, 'returnURLArray;returnFormat', NULL),
	('773', 'rescale', 'rescale_id', 'null', 'sourceURL;scaleMethod;from;to;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('774', 'rgb_extract', 'rgb_extract_id', 'null', 'sourceURL;outputGeoTiffType', NULL, 'redReturnURL;greenReturnURL;blueReturnURL;redReturnFormat;greenReturnFormat;blueReturnFormat', NULL),
	('776', 'profile_curvature', 'profile_curvature_id', 'null', 'sourceURL;zfactor;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('777', 'predefinedColor', 'predefinedColor_id', 'null', 'sourceURL;colorType;outputGeoTiffType', NULL, 'returnURL;returnFormat', NULL),
	('7isag2', 'test3', '# Write first python in Geoweaver\nprint("test python add problem,")', 'python', NULL, NULL, NULL, NULL),
	('7sb7xj', 'ShowCropMap', '{ "operation" : "ShowResultMap", "params":[{ "name": "resultfile", "value": "/home/zsun/demo1.png" }] }', 'builtin', NULL, NULL, NULL, NULL),
	('9v4udw', 'test5', '# Write first python in Geoweaver\nprint("test")', 'python', NULL, NULL, NULL, NULL),
	('a652kg', 'phenology_test', '# Write first python in Geoweaver\nprint("this is test for year 2019")', 'python', NULL, NULL, NULL, NULL),
	('ac4724', 'sleep15s', '#!/bin/bash\necho "test run bash function"\necho "sleep for 50 seconds"\nsleep 150s\necho "great now end"', 'shell', NULL, NULL, NULL, NULL),
	('aikfaz', 'ag-net-train', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\n\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nos.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152\nos.environ["CUDA_VISIBLE_DEVICES"] = ""\n\n\n# datearray = ["2016104", "2016120"]\n\nprint("this is change from christina")\n\nmodel = cm.getModel()\n\nbatch_size = 64\n\n\n#landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.landsat_folder="/home/zsun/crop-oh/landsat-5070/"\n\ncm.cdl_folder="/home/zsun/crop-oh/cdl-cut/"\n\nfor f in listdir(cm.landsat_folder):\n    if "band1.tif" in f:\n        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(cm.landsat_folder):\n\n        if "band1.tif" in f:\n            print("=========> Processing ",f)\n            exist = isfile(cm.cdl_folder + f)\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            sate=f[0:4]\n            date=f[17:25]\n            month=date[4:6]\n            tile=f[10:16]\n            year=date[0:4]\n            print("date: ", date, " tile: ", tile, " year:", year)\n            # if not exist or date != "20160314":\n            if not exist or int(year) < 2013 or int(month) < 7 or int(month) > 7:\n                # print("skip, cdl doesn\'t exist")\n                continue;\n\n            #if date != "20110705":\n            #    continue;\n\n            im1 = Image.open(cm.landsat_folder + f)\n            im2 = Image.open(cm.landsat_folder + f.replace("band1", "band2"))\n            im3 = Image.open(cm.landsat_folder + f.replace("band1", "band3"))\n            im4 = Image.open(cm.landsat_folder + f.replace("band1", "band4"))\n            im5 = Image.open(cm.landsat_folder + f.replace("band1", "band5"))\n            im6 = Image.open(cm.landsat_folder + f.replace("band1", "band6"))\n            im7 = Image.open(cm.landsat_folder + f.replace("band1", "band7"))\n            cfmask = Image.open(cm.landsat_folder + f.replace("sr_band1", "pixel_qa"))\n            cdl_im = Image.open(cm.cdl_folder + f)\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n            imarraymask = numpy.array(cfmask)\n            cdlarray = numpy.array(cdl_im)\n            # print(imarraymask.shape)\n            # print(cdlarray.shape)\n\n            # show a small tile of 360*360\n            x_tile_num = imarraymask.shape[0] / cm.img_width\n            y_tile_num = imarraymask.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n                # print("imgarray3 shape: ", imarray3.shape)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n                #                j * cm.img_height:(j + 1) * cm.img_height];\n                current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                               j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                # print(current_tile1.shape);\n                # bqa - High confidence cloud ? 480,992\n                # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n                # if the CDL contains 0, skip\n                if (  992 in current_mask or 834 in current_mask or 1 in current_mask or 480 in current_mask or 898 in current_mask or 928 in current_mask or 96 in current_mask or 112 in current_mask or 160 in current_mask or 176 in current_mask or 224 in current_mask or 0 in current_cdl):\n                #if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                    #print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                    continue;\n                elif(cm.checkOutSeasonCrops(current_cdl, month)):\n                    #print("tile ", i, " ", j, " is skipped because it is out of season")\n                    continue;\n                else:\n                    #print("tile ", i, " ", j, " is valid")\n                    current_tile1 = np.expand_dims(current_tile1, axis=2)\n                    current_tile2 = np.expand_dims(current_tile2, axis=2)\n                    current_tile3 = np.expand_dims(current_tile3, axis=2)\n                    current_tile4 = np.expand_dims(current_tile4, axis=2)\n                    current_tile5 = np.expand_dims(current_tile5, axis=2)\n                    current_tile6 = np.expand_dims(current_tile6, axis=2)\n                    current_tile7 = np.expand_dims(current_tile7, axis=2)\n                    # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                    current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                    combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                    combine_tensor = np.expand_dims(combine_tensor,\n                                                    axis=0)  # (1, height, width, channels), add a dimension because the\n                    # model expects this shape: (batch_size, height, width, channels)\n\n                    if (cm.NN == "ConvLSTM"):\n\n                        combine_tensor = np.expand_dims(combine_tensor,\n                                                        axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        # the model expects this shape: (batch_size, time, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor;\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                        cdl_array = keras.utils.to_categorical(current_cdl, num_classes=255)\n\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # add time dimensions: (time, height, width, channels)\n\n                        cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                        if (len(cm.cdl_tensor) == 0):\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                                                           axis=0);  # the new image will be a new batch\n\n                    elif (cm.NN == "SegNet"):\n\n                        # combine_tensor = np.expand_dims(combine_tensor,\n                        #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                        #  the model expects this shape: (batch_size, time, height, width, channels)\n\n                        # else:\n                        #\n                        #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n\n                        # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n\n                        cdl_array = np.ravel(current_cdl, \'c\')\n                        cdl_array = keras.utils.to_categorical(cdl_array, num_classes=255)\n                        cdl_array = np.expand_dims(cdl_array,\n                                                   axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                        if (len(cm.input_tensor) == 0):\n\n                            cm.input_tensor = combine_tensor\n\n                            cm.cdl_tensor = cdl_array\n\n                        else:\n\n                            cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                            cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                    if cm.cdl_tensor.shape[0] != batch_size:\n                        continue;\n\n                    model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1, callbacks=[])\n\n                    cm.input_tensor = [];\n\n                    cm.cdl_tensor = [];\n\n            # savemodel = model.get_layer(\'sequential_1\')\n\n            model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'python', NULL, NULL, NULL, NULL),
	('b6deul', 'asj', '{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Importing data from USGS web services for analysis and visualization.\\n"]},{"cell_type":"markdown","metadata":{},"source":["Load necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\\n","import matplotlib.pyplot as plt\\n","import datetime\\n","from suds.client import Client"]},{"cell_type":"markdown","metadata":{},"source":["Create the inputs for the web service call\\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["wsdlURL = \'http://hydroportal.cuahsi.org/nwisuv/cuahsi_1_1.asmx?WSDL\'\\n","siteCode = \'NWISUV:09380000\'\\n","variableCode = \'NWISUV:00060\'\\n","beginDate = \'2018-08-01\'\\n","endDate = str(datetime.datetime.now())"]},{"cell_type":"markdown","metadata":{},"source":["Create a new object \\"NWIS\\" for calling the web service methods\\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NWIS = Client(wsdlURL).service"]},{"cell_type":"markdown","metadata":{},"source":["Call the GetValuesObject method to return datavalues"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["response = NWIS.GetValuesObject(siteCode, variableCode, beginDate, endDate)"]},{"cell_type":"markdown","metadata":{},"source":["Get site name from the response\\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["siteName = response.timeSeries[0].sourceInfo.siteName"]},{"cell_type":"markdown","metadata":{},"source":["Create some blank lists to fill with values and dates"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["a = []  # for the values\\n","b = []  # for the dates"]},{"cell_type":"markdown","metadata":{},"source":["Get values and dates from web service response"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["values = response.timeSeries[0].values[0].value"]},{"cell_type":"markdown","metadata":{},"source":["Loop through values and load to blank lists using append"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for v in values:\\n","        a.append(float(v.value))\\n","        b.append(v._dateTime)"]},{"cell_type":"markdown","metadata":{},"source":["Create a Pandas Series object from the lists\\n","Set the index of the Series object to the dates\\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ts = pd.Series(a, index=b)"]},{"cell_type":"markdown","metadata":{},"source":["Use resample to determine daily mean, min, max from the 15-min data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dailyAvg = ts.resample(rule=\'1D\', base=0).mean()\\n","dailyMin = ts.resample(rule=\'1D\', base=0).min()\\n","dailyMax = ts.resample(rule=\'1D\', base=0).max()"]},{"cell_type":"markdown","metadata":{},"source":["Use MatPlotLib to create a plot of the time series. Add each of the data series, axes labels, grid and legend."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Use MatPlotLib to create a plot of the time series\\n","fig = plt.figure(figsize=(10, 4))\\n","ax = fig.add_subplot(1, 1, 1)\\n","\\n","# Add each of the data series\\n","ts.plot(color=\'gray\', linestyle=\'solid\', lw=0.75, label=\'15-minute Flows\')\\n","dailyAvg.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Average Flows\')\\n","dailyMin.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Minimum Flows\')\\n","dailyMax.plot(linestyle=\'solid\', lw=0.75, marker=\'o\', markersize=3, label=\'Daily Maximum Flows\')\\n","\\n","# Add axes labels, grid, legend\\n","ax.set_ylabel(\\"Discharge, cubic feet per second\\")\\n","ax.set_xlabel(\'Date\')\\n","ax.grid(True)\\n","ax.set_title(siteName)\\n","legend = ax.legend(loc=\'upper left\')\\n","\\n","# Show the plot\\n","fig.tight_layout()\\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}', 'jupyter', NULL, NULL, NULL, NULL),
	('biw0my', 'unzip-cdl', '#!/bin/bash\n#write your bash script\nsleep 5s\ncd /home/zsun/data/\n#chmod +x 2015_30m_cdls.zip\n#unzip 2014_30m_cdls.zip\nunzip 2015_30m_cdls.zip\n#unzip 2016_30m_cdls.zip\n#unzip 2017_30m_cdls.zip\n#unzip 2018_30m_cdls.zip', 'shell', NULL, NULL, NULL, NULL),
	('c0cs3l', 'test6', '# Write first python in Geoweaver\nprint("testsdfdsfsd")', 'python', NULL, NULL, NULL, NULL),
	('c7ot8y', 'prepare_training_dataset_oh', '#!/bin/bash\n#write your bash script\n\necho "start to prepare landsat into training dataset"\n\ncdl_folder=/home/zsun/cdl-raw/\n\ncdl_projected_folder=/home/zsun/cdl-projected/\n\nmkdir $cdl_projected_folder\n\n# transform projection to 32614\n#for entry in "$cdl_folder"/*cdls.img\n#do\n#	echo "$entry"\n#	filename=${entry##*/}\n#	if [ ! -f  $cdl_projected_folder$filename"_5070.tif" ]; then\n#\n#		echo " gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff "$entry" "$cdl_projected_folder$filename"_5070.tif"\n#	\n#		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $entry $cdl_projected_folder$filename"_5070.tif"\n#	fi\n#done\n\n# unzip landsat\nlandsat_zip_folder=/home/zsun/crop-oh/landsat/\n\nlandsat_unzip_folder=/home/zsun/crop-oh/landsat-unzip/\n\nlandsat_5070_folder=/home/zsun/crop-oh/landsat-5070/\n\ntileindex_folder=/home/zsun/crop-oh/tileindex/\n\ncut_cdl_folder=/home/zsun/crop-oh/cdl-cut/\n\nmkdir $landsat_unzip_folder\n\nmkdir $tileindex_folder\n\nmkdir $cut_cdl_folder\n\nmkdir $landsat_5070_folder\n\nfor entry in "$landsat_zip_folder"/*\ndo  	\n	echo "$entry"	\n	# get file name\n	filename=${entry##*/}\n	echo "get file name: "$filename\n\n	# get date\n\n	# LT050310272005080501T1-SC20180823155307.tar.giz\n	tile=${filename:4:6}\n	date=${filename:10:8}\n	echo "current date is: "$date\n	year=${date:0:4}\n	monthday=${date:4:4}\n\n	unzipped=0\n\n	for ba in "$landsat_unzip_folder"/*"$tile"*"$date"*band1*\n	do \n		if [ -f $ba ];then\n			echo "++++++++++++++++found band1 image: "$ba\n			unzipped=1\n		fi\n	done\n\n	#if [ $unzipped == 1 -a "$date" != "20160925" ] \n	if [ $unzipped == 1 ]\n	then\n		echo "already unzipped"\n	else\n\n		echo "unzip "$entry\n        tar -zxvf $entry -C $landsat_unzip_folder\n	fi\ndone\n\nfor tif in "$landsat_unzip_folder"/*.tif\ndo\n	filename=${tif##*/}\n	tile=${filename:10:6}\n    date=${filename:17:8}\n	targetfile=$landsat_5070_folder$filename\n	if [ -f $targetfile ]; then\n	#if [ "$date" != "20160925" ]; then\n		echo $filename" is already there"\n	else\n		gdalwarp -overwrite -t_srs EPSG:5070 -tr 30.0 30.0 -of GTiff $tif $landsat_5070_folder$filename\n	fi\ndone\n\nfor en in "$landsat_5070_folder"/*band1*tif\ndo\n	#echo "$en"\n	filename=${en##*/}\n	echo "get band name: "$filename\n	# LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n	tile=${filename:10:6}\n	date=${filename:17:8}\n    #echo "current date is: "$date\n    year=${date:0:4}\n    monthday=${date:4:4}\n\n	#echo "current date: "$date\n\n	uncut=1\n\n    for ba in "$cut_cdl_folder"/*"$tile"*"$date"*band1*\n    do\n        if [ -f $ba ]; then\n          uncut=0\n        fi\n    done\n\n	#	echo "==================================\\n uncut variable: "$uncut\n\n	if [ "$year" -lt 2008 -o "$uncut" == 0 ]; then\n	#if [ \\( "$year" -lt "2008" -o "$uncut" == 0 \\) -a \\( "$date" != "20160925" \\) ]; then \n        echo "skipping"\n    else\n        #       echo "create tile boundary using tileindex"\n        shpfile=$tileindex_folder$filename".shp"\n        #rm $tileindex_folder$filename"*"\n        find $tileindex_folder -name $filename\'*\' -delete\n        band1file=$en\n        echo "gdaltindex -tileindex location -t_srs EPSG:5070 "$shpfile" "$band1file\n        gdaltindex -tileindex location -t_srs EPSG:5070 $shpfile $band1file\n\n        #      echo "cut and resample CDL to fit the landsat scene"\n        cutcdlfile=$cut_cdl_folder$filename\n        # 2008_30m_cdls.img_32614.tif\n        echo "gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline "$shpfile" -crop_to_cutline -tr 30.0 30.0 -of GTiff "$cdl_folder$year"_30m_cdls.img "$cutcdlfile\n        gdalwarp -q -overwrite -t_srs EPSG:5070 -cutline $shpfile -crop_to_cutline -tr 30.0 30.0 -of GTiff $cdl_folder$year"_30m_cdls.img" $cutcdlfile\n\n    fi\ndone\n\necho "end the data preparation"\n', 'shell', NULL, NULL, NULL, NULL),
	('degrzr', 'testsshscript', '#!/bin/sh\necho "test geoweaver process running"\necho "Good"\n', 'shell', NULL, NULL, NULL, NULL),
	('dufwvd', 'test.sh', '#!/bin/bash\n\necho "Test2 + 3 + 4 + 5"\n\necho "{\\"cells\\":[{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"# Connecting to an existing IPython kernel using the Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## The Frontend/Kernel Model\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\\\n\\",\\"\\\\n\\",\\"While this traditional application still exists, the modern Jupyter consists of two processes:\\\\n\\",\\"\\\\n\\",\\"* Kernel: this is the process that runs the users code.\\\\n\\",\\"* Frontend: this is the process that provides the user interface where the user types code and sees results.\\\\n\\",\\"\\\\n\\",\\"Jupyter currently has 3 frontends:\\\\n\\",\\"\\\\n\\",\\"* Terminal Console (`jupyter console`)\\\\n\\",\\"* Qt Console (`jupyter qtconsole`)\\\\n\\",\\"* Notebook (`jupyter notebook`)\\\\n\\",\\"\\\\n\\",\\"The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\\\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\\\'s Kernel and use it as a help\\\\n\\",\\"browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\\\n\\",\\"one in the notebook).  \\\\n\\",\\"\\\\n\\",\\"This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\\\n\\",\\"The commands currently given here are specific to the IPython kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Manual connection\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%connect_info\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can see that this magic displays everything you need to connect to this Notebook\\\'s Kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Automatic connection using a new Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\\\n\\",\\"information and start the Qt Console for you automatically.\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"a = 10\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%qtconsole\\"]}],\\"metadata\\":{\\"nbsphinx\\":{\\"execute\\":\\"never\\"},\\"kernelspec\\":{\\"display_name\\":\\"Python 3\\",\\"language\\":\\"python\\",\\"name\\":\\"python3\\"},\\"language_info\\":{\\"codemirror_mode\\":{\\"name\\":\\"ipython\\",\\"version\\":3},\\"file_extension\\":\\".py\\",\\"mimetype\\":\\"text/x-python\\",\\"name\\":\\"python\\",\\"nbconvert_exporter\\":\\"python\\",\\"pygments_lexer\\":\\"ipython3\\",\\"version\\":\\"3.5.2\\"}},\\"nbformat\\":4,\\"nbformat_minor\\":1}\\r\\n" > testjupyter.ipynb;\n\necho "==== Geoweaver Bash Output Finished ====";\n\n\n\n\n\n', 'shell', '/home/zsun/test.sh', 'kps1gf', NULL, NULL),
	('ejc7yo', 'ag-net-ready', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\nfrom colormap import *\n# from keras import backend as K\nfrom pathlib import Path\nimport SegNet\n\nfrom os import listdir,environ\nfrom os.path import isfile, join\n\nenviron["CUDA_VISIBLE_DEVICES"] = "2"\n\n# datearray = ["2016104", "2016120"]\n\n# cm.modelpath = cm.folder + "/model/keras_cdl_SegNet_standard.net";\n\n\nbatch = 32\n\ncm.NN="SegNet"\n\ncm.reuse=True\n\ncm.modelpath = "/home/zsun/ag-net/keras_cdl_" + cm.NN +"_standard_multiple_oh_ready.net";#032027\n\ninput_folder="/home/zsun/crop-oh/ag-net-input/"\n\ntarget_folder="/home/zsun/crop-oh/ag-net-target/"\n\nmodel = cm.getModel()\n\n#for f in listdir(input_folder):\n#    if "band1.tif" in f:\n#        print (f)\n\nstart_time = time.time()\n\nfor n in range(0, cm.nEpoch):\n\n    print("^^^^^^^^^^^^^^^^^/n Epoch :", n)\n\n    for f in listdir(input_folder):\n\n        if "band1.tif" in f:\n            \n            # print("=========> Processing ",f)\n            exist1 = isfile(input_folder + f)\n            exist2 = isfile(input_folder + f.replace("band1", "band2"))\n            exist3 = isfile(input_folder + f.replace("band1", "band3"))\n            exist4 = isfile(input_folder + f.replace("band1", "band4"))\n            exist5 = isfile(input_folder + f.replace("band1", "band5"))\n            exist6 = isfile(input_folder + f.replace("band1", "band6"))\n            exist7 = isfile(input_folder + f.replace("band1", "band7"))\n            # 031026_20160718_57_76_band1.tif\n            # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n            #sate=f[0:4]\n            date=f[7:15]\n            month=date[4:6]\n            tile=f[0:6]\n            year=date[0:4]\n            # print("date: ", date, " tile: ", tile, " year:", year)\n            \n            # if not exist or date != "20160314":\n            \n            if not exist1 or not exist2 or not exist3 or not exist4 or not exist5 or not exist6 or not exist7 or int(year) < 2013 or int(month) < 5 or int(month) > 8 :\n                \n                continue;\n\n            im1 = Image.open(input_folder + f)\n            im2 = Image.open(input_folder + f.replace("band1", "band2"))\n            im3 = Image.open(input_folder + f.replace("band1", "band3"))\n            im4 = Image.open(input_folder + f.replace("band1", "band4"))\n            im5 = Image.open(input_folder + f.replace("band1", "band5"))\n            im6 = Image.open(input_folder + f.replace("band1", "band6"))\n            im7 = Image.open(input_folder + f.replace("band1", "band7"))\n            cdl_im = Image.open(target_folder + f.replace("band1", "cdl"))\n\n            imarray1 = numpy.array(im1)\n            imarray2 = numpy.array(im2)\n            imarray3 = numpy.array(im3)\n            imarray4 = numpy.array(im4)\n            imarray5 = numpy.array(im5)\n            imarray6 = numpy.array(im6)\n            imarray7 = numpy.array(im7)\n            cdlarray = numpy.array(cdl_im)\n            predict_cdl = numpy.zeros((imarray1.shape[0], imarray1.shape[1], 3))\n\n            # show a small tile of 360*360\n            x_tile_num = imarray1.shape[0] / cm.img_width\n            y_tile_num = imarray1.shape[1] / cm.img_height\n\n            total_num = int(x_tile_num * y_tile_num)\n\n            i_array = numpy.zeros(batch)\n\n            j_array = numpy.zeros(batch)\n\n            for k in range(0, total_num):\n\n                i = random.randint(0, int(x_tile_num)-1)\n                j = random.randint(0, int(y_tile_num)-1)\n\n                current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_width:(j + 1) * cm.img_height];\n            \n                current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                                j * cm.img_height:(j + 1) * cm.img_height];\n                current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width, j * cm.img_height:(j + 1) * cm.img_height];\n\n                current_tile1 = np.expand_dims(current_tile1, axis=2)\n                current_tile2 = np.expand_dims(current_tile2, axis=2)\n                current_tile3 = np.expand_dims(current_tile3, axis=2)\n                current_tile4 = np.expand_dims(current_tile4, axis=2)\n                current_tile5 = np.expand_dims(current_tile5, axis=2)\n                current_tile6 = np.expand_dims(current_tile6, axis=2)\n                current_tile7 = np.expand_dims(current_tile7, axis=2)\n                current_cdl = np.expand_dims(current_cdl, axis=2)\n\n                combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                                                     current_tile5, current_tile6, current_tile7), axis=2)\n                combine_tensor = np.expand_dims(combine_tensor, axis=0)  # (1, height, width, channels), add a dimension because the\n                \n                if (cm.NN == "ConvLSTM"):\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor;\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                                                             axis=0);  # use batch to combine multiple images. Each batch only\n                            # has one step, which is the sequence to sequence mode.\n\n                        # cdl_array = np.ravel(cdl_array, \'c\')\n\n                    cdl_array = keras.utils.to_categorical(current_cdl, num_classes=cm.n_classes)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # add time dimensions: (time, height, width, channels)\n\n                    cdl_array = np.expand_dims(cdl_array, axis=0)\n\n                    if (len(cm.cdl_tensor) == 0):\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0);  # the new image will be a new batch\n                \n                elif (cm.NN == "SegNet" or cm.NN == "U-Net"):\n                    \n                    cdl_array = np.ravel(current_cdl, \'c\')\n                    \n                    cdl_array = keras.utils.to_categorical(cdl_array, num_classes=cm.n_classes)\n                    \n                    cdl_array = np.expand_dims(cdl_array, axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n\n                    if (len(cm.input_tensor) == 0):\n\n                        cm.input_tensor = combine_tensor\n\n                        cm.cdl_tensor = cdl_array\n\n                    else:\n\n                        cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n\n                        cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                if cm.cdl_tensor.shape[0] < batch:\n\n                    continue;\n\n                model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch, epochs=1, callbacks=[])\n                    \n                cm.input_tensor = [];\n\n                cm.cdl_tensor = [];\n\n                model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n\n    model.save(cm.modelpath + "_checkpoint_" + str(n) + ".net") # prevent model failure\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'python', NULL, NULL, NULL, NULL),
	('ew8pku', 'cdl_class_mapping', '#!/bin/bash', 'shell', NULL, NULL, NULL, NULL),
	('f0qvfi', 'test3.py', 'import time\nstart = time.time()\na = range(100000)\nb = []\nfor i in a:\n    b.append(i*2)\nend = time.time()\nprint(end - start)', 'python', NULL, NULL, NULL, NULL),
	('fz04z1', 'move_data', '#!/bin/bash\n#write your bash script\nscp zsun@192.168.1.1:/home/zsun/data-to-move/* /home/newserver/folder/\n', 'shell', NULL, NULL, NULL, NULL),
	('gg3usv', 'colormap', '\ncolormap = [["#000000","0","0"],\n ["#ffd300","1","1"],\n ["#ff2626","2","2"],\n ["#00a8e2","3","3"],\n ["#ff9e0a","4","4"],\n ["#267000","5","5"],\n ["#ffff00","6","6"],\n ["#000000","7","7"],\n ["#000000","8","8"],\n ["#000000","9","9"],\n ["#70a500","10","10"],\n ["#00af49","11","11"],\n ["#dda50a","12","12"],\n ["#dda50a","13","13"],\n ["#7cd3ff","14","14"],\n ["#000000","15","15"],\n ["#000000","16","16"],\n ["#000000","17","17"],\n ["#000000","18","18"],\n ["#000000","19","19"],\n ["#000000","20","20"],\n ["#e2007c","21","21"],\n ["#896054","22","22"],\n ["#d8b56b","23","23"],\n ["#a57000","24","24"],\n ["#d69ebc","25","25"],\n ["#707000","26","26"],\n ["#aa007c","27","27"],\n ["#a05989","28","28"],\n ["#700049","29","29"],\n ["#d69ebc","30","30"],\n ["#d1ff00","31","31"],\n ["#7c99ff","32","32"],\n ["#d6d600","33","33"],\n ["#d1ff00","34","34"],\n ["#00af49","35","35"],\n ["#ffa5e2","36","36"],\n ["#a5f28c","37","37"],\n ["#00af49","38","38"],\n ["#d69ebc","39","39"],\n ["#000000","40","40"],\n ["#a800e2","41","41"],\n ["#a50000","42","42"],\n ["#702600","43","43"],\n ["#00af49","44","44"],\n ["#af7cff","45","45"],\n ["#702600","46","46"],\n ["#ff6666","47","47"],\n ["#ff6666","48","48"],\n ["#ffcc66","49","49"],\n ["#ff6666","50","50"],\n ["#00af49","51","51"],\n ["#00ddaf","52","52"],\n ["#54ff00","53","53"],\n ["#f2a377","54","54"],\n ["#ff6666","55","55"],\n ["#00af49","56","56"],\n ["#7cd3ff","57","57"],\n ["#e8bfff","58","58"],\n ["#afffdd","59","59"],\n ["#00af49","60","60"],\n ["#bfbf77","61","61"],\n ["#000000","62","62"],\n ["#93cc93","63","63"],\n ["#c6d69e","64","64"],\n ["#ccbfa3","65","65"],\n ["#ff00ff","66","66"],\n ["#ff8eaa","67","67"],\n ["#ba004f","68","68"],\n ["#704489","69","69"],\n ["#007777","70","70"],\n ["#af9970","71","71"],\n ["#ffff7c","72","72"],\n ["#000000","73","73"],\n ["#b5705b","74","74"],\n ["#00a582","75","75"],\n ["#e8d6af","76","76"],\n ["#af9970","77","77"],\n ["#000000","78","78"],\n ["#000000","79","79"],\n ["#000000","80","80"],\n ["#f2f2f2","81","81"],\n ["#999999","82","82"],\n ["#4970a3","83","83"],\n ["#000000","84","84"],\n ["#000000","85","85"],\n ["#000000","86","86"],\n ["#7cafaf","87","87"],\n ["#e8ffbf","88","88"],\n ["#000000","89","89"],\n ["#000000","90","90"],\n ["#000000","91","91"],\n ["#00ffff","92","92"],\n ["#000000","93","93"],\n ["#000000","94","94"],\n ["#000000","95","95"],\n ["#000000","96","96"],\n ["#000000","97","97"],\n ["#000000","98","98"],\n ["#000000","99","99"],\n ["#000000","100","100"],\n ["#000000","101","101"],\n ["#000000","102","102"],\n ["#000000","103","103"],\n ["#000000","104","104"],\n ["#000000","105","105"],\n ["#000000","106","106"],\n ["#000000","107","107"],\n ["#000000","108","108"],\n ["#000000","109","109"],\n ["#000000","110","110"],\n ["#4970a3","111","111"],\n ["#d3e2f9","112","112"],\n ["#000000","113","113"],\n ["#000000","114","114"],\n ["#000000","115","115"],\n ["#000000","116","116"],\n ["#000000","117","117"],\n ["#000000","118","118"],\n ["#000000","119","119"],\n ["#000000","120","120"],\n ["#999999","121","121"],\n ["#999999","122","122"],\n ["#999999","123","123"],\n ["#999999","124","124"],\n ["#000000","125","125"],\n ["#000000","126","126"],\n ["#000000","127","127"],\n ["#000000","128","128"],\n ["#000000","129","129"],\n ["#000000","130","130"],\n ["#ccbfa3","131","131"],\n ["#000000","132","132"],\n ["#000000","133","133"],\n ["#000000","134","134"],\n ["#000000","135","135"],\n ["#000000","136","136"],\n ["#000000","137","137"],\n ["#000000","138","138"],\n ["#000000","139","139"],\n ["#000000","140","140"],\n ["#93cc93","141","141"],\n ["#93cc93","142","142"],\n ["#93cc93","143","143"],\n ["#000000","144","144"],\n ["#000000","145","145"],\n ["#000000","146","146"],\n ["#000000","147","147"],\n ["#000000","148","148"],\n ["#000000","149","149"],\n ["#000000","150","150"],\n ["#000000","151","151"],\n ["#c6d69e","152","152"],\n ["#000000","153","153"],\n ["#000000","154","154"],\n ["#000000","155","155"],\n ["#000000","156","156"],\n ["#000000","157","157"],\n ["#000000","158","158"],\n ["#000000","159","159"],\n ["#000000","160","160"],\n ["#000000","161","161"],\n ["#000000","162","162"],\n ["#000000","163","163"],\n ["#000000","164","164"],\n ["#000000","165","165"],\n ["#000000","166","166"],\n ["#000000","167","167"],\n ["#000000","168","168"],\n ["#000000","169","169"],\n ["#000000","170","170"],\n ["#000000","171","171"],\n ["#000000","172","172"],\n ["#000000","173","173"],\n ["#000000","174","174"],\n ["#000000","175","175"],\n ["#e8ffbf","176","176"],\n ["#000000","177","177"],\n ["#000000","178","178"],\n ["#000000","179","179"],\n ["#000000","180","180"],\n ["#000000","181","181"],\n ["#000000","182","182"],\n ["#000000","183","183"],\n ["#000000","184","184"],\n ["#000000","185","185"],\n ["#000000","186","186"],\n ["#000000","187","187"],\n ["#000000","188","188"],\n ["#000000","189","189"],\n ["#7cafaf","190","190"],\n ["#000000","191","191"],\n ["#000000","192","192"],\n ["#000000","193","193"],\n ["#000000","194","194"],\n ["#7cafaf","195","195"],\n ["#000000","196","196"],\n ["#000000","197","197"],\n ["#000000","198","198"],\n ["#000000","199","199"],\n ["#000000","200","200"],\n ["#000000","201","201"],\n ["#000000","202","202"],\n ["#000000","203","203"],\n ["#00ff8c","204","204"],\n ["#d69ebc","205","205"],\n ["#ff6666","206","206"],\n ["#ff6666","207","207"],\n ["#ff6666","208","208"],\n ["#ff6666","209","209"],\n ["#ff8eaa","210","210"],\n ["#334933","211","211"],\n ["#e27026","212","212"],\n ["#ff6666","213","213"],\n ["#ff6666","214","214"],\n ["#000000","215","215"],\n ["#ff6666","216","216"],\n ["#af9970","217","217"],\n ["#ff8eaa","218","218"],\n ["#ff6666","219","219"],\n ["#ff8eaa","220","220"],\n ["#ff6666","221","221"],\n ["#ff6666","222","222"],\n ["#ff8eaa","223","223"],\n ["#00af49","224","224"],\n ["#ffd300","225","225"],\n ["#ffd300","226","226"],\n ["#ff6666","227","227"],\n ["#000000","228","228"],\n ["#ff6666","229","229"],\n ["#896054","230","230"],\n ["#ff6666","231","231"],\n ["#ff2626","232","232"],\n ["#e2007c","233","233"],\n ["#ff9e0a","234","234"],\n ["#ff9e0a","235","235"],\n ["#a57000","236","236"],\n ["#ffd300","237","237"],\n ["#a57000","238","238"],\n ["#267000","239","239"],\n ["#267000","240","240"],\n ["#ffd300","241","241"],\n ["#000099","242","242"],\n ["#ff6666","243","243"],\n ["#ff6666","244","244"],\n ["#ff6666","245","245"],\n ["#ff6666","246","246"],\n ["#ff6666","247","247"],\n ["#ff6666","248","248"],\n ["#ff6666","249","249"],\n ["#ff6666","250","250"],\n ["#ffd300","251","251"],\n ["#267000","252","252"],\n ["#a57000","253","253"],\n ["#267000","254","254"],\n ["#707000","255","255"]]\n\n\ndef hex_to_rgb(value):\n value = value.lstrip(\'#\')\n lv = len(value)\n return tuple(int(value[i:i + lv // 3], 16) for i in range(0, lv, lv // 3))\n\ndef getWindMillRGB(value):\n\n  if(value==0):\n   hex = "#000000"\n   rgb = hex_to_rgb(hex)\n  elif(value==1):\n   hex = "#FFFFFF"\n   rgb = hex_to_rgb(hex)\n\n  return rgb\n\ndef getCDLRGB(cdlvalue):\n # print("get cdl:", cdlvalue)\n for x in range(len(colormap)):\n   if(int(colormap[x][1])==cdlvalue):\n    hex = colormap[x][0]\n    rgb = hex_to_rgb(hex)\n    return rgb\n\nprint("The color of class 5 is: ", getCDLRGB(5));', 'python', NULL, NULL, NULL, NULL),
	('h2xbof', 'test-code', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["<!--BOOK_INFORMATION-->\\n","<img align=\\"left\\" style=\\"padding-right:10px;\\" src=\\"figures/PDSH-cover-small.png\\">\\n","\\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\\n","\\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]},{"cell_type":"markdown","metadata":{},"source":["# IPython: Beyond Normal Python"]},{"cell_type":"markdown","metadata":{},"source":["There are many options for development environments for Python, and I\'m often asked which one I use in my own work.\\n","My answer sometimes surprises people: my preferred environment is [IPython](http://ipython.org/) plus a text editor (in my case, Emacs or Atom depending on my mood).\\n","IPython (short for *Interactive Python*) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez\'s words, \\"Tools for the entire life cycle of research computing.\\"\\n","If Python is the engine of our data science task, you might think of IPython as the interactive control panel.\\n","\\n","As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we\'ll cover the most useful of these additions here.\\n","In addition, IPython is closely tied with the [Jupyter project](http://jupyter.org), which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.\\n","The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.\\n","As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.\\n","\\n","IPython is about using Python effectively for interactive scientific and data-intensive computing.\\n","This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.\\n","Next, we will go into a bit more depth on some of the more useful \\"magic commands\\" that can speed-up common tasks in creating and using data science code.\\n","Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results."]},{"cell_type":"markdown","metadata":{},"source":["## Shell or Notebook?\\n","\\n","There are two primary means of using IPython that we\'ll discuss in this chapter: the IPython shell and the IPython notebook.\\n","The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.\\n","In the few sections that are relevant to just one or the other, we will explicitly state that fact.\\n","Before we start, some words on how to launch the IPython shell and IPython notebook."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the IPython Shell\\n","\\n","This chapter, like most of this book, is not designed to be absorbed passively.\\n","I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.\\n","Start by launching the IPython interpreter by typing **``ipython``** on the command-line; alternatively, if you\'ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we\'ll discuss this more fully in [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\\n","\\n","Once you do this, you should see a prompt like the following:\\n","```\\n","IPython 4.0.1 -- An enhanced Interactive Python.\\n","?         -> Introduction and overview of IPython\'s features.\\n","%quickref -> Quick reference.\\n","help      -> Python\'s own help system.\\n","object?   -> Details about \'object\', use \'object??\' for extra details.\\n","In [1]:\\n","```\\n","With that, you\'re ready to follow along."]},{"cell_type":"markdown","metadata":{},"source":["### Launching the Jupyter Notebook\\n","\\n","The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.\\n","As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.\\n","Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.\\n","\\n","Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.\\n","This process (known as a \\"kernel\\") can be started by running the following command in your system shell:\\n","\\n","```\\n","$ jupyter notebook\\n","```\\n","\\n","This command will launch a local web server that will be visible to your browser.\\n","It immediately spits out a log showing what it is doing; that log will look something like this:\\n","\\n","```\\n","$ jupyter notebook\\n","[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook\\n","[NotebookApp] 0 active kernels \\n","[NotebookApp] The IPython Notebook is running at: http://localhost:8888/\\n","[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\\n","```\\n","\\n","Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;\\n","the exact address will depend on your system.\\n","If the browser does not open automatically, you can open a window and manually open this address (*http://localhost:8888/* in this example)."]},{"cell_type":"markdown","metadata":{},"source":["<!--NAVIGATION-->\\n","< [Preface](00.00-Preface.ipynb) | [Contents](Index.ipynb) | [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) >\\n","\\n","<a href=\\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\\"><img align=\\"left\\" src=\\"https://colab.research.google.com/assets/colab-badge.svg\\" alt=\\"Open in Colab\\" title=\\"Open and Execute in Google Colaboratory\\"></a>\\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"}},"nbformat":4,"nbformat_minor":0}', 'jupyter', NULL, NULL, NULL, NULL),
	('h5ti1l', 'my_keras_common', '# Common variables and data preparation work\n# Author: Ziheng Sun\n# Date: 08/21/2018\n\nimport numpy as np\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n\n# from keras import backend as K\nfrom pathlib import Path\nimport Segnet, LSTMRNN, UNet\nimport random\nimport string\nfrom keras.utils import multi_gpu_model\n\ndef id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n    return \'\'.join(random.choice(chars) for _ in range(size))\n\nNN = "SegNet" # e.g., SegNet, LSTM, ConvLSTM, U-Net\n\n\nreuse = True\n\nshow = True\n\nif(NN=="SegNet" or NN=="U-Net"):\n    img_width, img_height, img_channels,n_classes, nEpoch = 64, 64, 7, 255, 10\n\nif(NN=="ConvLSTM"):\n    img_width, img_height, img_channels,n_classes, nEpoch = 360, 360, 7, 255, 2\n\nfolder = "/home/zsun/dl-cdl"\n\nlandsat_folder="/home/zsun/dl-cdl/data/landsat-5070/"\n\n# folder = "D:/work/MyWorkspace"\n\nmodelpath = folder + "/model/keras_cdl_"+NN+"_standard.net";\n\n#saveimgpath = folder + "/data/cdl/"+NN+"_output_"+id_generator()+".tif";\n\nmodel_template = ""\n\nmodel=""\n\n# datelist = ["20110907", "2014258", "2015213", "2015245"]\n\n# datelist = ["2014258"]\n\ndatelist = []\n\ntestdate = "2015213"\n\ninput_tensor = []\n\ncdl_tensor = []\n\ncdlimg_show = []\n\ncdl_tensor_c = []\n\ndatagen = ImageDataGenerator()\n\n# The log is very annoying\n# tbCallBack = keras.callbacks.TensorBoard(log_dir=\'./Graph\', histogram_freq=0, write_graph=False, write_images=False)\n\ndef normalize(band):\n    # nonzero = band[np.nonzero(band)]\n    # min = np.min(band)\n    # max = np.max(band)\n    # print("max:",max, " - min:",min)\n    # band = (band - min) / (max - min)\n    # band = band.clip(min=0) # turn all negatives to zero\n    # band/=255.\n    return band\n\n# filter the tile with out-season crops\ndef checkOutSeasonCrops(cdlarray, month):\n    has = False\n    # soybeans - 5 - July, Aug, early Sep\n    # rice - 3 - May, Jun, Jul, Aug\n    # Spring Wheat - 23 - May, June, Jul\n    # Corn - 1 - Jun, Jul, Aug, Sep\n    # Cotton - 2 - Jun, Jul, Aug, Sep, Oct (maybe)\n    # Sorghum - 4 - Jul, Aug, early Sep\n    # Peanuts - 10 - June, Jul, Aug\n    # Barley - 21 - May, Jun, Jul, Aug\n    # Oats - 28 - May, Jun, Jul, Aug\n    # Winter Wheat - 24 - Apr, May, Jun, Oct, Nov, Dec\n    if(month==4 ):\n        if (5 in cdlarray or 3 in cdlarray or 23 in cdlarray or 1 in cdlarray or 2 in cdlarray or 4 in cdlarray or 10 in cdlarray or 21 in cdlarray or 28 in cdlarray):\n            has = True\n    elif(month==5):\n        if (5 in cdlarray or 1 in cdlarray or 2 in cdlarray or 4 in cdlarray or 10 in cdlarray):\n            has = True\n    elif(month==6):\n        if (5 in cdlarray or 4 in cdlarray):\n            has = True\n    elif(month==7):\n        print("july is the best month")\n    elif(month==8):\n        if (23 in cdlarray or 24 in cdlarray):\n            has = True\n    elif(month==9):\n        if (3 in cdlarray or 23 in cdlarray or 10 in cdlarray or 21 in cdlarray or 28 in cdlarray or 24 in cdlarray):\n            has = True\n    # if(has):\n    #     print("skip this batch becase it is out of season")\n    return has\n\n\n\ndef getModel():\n\n    print("Using Model: " + NN)\n\n    if reuse and Path(modelpath).is_file():\n\n        print("current model path", modelpath)\n\n        print("Reuse existing model..")\n\n        model = load_model(modelpath)\n\n        #return model\n\n    else:\n\n        print("Create a new neural network model..")\n\n        if(NN=="ConvLSTM"):\n\n            model = LSTMRNN.convlstm(n_classes, input_height=img_height, input_width=img_width, nChannels=img_channels)\n\n        elif(NN=="SegNet"):\n\n            model = Segnet.segnet(n_classes, input_height=img_height, input_width=img_width, channels=img_channels)\n        \n        elif(NN=="U-Net"):\n\n            model = UNet.Unet(n_classes, input_height=img_height, input_width=img_width, channels=img_channels)\n        #global model_template\n\n        #model_template = model\n\n    #parallel_model = multi_gpu_model(model, gpus=4, cpu_relocation=True, cpu_merge=True)\n\n        model.compile(loss=\'categorical_crossentropy\',\n\n                 optimizer=\'adadelta\',\n\n                 metrics=[\'accuracy\'])\n\n    return model\n\n    #parallel_model.compile(loss=\'categorical_crossentropy\',\n\n    #              optimizer=\'adadelta\',\n\n    #              metrics=[\'accuracy\'])\n\n    #parallel_model.summary()\n\n    #return model\n\ndef reshapePredictOutput(output):\n    if(NN=="SegNet" or NN=="U-Net"):\n        output = output.reshape((img_height, img_width, n_classes)).argmax(axis=2)\n    elif(NN=="ConvLSTM"):\n        output = output.reshape((img_height, img_width, n_classes)).argmax(axis=2)\n    return output\n\n', 'python', NULL, NULL, NULL, NULL),
	('hmwl0u', 'test1.sh', '#!/bin/bash\necho "Test"\necho "Test 2"\necho "Test for multiple lines"\ngdalinfo -version\npython -h\necho "End of test"\n', 'shell', '/home/zsun/test1.sh', 'kps1gf', NULL, NULL),
	('ikfk1x', 'ag-net-prepare', '# Write first python in Geoweaver\n# For Landsat 7-band Big Image\n# Ziheng Sun\n# 11/29/2018\nimport sys\nfrom PIL import Image\nimport numpy as np\nimport numpy\nimport random\nimport my_keras_common as cm\nimport keras\nimport time\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n# from keras.layers import Merge\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.regularizers import ActivityRegularizer\n# from keras import backend as K\nfrom pathlib import Path\nimport cv2\nimport imageio\n\nfrom os import listdir\nfrom os.path import isfile, join\n\n# datearray = ["2016104", "2016120"]\n\n# model = cm.getModel()\n\nbatch_size = 64\n\n# landsat_folder="/home/zsun/dl-cdl/data/landsat-3857/"\n\ncm.folder="/home/zsun/"\n\nlandsat_folder=cm.folder + "/crop-oh/landsat-5070/"\n\ncdl_folder = cm.folder + "/crop-oh/cdl-cut/"\n\ninput_folder = cm.folder + "/crop-oh/ag-net-input/"\n\ntarget_folder = cm.folder + "/crop-oh/ag-net-target/"\n\ndef checkComplete(f):\n#for f in listdir(landsat_folder):\n    complete=True\n    if "band1.tif" in f:\n        im1 = isfile(landsat_folder + f)\n        im2 = isfile(landsat_folder + f.replace("band1", "band2"))\n        im3 = isfile(landsat_folder + f.replace("band1", "band3"))\n        im4 = isfile(landsat_folder + f.replace("band1", "band4"))\n        im5 = isfile(landsat_folder + f.replace("band1", "band5"))\n        im6 = isfile(landsat_folder + f.replace("band1", "band6"))\n        im7 = isfile(landsat_folder + f.replace("band1", "band7"))\n        cfmask = isfile(landsat_folder + f.replace("sr_band1", "pixel_qa"))\n        cdl = isfile(cdl_folder + f)\n        if(not im1 or not im2 or not im3 or not im4 or not im5 or not im6 or not im7 or not cdl):\n            print("found incomplete tile: ", f)\n            complete=False\n    return complete\n\n# sys.exit()\n\nstart_time = time.time()\n\ndef isprocessed(date):\n    isp=False\n    for f in listdir(input_folder):\n        if date in f:\n            isp=True\n            print("this scene has already processed")\n            break;\n    return isp\n\n\nfor f in listdir(landsat_folder):\n\n    if "band1.tif" in f:\n        print("=========> Processing ", f)\n        exist = isfile(cdl_folder + f)\n                # LC08_L1TP_035026_20170428_20170515_01_T1_sr_band1.tif\n        sate = f[0:4]\n        date = f[17:25]\n        month = date[4:6]\n        tile = f[10:16]\n        year = date[0:4]\n        # processed=isprocessed(date)\n        print("cdl exist: ", exist," date: ", date, " tile: ", tile, " year:", year, " month", month)\n        # if not exist or date != "20160314":\n        if not exist or int(year) < 2013 or int(month) < 6 or int(month) > 8:\n            print("skip, cdl doesn\'t exist or the date is out of windows")\n            continue;\n\n        complete=checkComplete(f)\n\n        if not complete:\n            continue;\n        \n        print("slicing.....")\n\n        # if date != "20110705":\n        #    continue;\n\n        im1 = Image.open(landsat_folder + f)\n        im2 = Image.open(landsat_folder + f.replace("band1", "band2"))\n        im3 = Image.open(landsat_folder + f.replace("band1", "band3"))\n        im4 = Image.open(landsat_folder + f.replace("band1", "band4"))\n        im5 = Image.open(landsat_folder + f.replace("band1", "band5"))\n        im6 = Image.open(landsat_folder + f.replace("band1", "band6"))\n        im7 = Image.open(landsat_folder + f.replace("band1", "band7"))\n        cfmask = Image.open(landsat_folder + f.replace("sr_band1", "pixel_qa"))\n        cdl_im = Image.open(cdl_folder + f)\n\n        imarray1 = numpy.array(im1)\n        imarray2 = numpy.array(im2)\n        imarray3 = numpy.array(im3)\n        imarray4 = numpy.array(im4)\n        imarray5 = numpy.array(im5)\n        imarray6 = numpy.array(im6)\n        imarray7 = numpy.array(im7)\n        # imarrayndvi = (imarray4-imarray5)/(imarray4+imarray5)\n        imarraymask = numpy.array(cfmask)\n        cdlarray = numpy.array(cdl_im)\n        # print(imarraymask.shape)\n        # print(cdlarray.shape)\n        predict_cdl = numpy.zeros((imarraymask.shape[0], imarraymask.shape[1], 3))\n\n        # show a small tile of 360*360\n        x_tile_num = imarraymask.shape[0] / cm.img_width\n        y_tile_num = imarraymask.shape[1] / cm.img_height\n\n        total_num = int(x_tile_num * y_tile_num)\n\n        i_array = numpy.zeros(int(batch_size))\n\n        j_array = numpy.zeros(int(batch_size))\n\n        for k in range(0, total_num):\n\n            i = random.randint(0, int(x_tile_num) - 1)\n            j = random.randint(0, int(y_tile_num) - 1)\n\n            # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n            # print("imgarray3 shape: ", imarray3.shape)\n\n            # print("i: ", i, " j: ", j, " width: ", cm.img_width, " height: ", cm.img_height);\n            # print("imgarray3 shape: ", imarray3.shape)\n\n            current_tile1 = imarray1[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_width:(j + 1) * cm.img_height];\n            current_tile2 = imarray2[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile3 = imarray3[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile4 = imarray4[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile5 = imarray5[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile6 = imarray6[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            current_tile7 = imarray7[i * cm.img_width:(i + 1) * cm.img_width,\n                            j * cm.img_height:(j + 1) * cm.img_height];\n            # current_ndvi = imarrayndvi[i * cm.img_width:(i + 1) * cm.img_width,\n            #                j * cm.img_height:(j + 1) * cm.img_height];\n            current_mask = imarraymask[i * cm.img_width:(i + 1) * cm.img_width,\n                           j * cm.img_height:(j + 1) * cm.img_height];\n            current_cdl = cdlarray[i * cm.img_width:(i + 1) * cm.img_width,\n                          j * cm.img_height:(j + 1) * cm.img_height];\n\n            # print(current_tile1.shape);\n            # bqa - High confidence cloud ? 480,992\n            # if (1 in current_mask or 61440 in current_mask or 53248 in current_mask or 36864 in current_mask):\n            # if the CDL contains 0, skip\n            if (992 in current_mask or 834 in current_mask\n                    or 1 in current_mask or 480 in current_mask or 898 in current_mask\n                    or 928 in current_mask or 96 in current_mask or 112 in current_mask\n                    or 160 in current_mask or 176 in current_mask or 224 in current_mask\n                    or 0 in current_mask or 0 in current_cdl):\n                # if ( 0 in current_cdl or np.any( i > 1000 for i in current_tile1 )  ):\n                # print("tile ", i, " ", j, " is skipped because it contains nodata values")\n                continue;\n            elif (cm.checkOutSeasonCrops(current_cdl, month)):\n                # print("tile ", i, " ", j, " is skipped because it is out of season")\n                continue;\n            else:\n                # print(current_tile1)\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band1.tif", current_tile1);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band2.tif", current_tile2);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band3.tif", current_tile3);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band4.tif", current_tile4);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band5.tif", current_tile5);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band6.tif", current_tile6);\n                imageio.imwrite(input_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_band7.tif", current_tile7);\n                imageio.imwrite(target_folder + tile + "_" + str(date) + "_" + str(i) + "_" + str(j) + "_cdl.tif", current_cdl);\n                # print("tile ", i, " ", j, " is valid")\n                # current_tile1 = np.expand_dims(current_tile1, axis=2)\n                # current_tile2 = np.expand_dims(current_tile2, axis=2)\n                # current_tile3 = np.expand_dims(current_tile3, axis=2)\n                # current_tile4 = np.expand_dims(current_tile4, axis=2)\n                # current_tile5 = np.expand_dims(current_tile5, axis=2)\n                # current_tile6 = np.expand_dims(current_tile6, axis=2)\n                # current_tile7 = np.expand_dims(current_tile7, axis=2)\n                # # current_ndvi = np.expand_dims(current_ndvi, axis=2)\n                # current_cdl = np.expand_dims(current_cdl, axis=2)\n                #\n                # combine_tensor = np.concatenate((current_tile1, current_tile2, current_tile3, current_tile4,\n                #                                  current_tile5, current_tile6, current_tile7), axis=2)\n                # combine_tensor = np.expand_dims(combine_tensor,\n                #                                 axis=0)  # (1, height, width, channels), add a dimension because the\n                # # model expects this shape: (batch_size, height, width, channels)\n                # #                                   axis=0)  # (1, 1, height, width, channels), add a dimension because\n                # # the model expects this shape: (batch_size, time, height, width, channels)\n                # if (cm.NN == "ConvLSTM"):\n                #\n                #     if (len(cm.input_tensor) == 0):\n                #\n                #         cm.input_tensor = combine_tensor;\n                #\n                #     else:\n                #\n                #         cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor),\n                #                                          axis=0);  # use batch to combine multiple images. Each batch only\n                #         # has one step, which is the sequence to sequence mode.\n                #\n                #     # cdl_array = np.ravel(cdl_array, \'c\')\n                #\n                #     cdl_array = keras.utils.to_categorical(current_cdl, num_classes=256)\n                #\n                #     cdl_array = np.expand_dims(cdl_array,\n                #                                axis=0)  # add time dimensions: (time, height, width, channels)\n                #\n                #     cdl_array = np.expand_dims(cdl_array, axis=0)\n                #\n                #     if (len(cm.cdl_tensor) == 0):\n                #\n                #         cm.cdl_tensor = cdl_array\n                #\n                #     else:\n                #\n                #         cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array),\n                #                                        axis=0);  # the new image will be a new batch\n                #\n                # #    i_array[cm.cdl_tensor.shape[0]] = i\n                #\n                # #    j_array[cm.cdl_tensor.shape[0]] = j\n                #\n                # elif (cm.NN == "SegNet"):\n                #\n                #     # combine_tensor = np.expand_dims(combine_tensor,\n                #     #                                 axis=0)  # (1, 1, height, width, channels), add a dimension because\n                #     #  the model expects this shape: (batch_size, time, height, width, channels)\n                #\n                #     # else:\n                #     #\n                #     #     cm.input_tensor = np.concatenate((input_tensor, combine_tensor), axis=0);\n                #\n                #     # cdl_array = image.img_to_array(cdlimg)  # (height, width, channels)\n                #\n                #     cdl_array = np.ravel(current_cdl, \'c\')\n                #     cdl_array = keras.utils.to_categorical(cdl_array, num_classes=256)\n                #     cdl_array = np.expand_dims(cdl_array,\n                #                                axis=0)  # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n                #\n                #     if (len(cm.input_tensor) == 0):\n                #\n                #         cm.input_tensor = combine_tensor\n                #\n                #         cm.cdl_tensor = cdl_array\n                #\n                #     else:\n                #\n                #         cm.input_tensor = np.concatenate((cm.input_tensor, combine_tensor), axis=0);\n                #\n                #         cm.cdl_tensor = np.concatenate((cm.cdl_tensor, cdl_array), axis=0)\n\n                # if cm.cdl_tensor.shape[0] != batch_size:\n                #     continue;\n\n                # i_array[cm.cdl_tensor.shape[0]-1] = i\n                #\n                # j_array[cm.cdl_tensor.shape[0]-1] = j\n                #\n                # model.fit(cm.input_tensor, cm.cdl_tensor, validation_split=0.125, batch_size=batch_size, epochs=1,\n                #           callbacks=[])\n                #\n                # predict_output = model.predict(cm.input_tensor, batch_size=batch_size, verbose=0)\n                # print("Predict Output Shape: ", predict_output.shape)\n\n                # y_pred = np.argmax(predict_output, axis=1)\n\n                # for x in range(batch_size):\n                #\n                #     predict_output_single = cm.reshapePredictOutput(predict_output[x])\n                #\n                #     seg_img = np.zeros((cm.img_height, cm.img_width, 3))\n                #     # colors = [  ( np.random.randint(0,255),\n                #     #               np.random.randint(0,255),\n                #     #               np.random.randint(0,255)   ) for _ in range(n_classes)  ]\n                #     for c in range(cm.n_classes):\n                #         seg_img[:, :, 0] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[0])).astype(\'uint8\')\n                #         seg_img[:, :, 1] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[1])).astype(\'uint8\')\n                #         seg_img[:, :, 2] += ((predict_output_single[:, :] == c) * (getCDLRGB(c)[2])).astype(\'uint8\')\n                #\n                #     # save the predicted results to file\n                #     # seg_img = cv2.resize(seg_img, (360, 360))\n                #     # print(seg_img.shape)\n                #     # saveimg = seg_img[..., ::-1]\n                #     # cv2.imwrite(cm.saveimgpath, saveimg)\n                #\n                #     # predict_cdl[i * 360:(i + 1) * 360, j * 360:(j + 1) * 360] = predict_output;\n                #     predict_cdl[int(i_array[x]) * cm.img_width:(int(i_array[x]) + 1) * cm.img_width,\n                #     int(j_array[x]) * cm.img_height:(int(j_array[x]) + 1) * cm.img_height, :] = seg_img;\n\n                # cm.input_tensor = [];\n                #\n                # cm.cdl_tensor = [];\n\n        # savemodel = model.get_layer(\'sequential_1\')\n\n        # predict_cdl = cv2.resize(predict_cdl, imarraymask.shape)\n        #\n        # predict_cdl = predict_cdl[..., ::-1]\n        #\n        # saveimgpath = cm.folder + "/data/cdl/" + cm.NN + "_output_" + tile + "_" + str(date) + "_epoch_" + str(n) + ".jpg";\n        #\n        # print("save predicted picture", saveimgpath)\n        #\n        # cv2.imwrite(saveimgpath, predict_cdl)\n        #\n        # cm.model.save(cm.modelpath)  # save the model every epoch - must save the merged CPU model\n        #\n        # model.save(cm.modelpath + "_parallel.net")\n\n# firsttileimg = Image.fromarray(firsttile)\n# firsttileimg.show()\n\nelapsed_time = time.time() - start_time\nprint("total time cost: ", elapsed_time)\n\n\n', 'python', NULL, NULL, NULL, NULL),
	('j9pxl1', 'deep-learning-tutorial', '{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["\'2.0.8\'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import keras\\n","keras.__version__"]},{"cell_type":"markdown","metadata":{},"source":["# Classifying movie reviews: a binary classification example\\n","\\n","This notebook contains the code samples found in Chapter 3, Section 5 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\\n","\\n","----\\n","\\n","\\n","Two-class classification, or binary classification, may be the most widely applied kind of machine learning problem. In this example, we \\n","will learn to classify movie reviews into \\"positive\\" reviews and \\"negative\\" reviews, just based on the text content of the reviews."]},{"cell_type":"markdown","metadata":{},"source":["## The IMDB dataset\\n","\\n","\\n","We\'ll be working with \\"IMDB dataset\\", a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 \\n","reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews.\\n","\\n","Why do we have these two separate training and test sets? You should never test a machine learning model on the same data that you used to \\n","train it! Just because a model performs well on its training data doesn\'t mean that it will perform well on data it has never seen, and \\n","what you actually care about is your model\'s performance on new data (since you already know the labels of your training data -- obviously \\n","you don\'t need your model to predict those). For instance, it is possible that your model could end up merely _memorizing_ a mapping between \\n","your training samples and their targets -- which would be completely useless for the task of predicting targets for data never seen before. \\n","We will go over this point in much more detail in the next chapter.\\n","\\n","Just like the MNIST dataset, the IMDB dataset comes packaged with Keras. It has already been preprocessed: the reviews (sequences of words) \\n","have been turned into sequences of integers, where each integer stands for a specific word in a dictionary.\\n","\\n","The following code will load the dataset (when you run it for the first time, about 80MB of data will be downloaded to your machine):"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":true},"outputs":[],"source":["from keras.datasets import imdb\\n","\\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"]},{"cell_type":"markdown","metadata":{},"source":["\\n","The argument `num_words=10000` means that we will only keep the top 10,000 most frequently occurring words in the training data. Rare words \\n","will be discarded. This allows us to work with vector data of manageable size.\\n","\\n","The variables `train_data` and `test_data` are lists of reviews, each review being a list of word indices (encoding a sequence of words). \\n","`train_labels` and `test_labels` are lists of 0s and 1s, where 0 stands for \\"negative\\" and 1 stands for \\"positive\\":"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["[1,\\n"," 14,\\n"," 22,\\n"," 16,\\n"," 43,\\n"," 530,\\n"," 973,\\n"," 1622,\\n"," 1385,\\n"," 65,\\n"," 458,\\n"," 4468,\\n"," 66,\\n"," 3941,\\n"," 4,\\n"," 173,\\n"," 36,\\n"," 256,\\n"," 5,\\n"," 25,\\n"," 100,\\n"," 43,\\n"," 838,\\n"," 112,\\n"," 50,\\n"," 670,\\n"," 2,\\n"," 9,\\n"," 35,\\n"," 480,\\n"," 284,\\n"," 5,\\n"," 150,\\n"," 4,\\n"," 172,\\n"," 112,\\n"," 167,\\n"," 2,\\n"," 336,\\n"," 385,\\n"," 39,\\n"," 4,\\n"," 172,\\n"," 4536,\\n"," 1111,\\n"," 17,\\n"," 546,\\n"," 38,\\n"," 13,\\n"," 447,\\n"," 4,\\n"," 192,\\n"," 50,\\n"," 16,\\n"," 6,\\n"," 147,\\n"," 2025,\\n"," 19,\\n"," 14,\\n"," 22,\\n"," 4,\\n"," 1920,\\n"," 4613,\\n"," 469,\\n"," 4,\\n"," 22,\\n"," 71,\\n"," 87,\\n"," 12,\\n"," 16,\\n"," 43,\\n"," 530,\\n"," 38,\\n"," 76,\\n"," 15,\\n"," 13,\\n"," 1247,\\n"," 4,\\n"," 22,\\n"," 17,\\n"," 515,\\n"," 17,\\n"," 12,\\n"," 16,\\n"," 626,\\n"," 18,\\n"," 2,\\n"," 5,\\n"," 62,\\n"," 386,\\n"," 12,\\n"," 8,\\n"," 316,\\n"," 8,\\n"," 106,\\n"," 5,\\n"," 4,\\n"," 2223,\\n"," 5244,\\n"," 16,\\n"," 480,\\n"," 66,\\n"," 3785,\\n"," 33,\\n"," 4,\\n"," 130,\\n"," 12,\\n"," 16,\\n"," 38,\\n"," 619,\\n"," 5,\\n"," 25,\\n"," 124,\\n"," 51,\\n"," 36,\\n"," 135,\\n"," 48,\\n"," 25,\\n"," 1415,\\n"," 33,\\n"," 6,\\n"," 22,\\n"," 12,\\n"," 215,\\n"," 28,\\n"," 77,\\n"," 52,\\n"," 5,\\n"," 14,\\n"," 407,\\n"," 16,\\n"," 82,\\n"," 2,\\n"," 8,\\n"," 4,\\n"," 107,\\n"," 117,\\n"," 5952,\\n"," 15,\\n"," 256,\\n"," 4,\\n"," 2,\\n"," 7,\\n"," 3766,\\n"," 5,\\n"," 723,\\n"," 36,\\n"," 71,\\n"," 43,\\n"," 530,\\n"," 476,\\n"," 26,\\n"," 400,\\n"," 317,\\n"," 46,\\n"," 7,\\n"," 4,\\n"," 2,\\n"," 1029,\\n"," 13,\\n"," 104,\\n"," 88,\\n"," 4,\\n"," 381,\\n"," 15,\\n"," 297,\\n"," 98,\\n"," 32,\\n"," 2071,\\n"," 56,\\n"," 26,\\n"," 141,\\n"," 6,\\n"," 194,\\n"," 7486,\\n"," 18,\\n"," 4,\\n"," 226,\\n"," 22,\\n"," 21,\\n"," 134,\\n"," 476,\\n"," 26,\\n"," 480,\\n"," 5,\\n"," 144,\\n"," 30,\\n"," 5535,\\n"," 18,\\n"," 51,\\n"," 36,\\n"," 28,\\n"," 224,\\n"," 92,\\n"," 25,\\n"," 104,\\n"," 4,\\n"," 226,\\n"," 65,\\n"," 16,\\n"," 38,\\n"," 1334,\\n"," 88,\\n"," 12,\\n"," 16,\\n"," 283,\\n"," 5,\\n"," 16,\\n"," 4472,\\n"," 113,\\n"," 103,\\n"," 32,\\n"," 15,\\n"," 16,\\n"," 5345,\\n"," 19,\\n"," 178,\\n"," 32]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[0]"]},{"cell_type":"markdown","metadata":{},"source":["Since we restricted ourselves to the top 10,000 most frequent words, no word index will exceed 10,000:"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["9999"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["max([max(sequence) for sequence in train_data])"]},{"cell_type":"markdown","metadata":{},"source":["For kicks, here\'s how you can quickly decode one of these reviews back to English words:"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":true},"outputs":[],"source":["# word_index is a dictionary mapping words to an integer index\\n","word_index = imdb.get_word_index()\\n","# We reverse it, mapping integer indices to words\\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\\n","# We decode the review; note that our indices were offset by 3\\n","# because 0, 1 and 2 are reserved indices for \\"padding\\", \\"start of sequence\\", and \\"unknown\\".\\n","decoded_review = \' \'.join([reverse_word_index.get(i - 3, \'?\') for i in train_data[0]])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["\\"? this film was just brilliant casting location scenery story direction everyone\'s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy\'s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don\'t you think the whole story was so lovely because it was true and was someone\'s life after all that was shared with us all\\""]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["decoded_review"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing the data\\n","\\n","\\n","We cannot feed lists of integers into a neural network. We have to turn our lists into tensors. There are two ways we could do that:\\n","\\n","* We could pad our lists so that they all have the same length, and turn them into an integer tensor of shape `(samples, word_indices)`, \\n","then use as first layer in our network a layer capable of handling such integer tensors (the `Embedding` layer, which we will cover in \\n","detail later in the book).\\n","* We could one-hot-encode our lists to turn them into vectors of 0s and 1s. Concretely, this would mean for instance turning the sequence \\n","`[3, 5]` into a 10,000-dimensional vector that would be all-zeros except for indices 3 and 5, which would be ones. Then we could use as \\n","first layer in our network a `Dense` layer, capable of handling floating point vector data.\\n","\\n","We will go with the latter solution. Let\'s vectorize our data, which we will do manually for maximum clarity:"]},{"cell_type":"code","execution_count":27,"metadata":{"collapsed":true},"outputs":[],"source":["import numpy as np\\n","\\n","def vectorize_sequences(sequences, dimension=10000):\\n","    # Create an all-zero matrix of shape (len(sequences), dimension)\\n","    results = np.zeros((len(sequences), dimension))\\n","    for i, sequence in enumerate(sequences):\\n","        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\\n","    return results\\n","\\n","# Our vectorized training data\\n","x_train = vectorize_sequences(train_data)\\n","# Our vectorized test data\\n","x_test = vectorize_sequences(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["Here\'s what our samples look like now:"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 0.,  1.,  1., ...,  0.,  0.,  0.])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0]"]},{"cell_type":"markdown","metadata":{},"source":["We should also vectorize our labels, which is straightforward:"]},{"cell_type":"code","execution_count":29,"metadata":{"collapsed":true},"outputs":[],"source":["# Our vectorized labels\\n","y_train = np.asarray(train_labels).astype(\'float32\')\\n","y_test = np.asarray(test_labels).astype(\'float32\')"]},{"cell_type":"markdown","metadata":{},"source":["Now our data is ready to be fed into a neural network."]},{"cell_type":"markdown","metadata":{},"source":["## Building our network\\n","\\n","\\n","Our input data is simply vectors, and our labels are scalars (1s and 0s): this is the easiest setup you will ever encounter. A type of \\n","network that performs well on such a problem would be a simple stack of fully-connected (`Dense`) layers with `relu` activations: `Dense(16, \\n","activation=\'relu\')`\\n","\\n","The argument being passed to each `Dense` layer (16) is the number of \\"hidden units\\" of the layer. What\'s a hidden unit? It\'s a dimension \\n","in the representation space of the layer. You may remember from the previous chapter that each such `Dense` layer with a `relu` activation implements \\n","the following chain of tensor operations:\\n","\\n","`output = relu(dot(W, input) + b)`\\n","\\n","Having 16 hidden units means that the weight matrix `W` will have shape `(input_dimension, 16)`, i.e. the dot product with `W` will project the \\n","input data onto a 16-dimensional representation space (and then we would add the bias vector `b` and apply the `relu` operation). You can \\n","intuitively understand the dimensionality of your representation space as \\"how much freedom you are allowing the network to have when \\n","learning internal representations\\". Having more hidden units (a higher-dimensional representation space) allows your network to learn more \\n","complex representations, but it makes your network more computationally expensive and may lead to learning unwanted patterns (patterns that \\n","will improve performance on the training data but not on the test data).\\n","\\n","There are two key architecture decisions to be made about such stack of dense layers:\\n","\\n","* How many layers to use.\\n","* How many \\"hidden units\\" to chose for each layer.\\n","\\n","In the next chapter, you will learn formal principles to guide you in making these choices. \\n","For the time being, you will have to trust us with the following architecture choice: \\n","two intermediate layers with 16 hidden units each, \\n","and a third layer which will output the scalar prediction regarding the sentiment of the current review. \\n","The intermediate layers will use `relu` as their \\"activation function\\", \\n","and the final layer will use a sigmoid activation so as to output a probability \\n","(a score between 0 and 1, indicating how likely the sample is to have the target \\"1\\", i.e. how likely the review is to be positive). \\n","A `relu` (rectified linear unit) is a function meant to zero-out negative values, \\n","while a sigmoid \\"squashes\\" arbitrary values into the `[0, 1]` interval, thus outputting something that can be interpreted as a probability."]},{"cell_type":"markdown","metadata":{},"source":["Here\'s what our network looks like:\\n","\\n","![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"]},{"cell_type":"markdown","metadata":{},"source":["And here\'s the Keras implementation, very similar to the MNIST example you saw previously:"]},{"cell_type":"code","execution_count":30,"metadata":{"collapsed":true},"outputs":[],"source":["from keras import models\\n","from keras import layers\\n","\\n","model = models.Sequential()\\n","model.add(layers.Dense(16, activation=\'relu\', input_shape=(10000,)))\\n","model.add(layers.Dense(16, activation=\'relu\'))\\n","model.add(layers.Dense(1, activation=\'sigmoid\'))"]},{"cell_type":"markdown","metadata":{},"source":["\\n","Lastly, we need to pick a loss function and an optimizer. Since we are facing a binary classification problem and the output of our network \\n","is a probability (we end our network with a single-unit layer with a sigmoid activation), is it best to use the `binary_crossentropy` loss. \\n","It isn\'t the only viable choice: you could use, for instance, `mean_squared_error`. But crossentropy is usually the best choice when you \\n","are dealing with models that output probabilities. Crossentropy is a quantity from the field of Information Theory, that measures the \\"distance\\" \\n","between probability distributions, or in our case, between the ground-truth distribution and our predictions.\\n","\\n","Here\'s the step where we configure our model with the `rmsprop` optimizer and the `binary_crossentropy` loss function. Note that we will \\n","also monitor accuracy during training."]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":true},"outputs":[],"source":["model.compile(optimizer=\'rmsprop\',\\n","              loss=\'binary_crossentropy\',\\n","              metrics=[\'accuracy\'])"]},{"cell_type":"markdown","metadata":{},"source":["We are passing our optimizer, loss function and metrics as strings, which is possible because `rmsprop`, `binary_crossentropy` and \\n","`accuracy` are packaged as part of Keras. Sometimes you may want to configure the parameters of your optimizer, or pass a custom loss \\n","function or metric function. This former can be done by passing an optimizer class instance as the `optimizer` argument:"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true},"outputs":[],"source":["from keras import optimizers\\n","\\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\\n","              loss=\'binary_crossentropy\',\\n","              metrics=[\'accuracy\'])"]},{"cell_type":"markdown","metadata":{},"source":["The latter can be done by passing function objects as the `loss` or `metrics` arguments:"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true},"outputs":[],"source":["from keras import losses\\n","from keras import metrics\\n","\\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\\n","              loss=losses.binary_crossentropy,\\n","              metrics=[metrics.binary_accuracy])"]},{"cell_type":"markdown","metadata":{},"source":["## Validating our approach\\n","\\n","In order to monitor during training the accuracy of the model on data that it has never seen before, we will create a \\"validation set\\" by \\n","setting apart 10,000 samples from the original training data:"]},{"cell_type":"code","execution_count":32,"metadata":{"collapsed":true},"outputs":[],"source":["x_val = x_train[:10000]\\n","partial_x_train = x_train[10000:]\\n","\\n","y_val = y_train[:10000]\\n","partial_y_train = y_train[10000:]"]},{"cell_type":"markdown","metadata":{"collapsed":true},"source":["We will now train our model for 20 epochs (20 iterations over all samples in the `x_train` and `y_train` tensors), in mini-batches of 512 \\n","samples. At this same time we will monitor loss and accuracy on the 10,000 samples that we set apart. This is done by passing the \\n","validation data as the `validation_data` argument:"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 15000 samples, validate on 10000 samples\\n","Epoch 1/20\\n","15000/15000 [==============================] - 1s - loss: 0.5103 - acc: 0.7911 - val_loss: 0.4016 - val_acc: 0.8628\\n","Epoch 2/20\\n","15000/15000 [==============================] - 1s - loss: 0.3110 - acc: 0.9031 - val_loss: 0.3085 - val_acc: 0.8870\\n","Epoch 3/20\\n","15000/15000 [==============================] - 1s - loss: 0.2309 - acc: 0.9235 - val_loss: 0.2803 - val_acc: 0.8908\\n","Epoch 4/20\\n","15000/15000 [==============================] - 1s - loss: 0.1795 - acc: 0.9428 - val_loss: 0.2735 - val_acc: 0.8893\\n","Epoch 5/20\\n","15000/15000 [==============================] - 1s - loss: 0.1475 - acc: 0.9526 - val_loss: 0.2788 - val_acc: 0.8890\\n","Epoch 6/20\\n","15000/15000 [==============================] - 1s - loss: 0.1185 - acc: 0.9638 - val_loss: 0.3330 - val_acc: 0.8764\\n","Epoch 7/20\\n","15000/15000 [==============================] - 1s - loss: 0.1005 - acc: 0.9703 - val_loss: 0.3055 - val_acc: 0.8838\\n","Epoch 8/20\\n","15000/15000 [==============================] - 1s - loss: 0.0818 - acc: 0.9773 - val_loss: 0.3344 - val_acc: 0.8769\\n","Epoch 9/20\\n","15000/15000 [==============================] - 1s - loss: 0.0696 - acc: 0.9814 - val_loss: 0.3607 - val_acc: 0.8800\\n","Epoch 10/20\\n","15000/15000 [==============================] - 1s - loss: 0.0547 - acc: 0.9873 - val_loss: 0.3776 - val_acc: 0.8785\\n","Epoch 11/20\\n","15000/15000 [==============================] - 1s - loss: 0.0453 - acc: 0.9895 - val_loss: 0.4035 - val_acc: 0.8765\\n","Epoch 12/20\\n","15000/15000 [==============================] - 1s - loss: 0.0353 - acc: 0.9930 - val_loss: 0.4437 - val_acc: 0.8766\\n","Epoch 13/20\\n","15000/15000 [==============================] - 1s - loss: 0.0269 - acc: 0.9956 - val_loss: 0.4637 - val_acc: 0.8747\\n","Epoch 14/20\\n","15000/15000 [==============================] - 1s - loss: 0.0212 - acc: 0.9968 - val_loss: 0.4877 - val_acc: 0.8714\\n","Epoch 15/20\\n","15000/15000 [==============================] - 1s - loss: 0.0162 - acc: 0.9977 - val_loss: 0.6080 - val_acc: 0.8625\\n","Epoch 16/20\\n","15000/15000 [==============================] - 1s - loss: 0.0115 - acc: 0.9993 - val_loss: 0.5778 - val_acc: 0.8698\\n","Epoch 17/20\\n","15000/15000 [==============================] - 1s - loss: 0.0116 - acc: 0.9979 - val_loss: 0.5906 - val_acc: 0.8702\\n","Epoch 18/20\\n","15000/15000 [==============================] - 1s - loss: 0.0054 - acc: 0.9998 - val_loss: 0.6204 - val_acc: 0.8639\\n","Epoch 19/20\\n","15000/15000 [==============================] - 1s - loss: 0.0083 - acc: 0.9984 - val_loss: 0.6419 - val_acc: 0.8676\\n","Epoch 20/20\\n","15000/15000 [==============================] - 1s - loss: 0.0031 - acc: 0.9998 - val_loss: 0.6796 - val_acc: 0.8683\\n"]}],"source":["history = model.fit(partial_x_train,\\n","                    partial_y_train,\\n","                    epochs=20,\\n","                    batch_size=512,\\n","                    validation_data=(x_val, y_val))"]},{"cell_type":"markdown","metadata":{},"source":["On CPU, this will take less than two seconds per epoch -- training is over in 20 seconds. At the end of every epoch, there is a slight pause \\n","as the model computes its loss and accuracy on the 10,000 samples of the validation data.\\n","\\n","Note that the call to `model.fit()` returns a `History` object. This object has a member `history`, which is a dictionary containing data \\n","about everything that happened during training. Let\'s take a look at it:"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["dict_keys([\'val_acc\', \'acc\', \'val_loss\', \'loss\'])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["history_dict = history.history\\n","history_dict.keys()"]},{"cell_type":"markdown","metadata":{},"source":["It contains 4 entries: one per metric that was being monitored, during training and during validation. Let\'s use Matplotlib to plot the \\n","training and validation loss side by side, as well as the training and validation accuracy:"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\\n","text/plain":["<matplotlib.figure.Figure at 0x7f9e8b6b6588>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\\n","\\n","acc = history.history[\'acc\']\\n","val_acc = history.history[\'val_acc\']\\n","loss = history.history[\'loss\']\\n","val_loss = history.history[\'val_loss\']\\n","\\n","epochs = range(1, len(acc) + 1)\\n","\\n","# \\"bo\\" is for \\"blue dot\\"\\n","plt.plot(epochs, loss, \'bo\', label=\'Training loss\')\\n","# b is for \\"solid blue line\\"\\n","plt.plot(epochs, val_loss, \'b\', label=\'Validation loss\')\\n","plt.title(\'Training and validation loss\')\\n","plt.xlabel(\'Epochs\')\\n","plt.ylabel(\'Loss\')\\n","plt.legend()\\n","\\n","plt.show()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\\n","text/plain":["<matplotlib.figure.Figure at 0x7f9e8b6b6080>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.clf()   # clear figure\\n","acc_values = history_dict[\'acc\']\\n","val_acc_values = history_dict[\'val_acc\']\\n","\\n","plt.plot(epochs, acc, \'bo\', label=\'Training acc\')\\n","plt.plot(epochs, val_acc, \'b\', label=\'Validation acc\')\\n","plt.title(\'Training and validation accuracy\')\\n","plt.xlabel(\'Epochs\')\\n","plt.ylabel(\'Loss\')\\n","plt.legend()\\n","\\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\\n","The dots are the training loss and accuracy, while the solid lines are the validation loss and accuracy. Note that your own results may vary \\n","slightly due to a different random initialization of your network.\\n","\\n","As you can see, the training loss decreases with every epoch and the training accuracy increases with every epoch. That\'s what you would \\n","expect when running gradient descent optimization -- the quantity you are trying to minimize should get lower with every iteration. But that \\n","isn\'t the case for the validation loss and accuracy: they seem to peak at the fourth epoch. This is an example of what we were warning \\n","against earlier: a model that performs better on the training data isn\'t necessarily a model that will do better on data it has never seen \\n","before. In precise terms, what you are seeing is \\"overfitting\\": after the second epoch, we are over-optimizing on the training data, and we \\n","ended up learning representations that are specific to the training data and do not generalize to data outside of the training set.\\n","\\n","In this case, to prevent overfitting, we could simply stop training after three epochs. In general, there is a range of techniques you can \\n","leverage to mitigate overfitting, which we will cover in the next chapter.\\n","\\n","Let\'s train a new network from scratch for four epochs, then evaluate it on our test data:"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\\n","25000/25000 [==============================] - 1s - loss: 0.4738 - acc: 0.8044     \\n","Epoch 2/4\\n","25000/25000 [==============================] - 1s - loss: 0.2660 - acc: 0.9076     \\n","Epoch 3/4\\n","25000/25000 [==============================] - 1s - loss: 0.2028 - acc: 0.9277     \\n","Epoch 4/4\\n","25000/25000 [==============================] - 1s - loss: 0.1700 - acc: 0.9397     \\n","24544/25000 [============================>.] - ETA: 0s"]}],"source":["model = models.Sequential()\\n","model.add(layers.Dense(16, activation=\'relu\', input_shape=(10000,)))\\n","model.add(layers.Dense(16, activation=\'relu\'))\\n","model.add(layers.Dense(1, activation=\'sigmoid\'))\\n","\\n","model.compile(optimizer=\'rmsprop\',\\n","              loss=\'binary_crossentropy\',\\n","              metrics=[\'accuracy\'])\\n","\\n","model.fit(x_train, y_train, epochs=4, batch_size=512)\\n","results = model.evaluate(x_test, y_test)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["[0.29184698499679568, 0.88495999999999997]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"markdown","metadata":{},"source":["Our fairly naive approach achieves an accuracy of 88%. With state-of-the-art approaches, one should be able to get close to 95%."]},{"cell_type":"markdown","metadata":{},"source":["## Using a trained network to generate predictions on new data\\n","\\n","After having trained a network, you will want to use it in a practical setting. You can generate the likelihood of reviews being positive \\n","by using the `predict` method:"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.91966152],\\n","       [ 0.86563045],\\n","       [ 0.99936908],\\n","       ..., \\n","       [ 0.45731062],\\n","       [ 0.0038014 ],\\n","       [ 0.79525089]], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(x_test)"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, the network is very confident for some samples (0.99 or more, or 0.01 or less) but less confident for others (0.6, 0.4). \\n"]},{"cell_type":"markdown","metadata":{},"source":["## Further experiments\\n","\\n","\\n","* We were using 2 hidden layers. Try to use 1 or 3 hidden layers and see how it affects validation and test accuracy.\\n","* Try to use layers with more hidden units or less hidden units: 32 units, 64 units...\\n","* Try to use the `mse` loss function instead of `binary_crossentropy`.\\n","* Try to use the `tanh` activation (an activation that was popular in the early days of neural networks) instead of `relu`.\\n","\\n","These experiments will help convince you that the architecture choices we have made are all fairly reasonable, although they can still be \\n","improved!"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusions\\n","\\n","\\n","Here\'s what you should take away from this example:\\n","\\n","* There\'s usually quite a bit of preprocessing you need to do on your raw data in order to be able to feed it -- as tensors -- into a neural \\n","network. In the case of sequences of words, they can be encoded as binary vectors -- but there are other encoding options too.\\n","* Stacks of `Dense` layers with `relu` activations can solve a wide range of problems (including sentiment classification), and you will \\n","likely use them frequently.\\n","* In a binary classification problem (two output classes), your network should end with a `Dense` layer with 1 unit and a `sigmoid` activation, \\n","i.e. the output of your network should be a scalar between 0 and 1, encoding a probability.\\n","* With such a scalar sigmoid output, on a binary classification problem, the loss function you should use is `binary_crossentropy`.\\n","* The `rmsprop` optimizer is generally a good enough choice of optimizer, whatever your problem. That\'s one less thing for you to worry \\n","about.\\n","* As they get better on their training data, neural networks eventually start _overfitting_ and end up obtaining increasingly worse results on data \\n","never-seen-before. Make sure to always monitor performance on data that is outside of the training set.\\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":2}', 'jupyter', NULL, NULL, NULL, NULL),
	('jnzsga', 'test-url-category', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'jupyter', NULL, NULL, NULL, NULL),
	('m6bbrf', 'test_segnet', '#!/bin/bash\n#write your bash script\necho "test segnet"', 'shell', NULL, NULL, NULL, NULL),
	('nhi96d', 'download-landsat', '#!/bin/bash\n# download landsat data from geobrain\n\nmkdir /home/zsun/crop-oh/\n\nmkdir /home/zsun/crop-oh/landsat-2/\n\ncd /home/zsun/crop-oh/landsat-2/\n\ndownload_espa_order.py -u szhwhu@gmail.com  -e szhwhu@gmail.com -p Data123456789. -o espa-szhwhu@gmail.com-0101907010724 -d .\n\necho "download complete"', 'shell', NULL, NULL, NULL, NULL),
	('omop8l', 'match_cdl_landsat', '#!/bin/bash\nsleep 10s', 'shell', NULL, NULL, NULL, NULL),
	('qp820f', 'reprojection', '#!/bin/bash', 'shell', NULL, NULL, NULL, NULL),
	('rh1u8q', 'filter_cloud', '#!/bin/bash\necho "filter cloud"', 'shell', NULL, NULL, NULL, NULL),
	('rpnhlg', 'filter_shadow', '#!/bin/bash\necho "remove shadow pixels"', 'shell', NULL, NULL, NULL, NULL),
	('s8fh2z', 'Reproject', '#!/bin/bash\n#write your bash script\ncd /home/zsun/\ngdalinfo', 'shell', NULL, NULL, NULL, NULL),
	('spz3b5', 'rescale_cdl', '#!/bin/bash', 'shell', NULL, NULL, NULL, NULL),
	('t0cqqj', 'daily_aggregation', '{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false},"outputs":[],"source":["%matplotlib inline\\n","import os\\n","import sys\\n","module_path = os.path.abspath(os.path.join(\'..\'))\\n","if module_path not in sys.path:\\n","    sys.path.append(module_path)\\n","import pandas as pd\\n","import numpy as np\\n","import sqlite3\\n","from main_db_script import db_filename\\n","from hr_db_scripts.main_db_script import get_table_for_variable_code, get_db_table_as_df"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true},"outputs":[],"source":["def round_down_near_24(datetimes): # round down the times near midnight so the tide levels stay on the correct day\\n","    close_time_idx = datetimes.indexer_between_time(\'23:29\', \'23:59\')\\n","    adjusted_times = datetimes[close_time_idx] - pd.Timedelta(minutes=15)\\n","    dt = pd.Series(datetimes)\\n","    dt[close_time_idx] = adjusted_times\\n","    dt = pd.DatetimeIndex(dt)\\n","    return dt"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true},"outputs":[],"source":["def cln_n_rnd_times(df):\\n","    for i in range(df.shape[1]):\\n","        datetimes = df.iloc[:, i]\\n","        times = pd.DatetimeIndex(datetimes)\\n","        rnd_dn = round_down_near_24(times)\\n","        df.iloc[:, i] = rnd_dn\\n","    return df"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false},"outputs":[],"source":["def pivot_dv_df(df):\\n","    return df.pivot(columns=\'SiteID\', values=\'Value\')"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true},"outputs":[],"source":["def rename_cols(df, var_abbrev):\\n","    if var_abbrev != \\"\\":\\n","        new_df = df.copy()\\n","        cols = df.columns.tolist()\\n","        new_cols = [\'{}-{}\'.format(var_abbrev, c) for c in cols]\\n","        new_df.columns = new_cols\\n","        return new_df\\n","    else:\\n","        return df"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true},"outputs":[],"source":["def filter_max_rain_time_dfs(rain_daily_df, time_df):\\n","    timemx_filt = pd.DataFrame(np.where(rain_daily_df>0, time_df, np.datetime64(\'NaT\')))\\n","    timemx_filt.columns = time_df.columns\\n","    timemx_filt.index = time_df.index\\n","    return timemx_filt"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true},"outputs":[],"source":["def tide_when_rain_max(rn_mx_time_df):\\n","    td_df = get_table_for_variable_code(\'six_min_tide\')\\n","    td_df = pivot_dv_df(td_df)\\n","    td_df = td_df.resample(\'15T\').mean()\\n","    rn_mx_time_rnd = cln_n_rnd_times(rn_mx_time_df)\\n","    l = []\\n","    for c in rn_mx_time_rnd.columns:\\n","        times = rn_mx_time_rnd.loc[:, c]\\n","        tides = td_df.loc[times].resample(\'D\').max()\\n","        rain_var = c.split(\'_\')[0]\\n","        rain_site = c.split(\'-\')[-1]\\n","        new_cols = [\'{}-{}_td-{}\'.format(rain_var, rain_site, col) for col in tides.columns]\\n","        tides.columns = new_cols\\n","        l.append(tides)\\n","    new_df = pd.concat(l, axis=1)\\n","    new_df.sort_index(inplace=True)\\n","    return new_df"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true},"outputs":[],"source":["def daily_pivot_table(var_code, agg_function, abbreviation):\\n","    df = get_table_for_variable_code(var_code)\\n","    dfp = pivot_dv_df(df)\\n","    dfd = dfp.resample(\'D\')\\n","    aggrd = dfd.agg(agg_function)\\n","    rnmed = rename_cols(aggrd, abbreviation)\\n","    return rnmed"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true},"outputs":[],"source":["sites = get_db_table_as_df(\'sites\')"]},{"cell_type":"markdown","metadata":{},"source":["#  Rainfall"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true},"outputs":[],"source":["# get rainfall data at 15 min interval\\n","rain_df = get_table_for_variable_code(\'rainfall\')"]},{"cell_type":"markdown","metadata":{},"source":["## Daily Rainfall"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rd-19</th>\\n","      <th>rd-20</th>\\n","      <th>rd-1</th>\\n","      <th>rd-2</th>\\n","      <th>rd-7</th>\\n","      <th>rd-11</th>\\n","      <th>rd-12</th>\\n","      <th>rd-13</th>\\n","      <th>rd-14</th>\\n","      <th>rd-15</th>\\n","      <th>rd-16</th>\\n","      <th>rd-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.05</td>\\n","      <td>0.03</td>\\n","      <td>0.06</td>\\n","      <td>0.02</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","      <td>0.03</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.01</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.02</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.10</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.12</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            rd-19  rd-20  rd-1  rd-2  rd-7  rd-11  rd-12  rd-13  rd-14  rd-15  \\\\\\n","Datetime                                                                        \\n","2010-01-01   0.01   0.01   NaN   NaN  0.05   0.03   0.06   0.02   0.01   0.01   \\n","2010-01-02   0.00   0.00   NaN   NaN  0.00   0.01   0.00   0.00   0.00   0.00   \\n","2010-01-03   0.00   0.00   NaN   NaN  0.00   0.00   0.00   0.02   0.00   0.00   \\n","2010-01-04   0.00   0.00   NaN   NaN  0.10   0.10   0.00   0.11   0.00   0.00   \\n","2010-01-05   0.00   0.00   NaN   NaN  0.00   0.00   0.00   0.00   0.12   0.00   \\n","\\n","            rd-16  rd-21  \\n","Datetime                  \\n","2010-01-01   0.02   0.03  \\n","2010-01-02   0.00   0.00  \\n","2010-01-03   0.00   0.00  \\n","2010-01-04   0.00   0.00  \\n","2010-01-05   0.00   0.11  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["rain_daily15 = daily_pivot_table(\'rainfall\', np.sum, \'\')\\n","rain_daily = daily_pivot_table(\'daily_rainfall\', np.sum, \'\')\\n","rain_daily_comb_no_name = pd.concat([rain_daily, rain_daily15], axis=1)\\n","rain_daily_comb_named = rename_cols(rain_daily_comb_no_name, \'rd\')\\n","rain_daily_comb_named.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Hourly Rainfall"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rhrmx-1</th>\\n","      <th>rhrmx-2</th>\\n","      <th>rhrmx-7</th>\\n","      <th>rhrmx-11</th>\\n","      <th>rhrmx-12</th>\\n","      <th>rhrmx-13</th>\\n","      <th>rhrmx-14</th>\\n","      <th>rhrmx-15</th>\\n","      <th>rhrmx-16</th>\\n","      <th>rhrmx-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.04</td>\\n","      <td>0.01</td>\\n","      <td>0.04</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.01</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.02</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.10</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.12</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            rhrmx-1  rhrmx-2  rhrmx-7  rhrmx-11  rhrmx-12  rhrmx-13  rhrmx-14  \\\\\\n","Datetime                                                                        \\n","2010-01-01      NaN      NaN     0.04      0.01      0.04      0.01      0.01   \\n","2010-01-02      NaN      NaN     0.00      0.01      0.00      0.00      0.00   \\n","2010-01-03      NaN      NaN     0.00      0.00      0.00      0.02      0.00   \\n","2010-01-04      NaN      NaN     0.10      0.10      0.00      0.11      0.00   \\n","2010-01-05      NaN      NaN     0.00      0.00      0.00      0.00      0.12   \\n","\\n","            rhrmx-15  rhrmx-16  rhrmx-21  \\n","Datetime                                  \\n","2010-01-01      0.01      0.01      0.02  \\n","2010-01-02      0.00      0.00      0.00  \\n","2010-01-03      0.00      0.00      0.00  \\n","2010-01-04      0.00      0.00      0.00  \\n","2010-01-05      0.00      0.00      0.11  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["rain15 = pivot_dv_df(rain_df)\\n","rain_hourly_totals = rain15.rolling(window=\'H\').sum()\\n","rhr_mx = rain_hourly_totals.resample(\'D\').max()\\n","rhr_mx = rename_cols(rhr_mx, \'rhrmx\')\\n","rhr_mx.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rhr_mxtime-1</th>\\n","      <th>rhr_mxtime-2</th>\\n","      <th>rhr_mxtime-7</th>\\n","      <th>rhr_mxtime-11</th>\\n","      <th>rhr_mxtime-12</th>\\n","      <th>rhr_mxtime-13</th>\\n","      <th>rhr_mxtime-14</th>\\n","      <th>rhr_mxtime-15</th>\\n","      <th>rhr_mxtime-16</th>\\n","      <th>rhr_mxtime-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-01 22:45:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 23:00:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 05:00:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 23:00:00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-02 13:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-03 07:00:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 13:30:00</td>\\n","      <td>2010-01-04 13:00:00</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 12:45:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:30:00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["           rhr_mxtime-1 rhr_mxtime-2        rhr_mxtime-7       rhr_mxtime-11  \\\\\\n","Datetime                                                                       \\n","2010-01-01          NaT          NaT 2010-01-01 22:45:00 2010-01-01 00:15:00   \\n","2010-01-02          NaT          NaT                 NaT 2010-01-02 13:15:00   \\n","2010-01-03          NaT          NaT                 NaT                 NaT   \\n","2010-01-04          NaT          NaT 2010-01-04 13:30:00 2010-01-04 13:00:00   \\n","2010-01-05          NaT          NaT                 NaT                 NaT   \\n","\\n","                 rhr_mxtime-12       rhr_mxtime-13       rhr_mxtime-14  \\\\\\n","Datetime                                                                 \\n","2010-01-01 2010-01-01 23:00:00 2010-01-01 00:45:00 2010-01-01 00:15:00   \\n","2010-01-02                 NaT                 NaT                 NaT   \\n","2010-01-03                 NaT 2010-01-03 07:00:00                 NaT   \\n","2010-01-04                 NaT 2010-01-04 12:45:00                 NaT   \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:15:00   \\n","\\n","                 rhr_mxtime-15       rhr_mxtime-16       rhr_mxtime-21  \\n","Datetime                                                                \\n","2010-01-01 2010-01-01 05:00:00 2010-01-01 00:45:00 2010-01-01 23:00:00  \\n","2010-01-02                 NaT                 NaT                 NaT  \\n","2010-01-03                 NaT                 NaT                 NaT  \\n","2010-01-04                 NaT                 NaT                 NaT  \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:30:00  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["rhr_timemx = rain_hourly_totals.groupby(pd.TimeGrouper(\'D\')).idxmax()\\n","rhr_timemx = rename_cols(rhr_timemx, \'rhr_mxtime\')\\n","rhr_timemx = filter_max_rain_time_dfs(rain_daily15, rhr_timemx)\\n","rhr_timemx.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 15-min max rainfall"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r15mx-1</th>\\n","      <th>r15mx-2</th>\\n","      <th>r15mx-7</th>\\n","      <th>r15mx-11</th>\\n","      <th>r15mx-12</th>\\n","      <th>r15mx-13</th>\\n","      <th>r15mx-14</th>\\n","      <th>r15mx-15</th>\\n","      <th>r15mx-16</th>\\n","      <th>r15mx-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.02</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.01</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.02</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.10</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.12</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.11</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            r15mx-1  r15mx-2  r15mx-7  r15mx-11  r15mx-12  r15mx-13  r15mx-14  \\\\\\n","Datetime                                                                        \\n","2010-01-01      NaN      NaN     0.02      0.01      0.02      0.01      0.01   \\n","2010-01-02      NaN      NaN     0.00      0.01      0.00      0.00      0.00   \\n","2010-01-03      NaN      NaN     0.00      0.00      0.00      0.02      0.00   \\n","2010-01-04      NaN      NaN     0.10      0.10      0.00      0.11      0.00   \\n","2010-01-05      NaN      NaN     0.00      0.00      0.00      0.00      0.12   \\n","\\n","            r15mx-15  r15mx-16  r15mx-21  \\n","Datetime                                  \\n","2010-01-01      0.01      0.01      0.02  \\n","2010-01-02      0.00      0.00      0.00  \\n","2010-01-03      0.00      0.00      0.00  \\n","2010-01-04      0.00      0.00      0.00  \\n","2010-01-05      0.00      0.00      0.11  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["r15_mx = rain15.resample(\'D\').max()\\n","r15_mx = rename_cols(r15_mx, \'r15mx\')\\n","r15_mx.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r15_mxtime-1</th>\\n","      <th>r15_mxtime-2</th>\\n","      <th>r15_mxtime-7</th>\\n","      <th>r15_mxtime-11</th>\\n","      <th>r15_mxtime-12</th>\\n","      <th>r15_mxtime-13</th>\\n","      <th>r15_mxtime-14</th>\\n","      <th>r15_mxtime-15</th>\\n","      <th>r15_mxtime-16</th>\\n","      <th>r15_mxtime-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-01 22:30:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 22:45:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 00:15:00</td>\\n","      <td>2010-01-01 05:00:00</td>\\n","      <td>2010-01-01 00:45:00</td>\\n","      <td>2010-01-01 23:00:00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-02 13:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-03 07:00:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 13:30:00</td>\\n","      <td>2010-01-04 13:00:00</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-04 12:45:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:15:00</td>\\n","      <td>NaT</td>\\n","      <td>NaT</td>\\n","      <td>2010-01-05 10:30:00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["           r15_mxtime-1 r15_mxtime-2        r15_mxtime-7       r15_mxtime-11  \\\\\\n","Datetime                                                                       \\n","2010-01-01          NaT          NaT 2010-01-01 22:30:00 2010-01-01 00:15:00   \\n","2010-01-02          NaT          NaT                 NaT 2010-01-02 13:15:00   \\n","2010-01-03          NaT          NaT                 NaT                 NaT   \\n","2010-01-04          NaT          NaT 2010-01-04 13:30:00 2010-01-04 13:00:00   \\n","2010-01-05          NaT          NaT                 NaT                 NaT   \\n","\\n","                 r15_mxtime-12       r15_mxtime-13       r15_mxtime-14  \\\\\\n","Datetime                                                                 \\n","2010-01-01 2010-01-01 22:45:00 2010-01-01 00:45:00 2010-01-01 00:15:00   \\n","2010-01-02                 NaT                 NaT                 NaT   \\n","2010-01-03                 NaT 2010-01-03 07:00:00                 NaT   \\n","2010-01-04                 NaT 2010-01-04 12:45:00                 NaT   \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:15:00   \\n","\\n","                 r15_mxtime-15       r15_mxtime-16       r15_mxtime-21  \\n","Datetime                                                                \\n","2010-01-01 2010-01-01 05:00:00 2010-01-01 00:45:00 2010-01-01 23:00:00  \\n","2010-01-02                 NaT                 NaT                 NaT  \\n","2010-01-03                 NaT                 NaT                 NaT  \\n","2010-01-04                 NaT                 NaT                 NaT  \\n","2010-01-05                 NaT                 NaT 2010-01-05 10:30:00  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["r15_timemx = rain15.groupby(pd.TimeGrouper(\'D\')).idxmax()\\n","r15_timemx = rename_cols(r15_timemx, \'r15_mxtime\')\\n","r15_timemx = filter_max_rain_time_dfs(rain_daily15, r15_timemx)\\n","r15_timemx.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Rain prev 3 days"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r3d-19</th>\\n","      <th>r3d-20</th>\\n","      <th>r3d-1</th>\\n","      <th>r3d-2</th>\\n","      <th>r3d-7</th>\\n","      <th>r3d-11</th>\\n","      <th>r3d-12</th>\\n","      <th>r3d-13</th>\\n","      <th>r3d-14</th>\\n","      <th>r3d-15</th>\\n","      <th>r3d-16</th>\\n","      <th>r3d-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.05</td>\\n","      <td>0.04</td>\\n","      <td>0.06</td>\\n","      <td>0.04</td>\\n","      <td>0.01</td>\\n","      <td>0.01</td>\\n","      <td>0.02</td>\\n","      <td>0.03</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.10</td>\\n","      <td>0.11</td>\\n","      <td>0.00</td>\\n","      <td>0.13</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","      <td>0.00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            r3d-19  r3d-20  r3d-1  r3d-2  r3d-7  r3d-11  r3d-12  r3d-13  \\\\\\n","Datetime                                                                  \\n","2010-01-01     NaN     NaN    NaN    NaN    NaN     NaN     NaN     NaN   \\n","2010-01-02     NaN     NaN    NaN    NaN    NaN     NaN     NaN     NaN   \\n","2010-01-03     NaN     NaN    NaN    NaN    NaN     NaN     NaN     NaN   \\n","2010-01-04    0.01    0.01    NaN    NaN   0.05    0.04    0.06    0.04   \\n","2010-01-05    0.00    0.00    NaN    NaN   0.10    0.11    0.00    0.13   \\n","\\n","            r3d-14  r3d-15  r3d-16  r3d-21  \\n","Datetime                                    \\n","2010-01-01     NaN     NaN     NaN     NaN  \\n","2010-01-02     NaN     NaN     NaN     NaN  \\n","2010-01-03     NaN     NaN     NaN     NaN  \\n","2010-01-04    0.01    0.01    0.02    0.03  \\n","2010-01-05    0.00    0.00    0.00    0.00  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["rain_prev_3_days = rain_daily_comb_no_name.shift(1).rolling(window=3).sum()\\n","rain_prev_3_days = rename_cols(rain_prev_3_days, \'r3d\')\\n","rain_prev_3_days.head()"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":false},"outputs":[{"data":{"text/plain":["Series([], Freq: D, Name: rd-14, dtype: float64)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["rain_daily_comb_named[\'rd-14\'][rain_daily_comb_named[\'rd-14\']<0]"]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th>SiteID</th>\\n","      <th>1</th>\\n","      <th>2</th>\\n","      <th>7</th>\\n","      <th>11</th>\\n","      <th>12</th>\\n","      <th>13</th>\\n","      <th>14</th>\\n","      <th>15</th>\\n","      <th>16</th>\\n","      <th>21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2014-06-24 00:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:01:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:02:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:03:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:04:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:05:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:06:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:07:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:08:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:09:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:10:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:11:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:12:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:13:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:14:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:16:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:17:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:18:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:19:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:20:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:21:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:22:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:23:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:24:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:25:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:26:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:27:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:28:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 00:29:00</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>...</th>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","      <td>...</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 16:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 16:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 17:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 18:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 19:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 20:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 21:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 22:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:00:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:15:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:30:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2014-06-24 23:45:00</th>\\n","      <td>0.0</td>\\n","      <td>NaN</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","      <td>0.0</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","<p>531 rows  10 columns</p>\\n","</div>"],"text/plain":["SiteID                1   2    7    11   12   13   14   15   16   21\\n","Datetime                                                            \\n","2014-06-24 00:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 00:01:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:02:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:03:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:04:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:05:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:06:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:07:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:08:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:09:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:10:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:11:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:12:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:13:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:14:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 00:16:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:17:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:18:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:19:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:20:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:21:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:22:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:23:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:24:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:25:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:26:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:27:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:28:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","2014-06-24 00:29:00  NaN NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  NaN\\n","...                  ...  ..  ...  ...  ...  ...  ...  ...  ...  ...\\n","2014-06-24 16:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 16:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 17:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 18:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 19:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 20:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 21:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 22:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:00:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:15:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:30:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","2014-06-24 23:45:00  0.0 NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\\n","\\n","[531 rows x 10 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["rain15.loc[\'2014-06-24\']"]},{"cell_type":"code","execution_count":19,"metadata":{"collapsed":false},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x362cdc88>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\\nCSroiqIolqCCriiKYgkq6IqiKJbw/wGiRsm9GzhRmgAAAABJRU5ErkJggg==\\n","text/plain":["<matplotlib.figure.Figure at 0x362cd4a8>"]},"metadata":{},"output_type":"display_data"}],"source":["rain_prev_3_days.plot.box()"]},{"cell_type":"markdown","metadata":{},"source":["#  Groundwater"]},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>gw_av-4</th>\\n","      <th>gw_av-5</th>\\n","      <th>gw_av-6</th>\\n","      <th>gw_av-8</th>\\n","      <th>gw_av-9</th>\\n","      <th>gw_av-10</th>\\n","      <th>gw_av-11</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>0.181510</td>\\n","      <td>3.924140</td>\\n","      <td>NaN</td>\\n","      <td>6.050129</td>\\n","      <td>2.858511</td>\\n","      <td>3.167374</td>\\n","      <td>3.509806</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>0.051690</td>\\n","      <td>3.548121</td>\\n","      <td>NaN</td>\\n","      <td>5.990354</td>\\n","      <td>2.745979</td>\\n","      <td>3.238457</td>\\n","      <td>3.637924</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>-0.075826</td>\\n","      <td>3.103997</td>\\n","      <td>NaN</td>\\n","      <td>5.910525</td>\\n","      <td>2.650683</td>\\n","      <td>3.127058</td>\\n","      <td>3.511233</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>-0.186996</td>\\n","      <td>2.882649</td>\\n","      <td>NaN</td>\\n","      <td>5.770411</td>\\n","      <td>2.579872</td>\\n","      <td>2.990989</td>\\n","      <td>3.348661</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>-0.251922</td>\\n","      <td>2.772379</td>\\n","      <td>NaN</td>\\n","      <td>5.648158</td>\\n","      <td>2.538736</td>\\n","      <td>2.873044</td>\\n","      <td>3.232544</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["             gw_av-4   gw_av-5  gw_av-6   gw_av-8   gw_av-9  gw_av-10  \\\\\\n","Datetime                                                                \\n","2010-01-01  0.181510  3.924140      NaN  6.050129  2.858511  3.167374   \\n","2010-01-02  0.051690  3.548121      NaN  5.990354  2.745979  3.238457   \\n","2010-01-03 -0.075826  3.103997      NaN  5.910525  2.650683  3.127058   \\n","2010-01-04 -0.186996  2.882649      NaN  5.770411  2.579872  2.990989   \\n","2010-01-05 -0.251922  2.772379      NaN  5.648158  2.538736  2.873044   \\n","\\n","            gw_av-11  \\n","Datetime              \\n","2010-01-01  3.509806  \\n","2010-01-02  3.637924  \\n","2010-01-03  3.511233  \\n","2010-01-04  3.348661  \\n","2010-01-05  3.232544  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["gw_df = daily_pivot_table(\'shallow_well_depth\', np.mean, \'gw_av\')\\n","gw_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#  Tide"]},{"cell_type":"markdown","metadata":{},"source":["## Average daily tide"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>td_av-17</th>\\n","      <th>td_av-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>0.675800</td>\\n","      <td>0.679987</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>0.604608</td>\\n","      <td>0.707200</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>-0.608692</td>\\n","      <td>-0.579467</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>-0.515733</td>\\n","      <td>-0.522700</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>0.020037</td>\\n","      <td>0.017379</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            td_av-17  td_av-18\\n","Datetime                      \\n","2010-01-01  0.675800  0.679987\\n","2010-01-02  0.604608  0.707200\\n","2010-01-03 -0.608692 -0.579467\\n","2010-01-04 -0.515733 -0.522700\\n","2010-01-05  0.020037  0.017379"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tide_df = daily_pivot_table(\'six_min_tide\', np.mean, \'td_av\')\\n","tide_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["##  Tide when rain is at max"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>r15-1_td-17</th>\\n","      <th>r15-1_td-18</th>\\n","      <th>r15-2_td-17</th>\\n","      <th>r15-2_td-18</th>\\n","      <th>r15-7_td-17</th>\\n","      <th>r15-7_td-18</th>\\n","      <th>r15-11_td-17</th>\\n","      <th>r15-11_td-18</th>\\n","      <th>r15-12_td-17</th>\\n","      <th>r15-12_td-18</th>\\n","      <th>r15-13_td-17</th>\\n","      <th>r15-13_td-18</th>\\n","      <th>r15-14_td-17</th>\\n","      <th>r15-14_td-18</th>\\n","      <th>r15-15_td-17</th>\\n","      <th>r15-15_td-18</th>\\n","      <th>r15-16_td-17</th>\\n","      <th>r15-16_td-18</th>\\n","      <th>r15-21_td-17</th>\\n","      <th>r15-21_td-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.814333</td>\\n","      <td>2.148</td>\\n","      <td>-0.246</td>\\n","      <td>-0.092</td>\\n","      <td>1.8375</td>\\n","      <td>2.0505</td>\\n","      <td>-0.567500</td>\\n","      <td>-0.503500</td>\\n","      <td>-0.2460</td>\\n","      <td>-0.092</td>\\n","      <td>-0.049333</td>\\n","      <td>-0.431</td>\\n","      <td>-0.5675</td>\\n","      <td>-0.5035</td>\\n","      <td>1.836333</td>\\n","      <td>1.962000</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.912</td>\\n","      <td>1.273</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.869333</td>\\n","      <td>-1.160333</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.729333</td>\\n","      <td>0.919</td>\\n","      <td>0.901</td>\\n","      <td>1.135</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.968000</td>\\n","      <td>1.240500</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.6005</td>\\n","      <td>0.530</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.772000</td>\\n","      <td>0.740333</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            r15-1_td-17  r15-1_td-18  r15-2_td-17  r15-2_td-18  r15-7_td-17  \\\\\\n","Datetime                                                                      \\n","2010-01-01          NaN          NaN          NaN          NaN     1.814333   \\n","2010-01-02          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-03          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-04          NaN          NaN          NaN          NaN     0.729333   \\n","2010-01-05          NaN          NaN          NaN          NaN          NaN   \\n","\\n","            r15-7_td-18  r15-11_td-17  r15-11_td-18  r15-12_td-17  \\\\\\n","Datetime                                                            \\n","2010-01-01        2.148        -0.246        -0.092        1.8375   \\n","2010-01-02          NaN         0.912         1.273           NaN   \\n","2010-01-03          NaN           NaN           NaN           NaN   \\n","2010-01-04        0.919         0.901         1.135           NaN   \\n","2010-01-05          NaN           NaN           NaN           NaN   \\n","\\n","            r15-12_td-18  r15-13_td-17  r15-13_td-18  r15-14_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01        2.0505     -0.567500     -0.503500       -0.2460   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN     -0.869333     -1.160333           NaN   \\n","2010-01-04           NaN      0.968000      1.240500           NaN   \\n","2010-01-05           NaN           NaN           NaN        0.6005   \\n","\\n","            r15-14_td-18  r15-15_td-17  r15-15_td-18  r15-16_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01        -0.092     -0.049333        -0.431       -0.5675   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN           NaN           NaN           NaN   \\n","2010-01-04           NaN           NaN           NaN           NaN   \\n","2010-01-05         0.530           NaN           NaN           NaN   \\n","\\n","            r15-16_td-18  r15-21_td-17  r15-21_td-18  \\n","Datetime                                              \\n","2010-01-01       -0.5035      1.836333      1.962000  \\n","2010-01-02           NaN           NaN           NaN  \\n","2010-01-03           NaN           NaN           NaN  \\n","2010-01-04           NaN           NaN           NaN  \\n","2010-01-05           NaN      0.772000      0.740333  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["td_r15mx = tide_when_rain_max(r15_timemx)\\n","td_r15mx.head()"]},{"cell_type":"code","execution_count":23,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>rhr-1_td-17</th>\\n","      <th>rhr-1_td-18</th>\\n","      <th>rhr-2_td-17</th>\\n","      <th>rhr-2_td-18</th>\\n","      <th>rhr-7_td-17</th>\\n","      <th>rhr-7_td-18</th>\\n","      <th>rhr-11_td-17</th>\\n","      <th>rhr-11_td-18</th>\\n","      <th>rhr-12_td-17</th>\\n","      <th>rhr-12_td-18</th>\\n","      <th>rhr-13_td-17</th>\\n","      <th>rhr-13_td-18</th>\\n","      <th>rhr-14_td-17</th>\\n","      <th>rhr-14_td-18</th>\\n","      <th>rhr-15_td-17</th>\\n","      <th>rhr-15_td-18</th>\\n","      <th>rhr-16_td-17</th>\\n","      <th>rhr-16_td-18</th>\\n","      <th>rhr-21_td-17</th>\\n","      <th>rhr-21_td-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.837500</td>\\n","      <td>2.0505</td>\\n","      <td>-0.246</td>\\n","      <td>-0.092</td>\\n","      <td>1.836333</td>\\n","      <td>1.962</td>\\n","      <td>-0.567500</td>\\n","      <td>-0.503500</td>\\n","      <td>-0.2460</td>\\n","      <td>-0.092</td>\\n","      <td>-0.049333</td>\\n","      <td>-0.431</td>\\n","      <td>-0.5675</td>\\n","      <td>-0.5035</td>\\n","      <td>1.836333</td>\\n","      <td>1.962000</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.912</td>\\n","      <td>1.273</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.869333</td>\\n","      <td>-1.160333</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.729333</td>\\n","      <td>0.9190</td>\\n","      <td>0.901</td>\\n","      <td>1.135</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.968000</td>\\n","      <td>1.240500</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.6005</td>\\n","      <td>0.530</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.772000</td>\\n","      <td>0.740333</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            rhr-1_td-17  rhr-1_td-18  rhr-2_td-17  rhr-2_td-18  rhr-7_td-17  \\\\\\n","Datetime                                                                      \\n","2010-01-01          NaN          NaN          NaN          NaN     1.837500   \\n","2010-01-02          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-03          NaN          NaN          NaN          NaN          NaN   \\n","2010-01-04          NaN          NaN          NaN          NaN     0.729333   \\n","2010-01-05          NaN          NaN          NaN          NaN          NaN   \\n","\\n","            rhr-7_td-18  rhr-11_td-17  rhr-11_td-18  rhr-12_td-17  \\\\\\n","Datetime                                                            \\n","2010-01-01       2.0505        -0.246        -0.092      1.836333   \\n","2010-01-02          NaN         0.912         1.273           NaN   \\n","2010-01-03          NaN           NaN           NaN           NaN   \\n","2010-01-04       0.9190         0.901         1.135           NaN   \\n","2010-01-05          NaN           NaN           NaN           NaN   \\n","\\n","            rhr-12_td-18  rhr-13_td-17  rhr-13_td-18  rhr-14_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01         1.962     -0.567500     -0.503500       -0.2460   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN     -0.869333     -1.160333           NaN   \\n","2010-01-04           NaN      0.968000      1.240500           NaN   \\n","2010-01-05           NaN           NaN           NaN        0.6005   \\n","\\n","            rhr-14_td-18  rhr-15_td-17  rhr-15_td-18  rhr-16_td-17  \\\\\\n","Datetime                                                             \\n","2010-01-01        -0.092     -0.049333        -0.431       -0.5675   \\n","2010-01-02           NaN           NaN           NaN           NaN   \\n","2010-01-03           NaN           NaN           NaN           NaN   \\n","2010-01-04           NaN           NaN           NaN           NaN   \\n","2010-01-05         0.530           NaN           NaN           NaN   \\n","\\n","            rhr-16_td-18  rhr-21_td-17  rhr-21_td-18  \\n","Datetime                                              \\n","2010-01-01       -0.5035      1.836333      1.962000  \\n","2010-01-02           NaN           NaN           NaN  \\n","2010-01-03           NaN           NaN           NaN  \\n","2010-01-04           NaN           NaN           NaN  \\n","2010-01-05           NaN      0.772000      0.740333  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["td_rhrmx = tide_when_rain_max(rhr_timemx)\\n","td_rhrmx.head()"]},{"cell_type":"markdown","metadata":{},"source":["## HI/LOs"]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true},"outputs":[],"source":["hilos = []\\n","for v in [\'high_tide\', \'high_high_tide\', \'low_tide\', \'low_low_tide\']:\\n","    hilos.append(daily_pivot_table(v, np.mean, \\"\\".join(w[0] for w in v.split(\'_\'))))"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>ht-17</th>\\n","      <th>ht-18</th>\\n","      <th>hht-17</th>\\n","      <th>hht-18</th>\\n","      <th>lt-17</th>\\n","      <th>lt-18</th>\\n","      <th>llt-17</th>\\n","      <th>llt-18</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>1.952</td>\\n","      <td>2.241</td>\\n","      <td>2.493</td>\\n","      <td>2.7490</td>\\n","      <td>-0.797</td>\\n","      <td>-1.043</td>\\n","      <td>-1.198</td>\\n","      <td>-1.430</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.939</td>\\n","      <td>2.2395</td>\\n","      <td>-0.604</td>\\n","      <td>-0.840</td>\\n","      <td>-1.056</td>\\n","      <td>-1.132</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>0.830</td>\\n","      <td>1.096</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.841</td>\\n","      <td>-2.024</td>\\n","      <td>-2.516</td>\\n","      <td>-2.694</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.102</td>\\n","      <td>1.3190</td>\\n","      <td>-1.693</td>\\n","      <td>-1.949</td>\\n","      <td>-2.349</td>\\n","      <td>-2.566</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>1.355</td>\\n","      <td>1.654</td>\\n","      <td>1.480</td>\\n","      <td>1.7680</td>\\n","      <td>-1.253</td>\\n","      <td>-1.453</td>\\n","      <td>-1.306</td>\\n","      <td>-1.522</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            ht-17  ht-18  hht-17  hht-18  lt-17  lt-18  llt-17  llt-18\\n","Datetime                                                              \\n","2010-01-01  1.952  2.241   2.493  2.7490 -0.797 -1.043  -1.198  -1.430\\n","2010-01-02    NaN    NaN   1.939  2.2395 -0.604 -0.840  -1.056  -1.132\\n","2010-01-03  0.830  1.096     NaN     NaN -1.841 -2.024  -2.516  -2.694\\n","2010-01-04    NaN    NaN   1.102  1.3190 -1.693 -1.949  -2.349  -2.566\\n","2010-01-05  1.355  1.654   1.480  1.7680 -1.253 -1.453  -1.306  -1.522"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["hilo_df = pd.concat(hilos, axis=1)\\n","hilo_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#  Wind"]},{"cell_type":"code","execution_count":26,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>WDF2-19</th>\\n","      <th>WDF2-20</th>\\n","      <th>WSF2-19</th>\\n","      <th>WSF2-20</th>\\n","      <th>AWDR-19</th>\\n","      <th>AWND-19</th>\\n","      <th>AWND-20</th>\\n","      <th>WGF6-18</th>\\n","      <th>AWND-18</th>\\n","      <th>AWDR-18</th>\\n","      <th>AWND-3</th>\\n","      <th>AWDR-3</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-01-01</th>\\n","      <td>360.0</td>\\n","      <td>340.0</td>\\n","      <td>23.0</td>\\n","      <td>23.9</td>\\n","      <td>353.0</td>\\n","      <td>6.3</td>\\n","      <td>7.2</td>\\n","      <td>6.798833</td>\\n","      <td>4.384917</td>\\n","      <td>201.898458</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-02</th>\\n","      <td>340.0</td>\\n","      <td>310.0</td>\\n","      <td>23.9</td>\\n","      <td>30.0</td>\\n","      <td>321.0</td>\\n","      <td>13.9</td>\\n","      <td>19.9</td>\\n","      <td>18.064142</td>\\n","      <td>11.356569</td>\\n","      <td>337.813724</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-03</th>\\n","      <td>290.0</td>\\n","      <td>290.0</td>\\n","      <td>17.9</td>\\n","      <td>28.0</td>\\n","      <td>295.0</td>\\n","      <td>11.2</td>\\n","      <td>16.6</td>\\n","      <td>16.935208</td>\\n","      <td>10.734083</td>\\n","      <td>325.094250</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-04</th>\\n","      <td>330.0</td>\\n","      <td>310.0</td>\\n","      <td>16.1</td>\\n","      <td>21.0</td>\\n","      <td>306.0</td>\\n","      <td>7.2</td>\\n","      <td>9.8</td>\\n","      <td>9.317000</td>\\n","      <td>6.280500</td>\\n","      <td>324.969875</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-01-05</th>\\n","      <td>310.0</td>\\n","      <td>300.0</td>\\n","      <td>15.0</td>\\n","      <td>17.0</td>\\n","      <td>292.0</td>\\n","      <td>6.0</td>\\n","      <td>8.5</td>\\n","      <td>8.925750</td>\\n","      <td>6.063000</td>\\n","      <td>317.637125</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["            WDF2-19  WDF2-20  WSF2-19  WSF2-20  AWDR-19  AWND-19  AWND-20  \\\\\\n","Datetime                                                                    \\n","2010-01-01    360.0    340.0     23.0     23.9    353.0      6.3      7.2   \\n","2010-01-02    340.0    310.0     23.9     30.0    321.0     13.9     19.9   \\n","2010-01-03    290.0    290.0     17.9     28.0    295.0     11.2     16.6   \\n","2010-01-04    330.0    310.0     16.1     21.0    306.0      7.2      9.8   \\n","2010-01-05    310.0    300.0     15.0     17.0    292.0      6.0      8.5   \\n","\\n","              WGF6-18    AWND-18     AWDR-18  AWND-3  AWDR-3  \\n","Datetime                                                      \\n","2010-01-01   6.798833   4.384917  201.898458     NaN     NaN  \\n","2010-01-02  18.064142  11.356569  337.813724     NaN     NaN  \\n","2010-01-03  16.935208  10.734083  325.094250     NaN     NaN  \\n","2010-01-04   9.317000   6.280500  324.969875     NaN     NaN  \\n","2010-01-05   8.925750   6.063000  317.637125     NaN     NaN  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["wind_dfs = []\\n","for v in [\'WDF2\', \'WSF2\', \'AWDR\', \'AWND\', \'WGF6\', \'WSF6\', \'WDF6\', \'WS2min\', \'WD2min\']:\\n","    if v == \'WSF6\':\\n","        abbr = \'AWND\'\\n","    elif v == \'WDF6\':\\n","        abbr = \'AWDR\'\\n","    elif v == \'WS2min\':\\n","        abbr = \'AWND\'\\n","    elif v == \'WD2min\':\\n","        abbr = \'AWDR\'\\n","    else:\\n","        abbr = v\\n","    wind_dfs.append(daily_pivot_table(v, np.mean, abbr))\\n","all_wind = pd.concat(wind_dfs, axis=1)\\n","all_wind.head()"]},{"cell_type":"code","execution_count":27,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>WDF2-19</th>\\n","      <th>WDF2-20</th>\\n","      <th>WSF2-19</th>\\n","      <th>WSF2-20</th>\\n","      <th>AWDR-19</th>\\n","      <th>AWND-19</th>\\n","      <th>AWND-20</th>\\n","      <th>WGF6-18</th>\\n","      <th>AWND-18</th>\\n","      <th>AWDR-18</th>\\n","      <th>...</th>\\n","      <th>r3d-1</th>\\n","      <th>r3d-2</th>\\n","      <th>r3d-7</th>\\n","      <th>r3d-11</th>\\n","      <th>r3d-12</th>\\n","      <th>r3d-13</th>\\n","      <th>r3d-14</th>\\n","      <th>r3d-15</th>\\n","      <th>r3d-16</th>\\n","      <th>r3d-21</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-09-15</th>\\n","      <td>140.0</td>\\n","      <td>110.0</td>\\n","      <td>13.0</td>\\n","      <td>15.0</td>\\n","      <td>119.0</td>\\n","      <td>5.1</td>\\n","      <td>5.6</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>2.200000e-01</td>\\n","      <td>2.400000e-01</td>\\n","      <td>2.600000e-01</td>\\n","      <td>2.200000e-01</td>\\n","      <td>3.100000e-01</td>\\n","      <td>2.400000e-01</td>\\n","      <td>3.600000e-01</td>\\n","      <td>2.400000e-01</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-16</th>\\n","      <td>220.0</td>\\n","      <td>200.0</td>\\n","      <td>25.9</td>\\n","      <td>19.9</td>\\n","      <td>210.0</td>\\n","      <td>15.2</td>\\n","      <td>9.6</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.000000e-02</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-17</th>\\n","      <td>220.0</td>\\n","      <td>200.0</td>\\n","      <td>21.0</td>\\n","      <td>16.1</td>\\n","      <td>41.0</td>\\n","      <td>11.0</td>\\n","      <td>9.4</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.351350e-15</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-18</th>\\n","      <td>30.0</td>\\n","      <td>30.0</td>\\n","      <td>16.1</td>\\n","      <td>18.1</td>\\n","      <td>37.0</td>\\n","      <td>8.5</td>\\n","      <td>9.4</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.351350e-15</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-19</th>\\n","      <td>40.0</td>\\n","      <td>10.0</td>\\n","      <td>10.1</td>\\n","      <td>12.1</td>\\n","      <td>58.0</td>\\n","      <td>4.3</td>\\n","      <td>4.7</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>...</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.351350e-15</td>\\n","      <td>-3.053113e-16</td>\\n","      <td>-2.220446e-16</td>\\n","      <td>-3.608225e-16</td>\\n","      <td>3.330669e-16</td>\\n","      <td>-1.110223e-15</td>\\n","      <td>-1.554312e-15</td>\\n","      <td>-5.551115e-17</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","<p>5 rows  113 columns</p>\\n","</div>"],"text/plain":["            WDF2-19  WDF2-20  WSF2-19  WSF2-20  AWDR-19  AWND-19  AWND-20  \\\\\\n","Datetime                                                                    \\n","2010-09-15    140.0    110.0     13.0     15.0    119.0      5.1      5.6   \\n","2010-09-16    220.0    200.0     25.9     19.9    210.0     15.2      9.6   \\n","2010-09-17    220.0    200.0     21.0     16.1     41.0     11.0      9.4   \\n","2010-09-18     30.0     30.0     16.1     18.1     37.0      8.5      9.4   \\n","2010-09-19     40.0     10.0     10.1     12.1     58.0      4.3      4.7   \\n","\\n","            WGF6-18  AWND-18  AWDR-18      ...       r3d-1  r3d-2  \\\\\\n","Datetime                                   ...                      \\n","2010-09-15      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-16      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-17      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-18      NaN      NaN      NaN      ...         NaN    NaN   \\n","2010-09-19      NaN      NaN      NaN      ...         NaN    NaN   \\n","\\n","                   r3d-7        r3d-11        r3d-12        r3d-13  \\\\\\n","Datetime                                                             \\n","2010-09-15  2.200000e-01  2.400000e-01  2.600000e-01  2.200000e-01   \\n","2010-09-16  1.000000e-02 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","2010-09-17 -1.351350e-15 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","2010-09-18 -1.351350e-15 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","2010-09-19 -1.351350e-15 -3.053113e-16 -2.220446e-16 -3.608225e-16   \\n","\\n","                  r3d-14        r3d-15        r3d-16        r3d-21  \\n","Datetime                                                            \\n","2010-09-15  3.100000e-01  2.400000e-01  3.600000e-01  2.400000e-01  \\n","2010-09-16  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","2010-09-17  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","2010-09-18  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","2010-09-19  3.330669e-16 -1.110223e-15 -1.554312e-15 -5.551115e-17  \\n","\\n","[5 rows x 113 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["feature_df = pd.concat([all_wind, hilo_df, td_r15mx, td_rhrmx, tide_df, gw_df, r15_mx, rhr_mx, rain_daily_comb_named, rain_prev_3_days], axis=1)\\n","feature_df = feature_df.loc[\'2010-09-15\':\'2016-10-15\']\\n","feature_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["\\n","### Save Daily Observations to DB"]},{"cell_type":"code","execution_count":28,"metadata":{"collapsed":false},"outputs":[],"source":["con = sqlite3.connect(db_filename)\\n","feature_df.to_sql(con=con, name=\\"nor_daily_observations\\", if_exists=\\"replace\\")"]},{"cell_type":"markdown","metadata":{},"source":["### Make av. table"]},{"cell_type":"code","execution_count":29,"metadata":{"collapsed":false},"outputs":[{"data":{"text/plain":["array([\'WDF2\', \'WSF2\', \'AWDR\', \'AWND\', \'WGF6\', \'ht\', \'hht\', \'lt\', \'llt\',\\n","       \'r15_td\', \'rhr_td\', \'td_av\', \'gw_av\', \'r15mx\', \'rhrmx\', \'rd\', \'r3d\'], dtype=object)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["cols = pd.Series(feature_df.columns)\\n","cols_splt = cols.str.split(\'-\', expand=True)\\n","# do this to make sure the tide when the hourly and 15-min max rains have unique col names\\n","for a in cols_splt.iterrows():\\n","    if a[1].str.contains(\'\\\\d_td\').sum() == 1:\\n","        cols_splt.loc[a[0], 0] += \\"_td\\"\\n","col_vars = cols_splt[0].unique()\\n","col_vars"]},{"cell_type":"code","execution_count":30,"metadata":{"collapsed":false},"outputs":[],"source":["avdf = pd.DataFrame()\\n","for v in col_vars:\\n","    if v not in [\'r15_td\', \'rhr_td\']:\\n","        avdf[v] = feature_df[[a for a in feature_df.columns if a.startswith(v)]].mean(axis=1)\\n","    else:\\n","        avdf[v] = feature_df[cols[cols.str.contains(r\'{}-\\\\d+_td-\\\\d+\'.format(v.split(\'_\')[0]))]].mean(axis=1)"]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":false},"outputs":[],"source":["avdf.to_sql(con=con, name=\'nor_daily_observations_ave\', if_exists=\'replace\')"]},{"cell_type":"code","execution_count":32,"metadata":{"collapsed":false},"outputs":[{"data":{"text/html":["<div>\\n","<style>\\n","    .dataframe thead tr:only-child th {\\n","        text-align: right;\\n","    }\\n","\\n","    .dataframe thead th {\\n","        text-align: left;\\n","    }\\n","\\n","    .dataframe tbody tr th {\\n","        vertical-align: top;\\n","    }\\n","</style>\\n","<table border=\\"1\\" class=\\"dataframe\\">\\n","  <thead>\\n","    <tr style=\\"text-align: right;\\">\\n","      <th></th>\\n","      <th>WDF2</th>\\n","      <th>WSF2</th>\\n","      <th>AWDR</th>\\n","      <th>AWND</th>\\n","      <th>WGF6</th>\\n","      <th>ht</th>\\n","      <th>hht</th>\\n","      <th>lt</th>\\n","      <th>llt</th>\\n","      <th>r15_td</th>\\n","      <th>rhr_td</th>\\n","      <th>td_av</th>\\n","      <th>gw_av</th>\\n","      <th>r15mx</th>\\n","      <th>rhrmx</th>\\n","      <th>rd</th>\\n","      <th>r3d</th>\\n","    </tr>\\n","    <tr>\\n","      <th>Datetime</th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","      <th></th>\\n","    </tr>\\n","  </thead>\\n","  <tbody>\\n","    <tr>\\n","      <th>2010-09-15</th>\\n","      <td>125.0</td>\\n","      <td>14.00</td>\\n","      <td>119.0</td>\\n","      <td>5.35</td>\\n","      <td>NaN</td>\\n","      <td>1.5470</td>\\n","      <td>1.91250</td>\\n","      <td>-0.58400</td>\\n","      <td>-0.60400</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.630327</td>\\n","      <td>1.439483</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>2.570000e-01</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-16</th>\\n","      <td>210.0</td>\\n","      <td>22.90</td>\\n","      <td>210.0</td>\\n","      <td>12.40</td>\\n","      <td>NaN</td>\\n","      <td>1.2205</td>\\n","      <td>1.45200</td>\\n","      <td>-0.86250</td>\\n","      <td>-1.16800</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.317994</td>\\n","      <td>1.424287</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>1.000000e-03</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-17</th>\\n","      <td>210.0</td>\\n","      <td>18.55</td>\\n","      <td>41.0</td>\\n","      <td>10.20</td>\\n","      <td>NaN</td>\\n","      <td>0.8865</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-1.17150</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.033356</td>\\n","      <td>1.405075</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-18</th>\\n","      <td>30.0</td>\\n","      <td>17.10</td>\\n","      <td>37.0</td>\\n","      <td>8.95</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.63575</td>\\n","      <td>-0.83650</td>\\n","      <td>-0.67900</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.517577</td>\\n","      <td>1.373122</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-19</th>\\n","      <td>25.0</td>\\n","      <td>11.10</td>\\n","      <td>58.0</td>\\n","      <td>4.50</td>\\n","      <td>NaN</td>\\n","      <td>1.7275</td>\\n","      <td>2.01750</td>\\n","      <td>-0.51350</td>\\n","      <td>-0.45100</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.729448</td>\\n","      <td>1.365681</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-20</th>\\n","      <td>15.0</td>\\n","      <td>22.45</td>\\n","      <td>29.0</td>\\n","      <td>10.20</td>\\n","      <td>NaN</td>\\n","      <td>1.8965</td>\\n","      <td>2.35750</td>\\n","      <td>-0.22625</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.034590</td>\\n","      <td>1.354308</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-21</th>\\n","      <td>135.0</td>\\n","      <td>14.10</td>\\n","      <td>79.0</td>\\n","      <td>7.05</td>\\n","      <td>NaN</td>\\n","      <td>2.0685</td>\\n","      <td>1.97500</td>\\n","      <td>-0.52650</td>\\n","      <td>-0.22800</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.843558</td>\\n","      <td>1.314162</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-22</th>\\n","      <td>220.0</td>\\n","      <td>18.00</td>\\n","      <td>209.0</td>\\n","      <td>9.95</td>\\n","      <td>NaN</td>\\n","      <td>1.4095</td>\\n","      <td>1.43500</td>\\n","      <td>-0.83500</td>\\n","      <td>-0.78750</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.290825</td>\\n","      <td>1.293849</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-23</th>\\n","      <td>155.0</td>\\n","      <td>15.00</td>\\n","      <td>205.0</td>\\n","      <td>6.80</td>\\n","      <td>NaN</td>\\n","      <td>1.3130</td>\\n","      <td>NaN</td>\\n","      <td>-1.29600</td>\\n","      <td>-1.53200</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.065860</td>\\n","      <td>1.272830</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-24</th>\\n","      <td>200.0</td>\\n","      <td>18.45</td>\\n","      <td>221.0</td>\\n","      <td>10.75</td>\\n","      <td>NaN</td>\\n","      <td>1.2815</td>\\n","      <td>1.76700</td>\\n","      <td>-0.94350</td>\\n","      <td>-1.39250</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>0.213317</td>\\n","      <td>1.263802</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-25</th>\\n","      <td>215.0</td>\\n","      <td>18.55</td>\\n","      <td>217.0</td>\\n","      <td>11.40</td>\\n","      <td>NaN</td>\\n","      <td>1.0825</td>\\n","      <td>1.41750</td>\\n","      <td>-1.12200</td>\\n","      <td>-1.50100</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>-0.052823</td>\\n","      <td>1.267731</td>\\n","      <td>0.00000</td>\\n","      <td>-5.418842e-16</td>\\n","      <td>0.000</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-26</th>\\n","      <td>40.0</td>\\n","      <td>18.00</td>\\n","      <td>42.0</td>\\n","      <td>8.80</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.98000</td>\\n","      <td>-0.63800</td>\\n","      <td>-1.27600</td>\\n","      <td>-0.361573</td>\\n","      <td>-0.253688</td>\\n","      <td>0.378873</td>\\n","      <td>1.260087</td>\\n","      <td>0.06750</td>\\n","      <td>1.600000e-01</td>\\n","      <td>0.302</td>\\n","      <td>-4.654263e-16</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-27</th>\\n","      <td>165.0</td>\\n","      <td>15.10</td>\\n","      <td>190.0</td>\\n","      <td>5.60</td>\\n","      <td>NaN</td>\\n","      <td>1.7650</td>\\n","      <td>2.03900</td>\\n","      <td>-0.29550</td>\\n","      <td>-0.70050</td>\\n","      <td>1.634417</td>\\n","      <td>0.803500</td>\\n","      <td>0.696519</td>\\n","      <td>1.640508</td>\\n","      <td>0.27750</td>\\n","      <td>6.050000e-01</td>\\n","      <td>2.107</td>\\n","      <td>3.020000e-01</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-28</th>\\n","      <td>210.0</td>\\n","      <td>19.00</td>\\n","      <td>192.0</td>\\n","      <td>7.95</td>\\n","      <td>NaN</td>\\n","      <td>1.9180</td>\\n","      <td>2.09650</td>\\n","      <td>NaN</td>\\n","      <td>-0.35425</td>\\n","      <td>1.526219</td>\\n","      <td>1.638354</td>\\n","      <td>0.734892</td>\\n","      <td>2.067030</td>\\n","      <td>0.17750</td>\\n","      <td>2.750000e-01</td>\\n","      <td>0.438</td>\\n","      <td>2.409000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-29</th>\\n","      <td>120.0</td>\\n","      <td>21.90</td>\\n","      <td>84.0</td>\\n","      <td>7.80</td>\\n","      <td>NaN</td>\\n","      <td>1.4910</td>\\n","      <td>2.09300</td>\\n","      <td>-0.25075</td>\\n","      <td>NaN</td>\\n","      <td>0.699688</td>\\n","      <td>0.928375</td>\\n","      <td>0.753175</td>\\n","      <td>2.163813</td>\\n","      <td>0.22750</td>\\n","      <td>4.837500e-01</td>\\n","      <td>0.973</td>\\n","      <td>2.847000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-09-30</th>\\n","      <td>175.0</td>\\n","      <td>35.00</td>\\n","      <td>180.0</td>\\n","      <td>13.20</td>\\n","      <td>NaN</td>\\n","      <td>1.8240</td>\\n","      <td>1.87000</td>\\n","      <td>NaN</td>\\n","      <td>-0.02450</td>\\n","      <td>1.156938</td>\\n","      <td>0.991833</td>\\n","      <td>0.932358</td>\\n","      <td>4.159302</td>\\n","      <td>0.60500</td>\\n","      <td>1.321250e+00</td>\\n","      <td>8.350</td>\\n","      <td>3.518000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-01</th>\\n","      <td>170.0</td>\\n","      <td>19.45</td>\\n","      <td>348.0</td>\\n","      <td>10.60</td>\\n","      <td>NaN</td>\\n","      <td>2.2195</td>\\n","      <td>2.63150</td>\\n","      <td>0.22475</td>\\n","      <td>NaN</td>\\n","      <td>1.201875</td>\\n","      <td>1.286562</td>\\n","      <td>1.323240</td>\\n","      <td>4.636991</td>\\n","      <td>0.30500</td>\\n","      <td>9.050000e-01</td>\\n","      <td>0.609</td>\\n","      <td>9.761000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-02</th>\\n","      <td>35.0</td>\\n","      <td>19.55</td>\\n","      <td>42.0</td>\\n","      <td>10.60</td>\\n","      <td>NaN</td>\\n","      <td>2.0505</td>\\n","      <td>2.30850</td>\\n","      <td>NaN</td>\\n","      <td>-0.11975</td>\\n","      <td>NaN</td>\\n","      <td>NaN</td>\\n","      <td>1.140260</td>\\n","      <td>4.170616</td>\\n","      <td>0.00000</td>\\n","      <td>-6.088879e-16</td>\\n","      <td>0.000</td>\\n","      <td>9.932000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-03</th>\\n","      <td>20.0</td>\\n","      <td>28.00</td>\\n","      <td>38.0</td>\\n","      <td>17.20</td>\\n","      <td>NaN</td>\\n","      <td>2.3230</td>\\n","      <td>3.26800</td>\\n","      <td>0.31800</td>\\n","      <td>NaN</td>\\n","      <td>0.607354</td>\\n","      <td>0.555792</td>\\n","      <td>1.703937</td>\\n","      <td>4.088179</td>\\n","      <td>0.08875</td>\\n","      <td>1.750000e-01</td>\\n","      <td>0.596</td>\\n","      <td>8.959000e+00</td>\\n","    </tr>\\n","    <tr>\\n","      <th>2010-10-04</th>\\n","      <td>20.0</td>\\n","      <td>23.45</td>\\n","      <td>347.0</td>\\n","      <td>12.50</td>\\n","      <td>NaN</td>\\n","      <td>3.2105</td>\\n","      <td>3.61750</td>\\n","      <td>1.18600</td>\\n","      <td>0.53300</td>\\n","      <td>2.713385</td>\\n","      <td>2.945146</td>\\n","      <td>2.103325</td>\\n","      <td>4.225803</td>\\n","      <td>0.04000</td>\\n","      <td>1.200000e-01</td>\\n","      <td>0.320</td>\\n","      <td>1.205000e+00</td>\\n","    </tr>\\n","  </tbody>\\n","</table>\\n","</div>"],"text/plain":["             WDF2   WSF2   AWDR   AWND  WGF6      ht      hht       lt  \\\\\\n","Datetime                                                                 \\n","2010-09-15  125.0  14.00  119.0   5.35   NaN  1.5470  1.91250 -0.58400   \\n","2010-09-16  210.0  22.90  210.0  12.40   NaN  1.2205  1.45200 -0.86250   \\n","2010-09-17  210.0  18.55   41.0  10.20   NaN  0.8865      NaN      NaN   \\n","2010-09-18   30.0  17.10   37.0   8.95   NaN     NaN  1.63575 -0.83650   \\n","2010-09-19   25.0  11.10   58.0   4.50   NaN  1.7275  2.01750 -0.51350   \\n","2010-09-20   15.0  22.45   29.0  10.20   NaN  1.8965  2.35750 -0.22625   \\n","2010-09-21  135.0  14.10   79.0   7.05   NaN  2.0685  1.97500 -0.52650   \\n","2010-09-22  220.0  18.00  209.0   9.95   NaN  1.4095  1.43500 -0.83500   \\n","2010-09-23  155.0  15.00  205.0   6.80   NaN  1.3130      NaN -1.29600   \\n","2010-09-24  200.0  18.45  221.0  10.75   NaN  1.2815  1.76700 -0.94350   \\n","2010-09-25  215.0  18.55  217.0  11.40   NaN  1.0825  1.41750 -1.12200   \\n","2010-09-26   40.0  18.00   42.0   8.80   NaN     NaN  1.98000 -0.63800   \\n","2010-09-27  165.0  15.10  190.0   5.60   NaN  1.7650  2.03900 -0.29550   \\n","2010-09-28  210.0  19.00  192.0   7.95   NaN  1.9180  2.09650      NaN   \\n","2010-09-29  120.0  21.90   84.0   7.80   NaN  1.4910  2.09300 -0.25075   \\n","2010-09-30  175.0  35.00  180.0  13.20   NaN  1.8240  1.87000      NaN   \\n","2010-10-01  170.0  19.45  348.0  10.60   NaN  2.2195  2.63150  0.22475   \\n","2010-10-02   35.0  19.55   42.0  10.60   NaN  2.0505  2.30850      NaN   \\n","2010-10-03   20.0  28.00   38.0  17.20   NaN  2.3230  3.26800  0.31800   \\n","2010-10-04   20.0  23.45  347.0  12.50   NaN  3.2105  3.61750  1.18600   \\n","\\n","                llt    r15_td    rhr_td     td_av     gw_av    r15mx  \\\\\\n","Datetime                                                               \\n","2010-09-15 -0.60400       NaN       NaN  0.630327  1.439483  0.00000   \\n","2010-09-16 -1.16800       NaN       NaN  0.317994  1.424287  0.00000   \\n","2010-09-17 -1.17150       NaN       NaN -0.033356  1.405075  0.00000   \\n","2010-09-18 -0.67900       NaN       NaN  0.517577  1.373122  0.00000   \\n","2010-09-19 -0.45100       NaN       NaN  0.729448  1.365681  0.00000   \\n","2010-09-20      NaN       NaN       NaN  1.034590  1.354308  0.00000   \\n","2010-09-21 -0.22800       NaN       NaN  0.843558  1.314162  0.00000   \\n","2010-09-22 -0.78750       NaN       NaN  0.290825  1.293849  0.00000   \\n","2010-09-23 -1.53200       NaN       NaN -0.065860  1.272830  0.00000   \\n","2010-09-24 -1.39250       NaN       NaN  0.213317  1.263802  0.00000   \\n","2010-09-25 -1.50100       NaN       NaN -0.052823  1.267731  0.00000   \\n","2010-09-26 -1.27600 -0.361573 -0.253688  0.378873  1.260087  0.06750   \\n","2010-09-27 -0.70050  1.634417  0.803500  0.696519  1.640508  0.27750   \\n","2010-09-28 -0.35425  1.526219  1.638354  0.734892  2.067030  0.17750   \\n","2010-09-29      NaN  0.699688  0.928375  0.753175  2.163813  0.22750   \\n","2010-09-30 -0.02450  1.156938  0.991833  0.932358  4.159302  0.60500   \\n","2010-10-01      NaN  1.201875  1.286562  1.323240  4.636991  0.30500   \\n","2010-10-02 -0.11975       NaN       NaN  1.140260  4.170616  0.00000   \\n","2010-10-03      NaN  0.607354  0.555792  1.703937  4.088179  0.08875   \\n","2010-10-04  0.53300  2.713385  2.945146  2.103325  4.225803  0.04000   \\n","\\n","                   rhrmx     rd           r3d  \\n","Datetime                                       \\n","2010-09-15 -5.418842e-16  0.000  2.570000e-01  \\n","2010-09-16 -5.418842e-16  0.000  1.000000e-03  \\n","2010-09-17 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-18 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-19 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-20 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-21 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-22 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-23 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-24 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-25 -5.418842e-16  0.000 -4.654263e-16  \\n","2010-09-26  1.600000e-01  0.302 -4.654263e-16  \\n","2010-09-27  6.050000e-01  2.107  3.020000e-01  \\n","2010-09-28  2.750000e-01  0.438  2.409000e+00  \\n","2010-09-29  4.837500e-01  0.973  2.847000e+00  \\n","2010-09-30  1.321250e+00  8.350  3.518000e+00  \\n","2010-10-01  9.050000e-01  0.609  9.761000e+00  \\n","2010-10-02 -6.088879e-16  0.000  9.932000e+00  \\n","2010-10-03  1.750000e-01  0.596  8.959000e+00  \\n","2010-10-04  1.200000e-01  0.320  1.205000e+00  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["avdf.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"}},"nbformat":4,"nbformat_minor":0}', 'jupyter', NULL, NULL, NULL, NULL),
	('t9g0ta', 'test.sh', '#!/bin/bash\n\necho "Test2 + 3 + 4 + 5"\n\necho "{\\"cells\\":[{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"# Connecting to an existing IPython kernel using the Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## The Frontend/Kernel Model\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\\\n\\",\\"\\\\n\\",\\"While this traditional application still exists, the modern Jupyter consists of two processes:\\\\n\\",\\"\\\\n\\",\\"* Kernel: this is the process that runs the users code.\\\\n\\",\\"* Frontend: this is the process that provides the user interface where the user types code and sees results.\\\\n\\",\\"\\\\n\\",\\"Jupyter currently has 3 frontends:\\\\n\\",\\"\\\\n\\",\\"* Terminal Console (`jupyter console`)\\\\n\\",\\"* Qt Console (`jupyter qtconsole`)\\\\n\\",\\"* Notebook (`jupyter notebook`)\\\\n\\",\\"\\\\n\\",\\"The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\\\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\\\'s Kernel and use it as a help\\\\n\\",\\"browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\\\n\\",\\"one in the notebook).  \\\\n\\",\\"\\\\n\\",\\"This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\\\n\\",\\"The commands currently given here are specific to the IPython kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Manual connection\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%connect_info\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can see that this magic displays everything you need to connect to this Notebook\\\'s Kernel.\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"## Automatic connection using a new Qt Console\\"]},{\\"cell_type\\":\\"markdown\\",\\"metadata\\":{},\\"source\\":[\\"You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\\\n\\",\\"information and start the Qt Console for you automatically.\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"a = 10\\"]},{\\"cell_type\\":\\"code\\",\\"execution_count\\":null,\\"metadata\\":{},\\"outputs\\":[],\\"source\\":[\\"%qtconsole\\"]}],\\"metadata\\":{\\"nbsphinx\\":{\\"execute\\":\\"never\\"},\\"kernelspec\\":{\\"display_name\\":\\"Python 3\\",\\"language\\":\\"python\\",\\"name\\":\\"python3\\"},\\"language_info\\":{\\"codemirror_mode\\":{\\"name\\":\\"ipython\\",\\"version\\":3},\\"file_extension\\":\\".py\\",\\"mimetype\\":\\"text/x-python\\",\\"name\\":\\"python\\",\\"nbconvert_exporter\\":\\"python\\",\\"pygments_lexer\\":\\"ipython3\\",\\"version\\":\\"3.5.2\\"}},\\"nbformat\\":4,\\"nbformat_minor\\":1}\\r\\n" > testjupyter.ipynb;\n\necho "==== Geoweaver Bash Output Finished ====";\n\n\n\n\n\n', 'shell', '/home/zsun/test.sh', 'kps1gf', NULL, NULL),
	('umv6tx', 'filter_bad', '#!/bin/bash\necho "remove bad pixels"', 'shell', NULL, NULL, NULL, NULL),
	('wcyu4q', 'test-esip-2', '# Write first python in Geoweaver\nprint("oceanography example script")', 'python', NULL, NULL, NULL, NULL),
	('wqpypi', 'train_lstm', '#!/bin/bash\n', 'shell', NULL, NULL, NULL, NULL),
	('wssh33', 'test-folder-again', '{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Connecting to an existing IPython kernel using the Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["## The Frontend/Kernel Model"]},{"cell_type":"markdown","metadata":{},"source":["The traditional IPython (`ipython`) consists of a single process that combines a terminal based UI with the process that runs the users code.\\n","\\n","While this traditional application still exists, the modern Jupyter consists of two processes:\\n","\\n","* Kernel: this is the process that runs the users code.\\n","* Frontend: this is the process that provides the user interface where the user types code and sees results.\\n","\\n","Jupyter currently has 3 frontends:\\n","\\n","* Terminal Console (`jupyter console`)\\n","* Qt Console (`jupyter qtconsole`)\\n","* Notebook (`jupyter notebook`)\\n","\\n","The Kernel and Frontend communicate over a ZeroMQ/JSON based messaging protocol, which allows multiple Frontends (even of different types) to communicate with a single Kernel. This opens the door for all sorts of interesting things, such as connecting a Console or Qt Console to a Notebook\'s Kernel.  For example, you may want to connect a Qt console to your Notebook\'s Kernel and use it as a help\\n","browser, calling `??` on objects in the Qt console (whose pager is more flexible than the\\n","one in the notebook).  \\n","\\n","This Notebook describes how you would connect another Frontend to an IPython Kernel that is associated with a Notebook.\\n","The commands currently given here are specific to the IPython kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Manual connection"]},{"cell_type":"markdown","metadata":{},"source":["To connect another Frontend to a Kernel manually, you first need to find out the connection information for the Kernel using the `%connect_info` magic:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%connect_info"]},{"cell_type":"markdown","metadata":{},"source":["You can see that this magic displays everything you need to connect to this Notebook\'s Kernel."]},{"cell_type":"markdown","metadata":{},"source":["## Automatic connection using a new Qt Console"]},{"cell_type":"markdown","metadata":{},"source":["You can also start a new Qt Console connected to your current Kernel by using the `%qtconsole` magic. This will detect the necessary connection\\n","information and start the Qt Console for you automatically."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%qtconsole"]}],"metadata":{"nbsphinx":{"execute":"never"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}', 'jupyter', NULL, NULL, NULL, NULL),
	('wsxeps', 'download_cdl', '#!/bin/bash\n#write your bash script\necho "download cdl"', 'shell', NULL, NULL, NULL, NULL),
	('y9jmbe', 'test4', '# Write first python in Geoweaver\nprint("test add problem")', 'python', NULL, NULL, NULL, NULL),
	('zdh3ll', 'coords_transform', '#!/bin/bash\necho "coordinate transformation"\nsleep 5s', 'shell', NULL, NULL, NULL, NULL);
/*!40000 ALTER TABLE `process_type` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.products
DROP TABLE IF EXISTS `products`;
CREATE TABLE IF NOT EXISTS `products` (
  `identifier` varchar(50) NOT NULL DEFAULT '',
  `abbreviation` varchar(50) DEFAULT NULL,
  `description` tinytext,
  `keywords` tinytext,
  `name` varchar(100) NOT NULL,
  `east` double(20,6) DEFAULT NULL,
  `south` double(20,6) DEFAULT NULL,
  `west` double(20,6) DEFAULT NULL,
  `north` double(20,6) DEFAULT NULL,
  `srs` varchar(50) DEFAULT 'EPSG:4326',
  `begintime` date DEFAULT '1900-01-01',
  `endtime` date DEFAULT NULL,
  `ifvirtual` char(1) NOT NULL DEFAULT '0',
  `likes` tinyint(4) DEFAULT '0',
  `parent_abstract_model` varchar(50) DEFAULT NULL,
  `dataFormat` varchar(50) DEFAULT NULL,
  `accessURL` tinytext,
  `ontology_reference` tinytext,
  `lastUpdateDate` date DEFAULT NULL,
  `userid` int(10) DEFAULT NULL,
  `isspatial` char(1) DEFAULT NULL,
  PRIMARY KEY (`identifier`),
  UNIQUE KEY `identifier` (`identifier`),
  UNIQUE KEY `name` (`name`),
  KEY `ifvirtual` (`ifvirtual`),
  KEY `parent_abstract_model` (`parent_abstract_model`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='This table archives the metadata of VDPs.';

-- Dumping data for table cyberconnector.products: ~9 rows (approximately)
DELETE FROM `products`;
/*!40000 ALTER TABLE `products` DISABLE KEYS */;
INSERT INTO `products` (`identifier`, `abbreviation`, `description`, `keywords`, `name`, `east`, `south`, `west`, `north`, `srs`, `begintime`, `endtime`, `ifvirtual`, `likes`, `parent_abstract_model`, `dataFormat`, `accessURL`, `ontology_reference`, `lastUpdateDate`, `userid`, `isspatial`) VALUES
	('0h1k8d2dos3yo0vhkf3hvwv2mx5o5e', 'customized global VCI', 'vegetation condition index', 'vci', '16 days 250m global customizable VCI', 180.000000, -90.000000, -180.000000, 90.000000, 'EPSG:4326', '2001-01-01', '2015-08-12', '1', 13, 'urn:uuid:1aecf430-2f71-1033-b535-9c6f81aea662', 'image/geotiff', 'null', 'null', '2015-08-12', 1, '1'),
	('330j1mtkt6elfkud7anu2cnx9rrqrq', 'CRM_array_averaged_analysis_model', 'This model generates CSU array-averaged analysis products.', 'cloud, fluxes, sounding, forcing, q1, q2', 'CRM_array_averaged_analysis_model', 180.000000, -90.000000, -180.000000, 90.000000, 'null', '1970-01-01', '2016-02-04', '1', 1, 'urn:uuid:beb9d320-7531-1033-ac74-df4e81aea662', 'null', 'null', 'null', '2015-11-23', 1, '1'),
	('823q83eltkardidwgbn3c6cvfmsg07', 'fvcom wind forcing input', 'wind forcing  condition data', 'wind forcing condition data', 'wind forcing condition data', 180.000000, -90.000000, -180.000000, 90.000000, 'null', '2010-01-01', '2015-08-12', '1', 2, 'urn:uuid:23e43e80-5867-1033-acac-bba0c0a80002', 'custom text', 'null', 'null', '2015-10-17', 1, '1'),
	('9t1o2kjwpkrgcvchxueutiiz1ftkvj', 'fvcom river boundary condition input', 'river boundary condition data', 'river boundary condition data', 'river boundary condition data', 180.000000, -90.000000, -180.000000, 90.000000, 'null', '2001-01-01', '2015-08-12', '1', 2, 'urn:uuid:55918540-56ab-1033-a3e4-942e81aea662', 'custom binary', 'null', 'null', '2015-10-16', 1, '1'),
	('hl6tgckiv5k09lvsb4xf2gd79aa7kc', 'DownloadECMWFDatasets', 'This model helps downloading the ECMWF public datasets. The scripts take advantage of the ECMWF Web python API. The dataset will first downloaded and a URL link will be returned.', 'ECMWF, Temperature, Precipitation, Modeling', 'DownloadECMWFDatasets', 180.000000, -90.000000, -180.000000, 90.000000, 'EPSG:4326', '1979-01-01', '2017-02-22', '1', 1, 'urn:uuid:4da9efd0-dc6e-1034-a8e0-544681aea649', 'image/netcdf', 'null', 'null', '2017-02-22', 1, '1'),
	('iqm44atsu71ximwas0dv3w88ua4pcf', 'fvcom temperature and salinity input', 'temperature and salinity condition data', 'temperature and salinity condition data', 'temperature and salinity condition data', 180.000000, -90.000000, -180.000000, 90.000000, 'null', '2010-01-01', '2015-08-12', '1', 1, 'urn:uuid:7e364d60-581c-1033-877f-55fbc0a80002', 'custom text', 'null', 'null', '2015-10-17', 1, '1'),
	('iwvsnr3oxhxfg8p0yzzeflmk7pedr5', 'YearsDailyNDVIModel', 'Generate daily NDVI for one day in different year. The output is a list of daily NDVI corresponding to the year list.', 'NDVI, MODIS, Remote sensing', 'YearsDailyNDVIModel', 180.000000, -90.000000, -180.000000, 90.000000, 'null', '1970-01-01', '2016-02-05', '1', 0, 'urn:uuid:3aae5df0-af4a-1033-bd29-552e81aea662', 'null', 'null', 'null', '2016-02-05', 1, '1'),
	('pn6ubfd09y4e4cq9dl4idhislt4s3b', 'MODIS_NDVI_Generation_Model', 'Generating MODIS NDVI.', 'NDVI, VCI', 'MODIS_NDVI_Generation_Model', 180.000000, -90.000000, -180.000000, 90.000000, 'EPSG:4326', '1970-01-01', '2016-02-21', '1', 0, 'urn:uuid:00d25020-bc1d-1033-90a3-940e81aea662', 'image/png', 'null', 'null', '2016-02-21', 1, '1'),
	('y97hezrbzoon65ehb18y6i1hg5p10f', 'PreprocessingImageObjects', 'Preprocess image and generate objects.', 'image object', 'PreprocessingImageObjects', 180.000000, -90.000000, -180.000000, 90.000000, 'EPSG:4326', '1970-01-01', '2016-07-04', '1', 0, 'urn:uuid:10f33810-255f-1034-8580-adfdc0a80006', 'image/geotiff', 'null', 'null', '2016-07-04', 1, '1');
/*!40000 ALTER TABLE `products` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.requirements
DROP TABLE IF EXISTS `requirements`;
CREATE TABLE IF NOT EXISTS `requirements` (
  `productid` varchar(50) NOT NULL,
  `format` varchar(50) NOT NULL,
  `modelInput` varchar(50) NOT NULL,
  `type` enum('BoundingBox','TimeRange','TimeStamp','Projection','InitialDataURL','OutputFormat','SpatialPoint','SpatialPolygon','Unknown') NOT NULL,
  `constraints` varchar(50) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='This table is unused.';

-- Dumping data for table cyberconnector.requirements: ~0 rows (approximately)
DELETE FROM `requirements`;
/*!40000 ALTER TABLE `requirements` DISABLE KEYS */;
/*!40000 ALTER TABLE `requirements` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.service
DROP TABLE IF EXISTS `service`;
CREATE TABLE IF NOT EXISTS `service` (
  `tid` int(11) NOT NULL AUTO_INCREMENT,
  `id` varchar(48) NOT NULL,
  `home` varchar(255) DEFAULT NULL,
  `name` text,
  `description` text,
  `status` varchar(16) DEFAULT NULL,
  `registerdate` datetime DEFAULT NULL,
  `expiration` datetime DEFAULT NULL,
  `majorVersion` int(16) NOT NULL DEFAULT '1',
  `minorVersion` int(16) NOT NULL DEFAULT '0',
  `userVersion` varchar(64) DEFAULT NULL,
  `keywords` varchar(256) DEFAULT NULL,
  `serviceType` varchar(64) DEFAULT NULL,
  `accessURL` varchar(256) DEFAULT NULL,
  `wsdlURL` varchar(256) DEFAULT NULL,
  `userid` int(10) DEFAULT NULL,
  PRIMARY KEY (`tid`),
  KEY `id` (`id`),
  KEY `name` (`name`(64)),
  KEY `description` (`description`(255)),
  KEY `keywords` (`keywords`),
  KEY `serviceType` (`serviceType`),
  KEY `accessURL` (`accessURL`)
) ENGINE=InnoDB AUTO_INCREMENT=178 DEFAULT CHARSET=latin1 COMMENT='This table stores the metadata of physical web services.';

-- Dumping data for table cyberconnector.service: ~53 rows (approximately)
DELETE FROM `service`;
/*!40000 ALTER TABLE `service` DISABLE KEYS */;
INSERT INTO `service` (`tid`, `id`, `home`, `name`, `description`, `status`, `registerdate`, `expiration`, `majorVersion`, `minorVersion`, `userVersion`, `keywords`, `serviceType`, `accessURL`, `wsdlURL`, `userid`) VALUES
	(30, 'uuid:urn:259ac718-dd4e-4e12-889a-1475dba9c056', 'Vector_MergeSameClassService', 'Vector_MergeSameClassService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_MergeSameClass', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_MergeSameClass?wsdl', 1),
	(34, 'uuid:urn:b72dca5c-06a5-4c56-aa7c-a6be0b3a7c5a', 'NDVICalWorkflow', 'NDVICalWorkflow', 'NDVICalWorkflow', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://gis.csiss.gmu.edu/axis2/services/NDVICalWorkflow.NDVICalWorkflowHttpEndpoint/', 'http://gis.csiss.gmu.edu/axis2/services/NDVICalWorkflow?wsdl', 1),
	(36, 'uuid:urn:121f88c6-8195-4e36-91eb-2fb2f7e2d838', 'Raster_R2VService', 'Raster_R2VService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_R2V', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_R2V?wsdl', 1),
	(37, 'uuid:urn:dbf420d5-64fc-4400-808f-10941cb1c66a', 'Raster_EliminateSmallPolygonsService', 'Raster_EliminateSmallPolygonsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_EliminateSmallPolygons', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_EliminateSmallPolygons?wsdl', 1),
	(40, 'uuid:urn:0d887ae9-142b-41e3-8b14-fb962e7ea1b4', 'Raster_RGB2SingleValueService', 'Raster_RGB2SingleValueService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_RGB2SingleValue', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_RGB2SingleValue?wsdl', 1),
	(41, 'uuid:urn:0786d4ac-c01c-4b46-9a40-e3e4bde83e63', 'Raster_ImageSegmentService', 'Raster_ImageSegmentService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_ImageSegment', 'http://129.174.131.8:9006/GeoprocessingWS/services/Raster_ImageSegment?wsdl', 1),
	(42, 'uuid:urn:def95498-73dd-4662-980b-6068bafbdf49', 'Vector_KNNClassification_OnSampleDatabaseService', 'Vector_KNNClassification_OnSampleDatabaseService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_KNNClassification_OnSampleDatabase', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_KNNClassification_OnSampleDatabase?wsdl', 1),
	(44, 'uuid:urn:9c8c1d1e-4b5a-44eb-b8b6-027d01af0255', 'FVCOMService', 'FVCOMService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://www3.csiss.gmu.edu/CubeModelWS/services/FVCOM', 'http://www3.csiss.gmu.edu/CubeModelWS/services/FVCOM?wsdl', 1),
	(46, 'uuid:urn:f7548a4b-d3af-4175-a28b-41964cdc2e74', 'CRMService', 'CRMService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://www3.csiss.gmu.edu/CubeModelWS/services/CRM', 'http://www3.csiss.gmu.edu/CubeModelWS/services/CRM?wsdl', 1),
	(66, 'uuid:urn:237dddf7-ea8d-4031-9ba9-db55d7c5ef52', 'DrawDroughtPercentBarChart', 'DrawDroughtPercentBarChart', '\n		Please Type your service description here\n	', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://gis.csiss.gmu.edu/axis2/services/DrawDroughtPercentBarChart.DrawDroughtPercentBarChartHttpEndpoint/', 'http://gis.csiss.gmu.edu/axis2/services/DrawDroughtPercentBarChart?wsdl', 1),
	(101, 'uuid:urn:417534fe-c4fa-40c9-a4cf-cf60cc8b1f9b', 'NDVICalWorkflow', 'NDVICalWorkflow', 'NDVICalWorkflow', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://gis.csiss.gmu.edu/axis2/services/NDVICalWorkflow.NDVICalWorkflowHttpEndpoint/', 'http://gis.csiss.gmu.edu/axis2/services/NDVICalWorkflow?wsdl', 1),
	(106, 'uuid:urn:2b90e57c-7c9d-4b93-aeb3-5270659211b8', 'Vector_RemoveSmallPolygonsService', 'Vector_RemoveSmallPolygonsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_RemoveSmallPolygons', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_RemoveSmallPolygons?wsdl', 1),
	(107, 'uuid:urn:0cdc3e3c-de2b-40c9-9b18-290c5c773c7a', 'Vector_GetProjectionService', 'Vector_GetProjectionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_GetProjection', 'http://129.174.131.8:9006/GeoprocessingWS/services/Vector_GetProjection?wsdl', 1),
	(110, 'uuid:urn:79e457d5-edf6-4678-8cc7-d2ff4ac5c4eb', 'ECMWFService', 'ECMWFService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/CubeModelWS/services/ECMWF', 'http://cube.csiss.gmu.edu/CubeModelWS/services/ECMWF?wsdl', 1),
	(112, 'uuid:urn:eff86166-504c-44c5-ada4-c5b1ca1b48c8', 'Raster_GeoparameterCalculationService', 'Raster_GeoparameterCalculationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_GeoparameterCalculation', 'http://cube.csiss.gmu.edu/axis/services/Raster_GeoparameterCalculation?wsdl', 3),
	(113, 'uuid:urn:ff34a51f-004c-4f8d-a919-23a24a40b55b', 'Vector_GML2SHPService', 'Vector_GML2SHPService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_GML2SHP', 'http://cube.csiss.gmu.edu/axis/services/Vector_GML2SHP?wsdl', 3),
	(114, 'uuid:urn:c3e55c25-9ef2-459e-829d-5452fe0cde67', 'Vector_PatchService', 'Vector_PatchService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_Patch', 'http://cube.csiss.gmu.edu/axis/services/Vector_Patch?wsdl', 3),
	(115, 'uuid:urn:69459abe-517a-4abf-b68a-d0d7cff01c36', 'Raster_RGBcompositeService', 'Raster_RGBcompositeService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_RGBcomposite', 'http://cube.csiss.gmu.edu/axis/services/Raster_RGBcomposite?wsdl', 3),
	(116, 'uuid:urn:0304de9d-5211-4bd8-a881-18c803324a41', 'Raster_PatchSingleBandService', 'Raster_PatchSingleBandService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_PatchSingleBand', 'http://cube.csiss.gmu.edu/axis/services/Raster_PatchSingleBand?wsdl', 3),
	(117, 'uuid:urn:2459ef36-5f33-4ae5-9ee3-b11db972afb9', 'Raster_ImageAlgebraService', 'Raster_ImageAlgebraService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_ImageAlgebra', 'http://cube.csiss.gmu.edu/axis/services/Raster_ImageAlgebra?wsdl', 3),
	(118, 'uuid:urn:6912fbd1-2da4-4117-a8b6-77dabfc7fc18', 'Raster_OpennessCalculationService', 'Raster_OpennessCalculationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_OpennessCalculation', 'http://cube.csiss.gmu.edu/axis/services/Raster_OpennessCalculation?wsdl', 3),
	(119, 'uuid:urn:3772a8c8-a398-4696-a149-b1da0919dcf6', 'Raster_SurfaceGenerationService', 'Raster_SurfaceGenerationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_SurfaceGeneration', 'http://cube.csiss.gmu.edu/axis/services/Raster_SurfaceGeneration?wsdl', 3),
	(120, 'uuid:urn:f800d57e-7933-4083-b7d9-09247902e1a5', 'Raster_SupervisedClassificationService', 'Raster_SupervisedClassificationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_SupervisedClassification', 'http://cube.csiss.gmu.edu/axis/services/Raster_SupervisedClassification?wsdl', 3),
	(121, 'uuid:urn:a14ccd77-8457-47f3-9932-471f07b91871', 'Raster_RGB2HISService', 'Raster_RGB2HISService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_RGB2HIS', 'http://cube.csiss.gmu.edu/axis/services/Raster_RGB2HIS?wsdl', 3),
	(122, 'uuid:urn:a49e3fbb-f86f-4480-aaf1-ff37ecfc6dde', 'Raster_DefinedIntervalStatisticsService', 'Raster_DefinedIntervalStatisticsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_DefinedIntervalStatistics', 'http://cube.csiss.gmu.edu/axis/services/Raster_DefinedIntervalStatistics?wsdl', 3),
	(123, 'uuid:urn:11251b9a-8616-482b-a996-efcd59e4c9a3', 'Vector_ShortestPathService', 'Vector_ShortestPathService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_ShortestPath', 'http://cube.csiss.gmu.edu/axis/services/Vector_ShortestPath?wsdl', 3),
	(124, 'uuid:urn:443b69d5-e225-4c1f-bf43-833fe20639a3', 'Raster_EdgeDetectionService', 'Raster_EdgeDetectionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_EdgeDetection', 'http://cube.csiss.gmu.edu/axis/services/Raster_EdgeDetection?wsdl', 3),
	(125, 'uuid:urn:6e9c9bfe-8877-4138-b79e-f02af325fe16', 'Raster_TangentialCurvatureService', 'Raster_TangentialCurvatureService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_TangentialCurvature', 'http://cube.csiss.gmu.edu/axis/services/Raster_TangentialCurvature?wsdl', 3),
	(126, 'uuid:urn:fca26ce3-a42b-410e-a9c3-5344caf1d406', 'Raster_CovarianceCorrelationService', 'Raster_CovarianceCorrelationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_CovarianceCorrelation', 'http://cube.csiss.gmu.edu/axis/services/Raster_CovarianceCorrelation?wsdl', 3),
	(127, 'uuid:urn:c809b9cf-d6fa-4b9b-a0b5-af16b76d8c50', 'Raster_UnsupervisedClassificationService', 'Raster_UnsupervisedClassificationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_UnsupervisedClassification', 'http://cube.csiss.gmu.edu/axis/services/Raster_UnsupervisedClassification?wsdl', 3),
	(128, 'uuid:urn:5c926ff0-2cd8-44a7-a0db-59d774e35f0e', 'Raster_FFTService', 'Raster_FFTService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_FFT', 'http://cube.csiss.gmu.edu/axis/services/Raster_FFT?wsdl', 3),
	(129, 'uuid:urn:f8f27690-9caf-4ab1-8de2-059aec6c1829', 'Raster_ClassificationStatisticsService', 'Raster_ClassificationStatisticsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_ClassificationStatistics', 'http://cube.csiss.gmu.edu/axis/services/Raster_ClassificationStatistics?wsdl', 3),
	(130, 'uuid:urn:6fad3254-2c44-4329-9c54-4cb1c15b5f12', 'Raster_BufferService', 'Raster_BufferService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Buffer', 'http://cube.csiss.gmu.edu/axis/services/Raster_Buffer?wsdl', 3),
	(131, 'uuid:urn:c9dd3f42-05d4-43e2-bcb3-926267aa2eeb', 'Vector_BufferService', 'Vector_BufferService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_Buffer', 'http://cube.csiss.gmu.edu/axis/services/Vector_Buffer?wsdl', 3),
	(132, 'uuid:urn:3572f7a9-0a5d-4175-b25a-880ac47b466d', 'Raster_AspectService', 'Raster_AspectService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Aspect', 'http://cube.csiss.gmu.edu/axis/services/Raster_Aspect?wsdl', 3),
	(133, 'uuid:urn:1c329494-20fa-44aa-a35d-e57dc55c7d57', 'Raster_MosaicService', 'Raster_MosaicService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Mosaic', 'http://cube.csiss.gmu.edu/axis/services/Raster_Mosaic?wsdl', 3),
	(134, 'uuid:urn:bb5fe85a-aa5b-4f71-b936-3d2436307d39', 'Raster_TopographicShadingService', 'Raster_TopographicShadingService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_TopographicShading', 'http://cube.csiss.gmu.edu/axis/services/Raster_TopographicShading?wsdl', 3),
	(135, 'uuid:urn:c82f0dc3-85f5-4667-8243-240578f5da93', 'Raster_CreateContourService', 'Raster_CreateContourService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_CreateContour', 'http://cube.csiss.gmu.edu/axis/services/Raster_CreateContour?wsdl', 3),
	(136, 'uuid:urn:54be85ce-dc54-4d0d-9401-07f226471a67', 'Raster_LatLonBBoxClipService', 'Raster_LatLonBBoxClipService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_LatLonBBoxClip', 'http://cube.csiss.gmu.edu/axis/services/Raster_LatLonBBoxClip?wsdl', 3),
	(137, 'uuid:urn:44227ef5-92f0-4085-86ac-abf7b43b0a3a', 'Raster_DrainageBasinService', 'Raster_DrainageBasinService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_DrainageBasin', 'http://cube.csiss.gmu.edu/axis/services/Raster_DrainageBasin?wsdl', 3),
	(138, 'uuid:urn:17033043-e551-4bb4-8c53-a9bded84d77a', 'Raster_VectorizationService', 'Raster_VectorizationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Vectorization', 'http://cube.csiss.gmu.edu/axis/services/Raster_Vectorization?wsdl', 3),
	(139, 'uuid:urn:e7e16829-81ba-4969-b231-2ff797cb60cc', 'Raster_ManualIntervalStatisticsService', 'Raster_ManualIntervalStatisticsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_ManualIntervalStatistics', 'http://cube.csiss.gmu.edu/axis/services/Raster_ManualIntervalStatistics?wsdl', 3),
	(140, 'uuid:urn:4dc219cf-4fbf-4394-a8c7-0bc1d8f4b0e2', 'Vector_AttributeColumnService', 'Vector_AttributeColumnService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_AttributeColumn', 'http://cube.csiss.gmu.edu/axis/services/Vector_AttributeColumn?wsdl', 3),
	(141, 'uuid:urn:ba5917c9-3ca3-4613-8f9b-ffa552dec371', 'Raster_FlowDirectionService', 'Raster_FlowDirectionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_FlowDirection', 'http://cube.csiss.gmu.edu/axis/services/Raster_FlowDirection?wsdl', 3),
	(142, 'uuid:urn:faf923ce-2e8d-40eb-86f7-7192dd8a6f03', 'Raster_MatrixFilterService', 'Raster_MatrixFilterService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_MatrixFilter', 'http://cube.csiss.gmu.edu/axis/services/Raster_MatrixFilter?wsdl', 3),
	(143, 'uuid:urn:880a2a8e-7f01-421a-9b4c-f62e22f6a77a', 'Raster_HIS2RGBService', 'Raster_HIS2RGBService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_HIS2RGB', 'http://cube.csiss.gmu.edu/axis/services/Raster_HIS2RGB?wsdl', 3),
	(144, 'uuid:urn:bb10749f-a12e-475a-a336-08e7fd7f059f', 'Raster_AreaStatisticsService', 'Raster_AreaStatisticsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_AreaStatistics', 'http://cube.csiss.gmu.edu/axis/services/Raster_AreaStatistics?wsdl', 3),
	(145, 'uuid:urn:60905f64-7ed6-41f5-ba1a-b94b15f97b06', 'Raster_GreyScaleService', 'Raster_GreyScaleService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_GreyScale', 'http://cube.csiss.gmu.edu/axis/services/Raster_GreyScale?wsdl', 3),
	(146, 'uuid:urn:ebe0c3f2-96e1-4543-bb8e-c3944ed03a83', 'Vector_QueryInformationService', 'Vector_QueryInformationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_QueryInformation', 'http://cube.csiss.gmu.edu/axis/services/Vector_QueryInformation?wsdl', 3),
	(147, 'uuid:urn:bc1bd2ba-3425-4e5e-83df-8be6e8d1c67c', 'Raster_OIFService', 'Raster_OIFService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_OIF', 'http://cube.csiss.gmu.edu/axis/services/Raster_OIF?wsdl', 3),
	(148, 'uuid:urn:85a6a9af-08ef-4d92-9b08-b3d206926212', 'Vector_FeatureSelectionService', 'Vector_FeatureSelectionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_FeatureSelection', 'http://cube.csiss.gmu.edu/axis/services/Vector_FeatureSelection?wsdl', 3),
	(149, 'uuid:urn:4c7a748b-60b1-490c-b965-2bbba1dfe575', 'Raster_SurfaceInterpolationService', 'Raster_SurfaceInterpolationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_SurfaceInterpolation', 'http://cube.csiss.gmu.edu/axis/services/Raster_SurfaceInterpolation?wsdl', 3),
	(150, 'uuid:urn:2fa90659-29d0-40dc-8b52-409e3d3f6906', 'Raster_ChangeColortable_UserdefinedService', 'Raster_ChangeColortable_UserdefinedService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_ChangeColortable_Userdefined', 'http://cube.csiss.gmu.edu/axis/services/Raster_ChangeColortable_Userdefined?wsdl', 3),
	(151, 'uuid:urn:15b26da9-f44f-4fa4-a92a-c02c789d90dd', 'Raster_NDVIService', 'Raster_NDVIService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_NDVI', 'http://cube.csiss.gmu.edu/axis/services/Raster_NDVI?wsdl', 3),
	(152, 'uuid:urn:545ad808-87d8-43c3-962d-fbf9d0a730bf', 'Raster_PatchMultiBandService', 'Raster_PatchMultiBandService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_PatchMultiBand', 'http://cube.csiss.gmu.edu/axis/services/Raster_PatchMultiBand?wsdl', 3),
	(153, 'uuid:urn:0eb3f233-12d8-4a32-abf8-4d4886a23dfc', 'Raster_ProfileService', 'Raster_ProfileService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Profile', 'http://cube.csiss.gmu.edu/axis/services/Raster_Profile?wsdl', 3),
	(154, 'uuid:urn:4c4027a1-415f-46be-9886-dcb9c25f1b74', 'Vector_CleanTopologyService', 'Vector_CleanTopologyService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_CleanTopology', 'http://cube.csiss.gmu.edu/axis/services/Vector_CleanTopology?wsdl', 3),
	(155, 'uuid:urn:6cbf275f-f186-4462-a9be-89db18d9d343', 'Raster_BBoxClipService', 'Raster_BBoxClipService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_BBoxClip', 'http://cube.csiss.gmu.edu/axis/services/Raster_BBoxClip?wsdl', 3),
	(156, 'uuid:urn:1a564ba6-6f75-48d1-95de-2fc220d70f98', 'Vector_ValueExtractionService', 'Vector_ValueExtractionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_ValueExtraction', 'http://cube.csiss.gmu.edu/axis/services/Vector_ValueExtraction?wsdl', 3),
	(157, 'uuid:urn:17295474-d77e-4216-bf72-51f8dcaa3880', 'Raster_FusionBroveyService', 'Raster_FusionBroveyService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_FusionBrovey', 'http://cube.csiss.gmu.edu/axis/services/Raster_FusionBrovey?wsdl', 3),
	(158, 'uuid:urn:1e724ead-5b57-4f20-813b-eafe62bc3e7d', 'Vector_RasterizationService', 'Vector_RasterizationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_Rasterization', 'http://cube.csiss.gmu.edu/axis/services/Vector_Rasterization?wsdl', 3),
	(159, 'uuid:urn:5d69a5fd-5a5c-4d75-9994-32e62ea96277', 'Raster_FlowAccumulationService', 'Raster_FlowAccumulationService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_FlowAccumulation', 'http://cube.csiss.gmu.edu/axis/services/Raster_FlowAccumulation?wsdl', 3),
	(160, 'uuid:urn:e60c5c6c-4837-4879-a33b-2b766f7dbac0', 'Raster_SlopeService', 'Raster_SlopeService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Slope', 'http://cube.csiss.gmu.edu/axis/services/Raster_Slope?wsdl', 3),
	(161, 'uuid:urn:7ae48154-b923-40d7-8176-011324e3804c', 'Raster_PolygonClipService', 'Raster_PolygonClipService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_PolygonClip', 'http://cube.csiss.gmu.edu/axis/services/Raster_PolygonClip?wsdl', 3),
	(162, 'uuid:urn:1d62dd7c-b640-4f89-8a77-067b452f4a01', 'Vector_BuildPolylinesService', 'Vector_BuildPolylinesService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_BuildPolylines', 'http://cube.csiss.gmu.edu/axis/services/Vector_BuildPolylines?wsdl', 3),
	(163, 'uuid:urn:095f7d05-7d15-4857-b080-471d92508495', 'Raster_IFFTService', 'Raster_IFFTService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_IFFT', 'http://cube.csiss.gmu.edu/axis/services/Raster_IFFT?wsdl', 3),
	(164, 'uuid:urn:2e4f6b33-707a-4f31-baa1-9b6058dd6401', 'Raster_EqualIntervalStatisticsService', 'Raster_EqualIntervalStatisticsService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_EqualIntervalStatistics', 'http://cube.csiss.gmu.edu/axis/services/Raster_EqualIntervalStatistics?wsdl', 3),
	(165, 'uuid:urn:981244ba-b894-4335-9b20-884b6c28a88c', 'Raster_StreamExtractionService', 'Raster_StreamExtractionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_StreamExtraction', 'http://cube.csiss.gmu.edu/axis/services/Raster_StreamExtraction?wsdl', 3),
	(166, 'uuid:urn:89f09643-ba70-46f4-83e8-19df5222c18f', 'Raster_TopographicIndexService', 'Raster_TopographicIndexService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_TopographicIndex', 'http://cube.csiss.gmu.edu/axis/services/Raster_TopographicIndex?wsdl', 3),
	(167, 'uuid:urn:6efedd37-ab9c-4861-88ab-3c70bcae26f0', 'Raster_TasseledCapService', 'Raster_TasseledCapService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_TasseledCap', 'http://cube.csiss.gmu.edu/axis/services/Raster_TasseledCap?wsdl', 3),
	(168, 'uuid:urn:53b2d630-beea-4d6d-b2a1-28231133810c', 'Vector_OverlayService', 'Vector_OverlayService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_Overlay', 'http://cube.csiss.gmu.edu/axis/services/Vector_Overlay?wsdl', 3),
	(169, 'uuid:urn:d753989d-b01a-4d4b-a618-ba60917c49d4', 'Vector_BuildTopologyService', 'Vector_BuildTopologyService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_BuildTopology', 'http://cube.csiss.gmu.edu/axis/services/Vector_BuildTopology?wsdl', 3),
	(170, 'uuid:urn:26f8ea99-2506-40b7-ba5e-f3785bf6632d', 'Vector_FeatureExtractionService', 'Vector_FeatureExtractionService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_FeatureExtraction', 'http://cube.csiss.gmu.edu/axis/services/Vector_FeatureExtraction?wsdl', 3),
	(171, 'uuid:urn:53ed3ffe-c829-40e1-b1ab-c409d8e0fb7b', 'Vector_SHP2GMLService', 'Vector_SHP2GMLService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Vector_SHP2GML', 'http://cube.csiss.gmu.edu/axis/services/Vector_SHP2GML?wsdl', 3),
	(172, 'uuid:urn:153be9c5-0e81-452b-8a42-757b460a9d58', 'Raster_PCAService', 'Raster_PCAService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_PCA', 'http://cube.csiss.gmu.edu/axis/services/Raster_PCA?wsdl', 3),
	(173, 'uuid:urn:3e6cbe95-b0f3-4cc1-ba72-3d63944cd0af', 'Raster_RescaleService', 'Raster_RescaleService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_Rescale', 'http://cube.csiss.gmu.edu/axis/services/Raster_Rescale?wsdl', 3),
	(174, 'uuid:urn:78303af4-7773-4f5a-8f07-20ff3e14a606', 'Raster_RGBextractService', 'Raster_RGBextractService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_RGBextract', 'http://cube.csiss.gmu.edu/axis/services/Raster_RGBextract?wsdl', 3),
	(176, 'uuid:urn:d92d923f-da43-4bad-8971-513b936e32a4', 'Raster_ProfileCurvatureService', 'Raster_ProfileCurvatureService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_ProfileCurvature', 'http://cube.csiss.gmu.edu/axis/services/Raster_ProfileCurvature?wsdl', 3),
	(177, 'uuid:urn:b92a08f1-a64e-48e2-b7ee-5506ea43b2bd', 'Raster_ChangeColortable_PredefinedService', 'Raster_ChangeColortable_PredefinedService', '', 'released', NULL, NULL, 1, 0, NULL, NULL, 'SOAPWSDL', 'http://cube.csiss.gmu.edu/axis/services/Raster_ChangeColortable_Predefined', 'http://cube.csiss.gmu.edu/axis/services/Raster_ChangeColortable_Predefined?wsdl', 3);
/*!40000 ALTER TABLE `service` ENABLE KEYS */;


-- Dumping structure for table cyberconnector.users
DROP TABLE IF EXISTS `users`;
CREATE TABLE IF NOT EXISTS `users` (
  `uid` int(10) NOT NULL AUTO_INCREMENT,
  `name` varchar(20) NOT NULL,
  `pswd` text NOT NULL,
  `type` varchar(15) DEFAULT NULL,
  `address` tinytext NOT NULL,
  `fullname` varchar(50) DEFAULT NULL,
  `sex` varchar(6) DEFAULT NULL,
  `last_login_time` timestamp NULL DEFAULT NULL,
  `reg_time` timestamp NULL DEFAULT NULL,
  `last_operate_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `status` varchar(8) DEFAULT NULL,
  `token` varchar(50) DEFAULT NULL,
  `email` varchar(50) DEFAULT NULL,
  `phone` varchar(50) DEFAULT NULL,
  `department` varchar(50) DEFAULT NULL,
  `institute` varchar(50) DEFAULT NULL,
  `last_ip` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`uid`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=latin1;

-- Dumping data for table cyberconnector.users: ~5 rows (approximately)
DELETE FROM `users`;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` (`uid`, `name`, `pswd`, `type`, `address`, `fullname`, `sex`, `last_login_time`, `reg_time`, `last_operate_time`, `status`, `token`, `email`, `phone`, `department`, `institute`, `last_ip`) VALUES
	(1, 'szh', '0313d2b75573087db4319c9a70f71acfb5eab13ae0de69702416691c5bd7d908dcda97913c90977276c4e3e66f5d13ca7250a610cf1aa73669bd059acfd16483', 'null', '', '', NULL, '2017-01-28 01:33:37', NULL, '2018-10-31 17:04:52', 'active', 'null', 'zsun@gmu.edu', 'null', 'null', 'null', 'null'),
	(2, 'test', '769f1de2ae96358f58b955004ea92e7b615ed025980a1930b03523245a011bc6358924ca9ce3d9105b471eb8c8f3e63e8d105043234f8052168e357826a6b195', 'null', '', NULL, NULL, '2017-01-31 17:05:32', NULL, '2018-10-31 17:02:46', 'null', 'null', 'zsun@gmu.edu', 'null', 'null', 'null', 'null'),
	(3, 'Administrator', '0dae5bec74c015b77e0a108e45204e94fe1c7df3e2b10c43c5a17bafd8135d24fa2a367d27ea68b76696a60f5db278d183f805982b927cb84c2d8ed8cd4666d5', '', '123', 'dsfdsafsd', '', '2017-03-20 10:51:30', NULL, '2018-11-26 18:14:51', 'inactive', '', 'szhwhu@gmail.com', '', '2323', '121212', ''),
	(4, 'testuser', '2ee59823400b403921ca5f5347f823a608d20cbc3b4af4f2281a8818bddd22c02925cc668d84a9e234925883f2faa88e42cee851b290af3ae7197b80dcc512d7', '', 'sdf', '', '', '2019-02-18 14:50:04', NULL, '2019-02-27 12:02:43', 'active', '', 'test@gmu.edu', '', 'cola', 'gmu', ''),
	(5, 'sdfsd32434', 'd674344428807e98ff27c119f267705d5ed7cf2caf539d18ec92d65f2e225cb68828bcaca8b78495edc35dbc5a0bd1dda7a3d83edbd28754bb984a17a15b6304', '', 'sdfsad', '', '', '2019-02-26 09:53:58', NULL, '2019-02-26 09:53:58', '', '', 'werweqr@gmail.com', '', 'fdafda', 'fdsfda', '');
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
/*!40014 SET FOREIGN_KEY_CHECKS=1 */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
